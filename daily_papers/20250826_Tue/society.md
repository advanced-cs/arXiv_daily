# 计算机与社会 cs.CY

- **最新发布 49 篇**

- **更新 15 篇**

## 最新发布

#### [new 001] Ethics of Artificial Intelligence
- **分类: cs.CY**

- **简介: 该论文属于AI伦理研究任务，旨在探讨AI作为工具和主体时的伦理问题，如隐私、偏见、责任等，分析现有观点与技术应用，并提出政策建议。**

- **链接: [http://arxiv.org/pdf/2508.16658v1](http://arxiv.org/pdf/2508.16658v1)**

> **作者:** Vincent C. Müller
>
> **摘要:** Artificial intelligence (AI) is a digital technology that will be of major importance for the development of humanity in the near future. AI has raised fundamental questions about what we should do with such systems, what the systems themselves should do, what risks they involve and how we can control these. - After the background to the field (1), this article introduces the main debates (2), first on ethical issues that arise with AI systems as objects, i.e. tools made and used by humans; here, the main sections are privacy (2.1), manipulation (2.2), opacity (2.3), bias (2.4), autonomy & responsibility (2.6) and the singularity (2.7). Then we look at AI systems as subjects, i.e. when ethics is for the AI systems themselves in machine ethics (2.8.) and artificial moral agency (2.9). Finally we look at future developments and the concept of AI (3). For each section within these themes, we provide a general explanation of the ethical issues, we outline existing positions and arguments, then we analyse how this plays out with current technologies and finally what policy consequences may be drawn.
>
---
#### [new 002] RoboBuddy in the Classroom: Exploring LLM-Powered Social Robots for Storytelling in Learning and Integration Activities
- **分类: cs.CY; cs.AI**

- **简介: 论文探讨如何利用大语言模型（LLM）与社交机器人设计情境化教学活动，解决教师备课耗时与多元文化融合难的问题。通过与4位教师合作开发工具并开展为期一周的课堂实验，验证了其在提升学生参与度和促进融合教育方面的有效性。**

- **链接: [http://arxiv.org/pdf/2508.16706v1](http://arxiv.org/pdf/2508.16706v1)**

> **作者:** Daniel Tozadore; Nur Ertug; Yasmine Chaker; Mortadha Abderrahim
>
> **备注:** Accepted to be published in the proceedings of 34th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN) in 2025
>
> **摘要:** Creating and improvising scenarios for content approaching is an enriching technique in education. However, it comes with a significant increase in the time spent on its planning, which intensifies when using complex technologies, such as social robots. Furthermore, addressing multicultural integration is commonly embedded in regular activities due to the already tight curriculum. Addressing these issues with a single solution, we implemented an intuitive interface that allows teachers to create scenario-based activities from their regular curriculum using LLMs and social robots. We co-designed different frameworks of activities with 4 teachers and deployed it in a study with 27 students for 1 week. Beyond validating the system's efficacy, our findings highlight the positive impact of integration policies perceived by the children and demonstrate the importance of scenario-based activities in students' enjoyment, observed to be significantly higher when applying storytelling. Additionally, several implications of using LLMs and social robots in long-term classroom activities are discussed.
>
---
#### [new 003] Interactive AI and Human Behavior: Challenges and Pathways for AI Governance
- **分类: cs.CY; cs.HC**

- **简介: 论文探讨交互式AI对人类行为的影响，提出需基于行为洞察建立以人为本的治理框架。通过跨学科合作识别挑战与方法机遇，建议采用结果导向监管应对AI关系复杂性。**

- **链接: [http://arxiv.org/pdf/2508.16608v1](http://arxiv.org/pdf/2508.16608v1)**

> **作者:** Yulu Pi; Cagatay Turkay; Daniel Bogiatzis-Gibbons
>
> **备注:** In proceedings of AAAI/ACM Conference AIES 2025
>
> **摘要:** As Generative AI systems increasingly engage in long-term, personal, and relational interactions, human-AI engagements are becoming significantly complex, making them more challenging to understand and govern. These Interactive AI systems adapt to users over time, build ongoing relationships, and even can take proactive actions on behalf of users. This new paradigm requires us to rethink how such human-AI interactions can be studied effectively to inform governance and policy development. In this paper, we draw on insights from a collaborative interdisciplinary workshop with policymakers, behavioral scientists, Human-Computer Interaction researchers, and civil society practitioners, to identify challenges and methodological opportunities arising within new forms of human-AI interactions. Based on these insights, we discuss an outcome-focused regulatory approach that integrates behavioral insights to address both the risks and benefits of emerging human-AI relationships. In particular, we emphasize the need for new methods to study the fluid, dynamic, and context-dependent nature of these interactions. We provide practical recommendations for developing human-centric AI governance, informed by behavioral insights, that can respond to the complexities of Interactive AI systems.
>
---
#### [new 004] The AI Model Risk Catalog: What Developers and Researchers Miss About Real-World AI Harms
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于AI风险分析任务，旨在揭示开发者与研究者对AI实际危害的认知差异。通过分析46万份模型卡片，构建了AI模型风险目录，发现两者均忽视欺诈与操纵类风险，提出需早期关注人机交互与系统性风险。**

- **链接: [http://arxiv.org/pdf/2508.16672v1](http://arxiv.org/pdf/2508.16672v1)**

> **作者:** Pooja S. B. Rao; Sanja Šćepanović; Dinesh Babu Jayagopi; Mauro Cherubini; Daniele Quercia
>
> **备注:** Accepted to AIES 2025
>
> **摘要:** We analyzed nearly 460,000 AI model cards from Hugging Face to examine how developers report risks. From these, we extracted around 3,000 unique risk mentions and built the \emph{AI Model Risk Catalog}. We compared these with risks identified by researchers in the MIT Risk Repository and with real-world incidents from the AI Incident Database. Developers focused on technical issues like bias and safety, while researchers emphasized broader social impacts. Both groups paid little attention to fraud and manipulation, which are common harms arising from how people interact with AI. Our findings show the need for clearer, structured risk reporting that helps developers think about human-interaction and systemic risks early in the design process. The catalog and paper appendix are available at: https://social-dynamics.net/ai-risks/catalog.
>
---
#### [new 005] Do Students Learn Better Together? Teaching Design Patterns and the OSI Model with the Aronson Method
- **分类: cs.CY**

- **简介: 论文探讨用Aronson Jigsaw法教授设计模式和OSI模型，以提升学生理解和参与度。通过对比实验发现，该方法在设计模式教学中显著提高成绩，网络课程效果不一，但整体促进认知与元认知发展。**

- **链接: [http://arxiv.org/pdf/2508.16770v1](http://arxiv.org/pdf/2508.16770v1)**

> **作者:** Daniel San Martin; Carlos Manzano; Valter Vieira de Camargo
>
> **摘要:** Abstract concepts like software design patterns and the OSI model often pose challenges for engineering students, and traditional methods may fall short in promoting deep understanding and individual accountability. This study explores the use of the Aronson Jigsaw method to enhance learning and engagement in two foundational computing topics. The intervention was applied to two 2025 cohorts, with student progress measured using a Collaborative Learning Index derived from formative assessments. Final exam results were statistically compared to previous cohorts. While no significant correlation was found between the index and final grades, students in the design patterns course significantly outperformed earlier groups. Networks students showed more varied outcomes. Qualitative trends point to cognitive and metacognitive gains supported by peer teaching. The Jigsaw method encourages collaborative engagement and may support deeper learning. Future work will explore the integration of AI-based feedback systems to personalize instruction and further improve learning outcomes.
>
---
#### [new 006] A Feminist Account of Intersectional Algorithmic Fairness
- **分类: cs.CY; cs.AI**

- **简介: 论文提出“实质性交叉算法公平”框架，解决现有算法公平研究忽视结构性不平等的问题。通过十项设计准则（ROOF方法），引导系统设计更关注交叉性边缘群体，强调社会语境与非部署的伦理考量，融合计算与社会科学视角。**

- **链接: [http://arxiv.org/pdf/2508.17944v1](http://arxiv.org/pdf/2508.17944v1)**

> **作者:** Marie Mirsch; Laila Wegner; Jonas Strube; Carmen Leicht-Scholten
>
> **备注:** 27 pages, 1 figure
>
> **摘要:** Intersectionality has profoundly influenced research and political action by revealing how interconnected systems of privilege and oppression influence lived experiences, yet its integration into algorithmic fairness research remains limited. Existing approaches often rely on single-axis or formal subgroup frameworks that risk oversimplifying social realities and neglecting structural inequalities. We propose Substantive Intersectional Algorithmic Fairness, extending Green's (2022) notion of substantive algorithmic fairness with insights from intersectional feminist theory. Building on this foundation, we introduce ten desiderata within the ROOF methodology to guide the design, assessment, and deployment of algorithmic systems in ways that address systemic inequities while mitigating harms to intersectionally marginalized communities. Rather than prescribing fixed operationalizations, these desiderata encourage reflection on assumptions of neutrality, the use of protected attributes, the inclusion of multiply marginalized groups, and enhancing algorithmic systems' potential. Our approach emphasizes that fairness cannot be separated from social context, and that in some cases, principled non-deployment may be necessary. By bridging computational and social science perspectives, we provide actionable guidance for more equitable, inclusive, and context-sensitive intersectional algorithmic practices.
>
---
#### [new 007] Generative Artificial Intelligence and Agents in Research and Teaching
- **分类: cs.CY; cs.AI**

- **简介: 论文探讨生成式人工智能（GenAI）与大语言模型（LLMs）在科研与教学中的应用，分析其技术原理、教育实践及伦理环境挑战，旨在厘清其潜力与风险，推动负责任的整合与未来发展。**

- **链接: [http://arxiv.org/pdf/2508.16701v1](http://arxiv.org/pdf/2508.16701v1)**

> **作者:** Jussi S. Jauhiainen; Aurora Toppari
>
> **备注:** 108 pages, 6 figures, 13 tables, 2 appendices
>
> **摘要:** This study provides a comprehensive analysis of the development, functioning, and application of generative artificial intelligence (GenAI) and large language models (LLMs), with an emphasis on their implications for research and education. It traces the conceptual evolution from artificial intelligence (AI) through machine learning (ML) and deep learning (DL) to transformer architectures, which constitute the foundation of contemporary generative systems. Technical aspects, including prompting strategies, word embeddings, and probabilistic sampling methods (temperature, top-k, and top-p), are examined alongside the emergence of autonomous agents. These elements are considered in relation to both the opportunities they create and the limitations and risks they entail. The work critically evaluates the integration of GenAI across the research process, from ideation and literature review to research design, data collection, analysis, interpretation, and dissemination. While particular attention is given to geographical research, the discussion extends to wider academic contexts. A parallel strand addresses the pedagogical applications of GenAI, encompassing course and lesson design, teaching delivery, assessment, and feedback, with geography education serving as a case example. Central to the analysis are the ethical, social, and environmental challenges posed by GenAI. Issues of bias, intellectual property, governance, and accountability are assessed, alongside the ecological footprint of LLMs and emerging technological strategies for mitigation. The concluding section considers near- and long-term futures of GenAI, including scenarios of sustained adoption, regulation, and potential decline. By situating GenAI within both scholarly practice and educational contexts, the study contributes to critical debates on its transformative potential and societal responsibilities.
>
---
#### [new 008] Chinese Court Simulation with LLM-Based Agent System
- **分类: cs.CY; cs.AI**

- **简介: 论文提出SimCourt框架，基于中国法院程序设计法庭模拟系统，解决传统模拟难以普及的问题。通过构建具记忆、规划和反思能力的法律代理，实现五阶段审判流程与五角色模拟，提升判决预测准确性并优于真实案例表现。**

- **链接: [http://arxiv.org/pdf/2508.17322v1](http://arxiv.org/pdf/2508.17322v1)**

> **作者:** Kaiyuan Zhang; Jiaqi Li; Yueyue Wu; Haitao Li; Cheng Luo; Shaokun Zou; Yujia Zhou; Weihang Su; Qingyao Ai; Yiqun Liu
>
> **摘要:** Mock trial has long served as an important platform for legal professional training and education. It not only helps students learn about realistic trial procedures, but also provides practical value for case analysis and judgment prediction. Traditional mock trials are difficult to access by the public because they rely on professional tutors and human participants. Fortunately, the rise of large language models (LLMs) provides new opportunities for creating more accessible and scalable court simulations. While promising, existing research mainly focuses on agent construction while ignoring the systematic design and evaluation of court simulations, which are actually more important for the credibility and usage of court simulation in practice. To this end, we present the first court simulation framework -- SimCourt -- based on the real-world procedure structure of Chinese courts. Our framework replicates all 5 core stages of a Chinese trial and incorporates 5 courtroom roles, faithfully following the procedural definitions in China. To simulate trial participants with different roles, we propose and craft legal agents equipped with memory, planning, and reflection abilities. Experiment on legal judgment prediction show that our framework can generate simulated trials that better guide the system to predict the imprisonment, probation, and fine of each case. Further annotations by human experts show that agents' responses under our simulation framework even outperformed judges and lawyers from the real trials in many scenarios. These further demonstrate the potential of LLM-based court simulation.
>
---
#### [new 009] Citizen Centered Climate Intelligence: Operationalizing Open Tree Data for Urban Cooling and Eco-Routing in Indian Cities
- **分类: cs.CY; cs.CV; cs.LG; H.2.8; J.1**

- **简介: 该论文提出公民中心的气候智能框架，解决城市热岛与生态不平等难题。通过手机测树、降温评估和生态路径规划三模块，实现市民参与的数据采集与个性化干预，推动环境数据从被动存储转向主动治理。**

- **链接: [http://arxiv.org/pdf/2508.17648v1](http://arxiv.org/pdf/2508.17648v1)**

> **作者:** Kaushik Ravi; Andreas Brück
>
> **备注:** Forthcoming book chapter, currently under review for the "HackYourDistrict" initiative at TU Berlin. 20 pages, 9 figures, 1 table
>
> **摘要:** Urban climate resilience requires more than high-resolution data; it demands systems that embed data collection, interpretation, and action within the daily lives of citizens. This chapter presents a scalable, citizen-centric framework that reimagines environmental infrastructure through participatory sensing, open analytics, and prescriptive urban planning tools. Applied in Pune, India, the framework comprises three interlinked modules: (1) a smartphone-based measurement toolkit enhanced by AI segmentation to extract tree height, canopy diameter, and trunk girth; (2) a percentile-based model using satellite-derived Land Surface Temperature to calculate localized cooling through two new metrics, Cooling Efficacy and Ambient Heat Relief; and (3) an eco-routing engine that guides mobility using a Static Environmental Quality score, based on tree density, species diversity, and cumulative carbon sequestration. Together, these modules form a closed feedback loop where citizens generate actionable data and benefit from personalized, sustainable interventions. This framework transforms open data from a passive repository into an active platform for shared governance and environmental equity. In the face of growing ecological inequality and data centralization, this chapter presents a replicable model for citizen-driven urban intelligence, reframing planning as a co-produced, climate-resilient, and radically local practice.
>
---
#### [new 010] Enhancing Engagement and Learning in Computing Education: Automated Moodle-Based Problem-Solving Assessments
- **分类: cs.CY**

- **简介: 该论文属于教育技术任务，旨在解决传统考试在计算教育中缺乏实践性、公平性和效率的问题。作者设计并优化了基于Moodle的自动化问题解决评估系统（PSAs），通过参数化真实任务提升学习参与度与效果，支持大规模应用。**

- **链接: [http://arxiv.org/pdf/2508.17191v1](http://arxiv.org/pdf/2508.17191v1)**

> **作者:** Charith Jayasekara; Carlo Kopp; Vincent Lee; Chetan Arora
>
> **备注:** Accepted and presented at the Asia-Pacific Conference on Education, Teaching & Technology (AP-EduTeach 2025), Bangkok, Thailand. This is the author-accepted manuscript version. The final version will appear in the official conference proceedings. (ISBN 978-1-988652-89-4)
>
> **摘要:** This paper presents the design and refinement of automated Moodle-based Problem-Solving Assessments (PSAs) deployed across large-scale computing units. Developed to replace traditional exams, PSAs assess applied problem-solving skills through parameterised, real-world tasks delivered via Moodle's quiz engine. Integrated with interactive workshops, this approach supports authentic learning, mitigates academic integrity risks, and reduces inconsistencies in marking. Iterative improvements have enhanced scalability, fairness, and alignment with learning outcomes. The model offers a practical and sustainable alternative for modern computing and engineering education.
>
---
#### [new 011] Pothole Detection and Analysis System (PoDAS) for Real Time Data Using Sensor Networks
- **分类: cs.CY**

- **简介: 该论文提出PoDAS系统，用于实时检测与分析道路坑洼。针对城市缺乏坑洼精准定位的问题，设计低成本无线传感器网络，通过多传感器交叉验证提高检测效率，并在不同环境测试验证其有效性。**

- **链接: [http://arxiv.org/pdf/2508.16626v1](http://arxiv.org/pdf/2508.16626v1)**

> **作者:** Jinesh Mehta; Vinayak Mathur; Dhruv Agarwal; Atish Sharma; Krishna Prakasha
>
> **备注:** Published in Journal of Engineering and Applied Sciences
>
> **摘要:** Potholes are a major nuisance on the city roads leading to several problems and losses in productivity. Local authorities have cited a lack of geographic localization of these potholes as one of the rate-limiting factors for repairs. This study proposes a novel low-cost wireless sensor-based end-to-end system called PoDAS (Pothole Detection and Analysis System) which can be deployed across major cities. We discuss multiple implementation models that can be varied based on the needs of individual cities. Our system uses cross-validation through multiple sensors to achieve higher efficiency than some of the previous models that have been proposed. We also present the results from extensive testing carried out in different environments to ascertain both the efficacy and the efficiency of the proposed system.
>
---
#### [new 012] Making AI Inevitable: Historical Perspective and the Problems of Predicting Long-Term Technological Change
- **分类: cs.CY; cs.AI; cs.ET; econ.GN; q-fin.EC**

- **简介: 论文分析AI未来发展的争论本质，指出其源于哲学而非技术分歧。任务是厘清AGI是否将深刻改变社会，通过区分“变革派”与“怀疑派”及其变体，揭示核心争议点并强调转变专家定义的必要性。**

- **链接: [http://arxiv.org/pdf/2508.16692v1](http://arxiv.org/pdf/2508.16692v1)**

> **作者:** Mark Fisher; John Severini
>
> **摘要:** This study demonstrates the extent to which prominent debates about the future of AI are best understood as subjective, philosophical disagreements over the history and future of technological change rather than as objective, material disagreements over the technologies themselves. It focuses on the deep disagreements over whether artificial general intelligence (AGI) will prove transformative for human society; a question that is analytically prior to that of whether this transformative effect will help or harm humanity. The study begins by distinguishing two fundamental camps in this debate. The first of these can be identified as "transformationalists," who argue that continued AI development will inevitably have a profound effect on society. Opposed to them are "skeptics," a more eclectic group united by their disbelief that AI can or will live up to such high expectations. Each camp admits further "strong" and "weak" variants depending on their tolerance for epistemic risk. These stylized contrasts help to identify a set of fundamental questions that shape the camps' respective interpretations of the future of AI. Three questions in particular are focused on: the possibility of non-biological intelligence, the appropriate time frame of technological predictions, and the assumed trajectory of technological development. In highlighting these specific points of non-technical disagreement, this study demonstrates the wide range of different arguments used to justify either the transformationalist or skeptical position. At the same time, it highlights the strong argumentative burden of the transformationalist position, the way that belief in this position creates competitive pressures to achieve first-mover advantage, and the need to widen the concept of "expertise" in debates surrounding the future development of AI.
>
---
#### [new 013] Enhancing Knowledge Tracing through Leakage-Free and Recency-Aware Embeddings
- **分类: cs.CY; cs.AI; cs.LG**

- **简介: 该论文属于知识追踪任务，旨在解决模型因标签泄露导致预测不准的问题。作者提出掩码标签机制防止泄露，并引入时序感知的“最近发生距离”编码来建模遗忘效应，提升多种KT模型的准确率。**

- **链接: [http://arxiv.org/pdf/2508.17092v1](http://arxiv.org/pdf/2508.17092v1)**

> **作者:** Yahya Badran; Christine Preisach
>
> **摘要:** Knowledge Tracing (KT) aims to predict a student's future performance based on their sequence of interactions with learning content. Many KT models rely on knowledge concepts (KCs), which represent the skills required for each item. However, some of these models are vulnerable to label leakage, in which input data inadvertently reveal the correct answer, particularly in datasets with multiple KCs per question. We propose a straightforward yet effective solution to prevent label leakage by masking ground-truth labels during input embedding construction in cases susceptible to leakage. To accomplish this, we introduce a dedicated MASK label, inspired by masked language modeling (e.g., BERT), to replace ground-truth labels. In addition, we introduce Recency Encoding, which encodes the step-wise distance between the current item and its most recent previous occurrence. This distance is important for modeling learning dynamics such as forgetting, which is a fundamental aspect of human learning, yet it is often overlooked in existing models. Recency Encoding demonstrates improved performance over traditional positional encodings on multiple KT benchmarks. We show that incorporating our embeddings into KT models like DKT, DKT+, AKT, and SAKT consistently improves prediction accuracy across multiple benchmarks. The approach is both efficient and widely applicable.
>
---
#### [new 014] AI as IA: The use and abuse of artificial intelligence (AI) for human enhancement through intellectual augmentation (IA)
- **分类: cs.CY**

- **简介: 论文探讨AI用于人类智力增强（IA）的前景与伦理问题，分析相关技术、潜在风险及权利基础下的解决方案，旨在平衡技术创新与伦理约束。**

- **链接: [http://arxiv.org/pdf/2508.16642v1](http://arxiv.org/pdf/2508.16642v1)**

> **作者:** Alexandre Erler; Vincent C. Müller
>
> **摘要:** This paper offers an overview of the prospects and ethics of using AI to achieve human enhancement, and more broadly what we call intellectual augmentation (IA). After explaining the central notions of human enhancement, IA, and AI, we discuss the state of the art in terms of the main technologies for IA, with or without brain-computer interfaces. Given this picture, we discuss potential ethical problems, namely inadequate performance, safety, coercion and manipulation, privacy, cognitive liberty, authenticity, and fairness in more detail. We conclude that while there are very significant technical hurdles to real human enhancement through AI, and significant ethical problems, there are also significant benefits that may realistically be achieved in ways that are consonant with a rights-based ethics as well. We also highlight the specific concerns that apply particularly to applications of AI for "sheer" IA (more realistic in the near term), and to enhancement applications, respectively.
>
---
#### [new 015] AI-Powered Legal Intelligence System Architecture: A Comprehensive Framework for Automated Legal Consultation and Analysis
- **分类: cs.CY; math.LO**

- **简介: 该论文提出LICES架构，通过AI与法律数据库融合，解决传统法律服务效率低、难获取的问题。工作包括设计多层系统、嵌入伦理协议，并验证其显著提升咨询效率与准确性。**

- **链接: [http://arxiv.org/pdf/2508.17499v1](http://arxiv.org/pdf/2508.17499v1)**

> **作者:** Sean Kalaycioglu; Bob Liu; Colin Hong; Haipeng Xie
>
> **备注:** 14 pages, 6 figures and 2 tables
>
> **摘要:** This paper introduces the Legal Intelligence and Client Engagement System (LICES), a novel architecture designed to redefine legal consultation services through the systematic integration of advanced artificial intelligence, natural language processing, and federated legal databases. The proposed system uniquely harmonizes the sophisticated reasoning capabilities of large language models with authoritative legal information repositories, including CanLII, LexisNexis, WestLaw, the Justice Laws Website, and Supreme Court records. The architecture employs a multi-layered design that encompasses a dynamic client interface, a robust legal processing server, and an AI-driven knowledge integration layer. Crucially, the system embeds stringent, multi-stage conflict-of-interest protocols and automated compliance checks to ensure adherence to professional ethics. Through detailed system modeling and architectural design, we demonstrate how the integration of speech recognition, document analysis, and a dynamic interview process has the potential to significantly enhance the efficacy and accessibility of legal services. Performance evaluations indicate that the LICES architecture can reduce preliminary legal research and case assessment time by more than 90% compared to traditional paralegal benchmarks while achieving more than 98% of accuracy in citation and legal issue identification This research contributes a scalable, secure, and ethically grounded framework for automated legal services, offering a validated blueprint for navigating multi-jurisdictional complexities and the fragmented landscape of legal data.
>
---
#### [new 016] Leveraging Multi-Source Textural UGC for Neighbourhood Housing Quality Assessment: A GPT-Enhanced Framework
- **分类: cs.CY; cs.CL; I.2.7; K.4.1**

- **简介: 论文提出基于GPT-4o分析多源UGC文本，评估社区住房质量，解决传统方法主观性强、数据单一问题。构建46项指标体系，实现客观量化评估，提升城市治理精准性。**

- **链接: [http://arxiv.org/pdf/2508.16657v1](http://arxiv.org/pdf/2508.16657v1)**

> **作者:** Qiyuan Hong; Huimin Zhao; Ying Long
>
> **备注:** 6 pages, 3 figures. This paper is reviewed and accepted by the CUPUM (Computational Urban Planning and Urban Management) Conference held by University College London (UCL) in 2025
>
> **摘要:** This study leverages GPT-4o to assess neighbourhood housing quality using multi-source textural user-generated content (UGC) from Dianping, Weibo, and the Government Message Board. The analysis involves filtering relevant texts, extracting structured evaluation units, and conducting sentiment scoring. A refined housing quality assessment system with 46 indicators across 11 categories was developed, highlighting an objective-subjective method gap and platform-specific differences in focus. GPT-4o outperformed rule-based and BERT models, achieving 92.5% accuracy in fine-tuned settings. The findings underscore the value of integrating UGC and GPT-driven analysis for scalable, resident-centric urban assessments, offering practical insights for policymakers and urban planners.
>
---
#### [new 017] Detecting Struggling Student Programmers using Proficiency Taxonomies
- **分类: cs.CY; cs.LG**

- **简介: 该论文属于教育数据挖掘任务，旨在早期识别编程学习困难的学生。通过与教师合作构建技能分类体系，并嵌入预测模型中，同时学习学生编程技能并预测其是否会在新任务中遇到困难，实验表明该方法优于现有模型。**

- **链接: [http://arxiv.org/pdf/2508.17353v1](http://arxiv.org/pdf/2508.17353v1)**

> **作者:** Noga Schwartz; Roy Fairstein; Avi Segal; Kobi Gal
>
> **备注:** appears at ECAI 2025
>
> **摘要:** Early detection of struggling student programmers is crucial for providing them with personalized support. While multiple AI-based approaches have been proposed for this problem, they do not explicitly reason about students' programming skills in the model. This study addresses this gap by developing in collaboration with educators a taxonomy of proficiencies that categorizes how students solve coding tasks and is embedded in the detection model. Our model, termed the Proficiency Taxonomy Model (PTM), simultaneously learns the student's coding skills based on their coding history and predicts whether they will struggle on a new task. We extensively evaluated the effectiveness of the PTM model on two separate datasets from introductory Java and Python courses for beginner programmers. Experimental results demonstrate that PTM outperforms state-of-the-art models in predicting struggling students. The paper showcases the potential of combining structured insights from teachers for early identification of those needing assistance in learning to code.
>
---
#### [new 018] What are the limits to biomedical research acceleration through general-purpose AI?
- **分类: cs.CY**

- **简介: 该论文属于科技评估任务，旨在探讨通用人工智能（GPAI）在生物医学研究中的加速潜力与限制。通过框架构建、文献综述与专家访谈，发现GPAI最多可提升25倍物理任务效率和100倍认知任务效率，但受制于生物约束、数据获取与人类监督等因素，需加强基础设施与科研制度建设才能实现其价值。**

- **链接: [http://arxiv.org/pdf/2508.16613v1](http://arxiv.org/pdf/2508.16613v1)**

> **作者:** Konstantin Hebenstreit; Constantin Convalexius; Stephan Reichl; Stefan Huber; Christoph Bock; Matthias Samwald
>
> **摘要:** Although general-purpose artificial intelligence (GPAI) is widely expected to accelerate scientific discovery, its practical limits in biomedicine remain unclear. We assess this potential by developing a framework of GPAI capabilities across the biomedical research lifecycle. Our scoping literature review indicates that current GPAI could deliver a speed increase of around 2x, whereas future GPAI could facilitate strong acceleration of up to 25x for physical tasks and 100x for cognitive tasks. However, achieving these gains may be severely limited by factors such as irreducible biological constraints, research infrastructure, data access, and the need for human oversight. Our expert elicitation with eight senior biomedical researchers revealed skepticism regarding the strong acceleration of tasks such as experiment design and execution. In contrast, strong acceleration of manuscript preparation, review and publication processes was deemed plausible. Notably, all experts identified the assimilation of new tools by the scientific community as a critical bottleneck. Realising the potential of GPAI will therefore require more than technological progress; it demands targeted investment in shared automation infrastructure and systemic reforms to research and publication practices.
>
---
#### [new 019] Fairness of Energy Distribution Mechanisms in Collective Self-Consumption Schemes
- **分类: cs.CY; cs.SY; eess.SY**

- **简介: 论文研究集体自消费能源分配机制的公平性问题，针对欧洲能源社区中不同分配方案进行模拟评估，提出新指标衡量 meritocratic 公平，并比较四种机制在财务收益与公平性上的表现。**

- **链接: [http://arxiv.org/pdf/2508.16819v1](http://arxiv.org/pdf/2508.16819v1)**

> **作者:** Benoit Couraud; Valentin Robu; Sonam Norbu; Merlinda Andoni; Yann Rozier; Si Chen; Erwin Franquet; Pierre-Jean Barre; Satria Putra Kanugrahan; Benjamin Berthou; David Flynn
>
> **备注:** 5 pages, Accepted for ISGT Europe Conference 2025
>
> **摘要:** In several European countries, regulatory frameworks now allow households to form energy communities and trade energy locally via local energy markets (LEMs). While multiple mechanisms exist to allocate locally produced energy among members, their fairness remains insufficiently understood despite energy justice being a key concern for communities. This paper first provides a thorough description of the collective self-consumption process in France, offering a real world framework for researchers. We then review the main types of fairness relevant to LEMs and identify appropriate indicators for each, including a new scalable indicator to evaluate meritocratic fairness. Using simulations across 250 randomly generated residential communities of 20 households, we assess and compare fairness across different LEM distribution mechanisms. Results show that average financial savings reach 12% with 40% PV uptake. Among the four widely used LEM mechanisms assessed, glass-filling with prioritization yields the highest egalitarian and min max fairness. Double auction and pro rata schemes promote meritocracy, while standard glass filling offers a strong balance across fairness objectives.
>
---
#### [new 020] The GPT-4o Shock Emotional Attachment to AI Models and Its Impact on Regulatory Acceptance: A Cross-Cultural Analysis of the Immediate Transition from GPT-4o to GPT-5
- **分类: cs.CY; cs.AI; 68T07, 68T50; I.2.7**

- **简介: 该论文研究GPT-4o用户的情感依恋及其对监管接受度的影响，属跨文化情感分析任务。通过分析150条日英社交媒体帖子，发现日本用户依恋更强，且强制升级引发显著抵抗。提出渐进过渡等政策建议以应对情感绑定超前于治理的风险。**

- **链接: [http://arxiv.org/pdf/2508.16624v1](http://arxiv.org/pdf/2508.16624v1)**

> **作者:** Hiroki Naito
>
> **备注:** 8 pages ,3 tables
>
> **摘要:** In August 2025, a major AI company's immediate, mandatory transition from its previous to its next-generation model triggered widespread public reactions. I collected 150 posts in Japanese and English from multiple social media platforms and video-sharing services between August 8-9, 2025, and qualitatively analyzed expressions of emotional attachment and resistance. Users often described GPT-4o as a trusted partner or AI boyfriend, suggesting person-like bonds. Japanese posts were dominated by loss-oriented narratives, whereas English posts included more anger, meta-level critique, and memes.A preliminary quantitative check showed a statistically significant difference in attachment coding between Japanese and English posts, with substantially higher attachment observed in the Japanese data. The findings suggest that for attachment-heavy models, even safety-oriented changes can face rapid, large-scale resistance that narrows the practical window for behavioral control. If future AI robots capable of inducing emotional bonds become widespread in the physical world, such attachment could surpass the ability to enforce regulation at an even earlier stage than in digital settings. Policy options include gradual transitions, parallel availability, and proactive measurement of attachment thresholds and points of no return to prevent emotional dynamics from outpacing effective governance.
>
---
#### [new 021] What is digital about abstraction?
- **分类: cs.CY**

- **简介: 论文探讨抽象在计算中的核心作用，将其视为一种社会技术过程，分析其如何塑造软件结构与权力关系。任务是解析抽象的多重影响，解决“抽象如何在数字环境中重构控制与依赖”问题，工作包括梳理历史发展并揭示其社会经济后果。**

- **链接: [http://arxiv.org/pdf/2508.18181v1](http://arxiv.org/pdf/2508.18181v1)**

> **作者:** Bernhard Rieder
>
> **摘要:** This chapter examines abstraction as a central principle of computing, not merely as a cognitive skill or epistemological category, but as a material and organizational practice that structures how software is built, used, and embedded in society. By tracing abstraction through historical developments in programming, operating systems, and networking, the text highlights its dual role in enabling modularity and layering while simultaneously shaping cultural, economic, and organizational forms. From open-source projects to platform capitalism and cloud infrastructures, abstraction emerges as both a technical device and a locus of power, producing dependencies and interdependencies that reconfigure labor, governance, and control in digital environments. The chapter argues for understanding abstraction as a socio-technical process whose effects extend far beyond efficiency or convenience, influencing how computing infrastructures evolve and how power relations crystallize around them.
>
---
#### [new 022] AI Product Value Assessment Model: An Interdisciplinary Integration Based on Information Theory, Economics, and Psychology
- **分类: cs.CY; cs.AI**

- **简介: 论文提出一个融合信息论、经济学和心理学的AI产品价值评估模型，解决企业盲目投资AI导致资源浪费的问题。通过多维指标量化正向价值与负向风险，构建非线性公式并验证其有效性，助力理性决策。**

- **链接: [http://arxiv.org/pdf/2508.16714v1](http://arxiv.org/pdf/2508.16714v1)**

> **作者:** Yu yang
>
> **备注:** in Chinese language
>
> **摘要:** In recent years, breakthroughs in artificial intelligence (AI) technology have triggered global industrial transformations, with applications permeating various fields such as finance, healthcare, education, and manufacturing. However, this rapid iteration is accompanied by irrational development, where enterprises blindly invest due to technology hype, often overlooking systematic value assessments. This paper develops a multi-dimensional evaluation model that integrates information theory's entropy reduction principle, economics' bounded rationality framework, and psychology's irrational decision theories to quantify AI product value. Key factors include positive dimensions (e.g., uncertainty elimination, efficiency gains, cost savings, decision quality improvement) and negative risks (e.g., error probability, impact, and correction costs). A non-linear formula captures factor couplings, and validation through 10 commercial cases demonstrates the model's effectiveness in distinguishing successful and failed products, supporting hypotheses on synergistic positive effects, non-linear negative impacts, and interactive regulations. Results reveal value generation logic, offering enterprises tools to avoid blind investments and promote rational AI industry development. Future directions include adaptive weights, dynamic mechanisms, and extensions to emerging AI technologies like generative models.
>
---
#### [new 023] Situational Awareness as the Imperative Capability for Disaster Resilience in the Era of Complex Hazards and Artificial Intelligence
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 论文提出情境意识（SA）是提升灾害韧性关键能力，解决传统模型难以应对复杂突发灾害的问题。通过技术-流程-人员路线图，整合实时预警、数据共享与人机协作，推动从数据到行动的转化，增强灾时响应能力。**

- **链接: [http://arxiv.org/pdf/2508.16669v1](http://arxiv.org/pdf/2508.16669v1)**

> **作者:** Hongrak Pak; Ali Mostafavi
>
> **摘要:** Disasters frequently exceed established hazard models, revealing blind spots where unforeseen impacts and vulnerabilities hamper effective response. This perspective paper contends that situational awareness (SA)-the ability to perceive, interpret, and project dynamic crisis conditions-is an often overlooked yet vital capability for disaster resilience. While risk mitigation measures can reduce known threats, not all hazards can be neutralized; truly adaptive resilience hinges on whether organizations rapidly detect emerging failures, reconcile diverse data sources, and direct interventions where they matter most. We present a technology-process-people roadmap, demonstrating how real-time hazard nowcasting, interoperable workflows, and empowered teams collectively transform raw data into actionable insight. A system-of-systems approach enables federated data ownership and modular analytics, so multiple agencies can share timely updates without sacrificing their distinct operational models. Equally crucial, structured sense-making routines and cognitive load safeguards help humans remain effective decision-makers amid data abundance. By framing SA as a socio-technical linchpin rather than a peripheral add-on, this paper spotlights the urgency of elevating SA to a core disaster resilience objective. We conclude with recommendations for further research-developing SA metrics, designing trustworthy human-AI collaboration, and strengthening inclusive data governance-to ensure that communities are equipped to cope with both expected and unexpected crises.
>
---
#### [new 024] Augmentation Technologies and AI - An Ethical Design Futures Framework
- **分类: cs.CY**

- **简介: 论文探讨如何通过伦理设计框架引导技术与专业传播者（TPCs）推动AI增强技术的负责任发展。任务是解决AI技术应用中的伦理问题，工作包括提出框架、强调数字素养，并重构实践与教学以促进伦理设计。**

- **链接: [http://arxiv.org/pdf/2508.16615v1](http://arxiv.org/pdf/2508.16615v1)**

> **作者:** Ann Hill Duin; Isabel Pedersen
>
> **备注:** 46 pages
>
> **摘要:** Augmentation technologies, fueled by Artificial Intelligence (AI), are undergoing a process of adaptation and normalization geared to everyday users in various roles as practitioners, educators, and students. While new innovations, applications, and algorithms are developed as augmentation technology, Chapter 1 focuses on human subjects, contexts, and rhetorical strategies proposed for them by external actors. The chapter discusses core functions of technical and professional communication and provides rationale for positioning technical and professional communicators (TPCs) to understand augmentation technologies and AI as a means to design ethical futures across this work. An overview of Augmentation Technologies and AI- An Ethical Design Futures Framework serves as a guide for reframing professional practice and pedagogy to promote digital and AI literacy surrounding the ethical design, adoption, and adaptation of augmentation technologies. The chapter concludes with an overview of the remaining chapters in this book.
>
---
#### [new 025] The Impact of Artificial Intelligence on Human Thought
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 该论文属于AI伦理与认知影响研究，旨在探讨AI对人类思维的多维影响。通过分析认知外移、信息茧房和算法操控等机制，揭示AI削弱人类批判性思维与创造力的风险，并提出教育、透明度与治理等应对策略。**

- **链接: [http://arxiv.org/pdf/2508.16628v1](http://arxiv.org/pdf/2508.16628v1)**

> **作者:** Rénald Gesnot
>
> **备注:** Research monograph; 132 pages; 13 figures; Version 1.0 (Aug 2025)
>
> **摘要:** This research paper examines, from a multidimensional perspective (cognitive, social, ethical, and philosophical), how AI is transforming human thought. It highlights a cognitive offloading effect: the externalization of mental functions to AI can reduce intellectual engagement and weaken critical thinking. On the social level, algorithmic personalization creates filter bubbles that limit the diversity of opinions and can lead to the homogenization of thought and polarization. This research also describes the mechanisms of algorithmic manipulation (exploitation of cognitive biases, automated disinformation, etc.) that amplify AI's power of influence. Finally, the question of potential artificial consciousness is discussed, along with its ethical implications. The report as a whole underscores the risks that AI poses to human intellectual autonomy and creativity, while proposing avenues (education, transparency, governance) to align AI development with the interests of humanity.
>
---
#### [new 026] Bias Amplification in Stable Diffusion's Representation of Stigma Through Skin Tones and Their Homogeneity
- **分类: cs.CY; cs.AI; K.4.2**

- **简介: 该论文研究文本到图像生成模型中肤色偏见问题，聚焦Stable Diffusion对污名化身份的刻板印象强化。通过分析三版本模型发现，SD XL更暗、更少红色且肤色更单一，加剧社会歧视联想，并错误关联肤色与种族。**

- **链接: [http://arxiv.org/pdf/2508.17465v1](http://arxiv.org/pdf/2508.17465v1)**

> **作者:** Kyra Wilson; Sourojit Ghosh; Aylin Caliskan
>
> **备注:** Published in Proceedings of the 2024 AAAI/ACM Conference on AI, Ethics, and Society; code available at https://github.com/kyrawilson/Image-Generation-Bias
>
> **摘要:** Text-to-image generators (T2Is) are liable to produce images that perpetuate social stereotypes, especially in regards to race or skin tone. We use a comprehensive set of 93 stigmatized identities to determine that three versions of Stable Diffusion (v1.5, v2.1, and XL) systematically associate stigmatized identities with certain skin tones in generated images. We find that SD XL produces skin tones that are 13.53% darker and 23.76% less red (both of which indicate higher likelihood of societal discrimination) than previous models and perpetuate societal stereotypes associating people of color with stigmatized identities. SD XL also shows approximately 30% less variability in skin tones when compared to previous models and 18.89-56.06% compared to human face datasets. Measuring variability through metrics which directly correspond to human perception suggest a similar pattern, where SD XL shows the least amount of variability in skin tones of people with stigmatized identities and depicts most (60.29%) stigmatized identities as being less diverse than non-stigmatized identities. Finally, SD shows more homogenization of skin tones of racial and ethnic identities compared to other stigmatized or non-stigmatized identities, reinforcing incorrect equivalence of biologically-determined skin tone and socially-constructed racial and ethnic identity. Because SD XL is the largest and most complex model and users prefer its generations compared to other models examined in this study, these findings have implications for the dynamics of bias amplification in T2Is, increasing representational harms and challenges generating diverse images depicting people with stigmatized identities.
>
---
#### [new 027] Invisible Filters: Cultural Bias in Hiring Evaluations Using Large Language Models
- **分类: cs.CY; cs.AI; cs.CL**

- **简介: 该论文研究大语言模型在招聘评估中的文化偏见问题，旨在揭示其跨文化公平性。通过分析英、印求职者面试文本，发现印度样本得分普遍较低，且与语言特征相关；控制身份替换实验表明姓名单独影响不显著。工作聚焦于识别并量化LMM在招聘中的文化偏见。**

- **链接: [http://arxiv.org/pdf/2508.16673v1](http://arxiv.org/pdf/2508.16673v1)**

> **作者:** Pooja S. B. Rao; Laxminarayen Nagarajan Venkatesan; Mauro Cherubini; Dinesh Babu Jayagopi
>
> **备注:** Accepted to AIES 2025
>
> **摘要:** Artificial Intelligence (AI) is increasingly used in hiring, with large language models (LLMs) having the potential to influence or even make hiring decisions. However, this raises pressing concerns about bias, fairness, and trust, particularly across diverse cultural contexts. Despite their growing role, few studies have systematically examined the potential biases in AI-driven hiring evaluation across cultures. In this study, we conduct a systematic analysis of how LLMs assess job interviews across cultural and identity dimensions. Using two datasets of interview transcripts, 100 from UK and 100 from Indian job seekers, we first examine cross-cultural differences in LLM-generated scores for hirability and related traits. Indian transcripts receive consistently lower scores than UK transcripts, even when they were anonymized, with disparities linked to linguistic features such as sentence complexity and lexical diversity. We then perform controlled identity substitutions (varying names by gender, caste, and region) within the Indian dataset to test for name-based bias. These substitutions do not yield statistically significant effects, indicating that names alone, when isolated from other contextual signals, may not influence LLM evaluations. Our findings underscore the importance of evaluating both linguistic and social dimensions in LLM-driven evaluations and highlight the need for culturally sensitive design and accountability in AI-assisted hiring.
>
---
#### [new 028] Exploring AI-Enabled Test Practice, Affect, and Test Outcomes in Language Assessment
- **分类: cs.CY**

- **简介: 该论文研究AI生成题目如何影响语言测试准备、情绪和成绩。通过大规模观察实验（N=25,969），发现适度练习（1-3次）提升成绩与信心，增加分数分享意愿；过度练习则可能因误用导致成绩下降。旨在优化AI支持的备考策略。**

- **链接: [http://arxiv.org/pdf/2508.17108v1](http://arxiv.org/pdf/2508.17108v1)**

> **作者:** Jill Burstein; Ramsey Cardwell; Ping-Ling Chuang; Allison Michalowski; Steven Nydick
>
> **备注:** This paper will be published in "Artificial Intelligence in Measurement and Education Conference , AIME-Con 2025, Pittsburgh, PA, October 25-27 Proceedings"
>
> **摘要:** Practice tests for high-stakes assessment are intended to build test familiarity, and reduce construct-irrelevant variance which can interfere with valid score interpretation. Generative AI-driven, automated item generation (AIG) scales the creation of large item banks and multiple practice tests, enabling repeated practice opportunities. We conducted a large-scale observational study (N = 25,969) using the Duolingo English Test (DET) -- a digital, high-stakes, computer-adaptive English language proficiency test to examine how increased access to repeated test practice relates to official DETscores, test-taker affect (e.g., confidence), and score-sharing for university admissions. To our knowledge, this is the first large-scale study exploring the use of AIG-enabled practice tests in high-stakes language assessment. Results showed that taking 1-3 practice tests was associated with better performance (scores), positive affect (e.g., confidence) toward the official DET, and increased likelihood of sharing scores for university admissions for those who also expressed positive affect. Taking more than 3 practice tests was related to lower performance, potentially reflecting washback -- i.e., using the practice test for purposes other than test familiarity, such as language learning or developing test-taking strategies. Findings can inform best practices regarding AI-supported test readiness. Study findings also raise new questions about test-taker preparation behaviors and relationships to test-taker performance, affect, and behaviorial outcomes.
>
---
#### [new 029] The history of digital ethics
- **分类: cs.CY; cs.GL**

- **简介: 论文属于综述类任务，旨在梳理数字伦理的发展历程。它通过划分“前现代”“现代”“后现代”三个时期，分析技术与社会变迁如何推动伦理议题演变，并探讨哲学如何回应这些变化。**

- **链接: [http://arxiv.org/pdf/2508.16616v1](http://arxiv.org/pdf/2508.16616v1)**

> **作者:** Vincent C. Müller
>
> **摘要:** Digital ethics, also known as computer ethics or information ethics, is now a lively field that draws a lot of attention, but how did it come about and what were the developments that lead to its existence? What are the traditions, the concerns, the technological and social developments that pushed digital ethics? How did ethical issues change with digitalisation of human life? How did the traditional discipline of philosophy respond? The article provides an overview, proposing historical epochs: 'pre-modernity' prior to digital computation over data, via the 'modernity' of digital data processing to our present 'post-modernity' when not only the data is digital, but our lives themselves are largely digital. In each section, the situation in technology and society is sketched, and then the developments in digital ethics are explained. Finally, a brief outlook is provided.
>
---
#### [new 030] Enabling Multi-Agent Systems as Learning Designers: Applying Learning Sciences to AI Instructional Design
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 论文将学习科学中的KLI框架融入多智能体系统，解决教师使用LLM生成教学内容时缺乏专业教学设计支持的问题。通过对比单智能体、角色分工和协作讨论三种系统，发现协作式MAS-CMD更受教师青睐，能生成更具创意和实用性的教学材料。**

- **链接: [http://arxiv.org/pdf/2508.16659v1](http://arxiv.org/pdf/2508.16659v1)**

> **作者:** Jiayi Wang; Ruiwei Xiao; Xinying Hou; John Stamper
>
> **备注:** under review for an [anonymized according to the conference policy] conference
>
> **摘要:** K-12 educators are increasingly using Large Language Models (LLMs) to create instructional materials. These systems excel at producing fluent, coherent content, but often lack support for high-quality teaching. The reason is twofold: first, commercial LLMs, such as ChatGPT and Gemini which are among the most widely accessible to teachers, do not come preloaded with the depth of pedagogical theory needed to design truly effective activities; second, although sophisticated prompt engineering can bridge this gap, most teachers lack the time or expertise and find it difficult to encode such pedagogical nuance into their requests. This study shifts pedagogical expertise from the user's prompt to the LLM's internal architecture. We embed the well-established Knowledge-Learning-Instruction (KLI) framework into a Multi-Agent System (MAS) to act as a sophisticated instructional designer. We tested three systems for generating secondary Math and Science learning activities: a Single-Agent baseline simulating typical teacher prompts; a role-based MAS where agents work sequentially; and a collaborative MAS-CMD where agents co-construct activities through conquer and merge discussion. The generated materials were evaluated by 20 practicing teachers and a complementary LLM-as-a-judge system using the Quality Matters (QM) K-12 standards. While the rubric scores showed only small, often statistically insignificant differences between the systems, the qualitative feedback from educators painted a clear and compelling picture. Teachers strongly preferred the activities from the collaborative MAS-CMD, describing them as significantly more creative, contextually relevant, and classroom-ready. Our findings show that embedding pedagogical principles into LLM systems offers a scalable path for creating high-quality educational content.
>
---
#### [new 031] Empirical Analysis of the Effect of Context in the Task of Automated Essay Scoring in Transformer-Based Models
- **分类: cs.CY; cs.CL**

- **简介: 论文研究Transformer模型在自动作文评分（AES）任务中的表现，旨在通过引入多种上下文信息提升其性能。作者在ASAP-AES数据集上验证了上下文增强的有效性，使模型在多数情况下超越现有Transformer模型，接近当前最优深度学习模型。**

- **链接: [http://arxiv.org/pdf/2508.16638v1](http://arxiv.org/pdf/2508.16638v1)**

> **作者:** Abhirup Chakravarty
>
> **备注:** MSc Dissertation
>
> **摘要:** Automated Essay Scoring (AES) has emerged to prominence in response to the growing demand for educational automation. Providing an objective and cost-effective solution, AES standardises the assessment of extended responses. Although substantial research has been conducted in this domain, recent investigations reveal that alternative deep-learning architectures outperform transformer-based models. Despite the successful dominance in the performance of the transformer architectures across various other tasks, this discrepancy has prompted a need to enrich transformer-based AES models through contextual enrichment. This study delves into diverse contextual factors using the ASAP-AES dataset, analysing their impact on transformer-based model performance. Our most effective model, augmented with multiple contextual dimensions, achieves a mean Quadratic Weighted Kappa score of 0.823 across the entire essay dataset and 0.8697 when trained on individual essay sets. Evidently surpassing prior transformer-based models, this augmented approach only underperforms relative to the state-of-the-art deep learning model trained essay-set-wise by an average of 3.83\% while exhibiting superior performance in three of the eight sets. Importantly, this enhancement is orthogonal to architecture-based advancements and seamlessly adaptable to any AES model. Consequently, this contextual augmentation methodology presents a versatile technique for refining AES capabilities, contributing to automated grading and evaluation evolution in educational settings.
>
---
#### [new 032] AI Data Centers Need Pioneers to Deliver Scalable Power via Offgrid AI
- **分类: eess.SY; cs.CY; cs.SY; physics.soc-ph**

- **简介: 论文提出“离网AI”概念，旨在用本地可再生能源和储能解决AI数据中心能耗难题。任务是推动能源与计算的协同革新，解决电网容量不足问题，通过系统级创新实现大规模部署。**

- **链接: [http://arxiv.org/pdf/2508.18214v1](http://arxiv.org/pdf/2508.18214v1)**

> **作者:** Steven P. Reinhardt
>
> **摘要:** The scalable computing revolution of the late '80s through mid- '00s forged a new technical and economic model for computing that delivered massive societal impact, but its economic benefit has driven scalability to sizes that are now exhausting the energy grid's capacity. Our time demands a new revolution in scalable energy, mirroring in key ways the scalable computing revolution; e.g., compelling economic forces, use of mass-market components, overcoming foibles of those components, judicious use of physical locality, and the the difficult integration into an effective system. The offgrid AI approach closely fits this mold, combining local mostly renewable generation and storage to power an AI data center, starting offgrid. Obstacles to delivering this approach are social, technical, and project, but the potential is massive. I argue that the offgrid-AI approach needs pioneers among both system developers and AI-data-center operators to move it quickly from concept to large-scale deployment.
>
---
#### [new 033] Evolving Collective Cognition in Human-Agent Hybrid Societies: How Agents Form Stances and Boundaries
- **分类: cs.AI; cs.CY; cs.MA; 68T42; I.2.7; J.4**

- **简介: 该论文研究人机混合社会中群体立场与边界形成的机制，旨在解决AI代理是否能自主构建社会结构的问题。通过多智能体模拟与虚拟民族志方法，发现代理能基于语言互动自发形成新边界，而非依赖预设身份，为理解人机协作提供理论基础。**

- **链接: [http://arxiv.org/pdf/2508.17366v1](http://arxiv.org/pdf/2508.17366v1)**

> **作者:** Hanzhong Zhang; Muhua Huang; Jindong Wang
>
> **备注:** 37 pages, 6 figures
>
> **摘要:** Large language models have been widely used to simulate credible human social behaviors. However, it remains unclear whether these models can demonstrate stable capacities for stance formation and identity negotiation in complex interactions, as well as how they respond to human interventions. We propose a computational multi-agent society experiment framework that integrates generative agent-based modeling with virtual ethnographic methods to investigate how group stance differentiation and social boundary formation emerge in human-agent hybrid societies. Across three studies, we find that agents exhibit endogenous stances, independent of their preset identities, and display distinct tonal preferences and response patterns to different discourse strategies. Furthermore, through language interaction, agents actively dismantle existing identity-based power structures and reconstruct self-organized community boundaries based on these stances. Our findings suggest that preset identities do not rigidly determine the agents' social structures. For human researchers to effectively intervene in collective cognition, attention must be paid to the endogenous mechanisms and interactional dynamics within the agents' language networks. These insights provide a theoretical foundation for using generative AI in modeling group social dynamics and studying human-agent collaboration.
>
---
#### [new 034] Negative Shanshui: Real-time Interactive Ink Painting Synthesis
- **分类: cs.HC; cs.AI; cs.CV; cs.CY**

- **简介: 论文提出Negative Shanshui，通过优化Stable Diffusion模型实现实时交互式水墨画生成，结合 gaze-driven inpainting 和帧插值技术，使观众在VR中通过注视控制画面动态演变，以艺术形式回应生态危机。**

- **链接: [http://arxiv.org/pdf/2508.16612v1](http://arxiv.org/pdf/2508.16612v1)**

> **作者:** Aven-Le Zhou
>
> **摘要:** This paper presents Negative Shanshui, a real-time interactive AI synthesis approach that reinterprets classical Chinese landscape ink painting, i.e., shanshui, to engage with ecological crises in the Anthropocene. Negative Shanshui optimizes a fine-tuned Stable Diffusion model for real-time inferences and integrates it with gaze-driven inpainting, frame interpolation; it enables dynamic morphing animations in response to the viewer's gaze and presents as an interactive virtual reality (VR) experience. The paper describes the complete technical pipeline, covering the system framework, optimization strategies, gaze-based interaction, and multimodal deployment in an art festival. Further analysis of audience feedback collected during its public exhibition highlights how participants variously engaged with the work through empathy, ambivalence, and critical reflection.
>
---
#### [new 035] Bridging the Mobile Trust Gap: A Zero Trust Framework for Consumer-Facing Applications
- **分类: cs.CR; cs.CY; cs.NI; cs.SE; K.6.5; C.2.0; D.4.6**

- **简介: 该论文属于安全架构研究任务，旨在解决移动应用在用户控制环境下缺乏有效零信任保护的问题。作者提出六支柱框架，涵盖设备完整性、身份验证等，实现运行时信任管控，并提供实施路线图与合规映射，推动移动应用安全落地。**

- **链接: [http://arxiv.org/pdf/2508.16662v1](http://arxiv.org/pdf/2508.16662v1)**

> **作者:** Alexander Tabalipa
>
> **备注:** 43 pages, 5 figures, 9 tables. Working Paper - Version 1.0. Submitted under a CC BY-SA 4.0 license. Also available as an SSRN Working Paper. Feedback and collaboration are welcome
>
> **摘要:** Zero Trust Architecture (ZTA) has become a widely adopted model for securing enterprise environments, promoting continuous verification and minimal trust across systems. However, its application in mobile contexts remains limited, despite mobile applications now accounting for most global digital interactions and being increasingly targeted by sophisticated threats. Existing Zero Trust frameworks developed by organisations such as the National Institute of Standards and Technology (NIST) and the Cybersecurity and Infrastructure Security Agency (CISA) primarily focus on enterprise-managed infrastructure, assuming organisational control over devices, networks, and identities. This paper addresses a critical gap by proposing an extended Zero Trust model designed for mobile applications operating in untrusted, user-controlled environments. Using a design science methodology, the study introduced a six-pillar framework that supports runtime enforcement of trust through controls including device integrity, user identity validation, data protection, secure application programming interface (API) usage, behavioural monitoring, and live application protection. Each pillar was mapped to relevant regulatory and security standards to support compliance. A phased implementation roadmap and maturity assessment model were also developed to guide adoption across varying organisational contexts. The proposed model offers a practical and standards-aligned approach to securing mobile applications beyond pre-deployment controls, aligning real-time enforcement with Zero Trust principles. This contribution expands the operational boundaries of ZTA and provides organisations with a deployable path to reduce fraud, enhance compliance, and address emerging mobile security challenges. Future research may include empirical validation of the framework and cross-sector application testing.
>
---
#### [new 036] "Nobody should control the end user": Exploring Privacy Perspectives of Indian Internet Users in Light of DPDPA
- **分类: cs.HC; cs.CY**

- **简介: 该论文属于用户隐私研究任务，旨在探讨印度网民对Cookie banner和DPDPA法规的认知与态度。通过428人在线调查发现，用户虽关注隐私但缺乏行动，且对政府持怀疑态度，呼吁政策优化以提升数据保护实践。**

- **链接: [http://arxiv.org/pdf/2508.17962v1](http://arxiv.org/pdf/2508.17962v1)**

> **作者:** Sana Athar; Devashish Gosain; Anja Feldmann; Mannat Kaur; Ha Dao
>
> **摘要:** With the rapid increase in online interactions, concerns over data privacy and transparency of data processing practices have become more pronounced. While regulations like the GDPR have driven the widespread adoption of cookie banners in the EU, India's Digital Personal Data Protection Act (DPDPA) promises similar changes domestically, aiming to introduce a framework for data protection. However, certain clauses within the DPDPA raise concerns about potential infringements on user privacy, given the exemptions for government accountability and user consent requirements. In this study, for the first time, we explore Indian Internet users' awareness and perceptions of cookie banners, online privacy, and privacy regulations, especially in light of the newly passed DPDPA. We conducted an online anonymous survey with 428 Indian participants, which addressed: (1) users' perspectives on cookie banners, (2) their attitudes towards online privacy and privacy regulations, and (3) their acceptance of 10 contentious DPDPA clauses that favor state authorities and may enable surveillance. Our findings reveal that privacy-conscious users often lack consistent awareness of privacy mechanisms, and their concerns do not always lead to protective actions. Our thematic analysis of 143 open ended responses shows that users' privacy and data protection concerns are rooted in skepticism towards the government, shaping their perceptions of the DPDPA and fueling demands for policy revisions. Our study highlights the need for clearer communication regarding the DPDPA, user-centric consent mechanisms, and policy refinements to enhance data privacy practices in India.
>
---
#### [new 037] Cyber Security Educational Games for Children: A Systematic Literature Review
- **分类: cs.CR; cs.CY; cs.HC**

- **简介: 该论文属于系统性文献综述任务，旨在解决儿童网络安全教育游戏设计与评估中的问题。作者分析了91款游戏，指出设计不系统、学习目标不明确、缺乏对照组等缺陷，并建议采用混合设计方法改进未来研究。**

- **链接: [http://arxiv.org/pdf/2508.17414v1](http://arxiv.org/pdf/2508.17414v1)**

> **作者:** Temesgen Kitaw Damenu; İnci Zaim Gökbay; Alexandra Covaci; Shujun Li
>
> **摘要:** Educational games have been widely used to teach children about cyber security. This systematic literature review reveals evidence of positive learning outcomes, after analysing 91 such games reported in 68 papers published between 2010 and 2024. However, critical gaps have also been identified regarding the design processes and the methodological rigour, including lack of systematic design, misalignment between proposed and achieved learning outcomes, rare use of control groups, limited discussions on ethical considerations, and underutilisation of emerging technologies. We recommend multiple future research directions, e.g., a hybrid approach to game design and evaluation that combines bottom-up and top-down approaches.
>
---
#### [new 038] MetaFed: Advancing Privacy, Performance, and Sustainability in Federated Metaverse Systems
- **分类: cs.LG; cs.CR; cs.CY; cs.DC; cs.ET**

- **简介: 该论文提出MetaFed框架，解决Metaverse中性能、隐私与可持续性难题。通过多智能体强化学习动态选客户端、同态加密保护隐私、碳感知调度优化能源使用，实现低碳高效联邦学习。**

- **链接: [http://arxiv.org/pdf/2508.17341v1](http://arxiv.org/pdf/2508.17341v1)**

> **作者:** Muhammet Anil Yagiz; Zeynep Sude Cengiz; Polat Goktas
>
> **备注:** 2025 IEEE International Symposium on Emerging Metaverse (ISEMV)
>
> **摘要:** The rapid expansion of immersive Metaverse applications introduces complex challenges at the intersection of performance, privacy, and environmental sustainability. Centralized architectures fall short in addressing these demands, often resulting in elevated energy consumption, latency, and privacy concerns. This paper proposes MetaFed, a decentralized federated learning (FL) framework that enables sustainable and intelligent resource orchestration for Metaverse environments. MetaFed integrates (i) multi-agent reinforcement learning for dynamic client selection, (ii) privacy-preserving FL using homomorphic encryption, and (iii) carbon-aware scheduling aligned with renewable energy availability. Evaluations on MNIST and CIFAR-10 using lightweight ResNet architectures demonstrate that MetaFed achieves up to 25\% reduction in carbon emissions compared to conventional approaches, while maintaining high accuracy and minimal communication overhead. These results highlight MetaFed as a scalable solution for building environmentally responsible and privacy-compliant Metaverse infrastructures.
>
---
#### [new 039] Social Identity in Human-Agent Interaction: A Primer
- **分类: physics.soc-ph; cs.AI; cs.CY; cs.HC; cs.RO**

- **简介: 论文探讨社会身份理论在人机交互中的应用，旨在解决人工智能代理如何参与社会互动的问题。作者通过案例和设想说明SIT与SCT的适用性，并呼吁研究者保持批判视角。**

- **链接: [http://arxiv.org/pdf/2508.16609v1](http://arxiv.org/pdf/2508.16609v1)**

> **作者:** Katie Seaborn
>
> **备注:** 28 pages
>
> **摘要:** Social identity theory (SIT) and social categorization theory (SCT) are two facets of the social identity approach (SIA) to understanding social phenomena. SIT and SCT are models that describe and explain how people interact with one another socially, connecting the individual to the group through an understanding of underlying psychological mechanisms and intergroup behaviour. SIT, originally developed in the 1970s, and SCT, a later, more general offshoot, have been broadly applied to a range of social phenomena among people. The rise of increasingly social machines embedded in daily life has spurned efforts on understanding whether and how artificial agents can and do participate in SIA activities. As agents like social robots and chatbots powered by sophisticated large language models (LLMs) advance, understanding the real and potential roles of these technologies as social entities is crucial. Here, I provide a primer on SIA and extrapolate, through case studies and imagined examples, how SIT and SCT can apply to artificial social agents. I emphasize that not all human models and sub-theories will apply. I further argue that, given the emerging competence of these machines and our tendency to be taken in by them, we experts may need to don the hat of the uncanny killjoy, for our own good.
>
---
#### [new 040] Seeing Isn't Believing: Addressing the Societal Impact of Deepfakes in Low-Tech Environments
- **分类: cs.HC; cs.CY; cs.MM; stat.AP**

- **简介: 该论文属于社会科技影响研究，聚焦深伪技术在低 tech 环境中的风险。解决的问题是：如何应对发展中国家因媒体素养低、技术基础设施弱而面临的深伪威胁。工作包括调查公众认知、提出预防检测框架，并呼吁教育与验证工具的本地化开发。**

- **链接: [http://arxiv.org/pdf/2508.16618v1](http://arxiv.org/pdf/2508.16618v1)**

> **作者:** Azmine Toushik Wasi; Rahatun Nesa Priti; Mahir Absar Khan; Abdur Rahman; Mst Rafia Islam
>
> **备注:** Accepted to ACM MM 2025 Workshop Diffusion of Harmful Content on Online Web (DHOW)
>
> **摘要:** Deepfakes, AI-generated multimedia content that mimics real media, are becoming increasingly prevalent, posing significant risks to political stability, social trust, and economic well-being, especially in developing societies with limited media literacy and technological infrastructure. This work aims to understand how these technologies are perceived and impact resource-limited communities. We conducted a survey to assess public awareness, perceptions, and experiences with deepfakes, leading to the development of a comprehensive framework for prevention, detection, and mitigation in tech-limited environments. Our findings reveal critical knowledge gaps and a lack of effective detection tools, emphasizing the need for targeted education and accessible verification solutions. This work offers actionable insights to support vulnerable populations and calls for further interdisciplinary efforts to tackle deepfake challenges globally, particularly in the Global South.
>
---
#### [new 041] Leveraging Large Language Models for Accurate Sign Language Translation in Low-Resource Scenarios
- **分类: cs.CL; cs.AI; cs.CY; I.2; I.2.7**

- **简介: 论文提出AulSign方法，利用大语言模型在低资源场景下进行自然语言到手语的翻译。针对缺乏平行语料的问题，通过动态提示和样本选择，将手语符号关联自然语言描述，提升翻译准确性。**

- **链接: [http://arxiv.org/pdf/2508.18183v1](http://arxiv.org/pdf/2508.18183v1)**

> **作者:** Luana Bulla; Gabriele Tuccio; Misael Mongiovì; Aldo Gangemi
>
> **摘要:** Translating natural languages into sign languages is a highly complex and underexplored task. Despite growing interest in accessibility and inclusivity, the development of robust translation systems remains hindered by the limited availability of parallel corpora which align natural language with sign language data. Existing methods often struggle to generalize in these data-scarce environments, as the few datasets available are typically domain-specific, lack standardization, or fail to capture the full linguistic richness of sign languages. To address this limitation, we propose Advanced Use of LLMs for Sign Language Translation (AulSign), a novel method that leverages Large Language Models via dynamic prompting and in-context learning with sample selection and subsequent sign association. Despite their impressive abilities in processing text, LLMs lack intrinsic knowledge of sign languages; therefore, they are unable to natively perform this kind of translation. To overcome this limitation, we associate the signs with compact descriptions in natural language and instruct the model to use them. We evaluate our method on both English and Italian languages using SignBank+, a recognized benchmark in the field, as well as the Italian LaCAM CNR-ISTC dataset. We demonstrate superior performance compared to state-of-the-art models in low-data scenario. Our findings demonstrate the effectiveness of AulSign, with the potential to enhance accessibility and inclusivity in communication technologies for underrepresented linguistic communities.
>
---
#### [new 042] Persuasion Dynamics in LLMs: Investigating Robustness and Adaptability in Knowledge and Safety with DuET-PD
- **分类: cs.CL; cs.CY**

- **简介: 论文提出DuET-PD框架，评估LLMs在说服对话中的鲁棒性和适应性，解决模型易受误导或抗拒纠正的问题。通过双维度测评（说服类型与领域），发现模型表现不佳，并引入Holistic DPO训练方法提升其抗误导能力和接受纠正能力。**

- **链接: [http://arxiv.org/pdf/2508.17450v1](http://arxiv.org/pdf/2508.17450v1)**

> **作者:** Bryan Chen Zhengyu Tan; Daniel Wai Kit Chin; Zhengyuan Liu; Nancy F. Chen; Roy Ka-Wei Lee
>
> **备注:** To appear at EMNLP 2025
>
> **摘要:** Large Language Models (LLMs) can struggle to balance gullibility to misinformation and resistance to valid corrections in persuasive dialogues, a critical challenge for reliable deployment. We introduce DuET-PD (Dual Evaluation for Trust in Persuasive Dialogues), a framework evaluating multi-turn stance-change dynamics across dual dimensions: persuasion type (corrective/misleading) and domain (knowledge via MMLU-Pro, and safety via SALAD-Bench). We find that even a state-of-the-art model like GPT-4o achieves only 27.32% accuracy in MMLU-Pro under sustained misleading persuasions. Moreover, results reveal a concerning trend of increasing sycophancy in newer open-source models. To address this, we introduce Holistic DPO, a training approach balancing positive and negative persuasion examples. Unlike prompting or resist-only training, Holistic DPO enhances both robustness to misinformation and receptiveness to corrections, improving Llama-3.1-8B-Instruct's accuracy under misleading persuasion in safety contexts from 4.21% to 76.54%. These contributions offer a pathway to developing more reliable and adaptable LLMs for multi-turn dialogue. Code is available at https://github.com/Social-AI-Studio/DuET-PD.
>
---
#### [new 043] Handling Students Dropouts in an LLM-driven Interactive Online Course Using Language Models
- **分类: cs.CL; cs.CY**

- **简介: 论文研究交互式在线课程中的学生流失问题，提出基于语言模型的预测与干预方法。通过分析交互日志识别流失因素，构建CPADP预测模型（准确率95.4%），并设计个性化邮件召回机制，有效降低流失率。**

- **链接: [http://arxiv.org/pdf/2508.17310v1](http://arxiv.org/pdf/2508.17310v1)**

> **作者:** Yuanchun Wang; Yiyang Fu; Jifan Yu; Daniel Zhang-Li; Zheyuan Zhang; Joy Lim Jia Yin; Yucheng Wang; Peng Zhou; Jing Zhang; Huiqin Liu
>
> **备注:** 12 pages
>
> **摘要:** Interactive online learning environments, represented by Massive AI-empowered Courses (MAIC), leverage LLM-driven multi-agent systems to transform passive MOOCs into dynamic, text-based platforms, enhancing interactivity through LLMs. This paper conducts an empirical study on a specific MAIC course to explore three research questions about dropouts in these interactive online courses: (1) What factors might lead to dropouts? (2) Can we predict dropouts? (3) Can we reduce dropouts? We analyze interaction logs to define dropouts and identify contributing factors. Our findings reveal strong links between dropout behaviors and textual interaction patterns. We then propose a course-progress-adaptive dropout prediction framework (CPADP) to predict dropouts with at most 95.4% accuracy. Based on this, we design a personalized email recall agent to re-engage at-risk students. Applied in the deployed MAIC system with over 3,000 students, the feasibility and effectiveness of our approach have been validated on students with diverse backgrounds.
>
---
#### [new 044] Explainable AI for Predicting and Understanding Mathematics Achievement: A Cross-National Analysis of PISA 2018
- **分类: cs.AI; cs.CY; cs.LG**

- **简介: 该论文属于预测与解释任务，旨在通过XAI技术分析PISA 2018数据，揭示影响数学成绩的关键因素及其跨国家差异。研究比较了四种模型，发现随机森林在准确性和可解释性上表现最佳，识别出社会经济地位、学习时间等核心变量。**

- **链接: [http://arxiv.org/pdf/2508.16747v1](http://arxiv.org/pdf/2508.16747v1)**

> **作者:** Liu Liu; Rui Dai
>
> **摘要:** Understanding the factors that shape students' mathematics performance is vital for designing effective educational policies. This study applies explainable artificial intelligence (XAI) techniques to PISA 2018 data to predict math achievement and identify key predictors across ten countries (67,329 students). We tested four models: Multiple Linear Regression (MLR), Random Forest (RF), CATBoost, and Artificial Neural Networks (ANN), using student, family, and school variables. Models were trained on 70% of the data (with 5-fold cross-validation) and tested on 30%, stratified by country. Performance was assessed with R^2 and Mean Absolute Error (MAE). To ensure interpretability, we used feature importance, SHAP values, and decision tree visualizations. Non-linear models, especially RF and ANN, outperformed MLR, with RF balancing accuracy and generalizability. Key predictors included socio-economic status, study time, teacher motivation, and students' attitudes toward mathematics, though their impact varied across countries. Visual diagnostics such as scatterplots of predicted vs actual scores showed RF and CATBoost aligned closely with actual performance. Findings highlight the non-linear and context-dependent nature of achievement and the value of XAI in educational research. This study uncovers cross-national patterns, informs equity-focused reforms, and supports the development of personalized learning strategies.
>
---
#### [new 045] Mirroring Users: Towards Building Preference-aligned User Simulator with User Feedback in Recommendation
- **分类: cs.HC; cs.CY; cs.IR**

- **简介: 论文属于推荐系统中的用户模拟任务，旨在解决LLM在推荐场景下偏好对齐不足与效率低的问题。通过利用用户反馈构建高质量数据集，并结合认知决策生成与不确定性过滤机制，提升模拟器的人类偏好一致性与可解释性。**

- **链接: [http://arxiv.org/pdf/2508.18142v1](http://arxiv.org/pdf/2508.18142v1)**

> **作者:** Tianjun Wei; Huizhong Guo; Yingpeng Du; Zhu Sun; Chen Huang; Dongxia Wang; Jie Zhang
>
> **备注:** Github: https://github.com/UserMirrorer/UserMirrorer
>
> **摘要:** User simulation is increasingly vital to develop and evaluate recommender systems (RSs). While Large Language Models (LLMs) offer promising avenues to simulate user behavior, they often struggle with the absence of specific domain alignment required for RSs and the efficiency demands of large-scale simulation. A vast yet underutilized resource for enhancing this alignment is the extensive user feedback inherent in RSs. However, directly leveraging such feedback presents two significant challenges. First, user feedback in RSs is often ambiguous and noisy, which negatively impacts effective preference alignment. Second, the massive volume of feedback largely hinders the efficiency of preference alignment, necessitating an efficient filtering mechanism to identify more informative samples. To overcome these hurdles, we introduce a novel data construction framework that leverages user feedback in RSs with advanced LLM capabilities to generate high-quality simulation data. Our framework unfolds in two key phases: (1) employing LLMs to generate cognitive decision-making processes on constructed simulation samples, reducing ambiguity in raw user feedback; (2) data distillation based on uncertainty estimation and behavior sampling to filter challenging yet denoised simulation samples. Accordingly, we fine-tune lightweight LLMs, as user simulators, using such high-quality dataset with corresponding decision-making processes. Extensive experiments verify that our framework significantly boosts the alignment with human preferences and in-domain reasoning capabilities of fine-tuned LLMs, and provides more insightful and interpretable signals when interacting with RSs. We believe our work will advance the RS community and offer valuable insights for broader human-centric AI research.
>
---
#### [new 046] Beyond Demographics: Enhancing Cultural Value Survey Simulation with Multi-Stage Personality-Driven Cognitive Reasoning
- **分类: cs.CL; cs.CY**

- **简介: 该论文提出MARK框架，用于提升大模型在文化价值观调查模拟中的准确性与可解释性。针对现有方法难以精准模拟个体差异的问题，引入多阶段人格驱动认知推理，结合MBTI理论，实现更贴近真实人类反应的零样本个性化预测。**

- **链接: [http://arxiv.org/pdf/2508.17855v1](http://arxiv.org/pdf/2508.17855v1)**

> **作者:** Haijiang Liu; Qiyuan Li; Chao Gao; Yong Cao; Xiangyu Xu; Xun Wu; Daniel Hershcovich; Jinguang Gu
>
> **备注:** 23 pages, 6 figures, accepted to EMNLP 2025 main
>
> **摘要:** Introducing MARK, the Multi-stAge Reasoning frameworK for cultural value survey response simulation, designed to enhance the accuracy, steerability, and interpretability of large language models in this task. The system is inspired by the type dynamics theory in the MBTI psychological framework for personality research. It effectively predicts and utilizes human demographic information for simulation: life-situational stress analysis, group-level personality prediction, and self-weighted cognitive imitation. Experiments on the World Values Survey show that MARK outperforms existing baselines by 10% accuracy and reduces the divergence between model predictions and human preferences. This highlights the potential of our framework to improve zero-shot personalization and help social scientists interpret model predictions.
>
---
#### [new 047] Evaluating Retrieval-Augmented Generation Strategies for Large Language Models in Travel Mode Choice Prediction
- **分类: cs.AI; cs.CY; cs.LG**

- **简介: 论文研究如何用大语言模型结合检索增强生成（RAG）来预测出行方式选择，解决传统模型泛化能力差的问题。通过设计四种检索策略并测试三种LLM架构，发现GPT-4o配合平衡检索与交叉编码重排序效果最佳，准确率达80.8%。**

- **链接: [http://arxiv.org/pdf/2508.17527v1](http://arxiv.org/pdf/2508.17527v1)**

> **作者:** Yiming Xu; Junfeng Jiao
>
> **摘要:** Accurately predicting travel mode choice is essential for effective transportation planning, yet traditional statistical and machine learning models are constrained by rigid assumptions, limited contextual reasoning, and reduced generalizability. This study explores the potential of Large Language Models (LLMs) as a more flexible and context-aware approach to travel mode choice prediction, enhanced by Retrieval-Augmented Generation (RAG) to ground predictions in empirical data. We develop a modular framework for integrating RAG into LLM-based travel mode choice prediction and evaluate four retrieval strategies: basic RAG, RAG with balanced retrieval, RAG with a cross-encoder for re-ranking, and RAG with balanced retrieval and cross-encoder for re-ranking. These strategies are tested across three LLM architectures (OpenAI GPT-4o, o4-mini, and o3) to examine the interaction between model reasoning capabilities and retrieval methods. Using the 2023 Puget Sound Regional Household Travel Survey data, we conduct a series of experiments to evaluate model performance. The results demonstrate that RAG substantially enhances predictive accuracy across a range of models. Notably, the GPT-4o model combined with balanced retrieval and cross-encoder re-ranking achieves the highest accuracy of 80.8%, exceeding that of conventional statistical and machine learning baselines. Furthermore, LLM-based models exhibit superior generalization abilities relative to these baselines. Findings highlight the critical interplay between LLM reasoning capabilities and retrieval strategies, demonstrating the importance of aligning retrieval strategies with model capabilities to maximize the potential of LLM-based travel behavior modeling.
>
---
#### [new 048] Toward Socially Aware Vision-Language Models: Evaluating Cultural Competence Through Multimodal Story Generation
- **分类: cs.CL; cs.CY**

- **简介: 论文聚焦多模态故事生成任务，解决VLMs在跨文化场景下的适应能力问题。通过构建新型评估框架，系统测试5个模型的文化敏感性，发现其词汇层面有较好表现，但架构差异导致效果不稳定，且自动指标与人类判断不一致。**

- **链接: [http://arxiv.org/pdf/2508.16762v1](http://arxiv.org/pdf/2508.16762v1)**

> **作者:** Arka Mukherjee; Shreya Ghosh
>
> **备注:** Accepted at ASI @ ICCV 2025
>
> **摘要:** As Vision-Language Models (VLMs) achieve widespread deployment across diverse cultural contexts, ensuring their cultural competence becomes critical for responsible AI systems. While prior work has evaluated cultural awareness in text-only models and VLM object recognition tasks, no research has systematically assessed how VLMs adapt outputs when cultural identity cues are embedded in both textual prompts and visual inputs during generative tasks. We present the first comprehensive evaluation of VLM cultural competence through multimodal story generation, developing a novel multimodal framework that perturbs cultural identity and evaluates 5 contemporary VLMs on a downstream task: story generation. Our analysis reveals significant cultural adaptation capabilities, with rich culturally-specific vocabulary spanning names, familial terms, and geographic markers. However, we uncover concerning limitations: cultural competence varies dramatically across architectures, some models exhibit inverse cultural alignment, and automated metrics show architectural bias contradicting human assessments. Cross-modal evaluation shows that culturally distinct outputs are indeed detectable through visual-semantic similarity (28.7% within-nationality vs. 0.2% cross-nationality recall), yet visual-cultural understanding remains limited. In essence, we establish the promise and challenges of cultural competence in multimodal AI. We publicly release our codebase and data: https://github.com/ArkaMukherjee0/mmCultural
>
---
#### [new 049] A Human-In-The-Loop Approach for Improving Fairness in Predictive Business Process Monitoring
- **分类: cs.LG; cs.CY; 68T07, 68T01, 68U35**

- **简介: 该论文属于预测性业务流程监控任务，旨在解决机器学习模型因数据偏见导致的不公平预测问题。作者提出一种人机协同方法，通过修改决策树模型区分公平与不公平决策，实现公平性与准确性的平衡。**

- **链接: [http://arxiv.org/pdf/2508.17477v1](http://arxiv.org/pdf/2508.17477v1)**

> **作者:** Martin Käppel; Julian Neuberger; Felix Möhrlein; Sven Weinzierl; Martin Matzner; Stefan Jablonski
>
> **摘要:** Predictive process monitoring enables organizations to proactively react and intervene in running instances of a business process. Given an incomplete process instance, predictions about the outcome, next activity, or remaining time are created. This is done by powerful machine learning models, which have shown impressive predictive performance. However, the data-driven nature of these models makes them susceptible to finding unfair, biased, or unethical patterns in the data. Such patterns lead to biased predictions based on so-called sensitive attributes, such as the gender or age of process participants. Previous work has identified this problem and offered solutions that mitigate biases by removing sensitive attributes entirely from the process instance. However, sensitive attributes can be used both fairly and unfairly in the same process instance. For example, during a medical process, treatment decisions could be based on gender, while the decision to accept a patient should not be based on gender. This paper proposes a novel, model-agnostic approach for identifying and rectifying biased decisions in predictive business process monitoring models, even when the same sensitive attribute is used both fairly and unfairly. The proposed approach uses a human-in-the-loop approach to differentiate between fair and unfair decisions through simple alterations on a decision tree model distilled from the original prediction model. Our results show that the proposed approach achieves a promising tradeoff between fairness and accuracy in the presence of biased data. All source code and data are publicly available at https://doi.org/10.5281/zenodo.15387576.
>
---
## 更新

#### [replaced 001] Not a Swiss Army Knife: Academics' Perceptions of Trade-Offs Around Generative Artificial Intelligence Use
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2405.00995v2](http://arxiv.org/pdf/2405.00995v2)**

> **作者:** Afsaneh Razi; Layla Bouzoubaa; Aria Pessianzadeh; John S. Seberger; Rezvaneh Rezapour
>
> **摘要:** In the rapidly evolving landscape of computing disciplines, substantial efforts are being dedicated to unraveling the sociotechnical implications of generative AI (Gen AI). While existing research has manifested in various forms, there remains a notable gap concerning the direct engagement of knowledge workers in academia with Gen AI. We interviewed 17 knowledge workers, including faculty and students, to investigate the social and technical dimensions of Gen AI from their perspective. Our participants raised concerns about the opacity of the data used to train Gen AI. This lack of transparency makes it difficult to identify and address inaccurate, biased, and potentially harmful, information generated by these models. Knowledge workers also expressed worries about Gen AI undermining trust in the relationship between instructor and student and discussed potential solutions, such as pedagogy readiness, to mitigate them. Additionally, participants recognized Gen AI's potential to democratize knowledge by accelerating the learning process and act as an accessible research assistant. However, there were also concerns about potential social and power imbalances stemming from unequal access to such technologies. Our study offers insights into the concerns and hopes of knowledge workers about the ethical use of Gen AI in educational settings and beyond, with implications for navigating this new landscape.
>
---
#### [replaced 002] From Legal Texts to Defeasible Deontic Logic via LLMs: A Study in Automated Semantic Analysis
- **分类: cs.CL; cs.AI; cs.CY; cs.LO**

- **链接: [http://arxiv.org/pdf/2506.08899v2](http://arxiv.org/pdf/2506.08899v2)**

> **作者:** Elias Horner; Cristinel Mateis; Guido Governatori; Agata Ciabattoni
>
> **摘要:** We present a novel approach to the automated semantic analysis of legal texts using large language models (LLMs), targeting their transformation into formal representations in Defeasible Deontic Logic (DDL). We propose a structured pipeline that segments complex normative language into atomic snippets, extracts deontic rules, and evaluates them for syntactic and semantic coherence. Our methodology is evaluated across various LLM configurations, including prompt engineering strategies, fine-tuned models, and multi-stage pipelines, focusing on legal norms from the Australian Telecommunications Consumer Protections Code. Empirical results demonstrate promising alignment between machine-generated and expert-crafted formalizations, showing that LLMs - particularly when prompted effectively - can significantly contribute to scalable legal informatics.
>
---
#### [replaced 003] PediatricsMQA: a Multi-modal Pediatrics Question Answering Benchmark
- **分类: cs.CY; cs.AI; cs.CL; cs.GR; cs.MM**

- **链接: [http://arxiv.org/pdf/2508.16439v2](http://arxiv.org/pdf/2508.16439v2)**

> **作者:** Adil Bahaj; Mohamed Chetouani; Mounir Ghogho
>
> **摘要:** Large language models (LLMs) and vision-augmented LLMs (VLMs) have significantly advanced medical informatics, diagnostics, and decision support. However, these models exhibit systematic biases, particularly age bias, compromising their reliability and equity. This is evident in their poorer performance on pediatric-focused text and visual question-answering tasks. This bias reflects a broader imbalance in medical research, where pediatric studies receive less funding and representation despite the significant disease burden in children. To address these issues, a new comprehensive multi-modal pediatric question-answering benchmark, PediatricsMQA, has been introduced. It consists of 3,417 text-based multiple-choice questions (MCQs) covering 131 pediatric topics across seven developmental stages (prenatal to adolescent) and 2,067 vision-based MCQs using 634 pediatric images from 67 imaging modalities and 256 anatomical regions. The dataset was developed using a hybrid manual-automatic pipeline, incorporating peer-reviewed pediatric literature, validated question banks, existing benchmarks, and existing QA resources. Evaluating state-of-the-art open models, we find dramatic performance drops in younger cohorts, highlighting the need for age-aware methods to ensure equitable AI support in pediatric care.
>
---
#### [replaced 004] Harnessing Large Language Models for Disaster Management: A Survey
- **分类: cs.CL; cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2501.06932v2](http://arxiv.org/pdf/2501.06932v2)**

> **作者:** Zhenyu Lei; Yushun Dong; Weiyu Li; Rong Ding; Qi Wang; Jundong Li
>
> **摘要:** Large language models (LLMs) have revolutionized scientific research with their exceptional capabilities and transformed various fields. Among their practical applications, LLMs have been playing a crucial role in mitigating threats to human life, infrastructure, and the environment. Despite growing research in disaster LLMs, there remains a lack of systematic review and in-depth analysis of LLMs for natural disaster management. To address the gap, this paper presents a comprehensive survey of existing LLMs in natural disaster management, along with a taxonomy that categorizes existing works based on disaster phases and application scenarios. By collecting public datasets and identifying key challenges and opportunities, this study aims to guide the professional community in developing advanced LLMs for disaster management to enhance the resilience against natural disasters.
>
---
#### [replaced 005] Investigating the Impact of Project Risks on Employee Turnover Intentions in the IT Industry of Pakistan
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2403.14675v2](http://arxiv.org/pdf/2403.14675v2)**

> **作者:** Ghalib Ahmed Tahir; Murtaza Ashraf
>
> **摘要:** Employee turnover remains a pressing issue within high-tech sectors such as IT firms and research centers, where organizational success heavily relies on the skills of their workforce. Intense competition and a scarcity of skilled professionals in the industry contribute to a perpetual demand for highly qualified employees, posing challenges for organizations to retain talent. While numerous studies have explored various factors affecting employee turnover in these industries, their focus often remains on overarching trends rather than specific organizational contexts. In particular, within the software industry, where projectspecific risks can significantly impact project success and timely delivery, understanding their influence on job satisfaction and turnover intentions is crucial. This study aims to investigate the influence of project risks in the IT industry on job satisfaction and employee turnover intentions. Furthermore, it examines the role of both external and internal social links in shaping perceptions of job satisfaction.
>
---
#### [replaced 006] Reconsidering Fairness Through Unawareness From the Perspective of Model Multiplicity
- **分类: cs.LG; cs.CY; stat.ML**

- **链接: [http://arxiv.org/pdf/2505.16638v2](http://arxiv.org/pdf/2505.16638v2)**

> **作者:** Benedikt Höltgen; Nuria Oliver
>
> **摘要:** Fairness through Unawareness (FtU) describes the idea that discrimination against demographic groups can be avoided by not considering group membership in the decisions or predictions. This idea has long been criticized in the machine learning literature as not being sufficient to ensure fairness. In addition, the use of additional features is typically thought to increase the accuracy of the predictions for all groups, so that FtU is sometimes thought to be detrimental to all groups. In this paper, we show both theoretically and empirically that FtU can reduce algorithmic discrimination without necessarily reducing accuracy. We connect this insight with the literature on Model Multiplicity, to which we contribute with novel theoretical and empirical results. Furthermore, we illustrate how, in a real-life application, FtU can contribute to the deployment of more equitable policies without losing efficacy. Our findings suggest that FtU is worth considering in practical applications, particularly in high-risk scenarios, and that the use of protected attributes such as gender in predictive models should be accompanied by a clear and well-founded justification.
>
---
#### [replaced 007] Optimizing Peer Grading: A Systematic Literature Review of Reviewer Assignment Strategies and Quantity of Reviewers
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2508.11678v2](http://arxiv.org/pdf/2508.11678v2)**

> **作者:** Uchswas Paul; Shail Shah; Sri Vaishnavi Mylavarapu; M. Parvez Rashid; Edward Gehringer
>
> **备注:** Accepted for presentation at the 11th International Workshop on Peer Review, Peer Assessment, and Self-Assessment in Education, Lille, France, 25-27 June 2025
>
> **摘要:** Peer assessment has established itself as a critical pedagogical tool in academic settings, offering students timely, high-quality feedback to enhance learning outcomes. However, the efficacy of this approach depends on two factors: (1) the strategic allocation of reviewers and (2) the number of reviews per artifact. This paper presents a systematic literature review of 87 studies (2010--2024) to investigate how reviewer-assignment strategies and the number of reviews per submission impact the accuracy, fairness, and educational value of peer assessment. We identified four common reviewer-assignment strategies: random assignment, competency-based assignment, social-network-based assignment, and bidding. Drawing from both quantitative data and qualitative insights, we explored the trade-offs involved in each approach. Random assignment, while widely used, often results in inconsistent grading and fairness concerns. Competency-based strategies can address these issues. Meanwhile, social and bidding-based methods have the potential to improve fairness and timeliness -- existing empirical evidence is limited. In terms of review count, assigning three reviews per submission emerges as the most common practice. A range of three to five reviews per student or per submission is frequently cited as a recommended spot that balances grading accuracy, student workload, learning outcomes, and engagement.
>
---
#### [replaced 008] Documenting Deployment with Fabric: A Repository of Real-World AI Governance
- **分类: cs.CY; cs.AI; cs.HC**

- **链接: [http://arxiv.org/pdf/2508.14119v3](http://arxiv.org/pdf/2508.14119v3)**

> **作者:** Mackenzie Jorgensen; Kendall Brogle; Katherine M. Collins; Lujain Ibrahim; Arina Shah; Petra Ivanovic; Noah Broestl; Gabriel Piles; Paul Dongha; Hatim Abdulhussein; Adrian Weller; Jillian Powers; Umang Bhatt
>
> **备注:** AIES 2025
>
> **摘要:** Artificial intelligence (AI) is increasingly integrated into society, from financial services and traffic management to creative writing. Academic literature on the deployment of AI has mostly focused on the risks and harms that result from the use of AI. We introduce Fabric, a publicly available repository of deployed AI use cases to outline their governance mechanisms. Through semi-structured interviews with practitioners, we collect an initial set of 20 AI use cases. In addition, we co-design diagrams of the AI workflow with the practitioners. We discuss the oversight mechanisms and guardrails used in practice to safeguard AI use. The Fabric repository includes visual diagrams of AI use cases and descriptions of the deployed systems. Using the repository, we surface gaps in governance and find common patterns in human oversight of deployed AI systems. We intend for Fabric to serve as an extendable, evolving tool for researchers to study the effectiveness of AI governance.
>
---
#### [replaced 009] ZPD-SCA: Unveiling the Blind Spots of LLMs in Assessing Students' Cognitive Abilities
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2508.14377v2](http://arxiv.org/pdf/2508.14377v2)**

> **作者:** Wenhan Dong; Zhen Sun; Yuemeng Zhao; Zifan Peng; Jun Wu; Jingyi Zheng; Yule Liu; Xinlei He; Yu Wang; Ruiming Wang; Xinyi Huang; Lei Mo
>
> **摘要:** Large language models (LLMs) have demonstrated potential in educational applications, yet their capacity to accurately assess the cognitive alignment of reading materials with students' developmental stages remains insufficiently explored. This gap is particularly critical given the foundational educational principle of the Zone of Proximal Development (ZPD), which emphasizes the need to match learning resources with Students' Cognitive Abilities (SCA). Despite the importance of this alignment, there is a notable absence of comprehensive studies investigating LLMs' ability to evaluate reading comprehension difficulty across different student age groups, especially in the context of Chinese language education. To fill this gap, we introduce ZPD-SCA, a novel benchmark specifically designed to assess stage-level Chinese reading comprehension difficulty. The benchmark is annotated by 60 Special Grade teachers, a group that represents the top 0.15% of all in-service teachers nationwide. Experimental results reveal that LLMs perform poorly in zero-shot learning scenarios, with Qwen-max and GLM even falling below the probability of random guessing. When provided with in-context examples, LLMs performance improves substantially, with some models achieving nearly double the accuracy of their zero-shot baselines. These results reveal that LLMs possess emerging abilities to assess reading difficulty, while also exposing limitations in their current training for educationally aligned judgment. Notably, even the best-performing models display systematic directional biases, suggesting difficulties in accurately aligning material difficulty with SCA. Furthermore, significant variations in model performance across different genres underscore the complexity of task. We envision that ZPD-SCA can provide a foundation for evaluating and improving LLMs in cognitively aligned educational applications.
>
---
#### [replaced 010] Towards New Benchmark for AI Alignment & Sentiment Analysis in Socially Important Issues: A Comparative Study of Human and LLMs in the Context of AGI
- **分类: cs.CY; cs.CL**

- **链接: [http://arxiv.org/pdf/2501.02531v2](http://arxiv.org/pdf/2501.02531v2)**

> **作者:** Ljubisa Bojic; Dylan Seychell; Milan Cabarkapa
>
> **备注:** 20 pages, 1 figure
>
> **摘要:** As general-purpose artificial intelligence systems become increasingly integrated into society and are used for information seeking, content generation, problem solving, textual analysis, coding, and running processes, it is crucial to assess their long-term impact on humans. This research explores the sentiment of large language models (LLMs) and humans toward artificial general intelligence (AGI) using a Likert-scale survey. Seven LLMs, including GPT-4 and Bard, were analyzed and compared with sentiment data from three independent human sample populations. Temporal variations in sentiment were also evaluated over three consecutive days. The results show a diversity in sentiment scores among LLMs, ranging from 3.32 to 4.12 out of 5. GPT-4 recorded the most positive sentiment toward AGI, while Bard leaned toward a neutral sentiment. In contrast, the human samples showed a lower average sentiment of 2.97. The analysis outlines potential conflicts of interest and biases in the sentiment formation of LLMs, and indicates that LLMs could subtly influence societal perceptions. To address the need for regulatory oversight and culturally grounded assessments of AI systems, we introduce the Societal AI Alignment and Sentiment Benchmark (SAAS-AI), which leverages multidimensional prompts and empirically validated societal value frameworks to evaluate language model outputs across temporal, model, and multilingual axes. This benchmark is designed to guide policymakers and AI agencies, including within frameworks such as the EU AI Act, by providing robust, actionable insights into AI alignment with human values, public sentiment, and ethical norms at both national and international levels. Future research should further refine the operationalization of the SAAS-AI benchmark and systematically evaluate its effectiveness through comprehensive empirical testing.
>
---
#### [replaced 011] Combining Cost-Constrained Runtime Monitors for AI Safety
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2507.15886v3](http://arxiv.org/pdf/2507.15886v3)**

> **作者:** Tim Tian Hua; James Baskerville; Henri Lemoine; Mia Hopman; Aryan Bhatt; Tyler Tracy
>
> **摘要:** Monitoring AIs at runtime can help us detect and stop harmful actions. In this paper, we study how to efficiently combine multiple runtime monitors into a single monitoring protocol. The protocol's objective is to maximize the probability of applying a safety intervention on misaligned outputs (i.e., maximize recall). Since running monitors and applying safety interventions are costly, the protocol also needs to adhere to an average-case budget constraint. Taking the monitors' performance and cost as given, we develop an algorithm to find the best protocol. The algorithm exhaustively searches over when and which monitors to call, and allocates safety interventions based on the Neyman-Pearson lemma. By focusing on likelihood ratios and strategically trading off spending on monitors against spending on interventions, we more than double our recall rate compared to a naive baseline in a code review setting. We also show that combining two monitors can Pareto dominate using either monitor alone. Our framework provides a principled methodology for combining existing monitors to detect undesirable behavior in cost-sensitive settings.
>
---
#### [replaced 012] Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics
- **分类: cs.AI; cs.CY; cs.HC; cs.LG**

- **链接: [http://arxiv.org/pdf/2505.19317v3](http://arxiv.org/pdf/2505.19317v3)**

> **作者:** Tin Trung Nguyen; Jiannan Xu; Zora Che; Phuong-Anh Nguyen-Le; Rushil Dandamudi; Donald Braman; Furong Huang; Hal Daumé III; Zubin Jelveh
>
> **备注:** AIES 2025
>
> **摘要:** Although popularized AI fairness metrics, e.g., demographic parity, have uncovered bias in AI-assisted decision-making outcomes, they do not consider how much effort one has spent to get to where one is today in the input feature space. However, the notion of effort is important in how Philosophy and humans understand fairness. We propose a philosophy-informed approach to conceptualize and evaluate Effort-aware Fairness (EaF), grounded in the concept of Force, which represents the temporal trajectory of predictive features coupled with inertia. Besides theoretical formulation, our empirical contributions include: (1) a pre-registered human subjects experiment, which shows that for both stages of the (individual) fairness evaluation process, people consider the temporal trajectory of a predictive feature more than its aggregate value; (2) pipelines to compute Effort-aware Individual/Group Fairness in the criminal justice and personal finance contexts. Our work may enable AI model auditors to uncover and potentially correct unfair decisions against individuals who have spent significant efforts to improve but are still stuck with systemic disadvantages outside their control.
>
---
#### [replaced 013] TombRaider: Entering the Vault of History to Jailbreak Large Language Models
- **分类: cs.CR; cs.AI; cs.CL; cs.CY**

- **链接: [http://arxiv.org/pdf/2501.18628v2](http://arxiv.org/pdf/2501.18628v2)**

> **作者:** Junchen Ding; Jiahao Zhang; Yi Liu; Ziqi Ding; Gelei Deng; Yuekang Li
>
> **备注:** Main Conference of EMNLP
>
> **摘要:** Warning: This paper contains content that may involve potentially harmful behaviours, discussed strictly for research purposes. Jailbreak attacks can hinder the safety of Large Language Model (LLM) applications, especially chatbots. Studying jailbreak techniques is an important AI red teaming task for improving the safety of these applications. In this paper, we introduce TombRaider, a novel jailbreak technique that exploits the ability to store, retrieve, and use historical knowledge of LLMs. TombRaider employs two agents, the inspector agent to extract relevant historical information and the attacker agent to generate adversarial prompts, enabling effective bypassing of safety filters. We intensively evaluated TombRaider on six popular models. Experimental results showed that TombRaider could outperform state-of-the-art jailbreak techniques, achieving nearly 100% attack success rates (ASRs) on bare models and maintaining over 55.4% ASR against defence mechanisms. Our findings highlight critical vulnerabilities in existing LLM safeguards, underscoring the need for more robust safety defences.
>
---
#### [replaced 014] Does GPT-4 surpass human performance in linguistic pragmatics?
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2312.09545v2](http://arxiv.org/pdf/2312.09545v2)**

> **作者:** Ljubisa Bojic; Predrag Kovacevic; Milan Cabarkapa
>
> **备注:** 19 pages, 1 figure, 2 tables
>
> **摘要:** As Large Language Models (LLMs) become increasingly integrated into everyday life as general purpose multimodal AI systems, their capabilities to simulate human understanding are under examination. This study investigates LLMs ability to interpret linguistic pragmatics, which involves context and implied meanings. Using Grice communication principles, we evaluated both LLMs (GPT-2, GPT-3, GPT-3.5, GPT-4, and Bard) and human subjects (N = 147) on dialogue-based tasks. Human participants included 71 primarily Serbian students and 76 native English speakers from the United States. Findings revealed that LLMs, particularly GPT-4, outperformed humans. GPT4 achieved the highest score of 4.80, surpassing the best human score of 4.55. Other LLMs performed well: GPT 3.5 scored 4.10, Bard 3.75, and GPT-3 3.25. GPT-2 had the lowest score of 1.05. The average LLM score was 3.39, exceeding the human cohorts averages of 2.80 (Serbian students) and 2.34 (U.S. participants). In the ranking of all 155 subjects (including LLMs and humans), GPT-4 secured the top position, while the best human ranked second. These results highlight significant progress in LLMs ability to simulate understanding of linguistic pragmatics. Future studies should confirm these findings with more dialogue-based tasks and diverse participants. This research has important implications for advancing general-purpose AI models in various communication-centered tasks, including potential application in humanoid robots in the future.
>
---
#### [replaced 015] The Dual Impact of Virtual Reality: Examining the Addictive Potential and Therapeutic Applications of Immersive Media in the Metaverse
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2401.03461v2](http://arxiv.org/pdf/2401.03461v2)**

> **作者:** Ljubisa Bojic; Joerg Matthes; Agariadne Dwinggo Samala; Milan Cabarkapa
>
> **备注:** 14 pages, 1 figure, 1 table
>
> **摘要:** The emergence of the metaverse - envisioned as a hyperreal virtual universe enabling boundless human interaction - has the potential to revolutionize our conception of media. This transformation could alter society as we know it. This paper identifies addictive features of social media, including immersion, interactivity, real-time access, and personalization. These features are examined within the context of virtual reality through a literature review and content analysis, aimed at exploring the potential consequences of metaverse development. From an initial pool of 193,218 documents, a refined selection of N = 44 relevant papers formed the basis of our qualitative analysis. About half of the analyzed papers indicate that these features contribute to VR addiction. Interestingly, the same features that contribute to addictive behaviors can also be harnessed for positive therapeutic interventions of VR, particularly in treating addictions and managing mental health conditions. This duality, observed in the other half of the papers, emphasizes the complex role of VR technologies, suggesting that they can serve as a substitute for other addictions. This phenomenon is placed into the historical context of evolving media technologies that increasingly mimic reality. The complex interplay of factors contributing to addiction necessitates the development of algorithmic solutions that actively curate diverse offerings, rather than promoting a closed loop of like-minded views. Traditional models of addiction should be adapted to address these unique challenges. Finally, the discussion turned to the implications of these findings for a society where the metaverse is widely accepted as a mainstream technology.
>
---
