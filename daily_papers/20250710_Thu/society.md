# 计算机与社会 cs.CY

- **最新发布 22 篇**

- **更新 6 篇**

## 最新发布

#### [new 001] Connecting the Unconnected -- Sentiment Analysis of Field Survey of Internet Connectivity in Emerging Economies
- **分类: cs.CY; cs.NI**

- **简介: 该论文属于情感分析任务，旨在研究发展中国家互联网接入问题。通过实地调查，分析用户对互联网体验的反馈，揭示其积极情感及需求。**

- **链接: [http://arxiv.org/pdf/2507.06827v1](http://arxiv.org/pdf/2507.06827v1)**

> **作者:** Dibakar Das; Barath S Narayan; Aarna Bhammar; Jyotsna Bapat
>
> **摘要:** Internet has significantly improved the quality of citizens across the world. Though the internet coverage is quite high, 40% of global population do not have access to broadband internet. This paper presents an analysis of a field survey of population in some areas of Kathmandu, Nepal, an emerging economy. This survey was triggered by intermittent severe congestion of internet in certain areas of the city. People from three different areas were asked about their present experience of internet usage, its impact on their lives and their aspirations for the future. Survey pointed to high speed, low cost, reliable and secure internet as a major aspiration of the respondents. Based on their inputs, this paper presents a sentiment analysis as well as demographic information. Keys insights from this analysis shows that overall sentiment to most queries are positive. The variances of positive sentiments are high whereas those for negative ones are low. Also, some correlations and clusters are observed among the attributes though no dominant component exists in the data.
>
---
#### [new 002] A Collectivist, Economic Perspective on AI
- **分类: cs.CY; cs.AI; stat.ML**

- **简介: 论文属于人工智能伦理研究，旨在解决当前AI发展忽视社会文化因素的问题，提出融合经济与社会概念的新型工程视角。**

- **链接: [http://arxiv.org/pdf/2507.06268v1](http://arxiv.org/pdf/2507.06268v1)**

> **作者:** Michael I. Jordan
>
> **摘要:** Information technology is in the midst of a revolution in which omnipresent data collection and machine learning are impacting the human world as never before. The word "intelligence" is being used as a North Star for the development of this technology, with human cognition viewed as a baseline. This view neglects the fact that humans are social animals, and that much of our intelligence is social and cultural in origin. A related issue is that the current view treats the social consequences of technology as an afterthought. The path forward is not merely more data and compute, and not merely more attention paid to cognitive or symbolic representations, but a thorough blending of economic and social concepts with computational and inferential concepts, in the service of system-level designs in which social welfare is a first-class citizen, and with the aspiration that a new human-centric engineering field will emerge.
>
---
#### [new 003] Exploring Public Perceptions of Generative AI in Libraries: A Social Media Analysis of X Discussions
- **分类: cs.CY; cs.HC; cs.SI**

- **简介: 该论文属于社会媒体分析任务，旨在研究公众对生成式AI在图书馆中的看法。通过分析X平台上的讨论，探索其演变、情感倾向及关键参与者。**

- **链接: [http://arxiv.org/pdf/2507.07047v1](http://arxiv.org/pdf/2507.07047v1)**

> **作者:** Yuan Li; Teja Mandaloju; Haihua Chen
>
> **摘要:** This study investigates public perceptions of generative artificial intelligence (GenAI) in libraries through a large-scale analysis of posts on X (formerly Twitter). Using a mixed-method approach that combines temporal trend analysis, sentiment classification, and social network analysis, this paper explores how public discourse around GenAI and libraries has evolved over time, the emotional tones that dominate the conversation, and the key users or organizations driving engagement. The findings reveal that discussions are predominantly negative in tone, with surges linked to concerns about ethics and intellectual property. Furthermore, social network analysis identifies both institutional authority and individual bridge users who facilitate cross-domain engagement. The results in this paper contribute to the growing body of literature on GenAI in the library and GLAM (Galleries, Libraries, Archives, and Museums) sectors and offer a real-time, public-facing perspective on the emerging opportunities and concerns GenAI presents.
>
---
#### [new 004] Google Search Advertising after Dobbs v. Jackson
- **分类: cs.CY**

- **简介: 该论文属于信息检索研究，探讨Dobbs案后Google搜索中堕胎相关广告分布，分析广告类型与地域差异，关注医疗信息准确性及平台政策影响。**

- **链接: [http://arxiv.org/pdf/2507.06640v1](http://arxiv.org/pdf/2507.06640v1)**

> **作者:** Yelena Mejova; Ronald E. Robertson; Catherine A. Gimbrone; Sarah McKetta
>
> **摘要:** Search engines have become the gateway to information, products, and services, including those concerning healthcare. Access to reproductive health has been especially complicated in the wake of the 2022 Dobbs v. Jackson decision by the Supreme Court of the United States, splintering abortion regulations among the states. In this study, we performed an audit of the advertisements shown to Google Search users seeking information about abortion across the United States during the year following the Dobbs decision. We found that Crisis Pregnancy Centers (CPCs) -- organizations that target women with unexpected or "crisis" pregnancies, but do not provide abortions -- accounted for 47% of advertisements, whereas abortion clinics -- for 30%. Advertisements from CPCs were often returned for queries concerning information and safety. The type of advertisements returned, however, varied widely within each state, with Arizona returning the most advertisements from abortion clinics and other pro-choice organizations, and Minnesota the least. The proportion of pro-choice vs. anti-choice advertisements returned also varied over time, but estimates from Staggered Augmented Synthetic Control Methods did not indicate that changes in advertisement results were attributable to changes in state abortion laws. Our findings raise questions about the access to accurate medical information across the U.S. and point to a need for further examination of search engine advertisement policies and geographical bias.
>
---
#### [new 005] The Prompt War: How AI Decides on a Military Intervention
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于AI决策研究任务，探讨AI在军事干预中的决策因素。通过实验分析，发现国内支持和成功概率是主要影响因素。**

- **链接: [http://arxiv.org/pdf/2507.06277v1](http://arxiv.org/pdf/2507.06277v1)**

> **作者:** Maxim Chupilkin
>
> **备注:** 13 pages, 8 tables, 1 figure
>
> **摘要:** Which factors determine AI propensity for military intervention? While the use of AI in war games and military planning is growing exponentially, the simple analysis of key drivers embedded in the models has not yet been done. This paper does a simple conjoint experiment proposing a model to decide on military intervention in 640 vignettes where each was run for 100 times allowing to explore AI decision on military intervention systematically. The analysis finds that largest predictors of AI decision to intervene are high domestic support and high probability of success. Costs such as international condemnation, military deaths, civilian deaths, and negative economic effect are statistically significant, but their effect is around half of domestic support and probability of victory. Closing window of opportunity only reaches statistical significance in interaction with other factors. The results are remarkably consistent across scenarios and across different models (OpenAI GPT, Anthropic Claude, Google Gemini) suggesting a pattern in AI decision-making.
>
---
#### [new 006] Deprecating Benchmarks: Criteria and Framework
- **分类: cs.CY; cs.AI; cs.LG**

- **简介: 该论文属于AI评估任务，解决基准测试过时问题，提出基准淘汰标准与框架，以提升评估质量与透明度。**

- **链接: [http://arxiv.org/pdf/2507.06434v1](http://arxiv.org/pdf/2507.06434v1)**

> **作者:** Ayrton San Joaquin; Rokas Gipiškis; Leon Staufer; Ariel Gil
>
> **备注:** 10 pages, 1 table. Accepted to the ICML 2025 Technical AI Governance Workshop
>
> **摘要:** As frontier artificial intelligence (AI) models rapidly advance, benchmarks are integral to comparing different models and measuring their progress in different task-specific domains. However, there is a lack of guidance on when and how benchmarks should be deprecated once they cease to effectively perform their purpose. This risks benchmark scores over-valuing model capabilities, or worse, obscuring capabilities and safety-washing. Based on a review of benchmarking practices, we propose criteria to decide when to fully or partially deprecate benchmarks, and a framework for deprecating benchmarks. Our work aims to advance the state of benchmarking towards rigorous and quality evaluations, especially for frontier models, and our recommendations are aimed to benefit benchmark developers, benchmark users, AI governance actors (across governments, academia, and industry panels), and policy makers.
>
---
#### [new 007] The Emotional Alignment Design Policy
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于伦理设计任务，探讨如何使人工智能引发恰当的情感反应，解决情感对齐问题，提出设计原则及实施挑战。**

- **链接: [http://arxiv.org/pdf/2507.06263v1](http://arxiv.org/pdf/2507.06263v1)**

> **作者:** Eric Schwitzgebel; Jeff Sebo
>
> **摘要:** According to what we call the Emotional Alignment Design Policy, artificial entities should be designed to elicit emotional reactions from users that appropriately reflect the entities' capacities and moral status, or lack thereof. This principle can be violated in two ways: by designing an artificial system that elicits stronger or weaker emotional reactions than its capacities and moral status warrant (overshooting or undershooting), or by designing a system that elicits the wrong type of emotional reaction (hitting the wrong target). Although presumably attractive, practical implementation faces several challenges including: How can we respect user autonomy while promoting appropriate responses? How should we navigate expert and public disagreement and uncertainty about facts and values? What if emotional alignment seems to require creating or destroying entities with moral status? To what extent should designs conform to versus attempt to alter user assumptions and attitudes?
>
---
#### [new 008] Winning and losing with Artificial Intelligence: What public discourse about ChatGPT tells us about how societies make sense of technological change
- **分类: cs.CY; cs.AI; I.2; J.4; K.4.0**

- **简介: 该论文属于社会技术研究任务，探讨公众对AI技术变化的反应机制。通过分析380万条推文，研究经济利益与文化价值观如何影响人们对ChatGPT的讨论态度与参与时间。**

- **链接: [http://arxiv.org/pdf/2507.06876v1](http://arxiv.org/pdf/2507.06876v1)**

> **作者:** Adrian Rauchfleisch; Joshua Philip Suarez; Nikka Marie Sales; Andreas Jungherr
>
> **摘要:** Public product launches in Artificial Intelligence can serve as focusing events for collective attention, surfacing how societies react to technological change. Social media provide a window into the sensemaking around these events, surfacing hopes and fears and showing who chooses to engage in the discourse and when. We demonstrate that public sensemaking about AI is shaped by economic interests and cultural values of those involved. We analyze 3.8 million tweets posted by 1.6 million users across 117 countries in response to the public launch of ChatGPT in 2022. Our analysis shows how economic self-interest, proxied by occupational skill types in writing, programming, and mathematics, and national cultural orientations, as measured by Hofstede's individualism, uncertainty avoidance, and power distance dimensions, shape who speaks, when they speak, and their stance towards ChatGPT. Roles requiring more technical skills, such as programming and mathematics, tend to engage earlier and express more positive stances, whereas writing-centric occupations join later with greater skepticism. At the cultural level, individualism predicts both earlier engagement and a more negative stance, and uncertainty avoidance reduces the prevalence of positive stances but does not delay when users first engage with ChatGPT. Aggregate sentiment trends mask the dynamics observed in our study. The shift toward a more critical stance towards ChatGPT over time stems primarily from the entry of more skeptical voices rather than a change of heart among early adopters. Our findings underscore the importance of both the occupational background and cultural context in understanding public reactions to AI.
>
---
#### [new 009] Assessing the Prevalence of AI-assisted Cheating in Programming Courses: A Pilot Study
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 该论文属于教育技术领域，旨在评估AI辅助作弊在编程课程中的普遍性。通过问卷调查发现25%学生承认使用AI作弊，证明问卷是有效研究方法。**

- **链接: [http://arxiv.org/pdf/2507.06438v1](http://arxiv.org/pdf/2507.06438v1)**

> **作者:** Kaléu Delphino
>
> **备注:** 40 pages, 23 figures
>
> **摘要:** Tools that can generate computer code in response to inputs written in natural language, such as ChatGPT, pose an existential threat to Computer Science education in its current form, since students can now use these tools to solve assignments without much effort. While that risk has already been recognized by scholars, the proportion of the student body that is incurring in this new kind of plagiarism is still an open problem. We conducted a pilot study in a large CS class (n=120) to assess the feasibility of estimating AI plagiarism through anonymous surveys and interviews. More than 25% of the survey respondents admitted to committing AI plagiarism. Conversely, only one student accepted to be interviewed. Given the high levels of misconduct acknowledgment, we conclude that surveys are an effective method for studies on the matter, while interviews should be avoided or designed in a way that can entice participation.
>
---
#### [new 010] Girlhood Feminism as Soft Resistance: Affective Counterpublics and Algorithmic Negotiation on RedNote
- **分类: cs.CY**

- **简介: 该论文属于社会科学研究，探讨中国女性如何在算法限制下通过平台策略进行柔性抵抗，构建女性专属空间，解决性别权力与网络空间的关系问题。**

- **链接: [http://arxiv.org/pdf/2507.07059v1](http://arxiv.org/pdf/2507.07059v1)**

> **作者:** Meng Liang; Xiaoyue Zhang; Linqi Ye
>
> **备注:** 19 pages, 6 figures, AoIR Conference 2025
>
> **摘要:** This article explores how Chinese female users tactically mobilise platform features and hashtag practices to construct vernacular forms and an exclusive space of feminist resistance under algorithmic and cultural constraints. Focusing on the reappropriation of the hashtag Baby Supplementary Food (BSF), a female-dominated lifestyle app with over 300 million users, we analyse how users create a female-centered counterpublic through self-infantilisation, algorithmic play, and aesthetic withdrawal. Using the Computer-Assisted Learning and Measurement (CALM) framework, we analysed 1580 posts and propose the concept of girlhood feminism: an affective, culturally grounded form of soft resistance that refuses patriarchal life scripts without seeking direct confrontation or visibility. Rather than challenging censorship and misogyny directly, users rework platform affordances and domestic idioms to carve out emotional and symbolic spaces of dissent. Situated within the broader dynamics of East Asia's compressed modernity, this essay challenges liberal feminist paradigms grounded in confrontation and transparency. It advances a regionally grounded framework for understanding how gendered publics are navigated, negotiated, and quietly reimagined in algorithmically governed spaces.
>
---
#### [new 011] Domestic frontier AI regulation, an IAEA for AI, an NPT for AI, and a US-led Allied Public-Private Partnership for AI: Four institutions for governing and developing frontier AI
- **分类: cs.CY**

- **简介: 该论文属于AI治理研究，旨在解决如何安全发展前沿AI的问题。提出四个机构方案，包括国际AI机构、芯片协议及美盟合作项目，以确保AI安全可控。**

- **链接: [http://arxiv.org/pdf/2507.06379v1](http://arxiv.org/pdf/2507.06379v1)**

> **作者:** Haydn Belfield
>
> **备注:** 46 pages, 6 figures, 7 tables
>
> **摘要:** Compute governance can underpin international institutions for the governance of frontier AI. To demonstrate this I explore four institutions for governing and developing frontier AI. Next steps for compute-indexed domestic frontier AI regulation could include risk assessments and pre-approvals, data centre usage reports, and release gate regulation. Domestic regimes could be harmonized and monitored through an International AI Agency - an International Atomic Energy Agency (IAEA) for AI. This could be backed up by a Secure Chips Agreement - a Non-Proliferation Treaty (NPT) for AI. This would be a non-proliferation regime for advanced chips, building on the chip export controls - states that do not have an IAIA-certified frontier regulation regime would not be allowed to import advanced chips. Frontier training runs could be carried out by a megaproject between the USA and its allies - a US-led Allied Public-Private Partnership for frontier AI. As a project to develop advanced AI, this could have significant advantages over alternatives led by Big Tech or particular states: it could be more legitimate, secure, safe, non-adversarial, peaceful, and less prone to misuse. For each of these four scenarios, a key incentive for participation is access to the advanced AI chips that are necessary for frontier training runs and large-scale inference. Together, they can create a situation in which governments can be reassured that frontier AI is developed and deployed in a secure manner with misuse minimised and benefits widely shared. Building these institutions may take years or decades, but progress is incremental and evolutionary and the first steps have already been taken.
>
---
#### [new 012] Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles
- **分类: cs.CY; cs.AI; cs.MA**

- **简介: 该论文属于社会模拟任务，探讨LLM代理在建模中的挑战。解决LLM与建模原则不兼容的问题，通过实验揭示五个核心矛盾，提出适用场景。**

- **链接: [http://arxiv.org/pdf/2507.06310v1](http://arxiv.org/pdf/2507.06310v1)**

> **作者:** Yongchao Zeng; Calum Brown; Mark Rounsevell
>
> **摘要:** Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.
>
---
#### [new 013] Do AI tutors empower or enslave learners? Toward a critical use of AI in education
- **分类: cs.CY; cs.HC**

- **简介: 该论文属于教育技术领域，探讨AI在教育中的影响。旨在解决AI过度使用可能损害学生批判性思维的问题，分析其负面影响并提出合理使用策略。**

- **链接: [http://arxiv.org/pdf/2507.06878v1](http://arxiv.org/pdf/2507.06878v1)**

> **作者:** Lucile Favero; Juan-Antonio Pérez-Ortiz; Tanja Käser; Nuria Oliver
>
> **备注:** Applications of Generative AI to support teaching and learning in Higher Education, co-located with AIED 2025. Palermo Italy
>
> **摘要:** The increasing integration of AI tools in education presents both opportunities and challenges, particularly regarding the development of the students' critical thinking skills. This position paper argues that while AI can support learning, its unchecked use may lead to cognitive atrophy, loss of agency, emotional risks, and ethical concerns, ultimately undermining the core goals of education. Drawing on cognitive science and pedagogy, the paper explores how over-reliance on AI can disrupt meaningful learning, foster dependency and conformity, undermine the students' self-efficacy, academic integrity, and well-being, and raise concerns about questionable privacy practices. It also highlights the importance of considering the students' perspectives and proposes actionable strategies to ensure that AI serves as a meaningful support rather than a cognitive shortcut. The paper advocates for an intentional, transparent, and critically informed use of AI that empowers rather than diminishes the learner.
>
---
#### [new 014] Jolting Technologies: Superexponential Acceleration in AI Capabilities and Implications for AGI
- **分类: cs.AI; cs.CY; 68T01, 91B26, 93C15**

- **简介: 该论文属于AI发展研究任务，探讨AI能力超指数增长的假设，分析其对AGI的影响，通过理论建模与模拟验证相关机制。**

- **链接: [http://arxiv.org/pdf/2507.06398v1](http://arxiv.org/pdf/2507.06398v1)**

> **作者:** David Orban
>
> **备注:** 13 pages, 2 figures. Revised following peer review
>
> **摘要:** This paper investigates the Jolting Technologies Hypothesis, which posits superexponential growth (increasing acceleration, or a positive third derivative) in the development of AI capabilities. We develop a theoretical framework and validate detection methodologies through Monte Carlo simulations, while acknowledging that empirical validation awaits suitable longitudinal data. Our analysis focuses on creating robust tools for future empirical studies and exploring the potential implications should the hypothesis prove valid. The study examines how factors such as shrinking idea-to-action intervals and compounding iterative AI improvements drive this jolting pattern. By formalizing jolt dynamics and validating detection methods through simulation, this work provides the mathematical foundation necessary for understanding potential AI trajectories and their consequences for AGI emergence, offering insights for research and policy.
>
---
#### [new 015] Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues
- **分类: cs.CL; cs.CY**

- **简介: 该论文属于对话预测任务，旨在解决如何预测导师策略及学生结果的问题。研究使用LLMs分析数学辅导对话数据，发现现有模型在此任务上仍有不足。**

- **链接: [http://arxiv.org/pdf/2507.06910v1](http://arxiv.org/pdf/2507.06910v1)**

> **作者:** Fareya Ikram; Alexander Scarlatos; Andrew Lan
>
> **备注:** Published in BEA 2025: 20th Workshop on Innovative Use of NLP for Building Educational Applications
>
> **摘要:** Tutoring dialogues have gained significant attention in recent years, given the prominence of online learning and the emerging tutoring abilities of artificial intelligence (AI) agents powered by large language models (LLMs). Recent studies have shown that the strategies used by tutors can have significant effects on student outcomes, necessitating methods to predict how tutors will behave and how their actions impact students. However, few works have studied predicting tutor strategy in dialogues. Therefore, in this work we investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to predict both future tutor moves and student outcomes in dialogues, using two math tutoring dialogue datasets. We find that even state-of-the-art LLMs struggle to predict future tutor strategy while tutor strategy is highly indicative of student outcomes, outlining a need for more powerful methods to approach this task.
>
---
#### [new 016] Unifying Re-Identification, Attribute Inference, and Data Reconstruction Risks in Differential Privacy
- **分类: cs.LG; cs.AI; cs.CR; cs.CY; stat.ML**

- **简介: 该论文属于隐私保护任务，解决差分隐私机制难以准确评估和校准隐私风险的问题，提出统一的界限来衡量再识别、属性推断和数据重建风险。**

- **链接: [http://arxiv.org/pdf/2507.06969v1](http://arxiv.org/pdf/2507.06969v1)**

> **作者:** Bogdan Kulynych; Juan Felipe Gomez; Georgios Kaissis; Jamie Hayes; Borja Balle; Flavio du Pin Calmon; Jean Louis Raisaro
>
> **摘要:** Differentially private (DP) mechanisms are difficult to interpret and calibrate because existing methods for mapping standard privacy parameters to concrete privacy risks -- re-identification, attribute inference, and data reconstruction -- are both overly pessimistic and inconsistent. In this work, we use the hypothesis-testing interpretation of DP ($f$-DP), and determine that bounds on attack success can take the same unified form across re-identification, attribute inference, and data reconstruction risks. Our unified bounds are (1) consistent across a multitude of attack settings, and (2) tunable, enabling practitioners to evaluate risk with respect to arbitrary (including worst-case) levels of baseline risk. Empirically, our results are tighter than prior methods using $\varepsilon$-DP, R\'enyi DP, and concentrated DP. As a result, calibrating noise using our bounds can reduce the required noise by 20% at the same risk level, which yields, e.g., more than 15pp accuracy increase in a text classification task. Overall, this unifying perspective provides a principled framework for interpreting and calibrating the degree of protection in DP against specific levels of re-identification, attribute inference, or data reconstruction risk.
>
---
#### [new 017] Digital Wargames to Enhance Military Medical Evacuation Decision-Making
- **分类: cs.AI; cs.CY; cs.HC; cs.MM**

- **简介: 该论文属于军事医疗后送训练任务，旨在解决传统教学中缺乏模拟环境的问题。通过开发三维多人模拟系统MEWI，提升学员的决策能力和协作水平。**

- **链接: [http://arxiv.org/pdf/2507.06373v1](http://arxiv.org/pdf/2507.06373v1)**

> **作者:** Jeremy Fischer; Ram Krishnamoorthy; Vishal Kumar; Mahdi Al-Husseini
>
> **摘要:** Medical evacuation is one of the United States Army's most storied and critical mission sets, responsible for efficiently and expediently evacuating the battlefield ill and injured. Medical evacuation planning involves designing a robust network of medical platforms and facilities capable of moving and treating large numbers of casualties. Until now, there has not been a medium to simulate these networks in a classroom setting and evaluate both offline planning and online decision-making performance. This work describes the Medical Evacuation Wargaming Initiative (MEWI), a three-dimensional multiplayer simulation developed in Unity that replicates battlefield constraints and uncertainties. MEWI accurately models patient interactions at casualty collection points, ambulance exchange points, medical treatment facilities, and evacuation platforms. Two operational scenarios are introduced: an amphibious island assault in the Pacific and a Eurasian conflict across a sprawling road and river network. These scenarios pit students against the clock to save as many casualties as possible while adhering to doctrinal lessons learned during didactic training. We visualize performance data collected from two iterations of the MEWI Pacific scenario executed in the United States Army's Medical Evacuation Doctrine Course. We consider post-wargame Likert survey data from student participants and external observer notes to identify key planning decision points, document medical evacuation lessons learned, and quantify general utility. Results indicate that MEWI participation substantially improves uptake of medical evacuation lessons learned and co-operative decision-making. MEWI is a substantial step forward in the field of high-fidelity training tools for medical education, and our study findings offer critical insights into improving medical evacuation education and operations across the joint force.
>
---
#### [new 018] Are NFTs Ready to Keep Australian Artists Engaged?
- **分类: cs.CR; cs.CY; cs.ET**

- **简介: 该论文属于数字版权保护任务，旨在解决NFT是否能有效保护澳大利亚艺术家版权的问题。通过分析NFT结构及数据，发现其尚不成熟。**

- **链接: [http://arxiv.org/pdf/2507.06926v1](http://arxiv.org/pdf/2507.06926v1)**

> **作者:** Ruiqiang Li; Brian Yecies; Qin Wang; Shiping Chen; Jun Shen
>
> **摘要:** Non-Fungible Tokens (NFTs) offer a promising mechanism to protect Australian and Indigenous artists' copyright. They represent and transfer the value of artwork in digital form. Before adopting NFTs to protect Australian artwork, we in this paper investigate them empericially. We focus on examining the details of NFT structure. We start from the underlying structure of NFTs to show how they represent copyright for both artists and production owners, as well as how they aim to safeguard or secure the value of digital artworks. We then involve data collection from various types of sources with different storage methods, including on-chain, centralized, and decentralized systems. Based on both metadata and artwork content, we present our analysis and discussion on the following key issues: copyright, security and artist identification. The final results of the evaluation, unfortnately, show that the NFT is NOT ready to protect Australian and Indigenous artists' copyright.
>
---
#### [new 019] Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool
- **分类: cs.HC; cs.AI; cs.CL; cs.CY**

- **简介: 该论文属于AI辅助内容监测任务，旨在解决开放源代码工具与CSO协作不足的问题，通过反馈驱动改进模型，提升反民主运动监控效果。**

- **链接: [http://arxiv.org/pdf/2507.06734v1](http://arxiv.org/pdf/2507.06734v1)**

> **作者:** Milena Pustet; Elisabeth Steffen; Helena Mihaljević; Grischa Stanjek; Yannis Illies
>
> **摘要:** The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.
>
---
#### [new 020] Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice
- **分类: cs.HC; cs.AI; cs.CL; cs.CY; cs.SD; eess.AS**

- **简介: 该论文属于语音情感研究任务，旨在探索如何通过调整语音参数增强"可爱"感。研究分析了TTS和游戏角色语音，发现特定频率调整可提升kawaii效果。**

- **链接: [http://arxiv.org/pdf/2507.06235v1](http://arxiv.org/pdf/2507.06235v1)**

> **作者:** Yuto Mandai; Katie Seaborn; Tomoyasu Nakano; Xin Sun; Yijia Wang; Jun Kato
>
> **备注:** CHI '25
>
> **摘要:** "Kawaii" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet spots" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.
>
---
#### [new 021] Wallets as Universal Access Devices
- **分类: cs.CR; cs.CY; H.4.2**

- **简介: 论文探讨钱包作为Web3时代通用访问设备的角色，解决数字资产管理和身份认证问题，提出通过钱包实现安全、便捷的数字服务。**

- **链接: [http://arxiv.org/pdf/2507.06254v1](http://arxiv.org/pdf/2507.06254v1)**

> **作者:** Kim Peiter Jørgensen
>
> **备注:** 25 pages 1 figure. Accepted for Web3 Blockchain Economic Theory. Eds. Melinda Swan et al. London: World Scientific. 2026
>
> **摘要:** Wallets are access points for the digital economys value creation. Wallets for blockchains store the end-users cryptographic keys for administrating their digital assets and enable access to blockchain Web3 systems. Web3 delivers new service opportunities. This chapter focuses on the Web3 enabled release of value through the lens of wallets. Wallets may be implemented as software apps on smartphones, web apps on desktops, or hardware devices. Wallet users request high security, ease of use, and access of relevance from their wallets. Increasing connectivity, functionality, autonomy, personal support, and offline capability make the wallet into the user's Universal Access Device for any digital asset. Through wallet based services, the owner obtains enhanced digital empowerment. The new Web3 solutionareas, Identity and Decentralisation, enable considerable societal effects, and wallets are an integral part of these. One example is self sovereign identity solutions combined with wallet borne AI for personalised support, empowering the enduser beyond anything previously known. Improved welfare is foreseen globally through enlarged markets with collaborative services with drastically lowered transaction costs compared to today, the expected vastly increased levels of automation in society necessitate enhanced enduser protection. As wallets are considered a weak spot for security, improving overall security through blockchains is essential.
>
---
#### [new 022] Evaluating the Critical Risks of Amazon's Nova Premier under the Frontier Model Safety Framework
- **分类: cs.CR; cs.CY**

- **简介: 该论文属于AI安全评估任务，旨在评估Amazon Nova Premier模型在前沿模型安全框架下的风险。通过多维度测试，确认其安全性并支持公开发布。**

- **链接: [http://arxiv.org/pdf/2507.06260v1](http://arxiv.org/pdf/2507.06260v1)**

> **作者:** Satyapriya Krishna; Ninareh Mehrabi; Abhinav Mohanty; Matteo Memelli; Vincent Ponzo; Payal Motwani; Rahul Gupta
>
> **摘要:** Nova Premier is Amazon's most capable multimodal foundation model and teacher for model distillation. It processes text, images, and video with a one-million-token context window, enabling analysis of large codebases, 400-page documents, and 90-minute videos in a single prompt. We present the first comprehensive evaluation of Nova Premier's critical risk profile under the Frontier Model Safety Framework. Evaluations target three high-risk domains -- Chemical, Biological, Radiological & Nuclear (CBRN), Offensive Cyber Operations, and Automated AI R&D -- and combine automated benchmarks, expert red-teaming, and uplift studies to determine whether the model exceeds release thresholds. We summarize our methodology and report core findings. Based on this evaluation, we find that Nova Premier is safe for public release as per our commitments made at the 2025 Paris AI Safety Summit. We will continue to enhance our safety evaluation and mitigation pipelines as new risks and capabilities associated with frontier models are identified.
>
---
## 更新

#### [replaced 001] Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2306.08418v3](http://arxiv.org/pdf/2306.08418v3)**

> **作者:** Emmanouil Papadogiannakis; Nicolas Kourtellis; Panagiotis Papadopoulos; Evangelos P. Markatos
>
> **摘要:** The online advertising market has recently reached the 500 billion dollar mark. To accommodate the need to match a user with the highest bidder at a fraction of a second, it has moved towards a complex, automated and often opaque model that involves numerous agents and intermediaries. Stimulated by the lack of transparency, but also the enormous potential profits, bad actors have found ways to circumvent restrictions, and generate substantial revenue that can support websites with objectionable or even illegal content. In this work, we evaluate transparency Web standards and show how shady actors take advantage of gaps to absorb ad revenues while putting the brand safety of advertisers in danger. We collect and study a large corpus of thousands of websites and show how ad transparency standards can be abused by bad actors to obscure ad revenue flows. We show how identifier pooling can redirect ad revenues from reputable domains to notorious domains serving objectionable content, and that the phenomenon is underestimated by previous studies by a factor of 15. Finally, we publish a Web monitoring service that enhances the transparency of supply chains and business relationships between publishers and ad networks.
>
---
#### [replaced 002] Strategic Alignment Patterns in National AI Policies
- **分类: cs.CY; econ.GN; q-fin.EC**

- **链接: [http://arxiv.org/pdf/2507.05400v2](http://arxiv.org/pdf/2507.05400v2)**

> **作者:** Mohammad Hossein Azin; Hessam Zandhessami
>
> **摘要:** This paper introduces a novel visual mapping methodology for assessing strategic alignment in national artificial intelligence policies. The proliferation of AI strategies across countries has created an urgent need for analytical frameworks that can evaluate policy coherence between strategic objectives, foresight methods, and implementation instruments. Drawing on data from the OECD AI Policy Observatory, we analyze 15-20 national AI strategies using a combination of matrix-based visualization and network analysis to identify patterns of alignment and misalignment. Our findings reveal distinct alignment archetypes across governance models, with notable variations in how countries integrate foresight methodologies with implementation planning. High-coherence strategies demonstrate strong interconnections between economic competitiveness objectives and robust innovation funding instruments, while common vulnerabilities include misalignment between ethical AI objectives and corresponding regulatory frameworks. The proposed visual mapping approach offers both methodological contributions to policy analysis and practical insights for enhancing strategic coherence in AI governance. This research addresses significant gaps in policy evaluation methodology and provides actionable guidance for policymakers seeking to strengthen alignment in technological governance frameworks.
>
---
#### [replaced 003] Before & After: The Effect of EU's 2022 Code of Practice on Disinformation
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2410.11369v2](http://arxiv.org/pdf/2410.11369v2)**

> **作者:** Emmanouil Papadogiannakis; Panagiotis Papadopoulos; Nicolas Kourtellis; Evangelos P. Markatos
>
> **备注:** WWW '25: Proceedings of the ACM on Web Conference 2025
>
> **摘要:** Over the past few years, the European Commission has made significant steps to reduce disinformation in cyberspace. One of those steps has been the introduction of the 2022 "Strengthened Code of Practice on Disinformation". Signed by leading online platforms, this Strengthened Code of Practice on Disinformation is an attempt to combat disinformation on the Web. The Code of Practice includes a variety of measures including the demonetization of disinformation, urging, for example, advertisers "to avoid the placement of advertising next to Disinformation content". In this work, we set out to explore what was the impact of the Code of Practice and especially to explore to what extent ad networks continue to advertise on dis-/mis-information sites. We perform a historical analysis and find that, although at a hasty glance things may seem to be improving, there is really no significant reduction in the amount of advertising relationships among popular misinformation websites and major ad networks. In fact, we show that ad networks have withdrawn mostly from unpopular misinformation websites with very few visitors, but still form relationships with highly unreliable websites that account for the majority of misinformation traffic. To make matters worse, we show that ad networks continue to place advertisements of legitimate companies next to misinformation content. We show that major ad networks place ads in almost 400 misinformation websites in our dataset.
>
---
#### [replaced 004] Towards Collaborative Anti-Money Laundering Among Financial Institutions
- **分类: cs.SI; cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2502.19952v3](http://arxiv.org/pdf/2502.19952v3)**

> **作者:** Zhihua Tian; Yuan Ding; Wenjie Qu; Xiang Yu; Enchao Gong; Jian Liu; Kui Ren
>
> **备注:** Accepted by International World Wide Web Conference (WWW) 2025
>
> **摘要:** Money laundering is the process that intends to legalize the income derived from illicit activities, thus facilitating their entry into the monetary flow of the economy without jeopardizing their source. It is crucial to identify such activities accurately and reliably in order to enforce anti-money laundering (AML). Despite considerable efforts to AML, a large number of such activities still go undetected. Rule-based methods were first introduced and are still widely used in current detection systems. With the rise of machine learning, graph-based learning methods have gained prominence in detecting illicit accounts through the analysis of money transfer graphs. Nevertheless, these methods generally assume that the transaction graph is centralized, whereas in practice, money laundering activities usually span multiple financial institutions. Due to regulatory, legal, commercial, and customer privacy concerns, institutions tend not to share data, restricting their utility in practical usage. In this paper, we propose the first algorithm that supports performing AML over multiple institutions while protecting the security and privacy of local data. To evaluate, we construct Alipay-ECB, a real-world dataset comprising digital transactions from Alipay, the world's largest mobile payment platform, alongside transactions from E-Commerce Bank (ECB). The dataset includes over 200 million accounts and 300 million transactions, covering both intra-institution transactions and those between Alipay and ECB. This makes it the largest real-world transaction graph available for analysis. The experimental results demonstrate that our methods can effectively identify cross-institution money laundering subgroups. Additionally, experiments on synthetic datasets also demonstrate that our method is efficient, requiring only a few minutes on datasets with millions of transactions.
>
---
#### [replaced 005] Can adversarial attacks by large language models be attributed?
- **分类: cs.AI; cs.CL; cs.CY; cs.FL**

- **链接: [http://arxiv.org/pdf/2411.08003v2](http://arxiv.org/pdf/2411.08003v2)**

> **作者:** Manuel Cebrian; Andres Abeliuk; Jan Arne Telle
>
> **备注:** 21 pages, 5 figures, 2 tables
>
> **摘要:** Attributing outputs from Large Language Models (LLMs) in adversarial settings-such as cyberattacks and disinformation campaigns-presents significant challenges that are likely to grow in importance. We approach this attribution problem from both a theoretical and an empirical perspective, drawing on formal language theory (identification in the limit) and data-driven analysis of the expanding LLM ecosystem. By modeling an LLM's set of possible outputs as a formal language, we analyze whether finite samples of text can uniquely pinpoint the originating model. Our results show that, under mild assumptions of overlapping capabilities among models, certain classes of LLMs are fundamentally non-identifiable from their outputs alone. We delineate four regimes of theoretical identifiability: (1) an infinite class of deterministic (discrete) LLM languages is not identifiable (Gold's classical result from 1967); (2) an infinite class of probabilistic LLMs is also not identifiable (by extension of the deterministic case); (3) a finite class of deterministic LLMs is identifiable (consistent with Angluin's tell-tale criterion); and (4) even a finite class of probabilistic LLMs can be non-identifiable (we provide a new counterexample establishing this negative result). Complementing these theoretical insights, we quantify the explosion in the number of plausible model origins (hypothesis space) for a given output in recent years. Even under conservative assumptions-each open-source model fine-tuned on at most one new dataset-the count of distinct candidate models doubles approximately every 0.5 years, and allowing multi-dataset fine-tuning combinations yields doubling times as short as 0.28 years. This combinatorial growth, alongside the extraordinary computational cost of brute-force likelihood attribution across all models and potential users, renders exhaustive attribution infeasible in practice.
>
---
#### [replaced 006] AI Risk Atlas: Taxonomy and Tooling for Navigating AI Risks and Resources
- **分类: cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2503.05780v2](http://arxiv.org/pdf/2503.05780v2)**

> **作者:** Frank Bagehorn; Kristina Brimijoin; Elizabeth M. Daly; Jessica He; Michael Hind; Luis Garces-Erice; Christopher Giblin; Ioana Giurgiu; Jacquelyn Martino; Rahul Nair; David Piorkowski; Ambrish Rawat; John Richards; Sean Rooney; Dhaval Salwala; Seshu Tirupathi; Peter Urbanetz; Kush R. Varshney; Inge Vejsbjerg; Mira L. Wolf-Bauwens
>
> **备注:** 4.5 page main text, 22 page supporting material, 2 figures
>
> **摘要:** The rapid evolution of generative AI has expanded the breadth of risks associated with AI systems. While various taxonomies and frameworks exist to classify these risks, the lack of interoperability between them creates challenges for researchers, practitioners, and policymakers seeking to operationalise AI governance. To address this gap, we introduce the AI Risk Atlas, a structured taxonomy that consolidates AI risks from diverse sources and aligns them with governance frameworks. Additionally, we present the Risk Atlas Nexus, a collection of open-source tools designed to bridge the divide between risk definitions, benchmarks, datasets, and mitigation strategies. This knowledge-driven approach leverages ontologies and knowledge graphs to facilitate risk identification, prioritization, and mitigation. By integrating AI-assisted compliance workflows and automation strategies, our framework lowers the barrier to responsible AI adoption. We invite the broader research and open-source community to contribute to this evolving initiative, fostering cross-domain collaboration and ensuring AI governance keeps pace with technological advancements.
>
---
