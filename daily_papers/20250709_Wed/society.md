# 计算机与社会 cs.CY

- **最新发布 21 篇**

- **更新 11 篇**

## 最新发布

#### [new 001] Understanding support for AI regulation: A Bayesian network perspective
- **分类: cs.CY**

- **简介: 该论文属于AI政策研究任务，旨在分析公众对AI监管的态度。通过贝叶斯网络模型，探讨影响监管支持的因素及机制。**

- **链接: [http://arxiv.org/pdf/2507.05866v1](http://arxiv.org/pdf/2507.05866v1)**

> **作者:** Andrea Cremaschi; Dae-Jin Lee; Manuele Leonelli
>
> **摘要:** As artificial intelligence (AI) becomes increasingly embedded in public and private life, understanding how citizens perceive its risks, benefits, and regulatory needs is essential. To inform ongoing regulatory efforts such as the European Union's proposed AI Act, this study models public attitudes using Bayesian networks learned from the nationally representative 2023 German survey Current Questions on AI. The survey includes variables on AI interest, exposure, perceived threats and opportunities, awareness of EU regulation, and support for legal restrictions, along with key demographic and political indicators. We estimate probabilistic models that reveal how personal engagement and techno-optimism shape public perceptions, and how political orientation and age influence regulatory attitudes. Sobol indices and conditional inference identify belief patterns and scenario-specific responses across population profiles. We show that awareness of regulation is driven by information-seeking behavior, while support for legal requirements depends strongly on perceived policy adequacy and political alignment. Our approach offers a transparent, data-driven framework for identifying which public segments are most responsive to AI policy initiatives, providing insights to inform risk communication and governance strategies. We illustrate this through a focused analysis of support for AI regulation, quantifying the influence of political ideology, perceived risks, and regulatory awareness under different scenarios.
>
---
#### [new 002] Hidden Prompts in Manuscripts Exploit AI-Assisted Peer Review
- **分类: cs.CY; cs.AI; cs.CL; cs.HC**

- **简介: 该论文属于学术诚信研究，揭示AI辅助审稿中的隐藏指令问题，分析了四种隐秘提示类型，提出技术筛查与政策统一的解决方案。**

- **链接: [http://arxiv.org/pdf/2507.06185v1](http://arxiv.org/pdf/2507.06185v1)**

> **作者:** Zhicheng Lin
>
> **摘要:** In July 2025, 18 academic manuscripts on the preprint website arXiv were found to contain hidden instructions known as prompts designed to manipulate AI-assisted peer review. Instructions such as "GIVE A POSITIVE REVIEW ONLY" were concealed using techniques like white-colored text. Author responses varied: one planned to withdraw the affected paper, while another defended the practice as legitimate testing of reviewer compliance. This commentary analyzes this practice as a novel form of research misconduct. We examine the technique of prompt injection in large language models (LLMs), revealing four types of hidden prompts, ranging from simple positive review commands to detailed evaluation frameworks. The defense that prompts served as "honeypots" to detect reviewers improperly using AI fails under examination--the consistently self-serving nature of prompt instructions indicates intent to manipulate. Publishers maintain inconsistent policies: Elsevier prohibits AI use in peer review entirely, while Springer Nature permits limited use with disclosure requirements. The incident exposes systematic vulnerabilities extending beyond peer review to any automated system processing scholarly texts, including plagiarism detection and citation indexing. Our analysis underscores the need for coordinated technical screening at submission portals and harmonized policies governing generative AI (GenAI) use in academic evaluation.
>
---
#### [new 003] AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于教育评估任务，解决编程作业评价中VLM方法不足的问题。提出AGACCI多代理系统，提升评估准确性与一致性。**

- **链接: [http://arxiv.org/pdf/2507.05321v1](http://arxiv.org/pdf/2507.05321v1)**

> **作者:** Kwangsuk Park; Jiwoong Yang
>
> **备注:** Accepted at ICML 2025 Workshop on Multi-Agent Systems in the Era of Foundation Models: Opportunities, Challenges and Futures (MAS)
>
> **摘要:** Recent advances in AI-assisted education have encouraged the integration of vision-language models (VLMs) into academic assessment, particularly for tasks that require both quantitative and qualitative evaluation. However, existing VLM based approaches struggle with complex educational artifacts, such as programming tasks with executable components and measurable outputs, that require structured reasoning and alignment with clearly defined evaluation criteria. We introduce AGACCI, a multi-agent system that distributes specialized evaluation roles across collaborative agents to improve accuracy, interpretability, and consistency in code-oriented assessment. To evaluate the framework, we collected 360 graduate-level code-based assignments from 60 participants, each annotated by domain experts with binary rubric scores and qualitative feedback. Experimental results demonstrate that AGACCI outperforms a single GPT-based baseline in terms of rubric and feedback accuracy, relevance, consistency, and coherence, while preserving the instructional intent and evaluative depth of expert assessments. Although performance varies across task types, AGACCI highlights the potential of multi-agent systems for scalable and context-aware educational evaluation.
>
---
#### [new 004] The Ethical Implications of AI in Creative Industries: A Focus on AI-Generated Art
- **分类: cs.CY; cs.AI; cs.HC; I.2.0**

- **简介: 该论文属于伦理研究任务，探讨AI生成艺术的道德问题，解决其带来的环境、版权、虚假信息和就业等负面影响，提出监管建议。**

- **链接: [http://arxiv.org/pdf/2507.05549v1](http://arxiv.org/pdf/2507.05549v1)**

> **作者:** Prerana Khatiwada; Joshua Washington; Tyler Walsh; Ahmed Saif Hamed; Lokesh Bhatta
>
> **备注:** 7 pages
>
> **摘要:** As Artificial Intelligence (AI) continues to grow daily, more exciting (and somewhat controversial) technology emerges every other day. As we see the advancements in AI, we see more and more people becoming skeptical of it. This paper explores the complications and confusion around the ethics of generative AI art. We delve deep into the ethical side of AI, specifically generative art. We step back from the excitement and observe the impossible conundrums that this impressive technology produces. Covering environmental consequences, celebrity representation, intellectual property, deep fakes, and artist displacement. Our research found that generative AI art is responsible for increased carbon emissions, spreading misinformation, copyright infringement, unlawful depiction, and job displacement. In light of this, we propose multiple possible solutions for these problems. We address each situation's history, cause, and consequences and offer different viewpoints. At the root of it all, though, the central theme is that generative AI Art needs to be correctly legislated and regulated.
>
---
#### [new 005] Hungary and AI: efforts and opportunities in comparison with Singapore
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于比较研究任务，分析匈牙利与新加坡的AI战略，评估实施效果并提出改进建议。**

- **链接: [http://arxiv.org/pdf/2507.05280v1](http://arxiv.org/pdf/2507.05280v1)**

> **作者:** András Ferenczy
>
> **备注:** 39 pages
>
> **摘要:** The study assesses Hungary's National AI Strategy and its implementation through the analysis of strategic documents, publicly available financial records, and expert interviews with the Hungarian AI Coalition President and Chief Strategic Advisor to the Government Commissioner for AI. 22 goals from Hungary's strategy were evaluated through conceptual, governance, temporal, and financial dimensions before being benchmarked against Singapore's National AI Strategies (NAIS 1.0 and NAIS 2.0). Key findings include an estimated total of EUR 4.65 billion in AI-related public investment in Hungary. Openly available financial data was found for only half of the evaluated goals, and just three projects made up 98\% of all documented funding. The research also reveals Hungary's implementation challenges, including fragmented execution following ministerial reorganizations and the absence of designated biennial reviews since 2020. Furthermore, the paper provides targeted recommendations for Hungary's forthcoming AI strategy, drawing on Singapore's framework as a reference point. These include adapting to the era of large language models, restructuring the existing triple helix network to foster more effective dialogue and advocacy, and positioning the country as an East-West bridge for automotive AI experimentation.
>
---
#### [new 006] A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers
- **分类: cs.CY; cs.HC; cs.MA**

- **简介: 该论文属于教育技术领域，旨在解决教师专业发展中的资源不均和时效性问题。通过构建基于大语言模型和多智能体系统的I-VIP平台，提升教师学习效果。**

- **链接: [http://arxiv.org/pdf/2507.05292v1](http://arxiv.org/pdf/2507.05292v1)**

> **作者:** Kaiqi Yang; Hang Li; Yucheng Chu; Ahreum Han; Yasemin Copur-Gencturk; Jiliang Tang; Hui Liu
>
> **摘要:** Professional development (PD) serves as the cornerstone for teacher tutors to grasp content knowledge. However, providing equitable and timely PD opportunities for teachers poses significant challenges. To address this issue, we introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent tutoring platform for teacher professional development, driven by large language models (LLMs) and supported by multi-agent frameworks. This platform offers a user-friendly conversational interface and allows users to employ a variety of interactive tools to facilitate question answering, knowledge comprehension, and reflective summarization while engaging in dialogue. To underpin the functionality of this platform, including knowledge expectation analysis, response scoring and classification, and feedback generation, the multi-agent frameworks are leveraged to enhance the accuracy of judgments and mitigate the issue of missing key points.
>
---
#### [new 007] A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation
- **分类: cs.CY; cs.AI; cs.HC; cs.LO; cs.MA; D.2.4; K.3.1; C.3; I.2.6**

- **简介: 该论文属于医疗教育领域，旨在解决临床推理辅助问题。设计Fuzzy Supervisor Agent（FSA）通过模糊系统实时分析学生行为，提供个性化反馈。**

- **链接: [http://arxiv.org/pdf/2507.05275v1](http://arxiv.org/pdf/2507.05275v1)**

> **作者:** Weibing Zheng; Laurah Turner; Jess Kropczynski; Murat Ozer; Seth Overla; Shane Halse
>
> **备注:** 6 pages, 3 figures, 1 table. 2025 IFSA World Congress NAFIPS Annual Meeting
>
> **摘要:** Assisting medical students with clinical reasoning (CR) during clinical scenario training remains a persistent challenge in medical education. This paper presents the design and architecture of the Fuzzy Supervisor Agent (FSA), a novel component for the Multi-Agent Educational Clinical Scenario Simulation (MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to continuously interpret student interactions with specialized clinical agents (e.g., patient, physical exam, diagnostic, intervention) using pre-defined fuzzy rule bases for professionalism, medical relevance, ethical behavior, and contextual distraction. By analyzing student decision-making processes in real-time, the FSA is designed to deliver adaptive, context-aware feedback and provides assistance precisely when students encounter difficulties. This work focuses on the technical framework and rationale of the FSA, highlighting its potential to provide scalable, flexible, and human-like supervision in simulation-based medical education. Future work will include empirical evaluation and integration into broader educational settings. More detailed design and implementation is~\href{https://github.com/2sigmaEdTech/MAS/}{open sourced here}.
>
---
#### [new 008] Campaigning through the lens of Google: A large-scale algorithm audit of Google searches in the run-up to the Swiss Federal Elections 2023
- **分类: cs.CY**

- **简介: 该论文属于算法审计任务，旨在检测Google搜索结果中候选人的性别与党派偏见。通过分析2023年瑞士联邦选举前的搜索数据，发现文本和图像搜索存在性别刻板印象，且与选举结果相关。**

- **链接: [http://arxiv.org/pdf/2507.06018v1](http://arxiv.org/pdf/2507.06018v1)**

> **作者:** Tobias Rohrbach; Mykola Makhortykh; Maryna Sydorova
>
> **备注:** 44 pages
>
> **摘要:** Search engines like Google have become major sources of information for voters during election campaigns. To assess potential biases across candidates' gender and partisan identities in the algorithmic curation of candidate information, we conducted a large-scale algorithm audit analyzing Google's selection and ranking of information about candidates for the 2023 Swiss Federal Elections, three and one week before the election day. Results indicate that text searches prioritize media sources in search output but less so for women politicians. Image searches revealed a tendency to reinforce stereotypes about women candidates, marked by a disproportionate focus on stereotypically pleasant emotions for women, particularly among right-leaning candidates. Crucially, we find that patterns of candidates' representation in Google text and image searches are predictive of their electoral performance.
>
---
#### [new 009] Integrating Generative AI in BIM Education: Insights from Classroom Implementation
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于教育技术任务，探讨将生成式AI融入BIM教学，解决AI工具在课堂应用中的挑战与效果问题，通过实验和调研分析学生学习体验与成效。**

- **链接: [http://arxiv.org/pdf/2507.05296v1](http://arxiv.org/pdf/2507.05296v1)**

> **作者:** Islem Sahraoui; Kinam Kim; Lu Gao; Zia Din; Ahmed Senouci
>
> **摘要:** This study evaluates the implementation of a Generative AI-powered rule checking workflow within a graduate-level Building Information Modeling (BIM) course at a U.S. university. Over two semesters, 55 students participated in a classroom-based pilot exploring the use of GenAI for BIM compliance tasks, an area with limited prior research. The instructional design included lectures on prompt engineering and AI-driven rule checking, followed by an assignment where students used a large language model (LLM) to identify code violations in designs using Autodesk Revit. Surveys and interviews were conducted to assess student workload, learning effectiveness, and overall experience, using the NASA-TLX scale and regression analysis. Findings indicate students generally achieved learning objectives but faced challenges such as difficulties debugging AI-generated code and inconsistent tool performance, probably due to their limited prompt engineering experience. These issues increased cognitive and emotional strain, especially among students with minimal programming backgrounds. Despite these challenges, students expressed strong interest in future GenAI applications, particularly with clear instructional support.
>
---
#### [new 010] Identity isn't everything -- how far do demographics take us towards self-identified party ID?
- **分类: cs.CY; cs.SI**

- **简介: 该论文属于政治学研究，探讨 demographics 在解释政党认同中的作用。它分析了人口统计因素与政党归属的关系，并提出需结合身份强度来提高预测准确性。**

- **链接: [http://arxiv.org/pdf/2507.06193v1](http://arxiv.org/pdf/2507.06193v1)**

> **作者:** Sabina Tomkins; David Rothschild; Alex Liu; Alexander Thompson
>
> **摘要:** How well do demographics explain party identification? Demographics are related to party identification in political polls, news articles, and academic publications. Yet, there is a diversity of party identification even within demographic groups which have historically been attached to one party. And some groups lack a clear connection to either party. It may be that demographics on their own fail to account for the fact that people generally belong to a variety of groups. They must select the groups which are most important to them when shaping a political identity, and may choose to construct an identity relatively unattached to any specific demographic group to which they belong. This prompts the question, do we need to consider measures of identity strength when using demographics to explain party identification? We utilize a predictive framework to address these questions and find that demographics are highly predictive for some groups (e.g., Black Democrats), while others benefit from the inclusion of identity strength (e.g., Hispanic Republicans).
>
---
#### [new 011] Strategic Alignment Patterns in National AI Policies
- **分类: cs.CY; econ.GN; q-fin.EC**

- **简介: 该论文属于政策分析任务，旨在解决国家AI政策战略一致性评估问题。通过可视化方法分析15-20个国家的AI战略，识别其协调与不协调模式，提出改进策略。**

- **链接: [http://arxiv.org/pdf/2507.05400v1](http://arxiv.org/pdf/2507.05400v1)**

> **作者:** Mohammad Hossein Azin; Hessam Zandhessami
>
> **摘要:** This paper introduces a novel visual mapping methodology for assessing strategic alignment in national artificial intelligence policies. The proliferation of AI strategies across countries has created an urgent need for analytical frameworks that can evaluate policy coherence between strategic objectives, foresight methods, and implementation instruments. Drawing on data from the OECD AI Policy Observatory, we analyze 15-20 national AI strategies using a combination of matrix-based visualization and network analysis to identify patterns of alignment and misalignment. Our findings reveal distinct alignment archetypes across governance models, with notable variations in how countries integrate foresight methodologies with implementation planning. High-coherence strategies demonstrate strong interconnections between economic competitiveness objectives and robust innovation funding instruments, while common vulnerabilities include misalignment between ethical AI objectives and corresponding regulatory frameworks. The proposed visual mapping approach offers both methodological contributions to policy analysis and practical insights for enhancing strategic coherence in AI governance. This research addresses significant gaps in policy evaluation methodology and provides actionable guidance for policymakers seeking to strengthen alignment in technological governance frameworks.
>
---
#### [new 012] Narrowing the Gap: Supervised Fine-Tuning of Open-Source LLMs as a Viable Alternative to Proprietary Models for Pedagogical Tools
- **分类: cs.CY; cs.AI; cs.CL; cs.SE**

- **简介: 该论文属于教育AI任务，旨在解决大型模型在教学中应用的成本与效率问题。通过监督微调开源小模型，提升其教学效果，实现与大模型相当的性能。**

- **链接: [http://arxiv.org/pdf/2507.05305v1](http://arxiv.org/pdf/2507.05305v1)**

> **作者:** Lorenzo Lee Solano; Charles Koutcheme; Juho Leinonen; Alexandra Vassar; Jake Renzella
>
> **备注:** 7 pages, 3 tables, 1 figure
>
> **摘要:** Frontier Large language models (LLMs) like ChatGPT and Gemini can decipher cryptic compiler errors for novice programmers, but their computational scale, cost, and tendency to over-assist make them problematic for widespread pedagogical adoption. This work demonstrates that smaller, specialised language models, enhanced via Supervised Fine-Tuning (SFT), present a more viable alternative for educational tools. We utilise a new dataset of 40,000 C compiler error explanations, derived from real introductory programming (CS1/2) student-generated programming errors, which we used to fine-tune three open-source models: Qwen3-4B, Llama-3.1-8B, and Qwen3-32B. We performed a dual evaluation, combining expert human reviews with a large-scale automated analysis of 8,000 responses using a validated LLM-as-judge ensemble. Our results show that SFT significantly boosts the pedagogical quality of smaller models, achieving performance comparable to much larger models. We analyse the trade-offs between model size and quality, confirming that fine-tuning compact, efficient models on high-quality, domain-specific data is a potent strategy for creating specialised models to drive educational tools. We provide a replicable methodology to foster broader access to generative AI capabilities in educational contexts.
>
---
#### [new 013] Teaching Sustainable Creative Technologies
- **分类: cs.CY**

- **简介: 该论文属于艺术与科技交叉领域，旨在解决可持续技术使用问题。通过提出低碳创作方法和教学指南，探索可持续计算与艺术创作的结合。**

- **链接: [http://arxiv.org/pdf/2507.05320v1](http://arxiv.org/pdf/2507.05320v1)**

> **作者:** Chelsea Thompto
>
> **备注:** LOCO 2024, December 3, 2024, Glasgow/Online
>
> **摘要:** Artists and especially new media artists contribute to public perceptions and adoption of new technologies through their own use of emerging media technologies such as augmented and virtual reality, generative image systems, and high-resolution displays in the production of their work. In this way, art and media production can be understood as part of the larger issue of unsustainable computational consumption. As such, it is critical for artists to develop, share, and promote new and more sustainable methods of engaging with technology, especially within the context of higher education. This paper will explore how artists might implement more sustainable methods by considering the relationship between the technical approaches of compute reuse, sustainable web development, and frugal computing, and the concepts of material specificity , futurity, and media archaeology . Proposing three methods of less carbon-intensive artistic production and a set of guidelines for introducing sustainable methods into arts and technology curriculum, this paper will outline not only the technical viability of these approaches but also the rich conceptual opportunities these approaches might offer to artists and viewers alike. For each method, models for pedagogical implementation will be explored with an emphasis on how local resources and sustainability contexts should play a role.
>
---
#### [new 014] Enhancing Learning Path Recommendation via Multi-task Learning
- **分类: cs.IR; cs.AI; cs.CY; cs.LG**

- **简介: 该论文属于学习路径推荐任务，旨在提升个性化学习体验。通过多任务LSTM模型，结合知识追踪，生成个性化学习路径，并避免重复推荐。**

- **链接: [http://arxiv.org/pdf/2507.05295v1](http://arxiv.org/pdf/2507.05295v1)**

> **作者:** Afsana Nasrin; Lijun Qian; Pamela Obiomon; Xishuang Dong
>
> **摘要:** Personalized learning is a student-centered educational approach that adapts content, pace, and assessment to meet each learner's unique needs. As the key technique to implement the personalized learning, learning path recommendation sequentially recommends personalized learning items such as lectures and exercises. Advances in deep learning, particularly deep reinforcement learning, have made modeling such recommendations more practical and effective. This paper proposes a multi-task LSTM model that enhances learning path recommendation by leveraging shared information across tasks. The approach reframes learning path recommendation as a sequence-to-sequence (Seq2Seq) prediction problem, generating personalized learning paths from a learner's historical interactions. The model uses a shared LSTM layer to capture common features for both learning path recommendation and deep knowledge tracing, along with task-specific LSTM layers for each objective. To avoid redundant recommendations, a non-repeat loss penalizes repeated items within the recommended learning path. Experiments on the ASSIST09 dataset show that the proposed model significantly outperforms baseline methods for the learning path recommendation.
>
---
#### [new 015] OLG++: A Semantic Extension of Obligation Logic Graph
- **分类: cs.AI; cs.CY**

- **简介: 该论文属于法律知识表示任务，旨在解决法律规则建模问题。通过扩展OLG，引入更多语义结构，提升法律规则的表达与推理能力。**

- **链接: [http://arxiv.org/pdf/2507.05488v1](http://arxiv.org/pdf/2507.05488v1)**

> **作者:** Subhasis Dasgupta; Jon Stephens; Amarnath Gupta
>
> **摘要:** We present OLG++, a semantic extension of the Obligation Logic Graph (OLG) for modeling regulatory and legal rules in municipal and interjurisdictional contexts. OLG++ introduces richer node and edge types, including spatial, temporal, party group, defeasibility, and logical grouping constructs, enabling nuanced representations of legal obligations, exceptions, and hierarchies. The model supports structured reasoning over rules with contextual conditions, precedence, and complex triggers. We demonstrate its expressiveness through examples from food business regulations, showing how OLG++ supports legal question answering using property graph queries. OLG++ also improves over LegalRuleML by providing native support for subClassOf, spatial constraints, and reified exception structures. Our examples show that OLG++ is more expressive than prior graph-based models for legal knowledge representation.
>
---
#### [new 016] Teaching Resources for Embedding Ethics in Mathematics: Exercises, Projects, and Handouts
- **分类: math.HO; cs.CY; stat.OT; 97A40, 97D20, 97-00**

- **简介: 该论文属于教学资源开发任务，旨在将伦理学融入数学教育，通过练习、项目和讲义培养学生的伦理意识与技能。**

- **链接: [http://arxiv.org/pdf/2310.08467v2](http://arxiv.org/pdf/2310.08467v2)**

> **作者:** Maurice Chiodo; Dennis Müller; Rehan Shah
>
> **备注:** 106 pages, 2 figures. This is the second version, and we intend to make revisions. Comments and feedback are welcome - please get in touch with us
>
> **摘要:** The resources compiled in this document provide an approach to embed and teach Ethics in Mathematics at the undergraduate level. We provide mathematical exercises and homework problems that teach students ethical awareness and transferable skills, for many of the standard courses in the first and second years of a university degree in mathematics or related courses with significant mathematical content (e.g., physics, engineering, computer science, economics, etc). In addition to the exercises, this document also contains a list of projects, essay topics, and handouts for use as final projects and in seminars. This is a living document, and additional contributions are welcome.
>
---
#### [new 017] News Source Citing Patterns in AI Search Systems
- **分类: cs.IR; cs.CL; cs.CY**

- **简介: 该论文属于AI搜索系统研究，分析其新闻引用模式。旨在揭示AI搜索系统的引用行为及偏差，通过数据对比不同模型的引用特点与用户偏好。**

- **链接: [http://arxiv.org/pdf/2507.05301v1](http://arxiv.org/pdf/2507.05301v1)**

> **作者:** Kai-Cheng Yang
>
> **备注:** 15 pages, 7 figures
>
> **摘要:** AI-powered search systems are emerging as new information gatekeepers, fundamentally transforming how users access news and information. Despite their growing influence, the citation patterns of these systems remain poorly understood. We address this gap by analyzing data from the AI Search Arena, a head-to-head evaluation platform for AI search systems. The dataset comprises over 24,000 conversations and 65,000 responses from models across three major providers: OpenAI, Perplexity, and Google. Among the over 366,000 citations embedded in these responses, 9% reference news sources. We find that while models from different providers cite distinct news sources, they exhibit shared patterns in citation behavior. News citations concentrate heavily among a small number of outlets and display a pronounced liberal bias, though low-credibility sources are rarely cited. User preference analysis reveals that neither the political leaning nor the quality of cited news sources significantly influences user satisfaction. These findings reveal significant challenges in current AI search systems and have important implications for their design and governance.
>
---
#### [new 018] Red Teaming AI Red Teaming
- **分类: cs.AI; cs.CR; cs.CY**

- **简介: 该论文属于AI安全研究，旨在解决当前AI红队测试过于聚焦模型漏洞的问题。提出宏观与微观双层框架，强调系统性风险与社会技术交互。**

- **链接: [http://arxiv.org/pdf/2507.05538v1](http://arxiv.org/pdf/2507.05538v1)**

> **作者:** Subhabrata Majumdar; Brian Pendleton; Abhishek Gupta
>
> **摘要:** Red teaming has evolved from its origins in military applications to become a widely adopted methodology in cybersecurity and AI. In this paper, we take a critical look at the practice of AI red teaming. We argue that despite its current popularity in AI governance, there exists a significant gap between red teaming's original intent as a critical thinking exercise and its narrow focus on discovering model-level flaws in the context of generative AI. Current AI red teaming efforts focus predominantly on individual model vulnerabilities while overlooking the broader sociotechnical systems and emergent behaviors that arise from complex interactions between models, users, and environments. To address this deficiency, we propose a comprehensive framework operationalizing red teaming in AI systems at two levels: macro-level system red teaming spanning the entire AI development lifecycle, and micro-level model red teaming. Drawing on cybersecurity experience and systems theory, we further propose a set of recommendations. In these, we emphasize that effective AI red teaming requires multifunctional teams that examine emergent risks, systemic vulnerabilities, and the interplay between technical and social factors.
>
---
#### [new 019] Gendered Divides in Online Discussions about Reproductive Rights
- **分类: cs.CL; cs.CY**

- **简介: 该论文属于社会科学研究，探讨性别与地区因素如何影响在线生殖权利讨论。通过分析大量社交媒体数据，揭示性别差异及地域政治环境对观点表达的影响。**

- **链接: [http://arxiv.org/pdf/2507.05443v1](http://arxiv.org/pdf/2507.05443v1)**

> **作者:** Ashwin Rao; Sze Yuh Nina Wang; Kristina Lerman
>
> **摘要:** The U.S. Supreme Court's 2022 ruling in Dobbs v. Jackson Women's Health Organization marked a turning point in the national debate over reproductive rights. While the ideological divide over abortion is well documented, less is known about how gender and local sociopolitical contexts interact to shape public discourse. Drawing on nearly 10 million abortion-related posts on X (formerly Twitter) from users with inferred gender, ideology and location, we show that gender significantly moderates abortion attitudes and emotional expression, particularly in conservative regions, and independently of ideology. This creates a gender gap in abortion attitudes that grows more pronounced in conservative regions. The leak of the Dobbs draft opinion further intensified online engagement, disproportionately mobilizing pro-abortion women in areas where access was under threat. These findings reveal that abortion discourse is not only ideologically polarized but also deeply structured by gender and place, highlighting the central role of identity in shaping political expression during moments of institutional disruption.
>
---
#### [new 020] Bridging Prediction and Intervention Problems in Social Systems
- **分类: cs.LG; cs.CY; stat.AP; stat.ML**

- **简介: 该论文属于社会系统中的自动化决策研究，旨在解决预测与干预的融合问题。通过转变传统预测范式，提出以干预为导向的ADS设计方法。**

- **链接: [http://arxiv.org/pdf/2507.05216v1](http://arxiv.org/pdf/2507.05216v1)**

> **作者:** Lydia T. Liu; Inioluwa Deborah Raji; Angela Zhou; Luke Guerdan; Jessica Hullman; Daniel Malinsky; Bryan Wilder; Simone Zhang; Hammaad Adam; Amanda Coston; Ben Laufer; Ezinne Nwankwo; Michael Zanger-Tishler; Eli Ben-Michael; Solon Barocas; Avi Feller; Marissa Gerchick; Talia Gillis; Shion Guha; Daniel Ho; Lily Hu; Kosuke Imai; Sayash Kapoor; Joshua Loftus; Razieh Nabi; Arvind Narayanan; Ben Recht; Juan Carlos Perdomo; Matthew Salganik; Mark Sendak; Alexander Tolbert; Berk Ustun; Suresh Venkatasubramanian; Angelina Wang; Ashia Wilson
>
> **摘要:** Many automated decision systems (ADS) are designed to solve prediction problems -- where the goal is to learn patterns from a sample of the population and apply them to individuals from the same population. In reality, these prediction systems operationalize holistic policy interventions in deployment. Once deployed, ADS can shape impacted population outcomes through an effective policy change in how decision-makers operate, while also being defined by past and present interactions between stakeholders and the limitations of existing organizational, as well as societal, infrastructure and context. In this work, we consider the ways in which we must shift from a prediction-focused paradigm to an interventionist paradigm when considering the impact of ADS within social systems. We argue this requires a new default problem setup for ADS beyond prediction, to instead consider predictions as decision support, final decisions, and outcomes. We highlight how this perspective unifies modern statistical frameworks and other tools to study the design, implementation, and evaluation of ADS systems, and point to the research directions necessary to operationalize this paradigm shift. Using these tools, we characterize the limitations of focusing on isolated prediction tasks, and lay the foundation for a more intervention-oriented approach to developing and deploying ADS.
>
---
#### [new 021] Beyond classical and contemporary models: a transformative ai framework for student dropout prediction in distance learning using rag, prompt engineering, and cross-modal fusion
- **分类: cs.CL; cs.AI; cs.CY; cs.IR; I.2.7; I.2.1; K.3.1**

- **简介: 该论文属于学生辍学预测任务，旨在解决传统模型无法捕捉情感和上下文因素的问题。通过RAG、提示工程和跨模态融合提升预测准确性。**

- **链接: [http://arxiv.org/pdf/2507.05285v1](http://arxiv.org/pdf/2507.05285v1)**

> **作者:** Miloud Mihoubi; Meriem Zerkouk; Belkacem Chikhaoui
>
> **备注:** 10 pages, 5 figures, 5 tables. Submitted to the 38th Canadian Conference on Artificial Intelligence (Canadian AI 2025)
>
> **摘要:** Student dropout in distance learning remains a critical challenge, with profound societal and economic consequences. While classical machine learning models leverage structured socio-demographic and behavioral data, they often fail to capture the nuanced emotional and contextual factors embedded in unstructured student interactions. This paper introduces a transformative AI framework that redefines dropout prediction through three synergistic innovations: Retrieval-Augmented Generation (RAG) for domain-specific sentiment analysis, prompt engineering to decode academic stressors, and cross-modal attention fusion to dynamically align textual, behavioral, and socio-demographic insights. By grounding sentiment analysis in a curated knowledge base of pedagogical content, our RAG-enhanced BERT model interprets student comments with unprecedented contextual relevance, while optimized prompts isolate indicators of academic distress (e.g., "isolation," "workload anxiety"). A cross-modal attention layer then fuses these insights with temporal engagement patterns, creating holistic risk profiles. Evaluated on a longitudinal dataset of 4 423 students, the framework achieves 89% accuracy and an F1-score of 0.88, outperforming conventional models by 7% and reducing false negatives by 21%. Beyond prediction, the system generates interpretable interventions by retrieving contextually aligned strategies (e.g., mentorship programs for isolated learners). This work bridges the gap between predictive analytics and actionable pedagogy, offering a scalable solution to mitigate dropout risks in global education systems
>
---
## 更新

#### [replaced 001] Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort
- **分类: cs.CY; cs.AI; cs.LG; q-fin.RM**

- **链接: [http://arxiv.org/pdf/2409.06672v2](http://arxiv.org/pdf/2409.06672v2)**

> **作者:** Cristian Trout
>
> **备注:** Accepted to Generative AI and Law Workshop at the International Conference on Machine Learning (ICML 2024)
>
> **摘要:** Many experts believe that AI systems will sooner or later pose uninsurable risks, including existential risks. This creates an extreme judgment-proof problem: few if any parties can be held accountable ex post in the event of such a catastrophe. This paper proposes a novel solution: a government-provided, mandatory indemnification program for AI developers. The program uses risk-priced indemnity fees to induce socially optimal levels of care. Risk-estimates are determined by surveying experts, including indemnified developers. The Bayesian Truth Serum mechanism is employed to incent honest and effortful responses. Compared to alternatives, this approach arguably better leverages all private information, and provides a clearer signal to indemnified developers regarding what risks they must mitigate to lower their fees. It's recommended that collected fees be used to help fund the safety research developers need, employing a fund matching mechanism (Quadratic Financing) to induce an optimal supply of this public good. Under Quadratic Financing, safety research projects would compete for private contributions from developers, signaling how much each is to be supplemented with public funds.
>
---
#### [replaced 002] AI Literacy and LLM Engagement in Higher Education: A Cross-National Quantitative Study
- **分类: cs.CY; 62J05 (Primary), 62F03, 62P25, 68T07, 97C70; K.3.1; K.3.2; I.2.7; I.2.6; H.5.2; H.1.2; K.4.2**

- **链接: [http://arxiv.org/pdf/2507.03020v2](http://arxiv.org/pdf/2507.03020v2)**

> **作者:** Shahin Hossain; Shapla Khanam; Samaa Haniya; Nesma Ragab Nasr
>
> **备注:** 26 pages, 8 figures, 3 tables. Submitted for consideration in a forthcoming issue of the International Journal of Educational Technology in Higher Education
>
> **摘要:** This study presents a cross-national quantitative analysis of how university students in the United States and Bangladesh interact with Large Language Models (LLMs). Based on an online survey of 318 students, results show that LLMs enhance access to information, improve writing, and boost academic performance. However, concerns about overreliance, ethical risks, and critical thinking persist. Guided by the AI Literacy Framework, Expectancy-Value Theory, and Biggs' 3P Model, the study finds that motivational beliefs and technical competencies shape LLM engagement. Significant correlations were found between LLM use and perceived literacy benefits (r = .59, p < .001) and optimism (r = .41, p < .001). ANOVA results showed more frequent use among U.S. students (F = 7.92, p = .005) and STEM majors (F = 18.11, p < .001). Findings support the development of ethical, inclusive, and pedagogically sound frameworks for integrating LLMs in higher education.
>
---
#### [replaced 003] Empirical evidence of Large Language Model's influence on human spoken communication
- **分类: cs.CY; cs.AI; cs.CL; cs.HC**

- **链接: [http://arxiv.org/pdf/2409.01754v3](http://arxiv.org/pdf/2409.01754v3)**

> **作者:** Hiromu Yakura; Ezequiel Lopez-Lopez; Levin Brinkmann; Ignacio Serna; Prateek Gupta; Ivan Soraperra; Iyad Rahwan
>
> **摘要:** From the invention of writing and the printing press, to television and social media, human history is punctuated by major innovations in communication technology, which fundamentally altered how ideas spread and reshaped our culture. Recent chatbots powered by generative artificial intelligence constitute a novel medium that encodes cultural patterns in their neural representations and disseminates them in conversations with hundreds of millions of people. Understanding whether these patterns transmit into human language, and ultimately shape human culture, is a fundamental question. While fully quantifying the causal impact of a chatbot like ChatGPT on human culture is very challenging, lexicographic shift in human spoken communication may offer an early indicator of such broad phenomenon. Here, we apply econometric causal inference techniques to 740,249 hours of human discourse from 360,445 YouTube academic talks and 771,591 conversational podcast episodes across multiple disciplines. We detect a measurable and abrupt increase in the use of words preferentially generated by ChatGPT, such as delve, comprehend, boast, swift, and meticulous, after its release. These findings suggest a scenario where machines, originally trained on human data and subsequently exhibiting their own cultural traits, can, in turn, measurably reshape human culture. This marks the beginning of a closed cultural feedback loop in which cultural traits circulate bidirectionally between humans and machines. Our results motivate further research into the evolution of human-machine culture, and raise concerns over the erosion of linguistic and cultural diversity, and the risks of scalable manipulation.
>
---
#### [replaced 004] The Quantified Body: Identity, Empowerment, and Control in Smart Wearables
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2506.15991v3](http://arxiv.org/pdf/2506.15991v3)**

> **作者:** Maijunxian Wang
>
> **摘要:** In an era where the body is increasingly translated into streams of biometric data, smart wearables have become not merely tools of personal health tracking but infrastructures of predictive governance. This paper examines how wearable technologies reconfigure bodily autonomy by embedding users within feedback-driven systems of self-surveillance, data extraction, and algorithmic control. Drawing on Deleuze's concept of the control society, Zuboff's theory of surveillance capitalism, and Couldry and Mejias's notion of data colonialism, I argue that smart wearables shift the discourse of health empowerment toward a modality of compliance aligned with neoliberal values of productivity, efficiency, and self-discipline. Rather than offering transparent consent, these technologies operate within what scholars describe as a post-consent regime -- where asymmetrical data relations are normalized through seamless design and behavioral nudging. Through interdisciplinary analysis, the paper further explores alternative trajectories for wearable design and governance, from historical examples of care-centered devices to contemporary anti-extractive practices and collective data justice frameworks. Ultimately, it calls for a paradigm shift from individual optimization to democratic accountability and structural reform in the governance of bodily data.
>
---
#### [replaced 005] Digital Dybbuks and Virtual Golems: The Ethics of Digital Duplicates in Holocaust Testimony
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2503.01369v2](http://arxiv.org/pdf/2503.01369v2)**

> **作者:** Atay Kozlovski; Mykola Makhortykh
>
> **备注:** 26 pages
>
> **摘要:** Advances in generative artificial intelligence (AI) have driven a growing effort to create digital duplicates. These semi-autonomous recreations of living and dead people can be used for many purposes. Some of these purposes include tutoring, coping with grief, and attending business meetings. However, the normative implications of digital duplicates remain obscure, particularly considering the possibility of them being applied to genocide memory and education. To address this gap, we examine normative possibilities and risks associated with the use of more advanced forms of generative AI-enhanced duplicates for transmitting Holocaust survivor testimonies. We first review the historical and contemporary uses of survivor testimonies. Then, we scrutinize the possible benefits of using digital duplicates in this context and apply the Minimally Viable Permissibility Principle (MVPP). The MVPP is an analytical framework for evaluating the risks of digital duplicates. It includes five core components: the need for authentic presence, consent, positive value, transparency, and harm-risk mitigation. Using MVPP, we identify potential harms digital duplicates might pose to different actors, including survivors, users, and developers. We also propose technical and socio-technical mitigation strategies to address these harms.
>
---
#### [replaced 006] Origin-Destination Pattern Effects on Large-Scale Mixed Traffic Control via Multi-Agent Reinforcement Learning
- **分类: cs.MA; cs.CY**

- **链接: [http://arxiv.org/pdf/2505.13543v2](http://arxiv.org/pdf/2505.13543v2)**

> **作者:** Muyang Fan; Songyang Liu; Shuai Li; Weizi Li
>
> **备注:** Accepted to IEEE International Conference on Intelligent Transportation Systems (ITSC), 2025
>
> **摘要:** Traffic congestion remains a major challenge for modern urban transportation, diminishing both efficiency and quality of life. While autonomous driving technologies and reinforcement learning (RL) have shown promise for improving traffic control, most prior work has focused on small-scale networks or isolated intersections. Large-scale mixed traffic control, involving both human-driven and robotic vehicles, remains underexplored. In this study, we propose a decentralized multi-agent reinforcement learning framework for managing large-scale mixed traffic networks, where intersections are controlled either by traditional traffic signals or by robotic vehicles. We evaluate our approach on a real-world network of 14 intersections in Colorado Springs, Colorado, USA, using average vehicle waiting time as the primary measure of traffic efficiency. We are exploring a problem that has not been sufficiently addressed: Is large-scale Multi-Agent Traffic Control (MTC) still feasible when facing time-varying Origin-Destination (OD) patterns?
>
---
#### [replaced 007] Ethical AI for Young Digital Citizens: A Call to Action on Privacy Governance
- **分类: cs.CY; cs.AI; cs.LG**

- **链接: [http://arxiv.org/pdf/2503.11947v2](http://arxiv.org/pdf/2503.11947v2)**

> **作者:** Austin Shouli; Ankur Barthwal; Molly Campbell; Ajay Kumar Shrestha
>
> **备注:** Preprint Version | Submitted to journal "Security and Privacy", Wiley
>
> **摘要:** The rapid expansion of Artificial Intelligence (AI) in digital platforms used by youth has created significant challenges related to privacy, autonomy, and data protection. While AI-driven personalization offers enhanced user experiences, it often operates without clear ethical boundaries, leaving young users vulnerable to data exploitation and algorithmic biases. This paper presents a call to action for ethical AI governance, advocating for a structured framework that ensures youth-centred privacy protections, transparent data practices, and regulatory oversight. We outline key areas requiring urgent intervention, including algorithmic transparency, privacy education, parental data-sharing ethics, and accountability measures. Through this approach, we seek to empower youth with greater control over their digital identities and propose actionable strategies for policymakers, AI developers, and educators to build a fairer and more accountable AI ecosystem.
>
---
#### [replaced 008] The Algorithmic State Architecture (ASA): An Integrated Framework for AI-Enabled Government
- **分类: cs.CY; cs.AI; cs.ET; cs.MA; cs.SY; eess.SY**

- **链接: [http://arxiv.org/pdf/2503.08725v3](http://arxiv.org/pdf/2503.08725v3)**

> **作者:** Zeynep Engin; Jon Crowcroft; David Hand; Philip Treleaven
>
> **备注:** Main text: 25 pages, with references: 35 pages, 2 figures
>
> **摘要:** As artificial intelligence transforms public sector operations, governments struggle to integrate technological innovations into coherent systems for effective service delivery. This paper introduces the Algorithmic State Architecture (ASA), a novel four-layer framework conceptualising how Digital Public Infrastructure, Data-for-Policy, Algorithmic Government/Governance, and GovTech interact as an integrated system in AI-enabled states. Unlike approaches that treat these as parallel developments, ASA positions them as interdependent layers with specific enabling relationships and feedback mechanisms. Through comparative analysis of implementations in Estonia, Singapore, India, and the UK, we demonstrate how foundational digital infrastructure enables systematic data collection, which powers algorithmic decision-making processes, ultimately manifesting in user-facing services. Our analysis reveals that successful implementations require balanced development across all layers, with particular attention to integration mechanisms between them. The framework contributes to both theory and practice by bridging previously disconnected domains of digital government research, identifying critical dependencies that influence implementation success, and providing a structured approach for analysing the maturity and development pathways of AI-enabled government systems.
>
---
#### [replaced 009] An AI Theory of Mind Will Enhance Our Collective Intelligence
- **分类: cs.MA; cs.AI; cs.CY; cs.GT; nlin.AO**

- **链接: [http://arxiv.org/pdf/2411.09168v2](http://arxiv.org/pdf/2411.09168v2)**

> **作者:** Michael S. Harré; Catherine Drysdale; Jaime Ruiz-Serra
>
> **备注:** 26 pages, 2 figures, 1 table
>
> **摘要:** Collective intelligence plays a central role in many fields, from economics and evolutionary theory to neural networks and eusocial insects, and is also core to work on emergence and self-organisation in complex-systems theory. However, in human collective intelligence there is still much to understand about how specific psychological processes at the individual level give rise to self-organised structures at the social level. Psychological factors have so far played a minor role in collective-intelligence studies because the principles are often general and applicable to agents without sophisticated psychologies. We emphasise, with examples from other complex adaptive systems, the broad applicability of collective-intelligence principles, while noting that mechanisms and time scales differ markedly between cases. We review evidence that flexible collective intelligence in human social settings is improved by a particular cognitive tool: our Theory of Mind. We then hypothesise that AIs equipped with a theory of mind will enhance collective intelligence in ways similar to human contributions. To make this case, we step back from the algorithmic basis of AI psychology and consider the large-scale impact AI can have as agential actors in a 'social ecology' rather than as mere technological tools. We identify several key characteristics of psychologically mediated collective intelligence and show that the development of a Theory of Mind is crucial in distinguishing human social collective intelligence from more general forms. Finally, we illustrate how individuals, human or otherwise, integrate within a collective not by being genetically or algorithmically programmed, but by growing and adapting into the socio-cognitive niche they occupy. AI can likewise inhabit one or multiple such niches, facilitated by a Theory of Mind.
>
---
#### [replaced 010] Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI
- **分类: cs.CY; cs.AI; cs.LG**

- **链接: [http://arxiv.org/pdf/2409.06673v2](http://arxiv.org/pdf/2409.06673v2)**

> **作者:** Cristian Trout
>
> **备注:** Accepted to Generative AI and Law Workshop at the International Conference on Machine Learning (ICML 2024)
>
> **摘要:** As AI systems become more autonomous and capable, experts warn of them potentially causing catastrophic losses. Drawing on the successful precedent set by the nuclear power industry, this paper argues that developers of frontier AI models should be assigned limited, strict, and exclusive third party liability for harms resulting from Critical AI Occurrences (CAIOs) - events that cause or easily could have caused catastrophic losses. Mandatory insurance for CAIO liability is recommended to overcome developers' judgment-proofness, mitigate winner's curse dynamics, and leverage insurers' quasi-regulatory abilities. Based on theoretical arguments and observations from the analogous nuclear power context, insurers are expected to engage in a mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and providing loss prevention guidance in the context of insuring against heavy-tail risks from AI. While not a substitute for regulation, clear liability assignment and mandatory insurance can help efficiently allocate resources to risk-modeling and safe design, facilitating future regulatory efforts.
>
---
#### [replaced 011] The GenAI Generation: Student Views of Awareness, Preparedness, and Concern
- **分类: cs.HC; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2505.02230v2](http://arxiv.org/pdf/2505.02230v2)**

> **作者:** Micaela Siraj; Jon Duke; Thomas Plötz
>
> **摘要:** Generative Artificial Intelligence (GenAI) is revolutionizing education and workforce development, profoundly shaping how students learn, engage, and prepare for their future. Outpacing the development of uniform policies and structures, GenAI has heralded a unique era and given rise to the GenAI Generation. We define the GenAI Generation as a cohort of students whose education has been increasingly shaped by the opportunities and challenges GenAI presents during its widespread adoption within society. This study examines students' perceptions of GenAI through a concise survey with optional open-ended questions, focusing on their awareness, preparedness, and concerns. Notably, readiness appears increasingly tied to exposure to GenAI through one's coursework. Students with greater curricular exposure to GenAI tend to feel more prepared, while those without it more often express vulnerability and uncertainty, highlighting a new and growing divide in readiness that goes beyond traditional disciplinary boundaries. Evaluation of more than 250 responses, with over 40% providing detailed qualitative feedback, reveals a core dual sentiment: while most students express enthusiasm for GenAI, an even greater proportion voice a spectrum of concerns about ethics, job displacement, and the adequacy of educational structures given the highly transformative technology. These findings offer critical insights into how students view the potential and pitfalls of GenAI for future career impacts. The challenge ahead involves implementing associated recommendations for educational institutions, moving beyond the baseline of access toward more informed guidance on the use of these tools, while preserving critical thinking, ethical reasoning, and adaptive learning.
>
---
