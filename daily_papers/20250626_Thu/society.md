# 计算机与社会 cs.CY

- **最新发布 13 篇**

- **更新 6 篇**

## 最新发布

#### [new 001] Toward a Global Regime for Compute Governance: Building the Pause Button
- **分类: cs.CY**

- **简介: 该论文属于AI治理任务，旨在解决大规模AI训练带来的风险。提出全球“计算暂停按钮”框架，通过技术、可追溯性和监管手段限制计算资源访问。**

- **链接: [http://arxiv.org/pdf/2506.20530v1](http://arxiv.org/pdf/2506.20530v1)**

> **作者:** Ananthi Al Ramiah; Raymond Koopmanschap; Josh Thorsteinson; Sadruddin Khan; Jim Zhou; Shafira Noh; Joep Meindertsma; Farhan Shafiq
>
> **备注:** 34 pages, 2 figures
>
> **摘要:** As AI capabilities rapidly advance, the risk of catastrophic harm from large-scale training runs is growing. Yet the compute infrastructure that enables such development remains largely unregulated. This paper proposes a concrete framework for a global "Compute Pause Button": a governance system designed to prevent dangerously powerful AI systems from being trained by restricting access to computational resources. We identify three key intervention points -- technical, traceability, and regulatory -- and organize them within a Governance--Enforcement--Verification (GEV) framework to ensure rules are clear, violations are detectable, and compliance is independently verifiable. Technical mechanisms include tamper-proof FLOP caps, model locking, and offline licensing. Traceability tools track chips, components, and users across the compute supply chain. Regulatory mechanisms establish constraints through export controls, production caps, and licensing schemes. Unlike post-deployment oversight, this approach targets the material foundations of advanced AI development. Drawing from analogues ranging from nuclear non-proliferation to pandemic-era vaccine coordination, we demonstrate how compute can serve as a practical lever for global cooperation. While technical and political challenges remain, we argue that credible mechanisms already exist, and that the time to build this architecture is now, before the window for effective intervention closes.
>
---
#### [new 002] When Servers Meet Species: A Fab-to-Grave Lens on Computing's Biodiversity Impact
- **分类: cs.CY**

- **简介: 该论文属于可持续计算领域，旨在解决计算系统对生物多样性影响的评估问题。提出EBI和OBI指标及FABRIC框架，实现全生命周期分析。**

- **链接: [http://arxiv.org/pdf/2506.20442v1](http://arxiv.org/pdf/2506.20442v1)**

> **作者:** Tianyao Shi; Ritbik Kumar; Inez Hua; Yi Ding
>
> **备注:** Accepted by HotCarbon' 25
>
> **摘要:** Biodiversity loss is a critical planetary boundary, yet its connection to computing remains largely unexamined. Prior sustainability efforts in computing have focused on carbon and water, overlooking biodiversity due to the lack of appropriate metrics and modeling frameworks. This paper presents the first end-to-end analysis of biodiversity impact from computing systems. We introduce two new metrics--Embodied Biodiversity Index (EBI) and Operational Biodiversity Index (OBI)--to quantify biodiversity impact across the lifecycle, and present FABRIC, a modeling framework that links computing workloads to biodiversity impacts. Our evaluation highlights the need to consider biodiversity alongside carbon and water in sustainable computing design and optimization. The code is available at https://github.com/TianyaoShi/FABRIC.
>
---
#### [new 003] That's Not the Feedback I Need! -- Student Engagement with GenAI Feedback in the Tutor Kai
- **分类: cs.CY**

- **简介: 该论文属于教育技术领域，研究学生如何与GenAI反馈互动。旨在解决学生使用GenAI反馈的效果问题，通过实验分析反馈的注意力和实用性。**

- **链接: [http://arxiv.org/pdf/2506.20433v1](http://arxiv.org/pdf/2506.20433v1)**

> **作者:** Sven Jacobs; Maurice Kempf; Natalie Kiesler
>
> **备注:** Accepted for the UK and Ireland Computing Education Research conference (UKICER 2025)
>
> **摘要:** The potential of Generative AI (GenAI) for generating feedback in computing education has been the subject of numerous studies. However, there is still limited research on how computing students engage with this feedback and to what extent it supports their problem-solving. For this reason, we built a custom web application providing students with Python programming tasks, a code editor, GenAI feedback, and compiler feedback. Via a think-aloud protocol including eye-tracking and a post-interview with 11 undergraduate students, we investigate (1) how much attention the generated feedback received from learners and (2) to what extent the generated feedback is helpful (or not). In addition, students' attention to GenAI feedback is compared with that towards the compiler feedback. We further investigate differences between students with and without prior programming experience. The findings indicate that GenAI feedback generally receives a lot of visual attention, with inexperienced students spending twice as much fixation time. More experienced students requested GenAI less frequently, and could utilize it better to solve the given problem. It was more challenging for inexperienced students to do so, as they could not always comprehend the GenAI feedback. They often relied solely on the GenAI feedback, while compiler feedback was not read. Understanding students' attention and perception toward GenAI feedback is crucial for developing educational tools that support student learning.
>
---
#### [new 004] The Impact of the Russia-Ukraine Conflict on the Cloud Computing Risk Landscape
- **分类: cs.CY; cs.CR; cs.NI**

- **简介: 该论文属于风险管理任务，探讨俄乌冲突对云安全的影响，分析数据主权、安全策略及基础设施变化，提出多层防御方案以增强数字韧性。**

- **链接: [http://arxiv.org/pdf/2506.20104v1](http://arxiv.org/pdf/2506.20104v1)**

> **作者:** Malikussaid; Sutiyo
>
> **备注:** 16 pages, 4 tables, to be published in ICoSEIT Conference 2025, unabridged version
>
> **摘要:** The Russian invasion of Ukraine has fundamentally altered the information technology (IT) risk landscape, particularly in cloud computing environments. This paper examines how this geopolitical conflict has accelerated data sovereignty concerns, transformed cybersecurity paradigms, and reshaped cloud infrastructure strategies worldwide. Through an analysis of documented cyber operations, regulatory responses, and organizational adaptations between 2022 and early 2025, this research demonstrates how the conflict has served as a catalyst for a broader reassessment of IT risk. The research reveals that while traditional IT risk frameworks offer foundational guidance, their standard application may inadequately address the nuances of state-sponsored threats, conflicting data governance regimes, and the weaponization of digital dependencies without specific geopolitical augmentation. The contribution of this paper lies in its focused synthesis and strategic adaptation of existing best practices into a multi-layered approach. This approach uniquely synergizes resilient cloud architectures (including sovereign and hybrid models), enhanced data-centric security strategies (such as advanced encryption and privacy-enhancing technologies), and geopolitically-informed governance to build digital resilience. The interplay between these layers, emphasizing how geopolitical insights directly shape architectural and security choices beyond standard best practices-particularly by integrating the human element, including personnel vulnerabilities and expertise, as a core consideration in technical design and operational management-offers a more robust defense against the specific, multifaceted risks arising from geopolitical conflict in increasingly fractured digital territories.
>
---
#### [new 005] Enhancing Programming Pair Workshops: The Case of Teacher Pre-Prompting
- **分类: cs.CY; 68-01, 97Q60; K.3.2; K.3.1**

- **简介: 该论文属于教育技术领域，旨在解决编程协作教学中的问题。通过教师课前引导提问，促进学生有效合作与学习。**

- **链接: [http://arxiv.org/pdf/2506.20299v1](http://arxiv.org/pdf/2506.20299v1)**

> **作者:** Johan Petersson
>
> **备注:** 10 pages, 2 figures. Author's preprint of article published in SIGED/ECISER 2024 via AIS Electronic Library. The published version is available at: https://aisel.aisnet.org/siged2024/15/
>
> **摘要:** This paper explores the pedagogical potential of "teacher pre-prompting" as a means of guiding student collaboration in programming education. In particular, we investigate how brief teacher-initiated questions posed before students engage in pair programming workshops can help shape problem interpretation and division of labor. Based on qualitative analysis of video data from a university course in systems development, we identify five distinct pre-prompting patterns. Our findings suggest that such prompts can foster structured discussions, clarify task requirements, and create opportunities for shared learning experiences.
>
---
#### [new 006] Accept More, Reject Less: Reducing up to 19% Unnecessary Desk-Rejections over 11 Years of ICLR Data
- **分类: cs.DS; cs.CY; cs.DL; cs.IR; cs.LG**

- **简介: 该论文属于会议论文管理任务，旨在减少不必要的初审拒绝。通过优化算法，在不违反提交限制的前提下，提高了论文接受率。**

- **链接: [http://arxiv.org/pdf/2506.20141v1](http://arxiv.org/pdf/2506.20141v1)**

> **作者:** Xiaoyu Li; Zhao Song; Jiahao Zhang
>
> **摘要:** The explosive growth of AI research has driven paper submissions at flagship AI conferences to unprecedented levels, necessitating many venues in 2025 (e.g., CVPR, ICCV, KDD, AAAI, IJCAI, WSDM) to enforce strict per-author submission limits and to desk-reject any excess papers by simple ID order. While this policy helps reduce reviewer workload, it may unintentionally discard valuable papers and penalize authors' efforts. In this paper, we ask an essential research question on whether it is possible to follow submission limits while minimizing needless rejections. We first formalize the current desk-rejection policies as an optimization problem, and then develop a practical algorithm based on linear programming relaxation and a rounding scheme. Under extensive evaluation on 11 years of real-world ICLR (International Conference on Learning Representations) data, our method preserves up to $19.23\%$ more papers without violating any author limits. Moreover, our algorithm is highly efficient in practice, with all results on ICLR data computed within at most 53.64 seconds. Our work provides a simple and practical desk-rejection strategy that significantly reduces unnecessary rejections, demonstrating strong potential to improve current CS conference submission policies.
>
---
#### [new 007] Position: Machine Learning Conferences Should Establish a "Refutations and Critiques" Track
- **分类: cs.LG; cs.AI; cs.CL; cs.CY**

- **简介: 该论文属于观点类任务，旨在解决ML会议中错误研究难以被纠正的问题。提出设立“反驳与批评”专栏，以促进学术自我修正。**

- **链接: [http://arxiv.org/pdf/2506.19882v1](http://arxiv.org/pdf/2506.19882v1)**

> **作者:** Rylan Schaeffer; Joshua Kazdan; Yegor Denisov-Blanch; Brando Miranda; Matthias Gerstgrasser; Susan Zhang; Andreas Haupt; Isha Gupta; Elyas Obbad; Jesse Dodge; Jessica Zosa Forde; Koustuv Sinha; Francesco Orabona; Sanmi Koyejo; David Donoho
>
> **摘要:** Science progresses by iteratively advancing and correcting humanity's understanding of the world. In machine learning (ML) research, rapid advancements have led to an explosion of publications, but have also led to misleading, incorrect, flawed or perhaps even fraudulent studies being accepted and sometimes highlighted at ML conferences due to the fallibility of peer review. While such mistakes are understandable, ML conferences do not offer robust processes to help the field systematically correct when such errors are made.This position paper argues that ML conferences should establish a dedicated "Refutations and Critiques" (R & C) Track. This R & C Track would provide a high-profile, reputable platform to support vital research that critically challenges prior research, thereby fostering a dynamic self-correcting research ecosystem. We discuss key considerations including track design, review principles, potential pitfalls, and provide an illustrative example submission concerning a recent ICLR 2025 Oral. We conclude that ML conferences should create official, reputable mechanisms to help ML research self-correct.
>
---
#### [new 008] The Role of Partisan Culture in Mental Health Language Online
- **分类: cs.HC; cs.CY; cs.SI**

- **简介: 该论文属于社会计算任务，研究政治派别文化如何影响在线心理健康社区中的痛苦表达。通过分析大量用户帖子，探讨了党派文化对表达方式的影响。**

- **链接: [http://arxiv.org/pdf/2506.20377v1](http://arxiv.org/pdf/2506.20377v1)**

> **作者:** Sachin R. Pendse; Ben Rochford; Neha Kumar; Munmun De Choudhury
>
> **备注:** Accepted to the ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2025)
>
> **摘要:** The impact of culture on how people express distress in online support communities is increasingly a topic of interest within Computer Supported Cooperative Work (CSCW) and Human-Computer Interaction (HCI). In the United States, distinct cultures have emerged from each of the two dominant political parties, forming a primary lens by which people navigate online and offline worlds. We examine whether partisan culture may play a role in how U.S. Republican and Democrat users of online mental health support communities express distress. We present a large-scale observational study of 2,184,356 posts from 8,916 statistically matched Republican, Democrat, and unaffiliated online support community members. We utilize methods from causal inference to statistically match partisan users along covariates that correspond with demographic attributes and platform use, in order to create comparable cohorts for analysis. We then leverage methods from natural language processing to understand how partisan expressions of distress compare between these sets of closely matched opposing partisans, and between closely matched partisans and typical support community members. Our data spans January 2013 to December 2022, a period of both rising political polarization and mental health concerns. We find that partisan culture does play into expressions of distress, underscoring the importance of considering partisan cultural differences in the design of online support community platforms.
>
---
#### [new 009] Opinion Dynamics with Highly Oscillating Opinions
- **分类: cs.CE; cs.CY; cs.MA**

- **简介: 该论文属于 Opinion Dynamics 任务，旨在解决真实世界中高度波动意见的建模问题。通过优化算法评估不同模型，发现结合理性和情感机制的 ATBCR 模型最有效。**

- **链接: [http://arxiv.org/pdf/2506.20472v1](http://arxiv.org/pdf/2506.20472v1)**

> **作者:** Víctor A. Vargas-Pérez; Jesús Giráldez-Cru; Oscar Cordón
>
> **摘要:** Opinion Dynamics (OD) models are a particular case of Agent-Based Models in which the evolution of opinions within a population is studied. In most OD models, opinions evolve as a consequence of interactions between agents, and the opinion fusion rule defines how those opinions are updated. In consequence, despite being simplistic, OD models provide an explainable and interpretable mechanism for understanding the underlying dynamics of opinion evolution. Unfortunately, existing OD models mainly focus on explaining the evolution of (usually synthetic) opinions towards consensus, fragmentation, or polarization, but they usually fail to analyze scenarios of (real-world) highly oscillating opinions. This work overcomes this limitation by studying the ability of several OD models to reproduce highly oscillating dynamics. To this end, we formulate an optimization problem which is further solved using Evolutionary Algorithms, providing both quantitative results on the performance of the optimization and qualitative interpretations on the obtained results. Our experiments on a real-world opinion dataset about immigration from the monthly barometer of the Spanish Sociological Research Center show that the ATBCR, based on both rational and emotional mechanisms of opinion update, is the most accurate OD model for capturing highly oscillating opinions.
>
---
#### [new 010] Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models
- **分类: cs.CR; cs.CY; cs.LG**

- **简介: 该论文研究生成模型版权保护问题，提出“无责复制”框架，解决如何确保模型输出不侵权。**

- **链接: [http://arxiv.org/pdf/2506.19881v1](http://arxiv.org/pdf/2506.19881v1)**

> **作者:** Aloni Cohen
>
> **摘要:** Are there any conditions under which a generative model's outputs are guaranteed not to infringe the copyrights of its training data? This is the question of "provable copyright protection" first posed by Vyas, Kakade, and Barak (ICML 2023). They define near access-freeness (NAF) and propose it as sufficient for protection. This paper revisits the question and establishes new foundations for provable copyright protection -- foundations that are firmer both technically and legally. First, we show that NAF alone does not prevent infringement. In fact, NAF models can enable verbatim copying, a blatant failure of copy protection that we dub being tainted. Then, we introduce our blameless copy protection framework for defining meaningful guarantees, and instantiate it with clean-room copy protection. Clean-room copy protection allows a user to control their risk of copying by behaving in a way that is unlikely to copy in a counterfactual clean-room setting. Finally, we formalize a common intuition about differential privacy and copyright by proving that DP implies clean-room copy protection when the dataset is golden, a copyright deduplication requirement.
>
---
#### [new 011] Analyzing Security and Privacy Challenges in Generative AI Usage Guidelines for Higher Education
- **分类: cs.HC; cs.CY**

- **简介: 该论文属于安全与隐私研究任务，旨在解决GenAI在高等教育中的隐私和安全问题。通过分析多国高校的使用指南，识别挑战与改进机会。**

- **链接: [http://arxiv.org/pdf/2506.20463v1](http://arxiv.org/pdf/2506.20463v1)**

> **作者:** Bei Yi Ng; Jiarui Li; Xinyuan Tong; Kevin Ye; Gauthami Yenne; Varun Chandrasekaran; Jingjie Li
>
> **摘要:** Educators and learners worldwide are embracing the rise of Generative Artificial Intelligence (GenAI) as it reshapes higher education. However, GenAI also raises significant privacy and security concerns, as models and privacy-sensitive user data, such as student records, may be misused by service providers. Unfortunately, end-users often have little awareness of or control over how these models operate. To address these concerns, universities are developing institutional policies to guide GenAI use while safeguarding security and privacy. This work examines these emerging policies and guidelines, with a particular focus on the often-overlooked privacy and security dimensions of GenAI integration in higher education, alongside other academic values. Through a qualitative analysis of GenAI usage guidelines from universities across 12 countries, we identify key challenges and opportunities institutions face in providing effective privacy and security protections, including the need for GenAI safeguards tailored specifically to the academic context.
>
---
#### [new 012] Case-based Reasoning Augmented Large Language Model Framework for Decision Making in Realistic Safety-Critical Driving Scenarios
- **分类: cs.AI; cs.CY**

- **简介: 该论文属于自动驾驶决策任务，旨在解决安全关键场景下的快速、可靠决策问题。通过结合案例推理与大语言模型，提升决策的准确性与可解释性。**

- **链接: [http://arxiv.org/pdf/2506.20531v1](http://arxiv.org/pdf/2506.20531v1)**

> **作者:** Wenbin Gan; Minh-Son Dao; Koji Zettsu
>
> **备注:** 12 pages, 10 figures, under-review conference
>
> **摘要:** Driving in safety-critical scenarios requires quick, context-aware decision-making grounded in both situational understanding and experiential reasoning. Large Language Models (LLMs), with their powerful general-purpose reasoning capabilities, offer a promising foundation for such decision-making. However, their direct application to autonomous driving remains limited due to challenges in domain adaptation, contextual grounding, and the lack of experiential knowledge needed to make reliable and interpretable decisions in dynamic, high-risk environments. To address this gap, this paper presents a Case-Based Reasoning Augmented Large Language Model (CBR-LLM) framework for evasive maneuver decision-making in complex risk scenarios. Our approach integrates semantic scene understanding from dashcam video inputs with the retrieval of relevant past driving cases, enabling LLMs to generate maneuver recommendations that are both context-sensitive and human-aligned. Experiments across multiple open-source LLMs show that our framework improves decision accuracy, justification quality, and alignment with human expert behavior. Risk-aware prompting strategies further enhance performance across diverse risk types, while similarity-based case retrieval consistently outperforms random sampling in guiding in-context learning. Case studies further demonstrate the framework's robustness in challenging real-world conditions, underscoring its potential as an adaptive and trustworthy decision-support tool for intelligent driving systems.
>
---
#### [new 013] Ten simple rules for PIs to integrate Research Software Engineering into their research group
- **分类: cs.SE; cs.CE; cs.CY; 68-01; K.6.3**

- **简介: 该论文属于科研管理任务，旨在帮助PI将研究软件工程融入团队，解决RSEng认知不足和应用困难的问题，提出十项实用规则提升软件质量与研究可信度。**

- **链接: [http://arxiv.org/pdf/2506.20217v1](http://arxiv.org/pdf/2506.20217v1)**

> **作者:** Stuart M. Allen; Neil Chue Hong; Stephan Druskat; Toby Hodges; Daniel S. Katz; Jan Linxweiler; Frank Löffler; Lars Grunske; Heidi Seibold; Jan Philipp Thiele; Samantha Wittke
>
> **备注:** 10 pages, submitted to PLOS Computational Biology
>
> **摘要:** Research Software Engineering (RSEng) is a key success factor in producing high-quality research software, which in turn enables and improves research outcomes. However, as a principal investigator or leader of a research group you may not know what RSEng is, where to get started with it, or how to use it to maximize its benefit for your research. RSEng also often comes with technical complexity, and therefore reduced accessibility to some researchers. The ten simple rules presented in this paper aim to improve the accessibility of RSEng, and provide practical and actionable advice to PIs and leaders for integrating RSEng into their research group. By following these rules, readers can improve the quality, reproducibility, and trustworthiness of their research software, ultimately leading to better, more reproducible and more trustworthy research outcomes.
>
---
## 更新

#### [replaced 001] The Blind Men and the Elephant: Mapping Interdisciplinarity in Research on Decentralized Autonomous Organizations
- **分类: cs.DC; cs.CY; A.1; K.4**

- **链接: [http://arxiv.org/pdf/2502.09949v2](http://arxiv.org/pdf/2502.09949v2)**

> **作者:** Giorgia Sampò; Oliver Baumann; Marco Peressotti
>
> **摘要:** Decentralized Autonomous Organizations (DAOs) are attracting interdisciplinary interest, particularly in business, economics, and computer science. However, much like the parable of the blind men and the elephant, where each observer perceives only a fragment of the whole, DAO research remains fragmented across disciplines, limiting a comprehensive understanding of their potential. This paper assesses the maturity of interdisciplinary research on DAOs by analyzing knowledge flows between Business & Economics and Computer Science through citation network analysis, topic modelling, and outlet analysis. Our findings reveal that while DAOs serve as a vibrant topic of interdisciplinary discourse, current research remains predominantly applied and case-driven, with limited theoretical integration. Strengthening the alignment between organizational and technical insights is crucial for advancing DAO research and fostering a more cohesive interdisciplinary framework.
>
---
#### [replaced 002] AIDRIN 2.0: A Framework to Assess Data Readiness for AI
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2505.18213v2](http://arxiv.org/pdf/2505.18213v2)**

> **作者:** Kaveen Hiniduma; Dylan Ryan; Suren Byna; Jean Luca Bez; Ravi Madduri
>
> **备注:** 3 pages, 3 figures
>
> **摘要:** AI Data Readiness Inspector (AIDRIN) is a framework to evaluate and improve data preparedness for AI applications. It addresses critical data readiness dimensions such as data quality, bias, fairness, and privacy. This paper details enhancements to AIDRIN by focusing on user interface improvements and integration with a privacy-preserving federated learning (PPFL) framework. By refining the UI and enabling smooth integration with decentralized AI pipelines, AIDRIN becomes more accessible and practical for users with varying technical expertise. Integrating with an existing PPFL framework ensures that data readiness and privacy are prioritized in federated learning environments. A case study involving a real-world dataset demonstrates AIDRIN's practical value in identifying data readiness issues that impact AI model performance.
>
---
#### [replaced 003] FORTRESS: Frontier Risk Evaluation for National Security and Public Safety
- **分类: cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2506.14922v2](http://arxiv.org/pdf/2506.14922v2)**

> **作者:** Christina Q. Knight; Kaustubh Deshpande; Ved Sirdeshmukh; Meher Mankikar; Scale Red Team; SEAL Research Team; Julian Michael
>
> **备注:** 12 pages, 7 figures, submitted to NeurIPS
>
> **摘要:** The rapid advancement of large language models (LLMs) introduces dual-use capabilities that could both threaten and bolster national security and public safety (NSPS). Models implement safeguards to protect against potential misuse relevant to NSPS and allow for benign users to receive helpful information. However, current benchmarks often fail to test safeguard robustness to potential NSPS risks in an objective, robust way. We introduce FORTRESS: 500 expert-crafted adversarial prompts with instance-based rubrics of 4-7 binary questions for automated evaluation across 3 domains (unclassified information only): Chemical, Biological, Radiological, Nuclear and Explosive (CBRNE), Political Violence & Terrorism, and Criminal & Financial Illicit Activities, with 10 total subcategories across these domains. Each prompt-rubric pair has a corresponding benign version to test for model over-refusals. This evaluation of frontier LLMs' safeguard robustness reveals varying trade-offs between potential risks and model usefulness: Claude-3.5-Sonnet demonstrates a low average risk score (ARS) (14.09 out of 100) but the highest over-refusal score (ORS) (21.8 out of 100), while Gemini 2.5 Pro shows low over-refusal (1.4) but a high average potential risk (66.29). Deepseek-R1 has the highest ARS at 78.05, but the lowest ORS at only 0.06. Models such as o1 display a more even trade-off between potential risks and over-refusals (with an ARS of 21.69 and ORS of 5.2). To provide policymakers and researchers with a clear understanding of models' potential risks, we publicly release FORTRESS at https://huggingface.co/datasets/ScaleAI/fortress_public. We also maintain a private set for evaluation.
>
---
#### [replaced 004] A Comparison of Precinct and District Voting Data Using Persistent Homology to Identify Gerrymandering in North Carolina
- **分类: cs.SI; cs.CY**

- **链接: [http://arxiv.org/pdf/2506.13997v2](http://arxiv.org/pdf/2506.13997v2)**

> **作者:** Ananya Shah
>
> **摘要:** We present an extension of Feng and Porter's 2019 paper on the use of the level-set method for the construction of a filtered simplicial complex from geospatial election data. Precincts are regarded to be too small to be gerrymandered, allowing us to identify discrepancies between precinct and district level voting data to quantify gerrymandering in the United States. Comparing the persistent homologies of Democratic voting areas on the precinct and district level shows when areas have been 'cracked' or 'packed' for partisan gain. This analysis was done for North Carolina House of Representatives elections (2012 to 2024). North Carolina has been redistricted 4 times in the past 10 years, whereas most states redistrict decennially, allowing us to understand how and when redistricted maps deviate from precinct-level voting data, and when gerrymandering occurs. Comparing persistence barcodes at the precinct and district levels (using the bottleneck distance) shows that precinct-level voting patterns do not significantly fluctuate biannually, while district level patterns do, suggesting that shifts are likely a result of redistricting rather than voter behavior, providing strong evidence of gerrymandering. North Carolina election data was collected from the public domain. Composite shapefiles were created using QGIS and R, and rasterized using Python. The level-set method was employed to generate filtered simplicial complexes. Persistence barcodes were produced using GUDHI and PHAT libraries. Additionally, we compare our results with traditional measures such as Polsby-Popper and Reock scores (gerrymandering identification measures). This research presents a novel application of topological data analysis in evaluating gerrymandering.
>
---
#### [replaced 005] Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective
- **分类: cs.CL; cs.AI; cs.CY; 68T50; I.2.7**

- **链接: [http://arxiv.org/pdf/2506.19028v2](http://arxiv.org/pdf/2506.19028v2)**

> **作者:** Weijie Xu; Yiwen Wang; Chi Xue; Xiangkun Hu; Xi Fang; Guimin Dong; Chandan K. Reddy
>
> **备注:** 29 pages, 9 figures, 15 tables
>
> **摘要:** Large Language Models (LLMs) often generate responses with inherent biases, undermining their reliability in real-world applications. Existing evaluation methods often overlook biases in long-form responses and the intrinsic variability of LLM outputs. To address these challenges, we propose FiSCo(Fine-grained Semantic Computation), a novel statistical framework to evaluate group-level fairness in LLMs by detecting subtle semantic differences in long-form responses across demographic groups. Unlike prior work focusing on sentiment or token-level comparisons, FiSCo goes beyond surface-level analysis by operating at the claim level, leveraging entailment checks to assess the consistency of meaning across responses. We decompose model outputs into semantically distinct claims and apply statistical hypothesis testing to compare inter- and intra-group similarities, enabling robust detection of subtle biases. We formalize a new group counterfactual fairness definition and validate FiSCo on both synthetic and human-annotated datasets spanning gender, race, and age. Experiments show that FiSco more reliably identifies nuanced biases while reducing the impact of stochastic LLM variability, outperforming various evaluation metrics.
>
---
#### [replaced 006] The Alignment Trap: Complexity Barriers
- **分类: cs.AI; cs.CC; cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2506.10304v2](http://arxiv.org/pdf/2506.10304v2)**

> **作者:** Jasper Yao
>
> **备注:** 31 Pages, 4 Figures. Substantial revision. Restructured around the Enumeration Paradox and Five Pillars of Impossibility. Core mathematical results unchanged but significantly expanded. Added new impossibility proofs from statistical, information-theoretic, and dynamic perspectives
>
> **摘要:** This paper argues that AI alignment is not merely difficult, but is founded on a fundamental logical contradiction. We first establish The Enumeration Paradox: we use machine learning precisely because we cannot enumerate all necessary safety rules, yet making ML safe requires examples that can only be generated from the very enumeration we admit is impossible. This paradox is then confirmed by a set of five independent mathematical proofs, or "pillars of impossibility." Our main results show that: (1) Geometric Impossibility: The set of safe policies has measure zero, a necessary consequence of projecting infinite-dimensional world-context requirements onto finite-dimensional models. (2) Computational Impossibility: Verifying a policy's safety is coNP-complete, even for non-zero error tolerances. (3) Statistical Impossibility: The training data required for safety (abundant examples of rare disasters) is a logical contradiction and thus unobtainable. (4) Information-Theoretic Impossibility: Safety rules contain more incompressible, arbitrary information than any feasible network can store. (5) Dynamic Impossibility: The optimization process for increasing AI capability is actively hostile to safety, as the gradients for the two objectives are generally anti-aligned. Together, these results demonstrate that the pursuit of safe, highly capable AI is not a matter of overcoming technical hurdles, but of confronting fundamental, interlocking barriers. The paper concludes by presenting a strategic trilemma that these impossibilities force upon the field. A formal verification of the core theorems in Lean4 is currently in progress.
>
---
