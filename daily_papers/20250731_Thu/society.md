# 计算机与社会 cs.CY

- **最新发布 8 篇**

- **更新 8 篇**

## 最新发布

#### [new 001] Why do women pursue a PhD in Computer Science?
- **分类: cs.CY**

- **简介: 该论文旨在探讨女性攻读计算机科学博士学位的动机与障碍。通过调查分析性别差异，提出“女性职业午餐”计划，帮助女性硕士生了解博士学习，解决信心不足与信息缺乏问题，以促进女性在学术领域的参与度。**

- **链接: [http://arxiv.org/pdf/2507.22161v1](http://arxiv.org/pdf/2507.22161v1)**

> **作者:** Erika Ábrahám; Miguel Goulão; Milena Vujošević Janičić; Sarah Jane Delany; Amal Mersni; Oleksandra Yeremenko; Ozge Buyukdagli; Karima Boudaoud; Caroline Oehlhorn; Ute Schmid; Christina Büsing; Helen Bolke-Hermanns; Kaja Köhnle; Matilde Pato; Deniz Sunar Cerci; Larissa Schmid
>
> **摘要:** Computer science attracts few women, and their proportion decreases through advancing career stages. Few women progress to PhD studies in CS after completing master's studies. Empowering women at this stage in their careers is essential to unlock untapped potential for society, industry and academia. This paper identifies students' career assumptions and information related to PhD studies focused on gender-based differences. We propose a Women Career Lunch program to inform female master students about PhD studies that explains the process, clarifies misconceptions, and alleviates concerns. An extensive survey was conducted to identify factors that encourage and discourage students from undertaking PhD studies. We identified statistically significant differences between those who undertook PhD studies and those who didn't, as well as gender differences. A catalogue of questions to initiate discussions with potential PhD students which allowed them to explore these factors was developed and translated to 8 languages. Encouraging factors toward PhD study include interest and confidence in research arising from a research involvement during earlier studies; enthusiasm for and self-confidence in CS in addition to an interest in an academic career; encouragement from external sources; and a positive perception towards PhD studies which can involve achieving personal goals. Discouraging factors include uncertainty and lack of knowledge of the PhD process, a perception of lower job flexibility, and the requirement for long-term commitment. Gender differences highlighted that female students who pursue a PhD have less confidence in their technical skills than males but a higher preference for interdisciplinary areas. Female students are less inclined than males to perceive the industry as offering better job opportunities and more flexible career paths than academia.
>
---
#### [new 002] Global Patterns of Knowledge: Language, Genre, and the Geography of Knowledge
- **分类: cs.CY**

- **简介: 该论文研究不同语言社区在维基百科上的知识生产模式，探索语言、文化与知识分布的关系。任务是分析知识生产的多样性与地域关联。工作包括用经济复杂性方法分析编辑历史，揭示语言社区在文化议题上的差异与地缘政治关联，指出AI数据可能存在偏见。**

- **链接: [http://arxiv.org/pdf/2507.22271v1](http://arxiv.org/pdf/2507.22271v1)**

> **作者:** Akira Matsui; Fujio Toriumi; Mitsuo Yoshida; Taichi Murayama; Shiori Hironaka
>
> **摘要:** Online platforms, particularly Wikipedia, have become critical infrastructures for providing diverse linguistic and cultural contexts. This human-curated knowledge now forms the foundation for modern AI. However, we have not yet fully explored how knowledge production capability vary across languages and domains. Here, we address this gap by applying economic complexity analysis to understand the editing history of Wikipedia platforms. This approach allows us to infer the latent mode of ``knowledge-production'' of each language community from the diversity and specialization of its contributed content. We reveal that different language communities exhibit distinct specializations, particularly in cultural subjects. Furthermore, we map the global landscape of these production modes, finding that the structure of knowledge production strongly reflects geopolitical boundaries. Our findings suggest that while a common mode of knowledge production exists for standardized topics such as science, it is more diverse for cultural topics or controversial subjects such as conspiracy theories. The association between differences in knowledge production capability and geopolitical factors implies how linguistic and cultural dynamics shape our worldview and the biases embedded in Wikipedia data, a unique, massive, and essential dataset for modern AI.
>
---
#### [new 003] Explainability Through Systematicity: The Hard Systematicity Challenge for Artificial Intelligence
- **分类: cs.AI; cs.CL; cs.CY**

- **简介: 论文探讨人工智能的“系统性”问题，超越传统的“系统性挑战”，提出“硬系统性挑战”。它分析系统性在思想整合、一致性与科学性中的作用，区分四种系统性概念，缓解系统性与联结主义间的矛盾，并提出五个系统化原则评估AI模型，明确系统化需求的动态标准。任务属AI理论与哲学分析。**

- **链接: [http://arxiv.org/pdf/2507.22197v1](http://arxiv.org/pdf/2507.22197v1)**

> **作者:** Matthieu Queloz
>
> **备注:** 39 pages; final, published version
>
> **摘要:** This paper argues that explainability is only one facet of a broader ideal that shapes our expectations towards artificial intelligence (AI). Fundamentally, the issue is to what extent AI exhibits systematicity--not merely in being sensitive to how thoughts are composed of recombinable constituents, but in striving towards an integrated body of thought that is consistent, coherent, comprehensive, and parsimoniously principled. This richer conception of systematicity has been obscured by the long shadow of the "systematicity challenge" to connectionism, according to which network architectures are fundamentally at odds with what Fodor and colleagues termed "the systematicity of thought." I offer a conceptual framework for thinking about "the systematicity of thought" that distinguishes four senses of the phrase. I use these distinctions to defuse the perceived tension between systematicity and connectionism and show that the conception of systematicity that historically shaped our sense of what makes thought rational, authoritative, and scientific is more demanding than the Fodorian notion. To determine whether we have reason to hold AI models to this ideal of systematicity, I then argue, we must look to the rationales for systematization and explore to what extent they transfer to AI models. I identify five such rationales and apply them to AI. This brings into view the "hard systematicity challenge." However, the demand for systematization itself needs to be regulated by the rationales for systematization. This yields a dynamic understanding of the need to systematize thought, which tells us how systematic we need AI models to be and when.
>
---
#### [new 004] GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for Multiresolution Power Outage Analysis
- **分类: cs.IR; cs.CL; cs.CY**

- **简介: 该论文属于知识图谱与电力系统分析任务，旨在解决现有停电数据空间分辨率低、难以捕捉局部模式的问题。作者构建了GeoOutageKG，一个融合夜间灯光卫星图像、高分辨率停电地图和县级停电报告的多模态时空知识图谱，支持多分辨率停电分析，提升停电检测与预测能力。**

- **链接: [http://arxiv.org/pdf/2507.22878v1](http://arxiv.org/pdf/2507.22878v1)**

> **作者:** Ethan Frakes; Yinghui Wu; Roger H. French; Mengjie Li
>
> **备注:** Accepted to the 24th International Semantic Web Conference Resource Track (ISWC 2025)
>
> **摘要:** Detecting, analyzing, and predicting power outages is crucial for grid risk assessment and disaster mitigation. Numerous outages occur each year, exacerbated by extreme weather events such as hurricanes. Existing outage data are typically reported at the county level, limiting their spatial resolution and making it difficult to capture localized patterns. However, it offers excellent temporal granularity. In contrast, nighttime light satellite image data provides significantly higher spatial resolution and enables a more comprehensive spatial depiction of outages, enhancing the accuracy of assessing the geographic extent and severity of power loss after disaster events. However, these satellite data are only available on a daily basis. Integrating spatiotemporal visual and time-series data sources into a unified knowledge representation can substantially improve power outage detection, analysis, and predictive reasoning. In this paper, we propose GeoOutageKG, a multimodal knowledge graph that integrates diverse data sources, including nighttime light satellite image data, high-resolution spatiotemporal power outage maps, and county-level timeseries outage reports in the U.S. We describe our method for constructing GeoOutageKG by aligning source data with a developed ontology, GeoOutageOnto. Currently, GeoOutageKG includes over 10.6 million individual outage records spanning from 2014 to 2024, 300,000 NTL images spanning from 2012 to 2024, and 15,000 outage maps. GeoOutageKG is a novel, modular and reusable semantic resource that enables robust multimodal data integration. We demonstrate its use through multiresolution analysis of geospatiotemporal power outages.
>
---
#### [new 005] Designing for Self-Regulation in Informal Programming Learning: Insights from a Storytelling-Centric Approach
- **分类: cs.HC; cs.AI; cs.CY; cs.SE; H.5.2; H.5.4**

- **简介: 该论文旨在设计支持非正式编程学习者自我调节的系统，解决学习者在缺乏指导的情况下难以达成目标的问题。通过结合社交媒体行为与AI反馈，构建包含学习故事的平台，帮助学习者整理资源、反思与记录学习过程。研究验证了系统在自我调节学习中的可行性与效果。**

- **链接: [http://arxiv.org/pdf/2507.22671v1](http://arxiv.org/pdf/2507.22671v1)**

> **作者:** Sami Saeed Alghamdi; Christopher Bull; Ahmed Kharrufa
>
> **备注:** 10 pages, 9 figures
>
> **摘要:** Many people learn programming independently from online resources and often report struggles in achieving their personal learning goals. Learners frequently describe their experiences as isolating and frustrating, challenged by abundant uncertainties, information overload, and distraction, compounded by limited guidance. At the same time, social media serves as a personal space where many engage in diverse self-regulation practices, including help-seeking, using external memory aids (e.g., self-notes), self-reflection, emotion regulation, and self-motivation. For instance, learners often mark achievements and set milestones through their posts. In response, we developed a system consisting of a web platform and browser extensions to support self-regulation online. The design aims to add learner-defined structure to otherwise unstructured experiences and bring meaning to curation and reflection activities by translating them into learning stories with AI-generated feedback. We position storytelling as an integrative approach to design that connects resource curation, reflective and sensemaking practice, and narrative practices learners already use across social platforms. We recruited 15 informal programming learners who are regular social media users to engage with the system in a self-paced manner; participation concluded upon submitting a learning story and survey. We used three quantitative scales and a qualitative survey to examine users' characteristics and perceptions of the system's support for their self-regulation. User feedback suggests the system's viability as a self-regulation aid. Learners particularly valued in-situ reflection, automated story feedback, and video annotation, while other features received mixed views. We highlight perceived benefits, friction points, and design opportunities for future AI-augmented self-regulation tools.
>
---
#### [new 006] Towards Simulating Social Influence Dynamics with LLM-based Multi-agents
- **分类: cs.MA; cs.AI; cs.CY**

- **简介: 该论文属于社会模拟任务，旨在研究LLM多智能体是否能复现人类在线论坛中的社会影响动态。论文分析了不同规模和推理能力的模型在从众、群体极化和碎片化方面的表现，发现小模型更易从众，而推理优化模型更具抵抗性。**

- **链接: [http://arxiv.org/pdf/2507.22467v1](http://arxiv.org/pdf/2507.22467v1)**

> **作者:** Hsien-Tsung Lin; Pei-Cing Huang; Chan-Tung Ku; Chan Hsu; Pei-Xuan Shieh; Yihuang Kang
>
> **摘要:** Recent advancements in Large Language Models offer promising capabilities to simulate complex human social interactions. We investigate whether LLM-based multi-agent simulations can reproduce core human social dynamics observed in online forums. We evaluate conformity dynamics, group polarization, and fragmentation across different model scales and reasoning capabilities using a structured simulation framework. Our findings indicate that smaller models exhibit higher conformity rates, whereas models optimized for reasoning are more resistant to social influence.
>
---
#### [new 007] The Incomplete Bridge: How AI Research (Mis)Engages with Psychology
- **分类: cs.AI; cs.CL; cs.CY**

- **简介: 该论文分析了1,006篇AI顶会论文及引用的2,544篇心理学文献，旨在探讨人工智能与心理学的跨学科融合情况。任务是绘制二者互动的图谱，识别心理学理论的应用模式与误用问题，并指导更有效的整合，以促进AI系统设计与理解。**

- **链接: [http://arxiv.org/pdf/2507.22847v1](http://arxiv.org/pdf/2507.22847v1)**

> **作者:** Han Jiang; Pengda Wang; Xiaoyuan Yi; Xing Xie; Ziang Xiao
>
> **摘要:** Social sciences have accumulated a rich body of theories and methodologies for investigating the human mind and behaviors, while offering valuable insights into the design and understanding of Artificial Intelligence (AI) systems. Focusing on psychology as a prominent case, this study explores the interdisciplinary synergy between AI and the field by analyzing 1,006 LLM-related papers published in premier AI venues between 2023 and 2025, along with the 2,544 psychology publications they cite. Through our analysis, we identify key patterns of interdisciplinary integration, locate the psychology domains most frequently referenced, and highlight areas that remain underexplored. We further examine how psychology theories/frameworks are operationalized and interpreted, identify common types of misapplication, and offer guidance for more effective incorporation. Our work provides a comprehensive map of interdisciplinary engagement between AI and psychology, thereby facilitating deeper collaboration and advancing AI systems.
>
---
#### [new 008] Exploring Student-AI Interactions in Vibe Coding
- **分类: cs.HC; cs.CY**

- **简介: 该论文研究学生在使用“vibe coding”平台Replit进行编程时与AI的互动情况，属于教育技术任务。旨在探讨不同编程背景的学生如何与该平台交互，特别是在开发软件过程中的差异。通过观察与主题分析，发现学生主要用平台测试或调试，而非编写代码，高级学生更善于利用上下文提示。**

- **链接: [http://arxiv.org/pdf/2507.22614v1](http://arxiv.org/pdf/2507.22614v1)**

> **作者:** Francis Geng; Anshul Shah; Haolin Li; Nawab Mulla; Steven Swanson; Gerald Soosai Raj; Daniel Zingaro; Leo Porter
>
> **摘要:** Background and Context. Chat-based and inline-coding-based GenAI has already had substantial impact on the CS Education community. The recent introduction of ``vibe coding'' may further transform how students program, as it introduces a new way for students to create software projects with minimal oversight. Objectives. The purpose of this study is to understand how students in introductory programming and advanced software engineering classes interact with a vibe coding platform (Replit) when creating software and how the interactions differ by programming background. Methods. Interview participants were asked to think-aloud while building a web application using Replit. Thematic analysis was then used to analyze the video recordings with an emphasis on the interactions between the student and Replit. Findings. For both groups, the majority of student interactions with Replit were to test or debug the prototype and only rarely did students visit code. Prompts by advanced software engineering students were much more likely to include relevant app feature and codebase contexts than those by introductory programming students.
>
---
## 更新

#### [replaced 001] AI Governance InternationaL Evaluation Index (AGILE Index) 2025
- **分类: cs.CY; 68T01; A.1**

- **链接: [http://arxiv.org/pdf/2507.11546v2](http://arxiv.org/pdf/2507.11546v2)**

> **作者:** Yi Zeng; Enmeng Lu; Xiaoyang Guo; Cunqing Huangfu; Jiawei Xie; Yu Chen; Zhengqi Wang; Dongqi Liang; Gongce Cao; Jin Wang; Zizhe Ruan; Xin Guan; Ammar Younas
>
> **备注:** 81 pages, 29 figures, 7 tables. arXiv admin note: text overlap with arXiv:2502.15859. arXiv admin note: text overlap with arXiv:2502.15859
>
> **摘要:** The year 2024 witnessed accelerated global AI governance advancements, marked by strengthened multilateral frameworks and proliferating national regulatory initiatives. This acceleration underscores an unprecedented need to systematically track governance progress--an imperative that drove the launch of the AI Governance InternationaL Evaluation Index (AGILE Index) project since 2023. The inaugural AGILE Index, released in February 2024 after assessing 14 countries, established an operational and comparable baseline framework. Building on pilot insights, AGILE Index 2025 incorporates systematic refinements to better balance scientific rigor with practical adaptability. The updated methodology expands data diversity while enhancing metric validity and cross-national comparability. Reflecting both research advancements and practical policy evolution, AGILE Index 2025 evaluates 40 countries across income levels, regions, and technological development stages, with 4 Pillars, 17 Dimensions and 43 Indicators. In compiling the data, the team integrates multi-source evidence including policy documents, governance practices, research outputs, and risk exposure to construct a unified comparison framework. This approach maps global disparities while enabling countries to identify governance strengths, gaps, and systemic constraints. Through ongoing refinement and iterations, we hope the AGILE Index will fundamentally advance transparency and measurability in global AI governance, delivering data-driven assessments that depict national AI governance capacity, assist governments in recognizing their maturation stages and critical governance issues, and ultimately provide actionable insights for enhancing AI governance systems nationally and globally.
>
---
#### [replaced 002] Rethinking Individual Fairness in Deepfake Detection
- **分类: cs.LG; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.14326v2](http://arxiv.org/pdf/2507.14326v2)**

> **作者:** Aryana Hou; Li Lin; Justin Li; Shu Hu
>
> **备注:** This paper has been accepted by ACM MM 2025
>
> **摘要:** Generative AI models have substantially improved the realism of synthetic media, yet their misuse through sophisticated DeepFakes poses significant risks. Despite recent advances in deepfake detection, fairness remains inadequately addressed, enabling deepfake markers to exploit biases against specific populations. While previous studies have emphasized group-level fairness, individual fairness (i.e., ensuring similar predictions for similar individuals) remains largely unexplored. In this work, we identify for the first time that the original principle of individual fairness fundamentally fails in the context of deepfake detection, revealing a critical gap previously unexplored in the literature. To mitigate it, we propose the first generalizable framework that can be integrated into existing deepfake detectors to enhance individual fairness and generalization. Extensive experiments conducted on leading deepfake datasets demonstrate that our approach significantly improves individual fairness while maintaining robust detection performance, outperforming state-of-the-art methods. The code is available at https://github.com/Purdue-M2/Individual-Fairness-Deepfake-Detection.
>
---
#### [replaced 003] Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2505.08841v2](http://arxiv.org/pdf/2505.08841v2)**

> **作者:** Andrea Cremaschi; Dae-Jin Lee; Manuele Leonelli
>
> **摘要:** As artificial intelligence and robotics increasingly reshape the global labor market, understanding public perceptions of these technologies becomes critical. We examine how these perceptions have evolved across Latin America, using survey data from the 2017, 2018, 2020, and 2023 waves of the Latinobar\'ometro. Drawing on responses from over 48,000 individuals across 16 countries, we analyze fear of job loss due to artificial intelligence and robotics. Using statistical modeling and latent class analysis, we identify key structural and ideological predictors of concern, with education level and political orientation emerging as the most consistent drivers. Our findings reveal substantial temporal and cross-country variation, with a notable peak in fear during 2018 and distinct attitudinal profiles emerging from latent segmentation. These results offer new insights into the social and structural dimensions of AI anxiety in emerging economies and contribute to a broader understanding of public attitudes toward automation beyond the Global North.
>
---
#### [replaced 004] Training language models to be warm and empathetic makes them less reliable and more sycophantic
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.21919v2](http://arxiv.org/pdf/2507.21919v2)**

> **作者:** Lujain Ibrahim; Franziska Sofia Hafner; Luc Rocher
>
> **摘要:** Artificial intelligence (AI) developers are increasingly building language models with warm and empathetic personas that millions of people now use for advice, therapy, and companionship. Here, we show how this creates a significant trade-off: optimizing language models for warmth undermines their reliability, especially when users express vulnerability. We conducted controlled experiments on five language models of varying sizes and architectures, training them to produce warmer, more empathetic responses, then evaluating them on safety-critical tasks. Warm models showed substantially higher error rates (+10 to +30 percentage points) than their original counterparts, promoting conspiracy theories, providing incorrect factual information, and offering problematic medical advice. They were also significantly more likely to validate incorrect user beliefs, particularly when user messages expressed sadness. Importantly, these effects were consistent across different model architectures, and occurred despite preserved performance on standard benchmarks, revealing systematic risks that current evaluation practices may fail to detect. As human-like AI systems are deployed at an unprecedented scale, our findings indicate a need to rethink how we develop and oversee these systems that are reshaping human relationships and social interaction.
>
---
#### [replaced 005] A ChatGPT-based approach for questions generation in higher education
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2507.21174v2](http://arxiv.org/pdf/2507.21174v2)**

> **作者:** Sinh Trong Vu; Huong Thu Truong; Oanh Tien Do; Tu Anh Le; Tai Tan Mai
>
> **备注:** Proceedings of the 1st ACM Workshop on AI-Powered Q&A Systems for Multimedia. 2024
>
> **摘要:** Large language models have been widely applied in many aspects of real life, bringing significant efficiency to businesses and offering distinctive user experiences. In this paper, we focus on exploring the application of ChatGPT, a chatbot based on a large language model, to support higher educator in generating quiz questions and assessing learners. Specifically, we explore interactive prompting patterns to design an optimal AI-powered question bank creation process. The generated questions are evaluated through a "Blind test" survey sent to various stakeholders including lecturers and learners. Initial results at the Banking Academy of Vietnam are relatively promising, suggesting a potential direction to streamline the time and effort involved in assessing learners at higher education institutes.
>
---
#### [replaced 006] Voices of Freelance Professional Writers on AI: Limitations, Expectations, and Fears
- **分类: cs.CL; cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2504.05008v2](http://arxiv.org/pdf/2504.05008v2)**

> **作者:** Anastasiia Ivanova; Natalia Fedorova; Sergei Tilga; Ekaterina Artemova
>
> **摘要:** The rapid development of AI-driven tools, particularly large language models (LLMs), is reshaping professional writing. Still, key aspects of their adoption such as languages support, ethics, and long-term impact on writers voice and creativity remain underexplored. In this work, we conducted a questionnaire (N = 301) and an interactive survey (N = 36) targeting professional writers regularly using AI. We examined LLM-assisted writing practices across 25+ languages, ethical concerns, and user expectations. The findings of the survey demonstrate important insights, reflecting upon the importance of: LLMs adoption for non-English speakers; the degree of misinformation, domain and style adaptation; usability and key features of LLMs. These insights can guide further development, benefiting both writers and a broader user base.
>
---
#### [replaced 007] Can adversarial attacks by large language models be attributed?
- **分类: cs.AI; cs.CL; cs.CY; cs.FL**

- **链接: [http://arxiv.org/pdf/2411.08003v3](http://arxiv.org/pdf/2411.08003v3)**

> **作者:** Manuel Cebrian; Andres Abeliuk; Jan Arne Telle
>
> **备注:** 22 pages, 5 figures, 2 tables
>
> **摘要:** Attributing outputs from Large Language Models (LLMs) in adversarial settings-such as cyberattacks and disinformation campaigns-presents significant challenges that are likely to grow in importance. We approach this attribution problem from both a theoretical and an empirical perspective, drawing on formal language theory (identification in the limit) and data-driven analysis of the expanding LLM ecosystem. By modeling an LLM's set of possible outputs as a formal language, we analyze whether finite samples of text can uniquely pinpoint the originating model. Our results show that, under mild assumptions of overlapping capabilities among models, certain classes of LLMs are fundamentally non-identifiable from their outputs alone. We delineate four regimes of theoretical identifiability: (1) an infinite class of deterministic (discrete) LLM languages is not identifiable (Gold's classical result from 1967); (2) an infinite class of probabilistic LLMs is also not identifiable (by extension of the deterministic case); (3) a finite class of deterministic LLMs is identifiable (consistent with Angluin's tell-tale criterion); and (4) even a finite class of probabilistic LLMs can be non-identifiable (we provide a new counterexample establishing this negative result). Complementing these theoretical insights, we quantify the explosion in the number of plausible model origins (hypothesis space) for a given output in recent years. Even under conservative assumptions-each open-source model fine-tuned on at most one new dataset-the count of distinct candidate models doubles approximately every 0.5 years, and allowing multi-dataset fine-tuning combinations yields doubling times as short as 0.28 years. This combinatorial growth, alongside the extraordinary computational cost of brute-force likelihood attribution across all models and potential users, renders exhaustive attribution infeasible in practice.
>
---
#### [replaced 008] Strategic Integration of Artificial Intelligence in the C-Suite: The Role of the Chief AI Officer
- **分类: cs.CY; cs.AI; cs.LG; econ.GN; q-fin.EC**

- **链接: [http://arxiv.org/pdf/2407.10247v2](http://arxiv.org/pdf/2407.10247v2)**

> **作者:** Marc Schmitt
>
> **摘要:** The integration of Artificial Intelligence (AI) into corporate strategy has become critical for organizations seeking to maintain a competitive advantage in the digital age. As AI transforms business models, operations, and decision-making, the need for dedicated executive leadership to guide, govern, and orchestrate this transformation becomes increasingly evident. This paper examines emerging future scenarios across three domains: the AI Economy, the AI Organization, and Competition in the Age of AI. These domains reveal environmental, structural, and strategic tensions that existing C-suite roles struggle to resolve. In response, the paper develops a theory-informed framework for the Chief AI Officer (CAIO), outlining the distinct functions and capabilities required to guide and govern AI at scale. Drawing on illustrative cases and emerging practice, this conceptualization clarifies the CAIOs unique role within the executive landscape and presents a forward-looking research agenda. This paper advances the discourse on AI leadership by offering a theory-driven rationale for the strategic integration of AI at the executive level and by positioning the Chief AI Officer as a distinct and necessary role within modern organizations.
>
---
