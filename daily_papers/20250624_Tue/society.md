# 计算机与社会 cs.CY

- **最新发布 31 篇**

- **更新 11 篇**

## 最新发布

#### [new 001] Optimizing Mastery Learning by Fast-Forwarding Over-Practice Steps
- **分类: cs.CY; cs.AI; cs.LG**

- **简介: 该论文属于教育技术领域，旨在解决学习过程中过度练习的问题。通过提出Fast-Forwarding技术，优化问题选择算法，减少学生重复练习已掌握技能的时间。**

- **链接: [http://arxiv.org/pdf/2506.17577v1](http://arxiv.org/pdf/2506.17577v1)**

> **作者:** Meng Xia; Robin Schmucker; Conrad Borchers; Vincent Aleven
>
> **备注:** Full research paper accepted at EC-TEL 2025
>
> **摘要:** Mastery learning improves learning proficiency and efficiency. However, the overpractice of skills--students spending time on skills they have already mastered--remains a fundamental challenge for tutoring systems. Previous research has reduced overpractice through the development of better problem selection algorithms and the authoring of focused practice tasks. However, few efforts have concentrated on reducing overpractice through step-level adaptivity, which can avoid resource-intensive curriculum redesign. We propose and evaluate Fast-Forwarding as a technique that enhances existing problem selection algorithms. Based on simulation studies informed by learner models and problem-solving pathways derived from real student data, Fast-Forwarding can reduce overpractice by up to one-third, as it does not require students to complete problem-solving steps if all remaining pathways are fully mastered. Fast-Forwarding is a flexible method that enhances any problem selection algorithm, though its effectiveness is highest for algorithms that preferentially select difficult problems. Therefore, our findings suggest that while Fast-Forwarding may improve student practice efficiency, the size of its practical impact may also depend on students' ability to stay motivated and engaged at higher levels of difficulty.
>
---
#### [new 002] The California Report on Frontier AI Policy
- **分类: cs.CY**

- **简介: 该论文属于政策研究任务，旨在解决AI发展中的治理问题，通过多学科方法提出风险管理框架与政策原则。**

- **链接: [http://arxiv.org/pdf/2506.17303v1](http://arxiv.org/pdf/2506.17303v1)**

> **作者:** Rishi Bommasani; Scott R. Singer; Ruth E. Appel; Sarah Cen; A. Feder Cooper; Elena Cryst; Lindsey A. Gailmard; Ian Klaus; Meredith M. Lee; Inioluwa Deborah Raji; Anka Reuel; Drew Spence; Alexander Wan; Angelina Wang; Daniel Zhang; Daniel E. Ho; Percy Liang; Dawn Song; Joseph E. Gonzalez; Jonathan Zittrain; Jennifer Tour Chayes; Mariano-Florentino Cuellar; Li Fei-Fei
>
> **备注:** Authored by the Joint California Policy Working Group on AI Frontier Models
>
> **摘要:** The innovations emerging at the frontier of artificial intelligence (AI) are poised to create historic opportunities for humanity but also raise complex policy challenges. Continued progress in frontier AI carries the potential for profound advances in scientific discovery, economic productivity, and broader social well-being. As the epicenter of global AI innovation, California has a unique opportunity to continue supporting developments in frontier AI while addressing substantial risks that could have far reaching consequences for the state and beyond. This report leverages broad evidence, including empirical research, historical analysis, and modeling and simulations, to provide a framework for policymaking on the frontier of AI development. Building on this multidisciplinary approach, this report derives policy principles that can inform how California approaches the use, assessment, and governance of frontier AI: principles rooted in an ethos of trust but verify. This approach takes into account the importance of innovation while establishing appropriate strategies to reduce material risks.
>
---
#### [new 003] AI based Content Creation and Product Recommendation Applications in E-commerce: An Ethical overview
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于伦理研究任务，旨在解决AI在电商内容生成和推荐中的伦理问题，如数据隐私、算法偏见等，并提出公平、透明的解决方案。**

- **链接: [http://arxiv.org/pdf/2506.17370v1](http://arxiv.org/pdf/2506.17370v1)**

> **作者:** Aditi Madhusudan Jain; Ayush Jain
>
> **摘要:** As e-commerce rapidly integrates artificial intelligence for content creation and product recommendations, these technologies offer significant benefits in personalization and efficiency. AI-driven systems automate product descriptions, generate dynamic advertisements, and deliver tailored recommendations based on consumer behavior, as seen in major platforms like Amazon and Shopify. However, the widespread use of AI in e-commerce raises crucial ethical challenges, particularly around data privacy, algorithmic bias, and consumer autonomy. Bias -- whether cultural, gender-based, or socioeconomic -- can be inadvertently embedded in AI models, leading to inequitable product recommendations and reinforcing harmful stereotypes. This paper examines the ethical implications of AI-driven content creation and product recommendations, emphasizing the need for frameworks to ensure fairness, transparency, and need for more established and robust ethical standards. We propose actionable best practices to remove bias and ensure inclusivity, such as conducting regular audits of algorithms, diversifying training data, and incorporating fairness metrics into AI models. Additionally, we discuss frameworks for ethical conformance that focus on safeguarding consumer data privacy, promoting transparency in decision-making processes, and enhancing consumer autonomy. By addressing these issues, we provide guidelines for responsibly utilizing AI in e-commerce applications for content creation and product recommendations, ensuring that these technologies are both effective and ethically sound.
>
---
#### [new 004] Automatic Large Language Models Creation of Interactive Learning Lessons
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 该论文属于教育技术任务，旨在解决如何自动生成互动教学课程的问题。通过分解任务策略，利用AI生成培训课程，并进行评估验证效果。**

- **链接: [http://arxiv.org/pdf/2506.17356v1](http://arxiv.org/pdf/2506.17356v1)**

> **作者:** Jionghao Lin; Jiarui Rao; Yiyang Zhao; Yuting Wang; Ashish Gurung; Amanda Barany; Jaclyn Ocumpaugh; Ryan S. Baker; Kenneth R. Koedinger
>
> **备注:** Full Research Paper, 15 pages, In Proceedings of 20th European Conference on Technology Enhanced Learning (ECTEL2025)
>
> **摘要:** We explore the automatic generation of interactive, scenario-based lessons designed to train novice human tutors who teach middle school mathematics online. Employing prompt engineering through a Retrieval-Augmented Generation approach with GPT-4o, we developed a system capable of creating structured tutor training lessons. Our study generated lessons in English for three key topics: Encouraging Students' Independence, Encouraging Help-Seeking Behavior, and Turning on Cameras, using a task decomposition prompting strategy that breaks lesson generation into sub-tasks. The generated lessons were evaluated by two human evaluators, who provided both quantitative and qualitative evaluations using a comprehensive rubric informed by lesson design research. Results demonstrate that the task decomposition strategy led to higher-rated lessons compared to single-step generation. Human evaluators identified several strengths in the LLM-generated lessons, including well-structured content and time-saving potential, while also noting limitations such as generic feedback and a lack of clarity in some instructional sections. These findings underscore the potential of hybrid human-AI approaches for generating effective lessons in tutor training.
>
---
#### [new 005] Evaluating the Impact of Lean and Green Practices on Operational Performance: A Real Data-Driven Simulation Case Study
- **分类: cs.CY**

- **简介: 该论文属于评估任务，旨在解决传统生产与可持续性结合的问题。通过仿真和OEEE指标，分析精益绿色实践对运营绩效的影响，并提出改进方案。**

- **链接: [http://arxiv.org/pdf/2506.17354v1](http://arxiv.org/pdf/2506.17354v1)**

> **作者:** Farah Altarazi
>
> **备注:** 16 pages, 6 Figures, 4 Tables, This work is based on part of my Master's thesis at the Department of Industrial Engineering, University of Jordan, Jordan
>
> **摘要:** Global market-driven forces and customer needs are continuously changing. In the past, profitability and efficiency were the primary objectives of most companies. However, in recent decades, sustainable performance has emerged as a new competitive advantage. Companies have been compelled to adopt a concept that combines these evolving global interests with traditional goals resulting in the innovation of the lean and green approach. In this study, a research methodology that includes system analysis and modeling procedures to apply the lean and green concept, combined with a new evaluation metric, the Overall Environmental Equipment Effectiveness (OEEE) was used to investigate the effects of adopting lean and green practices on overall performance. A simulation model and energy value stream mapping were implemented, and the OEEE value was calculated to assess the current performance in terms of quality, availability, productivity, and sustainability. The current state production lead time was 329.1 minutes per batch, and the OEEE value was 13.1%. This result indicates existing issues in performance and sustainability, suggesting that improvement efforts should focus on enhancing these two aspects to increase the overall OEEE value. Several improvement scenarios were proposed, including combining and rearranging the inspection workstations as the first scenario, and using UV lighting for drying purposes at the framing workstation as the second. After applying these improvements, both scenarios showed increased OEEE values and reduced lead times compared to the current state. In the first scenario, the lead time decreased to 158.23 minutes, and the OEEE increased to 35%. In the second scenario, the lead time was reduced to 292 minutes, with the OEEE increasing to 24%.
>
---
#### [new 006] A Large-Scale Real-World Evaluation of LLM-Based Virtual Teaching Assistant
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于教育技术任务，旨在评估LLM驱动的虚拟助教在真实课堂中的效果与接受度。通过实证研究和交互分析，探讨其可行性与挑战。**

- **链接: [http://arxiv.org/pdf/2506.17363v1](http://arxiv.org/pdf/2506.17363v1)**

> **作者:** Sunjun Kweon; Sooyohn Nam; Hyunseung Lim; Hwajung Hong; Edward Choi
>
> **备注:** ACL 2025 Industry Track
>
> **摘要:** Virtual Teaching Assistants (VTAs) powered by Large Language Models (LLMs) have the potential to enhance student learning by providing instant feedback and facilitating multi-turn interactions. However, empirical studies on their effectiveness and acceptance in real-world classrooms are limited, leaving their practical impact uncertain. In this study, we develop an LLM-based VTA and deploy it in an introductory AI programming course with 477 graduate students. To assess how student perceptions of the VTA's performance evolve over time, we conduct three rounds of comprehensive surveys at different stages of the course. Additionally, we analyze 3,869 student--VTA interaction pairs to identify common question types and engagement patterns. We then compare these interactions with traditional student--human instructor interactions to evaluate the VTA's role in the learning process. Through a large-scale empirical study and interaction analysis, we assess the feasibility of deploying VTAs in real-world classrooms and identify key challenges for broader adoption. Finally, we release the source code of our VTA system, fostering future advancements in AI-driven education: \texttt{https://github.com/sean0042/VTA}.
>
---
#### [new 007] Using Machine Learning in Analyzing Air Quality Discrepancies of Environmental Impact
- **分类: cs.CY; cs.LG**

- **简介: 该论文属于环境与社会公平研究任务，旨在分析空气污染差异及其与保险评估方法的关联，通过机器学习揭示政策对居民生活质量的影响。**

- **链接: [http://arxiv.org/pdf/2506.17319v1](http://arxiv.org/pdf/2506.17319v1)**

> **作者:** Shuangbao Paul Wang; Lucas Yang; Rahouane Chouchane; Jin Guo; Michael Bailey
>
> **备注:** IEEE 2024 International Conference on AI x Data & Knowledge Engineering (AIxDKE)
>
> **摘要:** In this study, we apply machine learning and software engineering in analyzing air pollution levels in City of Baltimore. The data model was fed with three primary data sources: 1) a biased method of estimating insurance risk used by homeowners loan corporation, 2) demographics of Baltimore residents, and 3) census data estimate of NO2 and PM2.5 concentrations. The dataset covers 650,643 Baltimore residents in 44.7 million residents in 202 major cities in US. The results show that air pollution levels have a clear association with the biased insurance estimating method. Great disparities present in NO2 level between more desirable and low income blocks. Similar disparities exist in air pollution level between residents' ethnicity. As Baltimore population consists of a greater proportion of people of color, the finding reveals how decades old policies has continued to discriminate and affect quality of life of Baltimore citizens today.
>
---
#### [new 008] MAARTA:Multi-Agentic Adaptive Radiology Teaching Assistant
- **分类: cs.CY; cs.CV; cs.LG**

- **简介: 该论文属于医学教育任务，旨在解决放射学学生因缺乏指导而产生的感知错误。工作是提出MAARTA系统，通过分析眼动和报告提供个性化反馈。**

- **链接: [http://arxiv.org/pdf/2506.17320v1](http://arxiv.org/pdf/2506.17320v1)**

> **作者:** Akash Awasthi; Brandon V. Chang; Anh M. Vu; Ngan Le; Rishi Agrawal; Zhigang Deng; Carol Wu; Hien Van Nguyen
>
> **备注:** Accepted to MICCAI 2025 (Main Conference)
>
> **摘要:** Radiology students often struggle to develop perceptual expertise due to limited expert mentorship time, leading to errors in visual search and diagnostic interpretation. These perceptual errors, such as missed fixations, short dwell times, or misinterpretations, are not adequately addressed by current AI systems, which focus on diagnostic accuracy but fail to explain how and why errors occur. To address this gap, we introduce MAARTA (Multi-Agentic Adaptive Radiology Teaching Assistant), a multi-agent framework that analyzes gaze patterns and radiology reports to provide personalized feedback. Unlike single-agent models, MAARTA dynamically selects agents based on error complexity, enabling adaptive and efficient reasoning. By comparing expert and student gaze behavior through structured graphs, the system identifies missed findings and assigns Perceptual Error Teacher agents to analyze discrepancies. MAARTA then uses step-by-step prompting to help students understand their errors and improve diagnostic reasoning, advancing AI-driven radiology education.
>
---
#### [new 009] PasteTrace: A Single Source Plagiarism Detection Tool For Introductory Programming Courses
- **分类: cs.CY**

- **简介: 该论文提出PasteTrace，一款用于初学者编程课程的抄袭检测工具，旨在解决编程作业抄袭问题。**

- **链接: [http://arxiv.org/pdf/2506.17355v1](http://arxiv.org/pdf/2506.17355v1)**

> **作者:** Jesse McDonald; Scott Robertson; Anthony Peruma
>
> **摘要:** Introductory Computer Science classes are important for laying the foundation for advanced programming courses. However, students without prior programming experience may find these courses challenging, leading to difficulties in understanding concepts and engaging in academic dishonesty such as plagiarism. While there exists plagiarism detection techniques and tools, not all of them are suitable for academic settings, especially in introductory programming courses. This paper introduces PasteTrace, a novel open-source plagiarism detection tool designed specifically for introductory programming courses. Unlike traditional methods, PasteTrace operates within an Integrated Development Environment that tracks the student's coding activities in real-time for evidence of plagiarism. Our evaluation of PasteTrace in two introductory programming courses demonstrates the tool's ability to provide insights into student behavior and detect various forms of plagiarism, outperforming an existing well-established tool. A video demonstration of PasteTrace and its source code, and case study data are made available at https://doi.org/10.6084/m9.figshare.27115852
>
---
#### [new 010] Experimental Evidence for the Propagation and Preservation of Machine Discoveries in Human Populations
- **分类: cs.CY**

- **简介: 该论文属于人工智能与人类文化交互研究，探讨机器发现的策略如何被人类传播和保留，解决机器如何影响人类问题解决能力的问题。通过实验和模拟验证了三个关键条件。**

- **链接: [http://arxiv.org/pdf/2506.17741v1](http://arxiv.org/pdf/2506.17741v1)**

> **作者:** Levin Brinkmann; Thomas F. Eisenmann; Anne-Marie Nussberger; Maxim Derex; Sara Bonati; Valerii Chirkov; Iyad Rahwan
>
> **摘要:** Intelligent machines with superhuman capabilities have the potential to uncover problem-solving strategies beyond human discovery. Emerging evidence from competitive gameplay, such as Go, demonstrates that AI systems are evolving from mere tools to sources of cultural innovation adopted by humans. However, the conditions under which intelligent machines transition from tools to drivers of persistent cultural change remain unclear. We identify three key conditions for machines to fundamentally influence human problem-solving: the discovered strategies must be non-trivial, learnable, and offer a clear advantage. Using a cultural transmission experiment and an agent-based simulation, we demonstrate that when these conditions are met, machine-discovered strategies can be transmitted, understood, and preserved by human populations, leading to enduring cultural shifts. These findings provide a framework for understanding how machines can persistently expand human cognitive skills and underscore the need to consider their broader implications for human cognition and cultural evolution.
>
---
#### [new 011] AI-based Multimodal Biometrics for Detecting Smartphone Distractions: Application to Online Learning
- **分类: cs.CY; cs.AI; cs.CV; cs.HC**

- **简介: 该论文属于注意力检测任务，旨在解决在线学习中因手机使用导致的分心问题。通过多模态生物特征数据，提出AI方法提升检测准确性。**

- **链接: [http://arxiv.org/pdf/2506.17364v1](http://arxiv.org/pdf/2506.17364v1)**

> **作者:** Alvaro Becerra; Roberto Daza; Ruth Cobos; Aythami Morales; Mutlu Cukurova; Julian Fierrez
>
> **备注:** Accepted in EC-TEL25: 20th European Conference on Technology Enhanced Learning, Newcastle and Durham, UK, 15-19 September 2025
>
> **摘要:** This work investigates the use of multimodal biometrics to detect distractions caused by smartphone use during tasks that require sustained attention, with a focus on computer-based online learning. Although the methods are applicable to various domains, such as autonomous driving, we concentrate on the challenges learners face in maintaining engagement amid internal (e.g., motivation), system-related (e.g., course design) and contextual (e.g., smartphone use) factors. Traditional learning platforms often lack detailed behavioral data, but Multimodal Learning Analytics (MMLA) and biosensors provide new insights into learner attention. We propose an AI-based approach that leverages physiological signals and head pose data to detect phone use. Our results show that single biometric signals, such as brain waves or heart rate, offer limited accuracy, while head pose alone achieves 87%. A multimodal model combining all signals reaches 91% accuracy, highlighting the benefits of integration. We conclude by discussing the implications and limitations of deploying these models for real-time support in online learning environments.
>
---
#### [new 012] Distinguishing Predictive and Generative AI in Regulation
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于政策分析任务，旨在解决监管框架与生成式AI不匹配的问题，提出针对性政策建议。**

- **链接: [http://arxiv.org/pdf/2506.17347v1](http://arxiv.org/pdf/2506.17347v1)**

> **作者:** Jennifer Wang; Andrew Selbst; Solon Barocas; Suresh Venkatasubramanian
>
> **摘要:** Over the past decade, policymakers have developed a set of regulatory tools to ensure AI development aligns with key societal goals. Many of these tools were initially developed in response to concerns with predictive AI and therefore encode certain assumptions about the nature of AI systems and the utility of certain regulatory approaches. With the advent of generative AI, however, some of these assumptions no longer hold, even as policymakers attempt to maintain a single regulatory target that covers both types of AI. In this paper, we identify four distinct aspects of generative AI that call for meaningfully different policy responses. These are the generality and adaptability of generative AI that make it a poor regulatory target, the difficulty of designing effective evaluations, new legal concerns that change the ecosystem of stakeholders and sources of expertise, and the distributed structure of the generative AI value chain. In light of these distinctions, policymakers will need to evaluate where the past decade of policy work remains relevant and where new policies, designed to address the unique risks posed by generative AI, are necessary. We outline three recommendations for policymakers to more effectively identify regulatory targets and leverage constraints across the broader ecosystem to govern generative AI.
>
---
#### [new 013] Public Perceptions of Autonomous Vehicles: A Survey of Pedestrians and Cyclists in Pittsburgh
- **分类: cs.CY; cs.RO**

- **简介: 该论文属于社会调研任务，旨在了解行人和骑车人对自动驾驶汽车的感知。通过调查分析，探讨了人口统计、基础设施与信任的关系，以促进AV技术的接受与应用。**

- **链接: [http://arxiv.org/pdf/2506.17513v1](http://arxiv.org/pdf/2506.17513v1)**

> **作者:** Rudra Y. Bedekar
>
> **摘要:** This study investigates how autonomous vehicle(AV) technology is perceived by pedestrians and bicyclists in Pittsburgh. Using survey data from over 1200 respondents, the research explores the interplay between demographics, AV interactions, infrastructural readiness, safety perceptions, and trust. Findings highlight demographic divides, infrastructure gaps, and the crucial role of communication and education in AV adoption.
>
---
#### [new 014] Aggregated Individual Reporting for Post-Deployment Evaluation
- **分类: cs.CY**

- **简介: 该论文属于AI系统评估任务，旨在通过公众个体报告进行部署后评估，解决AI系统安全与性能的动态监控问题。**

- **链接: [http://arxiv.org/pdf/2506.18133v1](http://arxiv.org/pdf/2506.18133v1)**

> **作者:** Jessica Dai; Inioluwa Deborah Raji; Benjamin Recht; Irene Y. Chen
>
> **摘要:** The need for developing model evaluations beyond static benchmarking, especially in the post-deployment phase, is now well-understood. At the same time, concerns about the concentration of power in deployed AI systems have sparked a keen interest in 'democratic' or 'public' AI. In this work, we bring these two ideas together by proposing mechanisms for aggregated individual reporting (AIR), a framework for post-deployment evaluation that relies on individual reports from the public. An AIR mechanism allows those who interact with a specific, deployed (AI) system to report when they feel that they may have experienced something problematic; these reports are then aggregated over time, with the goal of evaluating the relevant system in a fine-grained manner. This position paper argues that individual experiences should be understood as an integral part of post-deployment evaluation, and that the scope of our proposed aggregated individual reporting mechanism is a practical path to that end. On the one hand, individual reporting can identify substantively novel insights about safety and performance; on the other, aggregation can be uniquely useful for informing action. From a normative perspective, the post-deployment phase completes a missing piece in the conversation about 'democratic' AI. As a pathway to implementation, we provide a workflow of concrete design decisions and pointers to areas requiring further research and methodological development.
>
---
#### [new 015] Multimodal Political Bias Identification and Neutralization
- **分类: cs.CY; cs.AI; cs.CV**

- **简介: 该论文属于多模态政治偏见识别与消除任务，旨在解决文本和图像中的主观偏见问题，通过四步模型实现文本和图像的去偏处理。**

- **链接: [http://arxiv.org/pdf/2506.17372v1](http://arxiv.org/pdf/2506.17372v1)**

> **作者:** Cedric Bernard; Xavier Pleimling; Amun Kharel; Chase Vickery
>
> **摘要:** Due to the presence of political echo chambers, it becomes imperative to detect and remove subjective bias and emotionally charged language from both the text and images of political articles. However, prior work has focused on solely the text portion of the bias rather than both the text and image portions. This is a problem because the images are just as powerful of a medium to communicate information as text is. To that end, we present a model that leverages both text and image bias which consists of four different steps. Image Text Alignment focuses on semantically aligning images based on their bias through CLIP models. Image Bias Scoring determines the appropriate bias score of images via a ViT classifier. Text De-Biasing focuses on detecting biased words and phrases and neutralizing them through BERT models. These three steps all culminate to the final step of debiasing, which replaces the text and the image with neutralized or reduced counterparts, which for images is done by comparing the bias scores. The results so far indicate that this approach is promising, with the text debiasing strategy being able to identify many potential biased words and phrases, and the ViT model showcasing effective training. The semantic alignment model also is efficient. However, more time, particularly in training, and resources are needed to obtain better results. A human evaluation portion was also proposed to ensure semantic consistency of the newly generated text and images.
>
---
#### [new 016] The Democratic Paradox in Large Language Models' Underestimation of Press Freedom
- **分类: cs.CY; cs.AI; cs.CL; K.4; I.2.7; I.2.0**

- **简介: 该论文属于自然语言处理中的偏差分析任务，旨在揭示大语言模型对新闻自由评估的系统性低估问题。研究对比了六款模型与专家评分的差异，发现其存在负面偏误和本土偏见。**

- **链接: [http://arxiv.org/pdf/2506.18045v1](http://arxiv.org/pdf/2506.18045v1)**

> **作者:** I. Loaiza; R. Vestrelli; A. Fronzetti Colladon; R. Rigobon
>
> **摘要:** As Large Language Models (LLMs) increasingly mediate global information access for millions of users worldwide, their alignment and biases have the potential to shape public understanding and trust in fundamental democratic institutions, such as press freedom. In this study, we uncover three systematic distortions in the way six popular LLMs evaluate press freedom in 180 countries compared to expert assessments of the World Press Freedom Index (WPFI). The six LLMs exhibit a negative misalignment, consistently underestimating press freedom, with individual models rating between 71% to 93% of countries as less free. We also identify a paradoxical pattern we term differential misalignment: LLMs disproportionately underestimate press freedom in countries where it is strongest. Additionally, five of the six LLMs exhibit positive home bias, rating their home countries' press freedoms more favorably than would be expected given their negative misalignment with the human benchmark. In some cases, LLMs rate their home countries between 7% to 260% more positively than expected. If LLMs are set to become the next search engines and some of the most important cultural tools of our time, they must ensure accurate representations of the state of our human and civic rights globally.
>
---
#### [new 017] A Grassroots Network and Community Roadmap for Interconnected Autonomous Science Laboratories for Accelerated Discovery
- **分类: cs.CY; cs.DC; physics.soc-ph**

- **简介: 该论文提出AISLE系统，解决自主实验室协作问题，通过跨机构设备协调、智能数据管理等五方面工作，推动科学发现加速。**

- **链接: [http://arxiv.org/pdf/2506.17510v1](http://arxiv.org/pdf/2506.17510v1)**

> **作者:** Rafael Ferreira da Silva; Milad Abolhasani; Dionysios A. Antonopoulos; Laura Biven; Ryan Coffee; Ian T. Foster; Leslie Hamilton; Shantenu Jha; Theresa Mayer; Benjamin Mintz; Robert G. Moore; Salahudin Nimer; Noah Paulson; Woong Shin; Frederic Suter; Mitra Taheri; Michela Taufer; Newell R. Washburn
>
> **摘要:** Scientific discovery is being revolutionized by AI and autonomous systems, yet current autonomous laboratories remain isolated islands unable to collaborate across institutions. We present the Autonomous Interconnected Science Lab Ecosystem (AISLE), a grassroots network transforming fragmented capabilities into a unified system that shorten the path from ideation to innovation to impact and accelerates discovery from decades to months. AISLE addresses five critical dimensions: (1) cross-institutional equipment orchestration, (2) intelligent data management with FAIR compliance, (3) AI-agent driven orchestration grounded in scientific principles, (4) interoperable agent communication interfaces, and (5) AI/ML-integrated scientific education. By connecting autonomous agents across institutional boundaries, autonomous science can unlock research spaces inaccessible to traditional approaches while democratizing cutting-edge technologies. This paradigm shift toward collaborative autonomous science promises breakthroughs in sustainable energy, materials development, and public health.
>
---
#### [new 018] AI is the Strategy: From Agentic AI to Autonomous Business Models onto Strategy in the Age of AI
- **分类: cs.CY; econ.GN; q-fin.EC**

- **简介: 该论文属于战略管理研究，探讨AI驱动的自主商业模式（ABM）如何重构企业战略。旨在解决传统战略与AI关系的问题，通过案例分析提出AI作为核心战略主体的新范式。**

- **链接: [http://arxiv.org/pdf/2506.17339v1](http://arxiv.org/pdf/2506.17339v1)**

> **作者:** René Bohnsack; Mickie de Wet
>
> **备注:** 21 pages, 6 figures, 3 tables. Under review at Strategy Science (no decision yet). This version posted to facilitate citation and feedback
>
> **摘要:** This article develops the concept of Autonomous Business Models (ABMs) as a distinct managerial and strategic logic in the age of agentic AI. While most firms still operate within human-driven or AI-augmented models, we argue that we are now entering a phase where agentic AI (systems capable of initiating, coordinating, and adapting actions autonomously) can increasingly execute the core mechanisms of value creation, delivery, and capture. This shift reframes AI not as a tool to support strategy, but as the strategy itself. Using two illustrative cases, getswan.ai, an Israeli startup pursuing autonomy by design, and a hypothetical reconfiguration of Ryanair as an AI-driven incumbent, we depict the evolution from augmented to autonomous business models. We show how ABMs reshape competitive advantage through agentic execution, continuous adaptation, and the gradual offloading of human decision-making. This transition introduces new forms of competition between AI-led firms, which we term synthetic competition, where strategic interactions occur at rapid, machine-level speed and scale. It also challenges foundational assumptions in strategy, organizational design, and governance. By positioning agentic AI as the central actor in business model execution, the article invites us to rethink strategic management in an era where firms increasingly run themselves.
>
---
#### [new 019] Can Large Language Models Be Trusted Paper Reviewers? A Feasibility Study
- **分类: cs.CY**

- **简介: 该论文属于学术论文评审任务，旨在探索使用大语言模型自动评审的可行性。研究提出一个自动化系统，但发现其准确性有限，建议作为辅助工具使用。**

- **链接: [http://arxiv.org/pdf/2506.17311v1](http://arxiv.org/pdf/2506.17311v1)**

> **作者:** Chuanlei Li; Xu Hu; Minghui Xu; Kun Li; Yue Zhang; Xiuzhen Cheng
>
> **摘要:** Academic paper review typically requires substantial time, expertise, and human resources. Large Language Models (LLMs) present a promising method for automating the review process due to their extensive training data, broad knowledge base, and relatively low usage cost. This work explores the feasibility of using LLMs for academic paper review by proposing an automated review system. The system integrates Retrieval Augmented Generation (RAG), the AutoGen multi-agent system, and Chain-of-Thought prompting to support tasks such as format checking, standardized evaluation, comment generation, and scoring. Experiments conducted on 290 submissions from the WASA 2024 conference using GPT-4o show that LLM-based review significantly reduces review time (average 2.48 hours) and cost (average \$104.28 USD). However, the similarity between LLM-selected papers and actual accepted papers remains low (average 38.6\%), indicating issues such as hallucination, lack of independent judgment, and retrieval preferences. Therefore, it is recommended to use LLMs as assistive tools to support human reviewers, rather than to replace them.
>
---
#### [new 020] The value of human and machine in machine-generated creative contents
- **分类: cs.CY**

- **简介: 该论文属于人工智能与创造力交叉领域，探讨机器生成内容中人类与机器的协作关系，旨在澄清机器创造力的来源，强调人类解释的重要性。**

- **链接: [http://arxiv.org/pdf/2506.17808v1](http://arxiv.org/pdf/2506.17808v1)**

> **作者:** Weina Jin
>
> **摘要:** The seemingly "imagination" and "creativity" from machine-generated contents should not be misattributed to the accomplishment of machine. They are accomplishments of both human and machine. Without human interpretation, the machine-generated contents remain in the imaginary space of the large language models, and cannot automatically establish grounding in the reality and human experience.
>
---
#### [new 021] Research on the recommendation framework of foreign enterprises from the perspective of multidimensional proximity
- **分类: stat.AP; cs.CY**

- **简介: 该论文属于企业推荐任务，旨在解决如何识别适合本地投资的优质外企问题。通过构建多维接近性框架，结合数据分析与案例验证，筛选出最优候选企业。**

- **链接: [http://arxiv.org/pdf/2506.17657v1](http://arxiv.org/pdf/2506.17657v1)**

> **作者:** Guoqiang Liang; Jiarui Xie; Mengxuan Li; Shuo Zhang
>
> **摘要:** As global economic integration progresses, foreign-funded enterprises play an increasingly crucial role in fostering local economic growth and enhancing industrial development. However, there are not many researches to deal with this aspect in recent years. This study utilizes the multidimensional proximity theory to thoroughly examine the criteria for selecting high-quality foreign-funded companies that are likely to invest in and establish factories in accordance with local conditions during the investment attraction process.First, this study leverages databases such as Wind and Osiris, along with government policy documents, to investigate foreign-funded enterprises and establish a high-quality database. Second, using a two-step method, enterprises aligned with local industrial strategies are identified. Third, a detailed analysis is conducted on key metrics, including industry revenue, concentration (measured by the Herfindahl-Hirschman Index), and geographical distance (calculated using the Haversine formula). Finally, a multi-criteria decision analysis ranks the top five companies as the most suitable candidates for local investment, with the methodology validated through a case study in a district of Beijing.The example results show that the established framework helps local governments identify high-quality foreign-funded enterprises.
>
---
#### [new 022] A Modular Taxonomy for Hate Speech Definitions and Its Impact on Zero-Shot LLM Classification Performance
- **分类: cs.CL; cs.CY**

- **简介: 该论文属于自然语言处理中的有害内容检测任务，旨在解决 hate speech 定义模糊及其对模型性能影响的问题。通过构建分类体系并实验验证不同定义对模型效果的影响。**

- **链接: [http://arxiv.org/pdf/2506.18576v1](http://arxiv.org/pdf/2506.18576v1)**

> **作者:** Matteo Melis; Gabriella Lapesa; Dennis Assenmacher
>
> **摘要:** Detecting harmful content is a crucial task in the landscape of NLP applications for Social Good, with hate speech being one of its most dangerous forms. But what do we mean by hate speech, how can we define it, and how does prompting different definitions of hate speech affect model performance? The contribution of this work is twofold. At the theoretical level, we address the ambiguity surrounding hate speech by collecting and analyzing existing definitions from the literature. We organize these definitions into a taxonomy of 14 Conceptual Elements-building blocks that capture different aspects of hate speech definitions, such as references to the target of hate (individual or groups) or of the potential consequences of it. At the experimental level, we employ the collection of definitions in a systematic zero-shot evaluation of three LLMs, on three hate speech datasets representing different types of data (synthetic, human-in-the-loop, and real-world). We find that choosing different definitions, i.e., definitions with a different degree of specificity in terms of encoded elements, impacts model performance, but this effect is not consistent across all architectures.
>
---
#### [new 023] Neural Total Variation Distance Estimators for Changepoint Detection in News Data
- **分类: cs.LG; cs.CL; cs.CY; cs.SI**

- **简介: 该论文属于 changepoint detection 任务，旨在检测新闻数据中公众话语的突变点。通过神经网络估计总变分距离，识别重大事件引发的语义变化。**

- **链接: [http://arxiv.org/pdf/2506.18764v1](http://arxiv.org/pdf/2506.18764v1)**

> **作者:** Csaba Zsolnai; Niels Lörch; Julian Arnold
>
> **备注:** 16 pages, 3 figures
>
> **摘要:** Detecting when public discourse shifts in response to major events is crucial for understanding societal dynamics. Real-world data is high-dimensional, sparse, and noisy, making changepoint detection in this domain a challenging endeavor. In this paper, we leverage neural networks for changepoint detection in news data, introducing a method based on the so-called learning-by-confusion scheme, which was originally developed for detecting phase transitions in physical systems. We train classifiers to distinguish between articles from different time periods. The resulting classification accuracy is used to estimate the total variation distance between underlying content distributions, where significant distances highlight changepoints. We demonstrate the effectiveness of this method on both synthetic datasets and real-world data from The Guardian newspaper, successfully identifying major historical events including 9/11, the COVID-19 pandemic, and presidential elections. Our approach requires minimal domain knowledge, can autonomously discover significant shifts in public discourse, and yields a quantitative measure of change in content, making it valuable for journalism, policy analysis, and crisis monitoring.
>
---
#### [new 024] Leveraging LLMs to Assess Tutor Moves in Real-Life Dialogues: A Feasibility Study
- **分类: cs.CL; cs.CY**

- **简介: 该论文属于教育技术任务，旨在通过大语言模型评估真实对话中的导师行为。研究解决如何规模化识别和评价 tutoring 行为的问题，通过分析对话转录文本并验证模型效果。**

- **链接: [http://arxiv.org/pdf/2506.17410v1](http://arxiv.org/pdf/2506.17410v1)**

> **作者:** Danielle R. Thomas; Conrad Borchers; Jionghao Lin; Sanjit Kakarla; Shambhavi Bhushan; Erin Gatz; Shivang Gupta; Ralph Abboud; Kenneth R. Koedinger
>
> **备注:** Short research paper accepted at EC-TEL 2025
>
> **摘要:** Tutoring improves student achievement, but identifying and studying what tutoring actions are most associated with student learning at scale based on audio transcriptions is an open research problem. This present study investigates the feasibility and scalability of using generative AI to identify and evaluate specific tutor moves in real-life math tutoring. We analyze 50 randomly selected transcripts of college-student remote tutors assisting middle school students in mathematics. Using GPT-4, GPT-4o, GPT-4-turbo, Gemini-1.5-pro, and LearnLM, we assess tutors' application of two tutor skills: delivering effective praise and responding to student math errors. All models reliably detected relevant situations, for example, tutors providing praise to students (94-98% accuracy) and a student making a math error (82-88% accuracy) and effectively evaluated the tutors' adherence to tutoring best practices, aligning closely with human judgments (83-89% and 73-77%, respectively). We propose a cost-effective prompting strategy and discuss practical implications for using large language models to support scalable assessment in authentic settings. This work further contributes LLM prompts to support reproducibility and research in AI-supported learning.
>
---
#### [new 025] SoK: Current State of Ethereum's Enshrined Proposer Builder Separation
- **分类: cs.CR; cs.CY; C.2.4**

- **简介: 该论文属于系统综述（SoK）任务，探讨以太坊的PBS机制及其集成化问题，旨在分析当前方案、需求及潜在影响。**

- **链接: [http://arxiv.org/pdf/2506.18189v1](http://arxiv.org/pdf/2506.18189v1)**

> **作者:** Maxwell Koegler
>
> **备注:** 12 pages, 2 figures, submitted to The Science of Blockchain Conference 2025
>
> **摘要:** Initially introduced to Ethereum via Flashbots' MEV-boost, Proposer-Builder Separation allows proposers to auction off blockspace to a market of transaction orderers, known as builders. PBS is currently available to validators through the aforementioned MEV-boost, but its unregulated and relay-dependent nature has much of the Ethereum community calling for its enshrinement. Providing a protocol-integrated PBS marketspace and communication channel for payload outsourcing is termed PBS enshrinement. Although ePBS potentially introduces native MEV mitigation mechanisms and reduces validator operation costs, fears of multiparty collusion and chain stagnation are all too real. In addition to mitigating these potential drawbacks, PBS research pursues many tenets revered by Web3 enthusiasts, including but not limited to, censorship resistance, validator reward equity, and deflationary finance. The subsequent SoK will identify current PBS mechanisms, the need for enshrinement, additions to the ePBS upgrade, and the existing or potential on-chain socioeconomic implications of each.
>
---
#### [new 026] Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review
- **分类: cs.CL; cs.AI; cs.CY; cs.HC**

- **简介: 该论文属于自然语言处理中的偏见缓解任务，旨在解决大型语言模型中对阿拉伯人和穆斯林的文化偏见问题。通过系统综述，分析了五种提示工程方法的有效性。**

- **链接: [http://arxiv.org/pdf/2506.18199v1](http://arxiv.org/pdf/2506.18199v1)**

> **作者:** Bushra Asseri; Estabrag Abdelaziz; Areej Al-Wabil
>
> **摘要:** Large language models have demonstrated remarkable capabilities across various domains, yet concerns about cultural bias - particularly towards Arabs and Muslims - pose significant ethical challenges by perpetuating harmful stereotypes and marginalization. Despite growing recognition of bias in LLMs, prompt engineering strategies specifically addressing Arab and Muslim representation remain understudied. This mixed-methods systematic review examines such techniques, offering evidence-based guidance for researchers and practitioners. Following PRISMA guidelines and Kitchenham's systematic review methodology, we analyzed 8 empirical studies published between 2021-2024 investigating bias mitigation strategies. Our findings reveal five primary prompt engineering approaches: cultural prompting, affective priming, self-debiasing techniques, structured multi-step pipelines, and parameter-optimized continuous prompts. Although all approaches show potential for reducing bias, effectiveness varied substantially across studies and bias types. Evidence suggests that certain bias types may be more resistant to prompt-based mitigation than others. Structured multi-step pipelines demonstrated the highest overall effectiveness, achieving up to 87.7% reduction in bias, though they require greater technical expertise. Cultural prompting offers broader accessibility with substantial effectiveness. These results underscore the accessibility of prompt engineering for mitigating cultural bias without requiring access to model parameters. The limited number of studies identified highlights a significant research gap in this critical area. Future research should focus on developing culturally adaptive prompting techniques, creating Arab and Muslim-specific evaluation resources, and integrating prompt engineering with complementary debiasing methods to address deeper stereotypes while maintaining model utility.
>
---
#### [new 027] Mental Health Equity in LLMs: Leveraging Multi-Hop Question Answering to Detect Amplified and Silenced Perspectives
- **分类: cs.CL; cs.AI; cs.CY**

- **简介: 该论文属于自然语言处理中的偏见检测任务，旨在解决LLMs在心理健康领域可能放大的偏见问题。通过多跳问答框架分析数据，识别并减少模型中的系统性偏差。**

- **链接: [http://arxiv.org/pdf/2506.18116v1](http://arxiv.org/pdf/2506.18116v1)**

> **作者:** Batool Haider; Atmika Gorti; Aman Chadha; Manas Gaur
>
> **备注:** 19 Pages, 7 Figures, 4 Tables (Note: Under Review)
>
> **摘要:** Large Language Models (LLMs) in mental healthcare risk propagating biases that reinforce stigma and harm marginalized groups. While previous research identified concerning trends, systematic methods for detecting intersectional biases remain limited. This work introduces a multi-hop question answering (MHQA) framework to explore LLM response biases in mental health discourse. We analyze content from the Interpretable Mental Health Instruction (IMHI) dataset across symptom presentation, coping mechanisms, and treatment approaches. Using systematic tagging across age, race, gender, and socioeconomic status, we investigate bias patterns at demographic intersections. We evaluate four LLMs: Claude 3.5 Sonnet, Jamba 1.6, Gemma 3, and Llama 4, revealing systematic disparities across sentiment, demographics, and mental health conditions. Our MHQA approach demonstrates superior detection compared to conventional methods, identifying amplification points where biases magnify through sequential reasoning. We implement two debiasing techniques: Roleplay Simulation and Explicit Bias Reduction, achieving 66-94% bias reductions through few-shot prompting with BBQ dataset examples. These findings highlight critical areas where LLMs reproduce mental healthcare biases, providing actionable insights for equitable AI development.
>
---
#### [new 028] Trustworthy Chronic Disease Risk Prediction For Self-Directed Preventive Care via Medical Literature Validation
- **分类: cs.LG; cs.CY**

- **简介: 该论文属于慢性病风险预测任务，旨在解决现有模型依赖医疗数据、缺乏可解释性及验证的问题。研究构建了基于个人和生活方式因素的深度学习模型，并通过SHAP验证其特征与医学文献的一致性，提升模型可信度。**

- **链接: [http://arxiv.org/pdf/2506.17620v1](http://arxiv.org/pdf/2506.17620v1)**

> **作者:** Minh Le; Khoi Ton
>
> **摘要:** Chronic diseases are long-term, manageable, yet typically incurable conditions, highlighting the need for effective preventive strategies. Machine learning has been widely used to assess individual risk for chronic diseases. However, many models rely on medical test data (e.g. blood results, glucose levels), which limits their utility for proactive self-assessment. Additionally, to gain public trust, machine learning models should be explainable and transparent. Although some research on self-assessment machine learning models includes explainability, their explanations are not validated against established medical literature, reducing confidence in their reliability. To address these issues, we develop deep learning models that predict the risk of developing 13 chronic diseases using only personal and lifestyle factors, enabling accessible, self-directed preventive care. Importantly, we use SHAP-based explainability to identify the most influential model features and validate them against established medical literature. Our results show a strong alignment between the models' most influential features and established medical literature, reinforcing the models' trustworthiness. Critically, we find that this observation holds across 13 distinct diseases, indicating that this machine learning approach can be broadly trusted for chronic disease prediction. This work lays the foundation for developing trustworthy machine learning tools for self-directed preventive care. Future research can explore other approaches for models' trustworthiness and discuss how the models can be used ethically and responsibly.
>
---
#### [new 029] Triadic Novelty: A Typology and Measurement Framework for Recognizing Novel Contributions in Science
- **分类: physics.soc-ph; cs.CY; cs.SI; stat.AP**

- **简介: 该论文属于科学评价任务，旨在解决现有奖励系统忽视真正创新的问题。提出三类创新类型并建立评估框架，分析其影响力与认可度。**

- **链接: [http://arxiv.org/pdf/2506.17851v1](http://arxiv.org/pdf/2506.17851v1)**

> **作者:** Jin Ai; Richard S. Steinberg; Chao Guo; Filipi Nascimento Silva
>
> **备注:** 27 pages, 3 figures, 5 tables
>
> **摘要:** Scientific progress depends on novel ideas, but current reward systems often fail to recognize them. Many existing metrics conflate novelty with popularity, privileging ideas that fit existing paradigms over those that challenge them. This study develops a theory-driven framework to better understand how different types of novelty emerge, take hold, and receive recognition. Drawing on network science and theories of discovery, we introduce a triadic typology: Pioneers, who introduce entirely new topics; Mavericks, who recombine distant concepts; and Vanguards, who reinforce weak but promising connections. We apply this typology to a dataset of 41,623 articles in the interdisciplinary field of philanthropy and nonprofit studies, linking novelty types to five-year citation counts using mixed-effects negative binomial regression. Results show that novelty is not uniformly rewarded. Pioneer efforts are foundational but often overlooked. Maverick novelty shows consistent citation benefits, particularly rewarded when it displaces prior focus. Vanguard novelty is more likely to gain recognition when it strengthens weakly connected topics, but its citation advantage diminishes as those reinforced nodes become more central. To enable fair comparison across time and domains, we introduce a simulated baseline model. These findings improve the evaluation of innovations, affecting science policy, funding, and institutional assessment practices.
>
---
#### [new 030] Mind the Gap: Assessing Wiktionary's Crowd-Sourced Linguistic Knowledge on Morphological Gaps in Two Related Languages
- **分类: cs.CL; cs.CY**

- **简介: 该论文属于计算语言学任务，旨在解决形态缺陷性问题。通过分析维基词典数据，验证其在拉丁语和意大利语中的可靠性，发现部分缺陷词目存在争议。**

- **链接: [http://arxiv.org/pdf/2506.17603v1](http://arxiv.org/pdf/2506.17603v1)**

> **作者:** Jonathan Sakunkoo; Annabella Sakunkoo
>
> **摘要:** Morphological defectivity is an intriguing and understudied phenomenon in linguistics. Addressing defectivity, where expected inflectional forms are absent, is essential for improving the accuracy of NLP tools in morphologically rich languages. However, traditional linguistic resources often lack coverage of morphological gaps as such knowledge requires significant human expertise and effort to document and verify. For scarce linguistic phenomena in under-explored languages, Wikipedia and Wiktionary often serve as among the few accessible resources. Despite their extensive reach, their reliability has been a subject of controversy. This study customizes a novel neural morphological analyzer to annotate Latin and Italian corpora. Using the massive annotated data, crowd-sourced lists of defective verbs compiled from Wiktionary are validated computationally. Our results indicate that while Wiktionary provides a highly reliable account of Italian morphological gaps, 7% of Latin lemmata listed as defective show strong corpus evidence of being non-defective. This discrepancy highlights potential limitations of crowd-sourced wikis as definitive sources of linguistic knowledge, particularly for less-studied phenomena and languages, despite their value as resources for rare linguistic features. By providing scalable tools and methods for quality assurance of crowd-sourced data, this work advances computational morphology and expands linguistic knowledge of defectivity in non-English, morphologically rich languages.
>
---
#### [new 031] Computational Approaches to Understanding Large Language Model Impact on Writing and Information Ecosystems
- **分类: cs.CL; cs.AI; cs.CY; cs.HC; cs.LG**

- **简介: 该论文研究大语言模型对写作和信息生态的影响，解决AI公平性、应用扩散及反馈支持问题，通过实证分析探讨其社会影响。**

- **链接: [http://arxiv.org/pdf/2506.17467v1](http://arxiv.org/pdf/2506.17467v1)**

> **作者:** Weixin Liang
>
> **备注:** Stanford CS PhD Dissertation
>
> **摘要:** Large language models (LLMs) have shown significant potential to change how we write, communicate, and create, leading to rapid adoption across society. This dissertation examines how individuals and institutions are adapting to and engaging with this emerging technology through three research directions. First, I demonstrate how the institutional adoption of AI detectors introduces systematic biases, particularly disadvantaging writers of non-dominant language varieties, highlighting critical equity concerns in AI governance. Second, I present novel population-level algorithmic approaches that measure the increasing adoption of LLMs across writing domains, revealing consistent patterns of AI-assisted content in academic peer reviews, scientific publications, consumer complaints, corporate communications, job postings, and international organization press releases. Finally, I investigate LLMs' capability to provide feedback on research manuscripts through a large-scale empirical analysis, offering insights into their potential to support researchers who face barriers in accessing timely manuscript feedback, particularly early-career researchers and those from under-resourced settings.
>
---
## 更新

#### [replaced 001] Position is Power: System Prompts as a Mechanism of Bias in Large Language Models (LLMs)
- **分类: cs.CY; cs.AI; cs.CL**

- **链接: [http://arxiv.org/pdf/2505.21091v3](http://arxiv.org/pdf/2505.21091v3)**

> **作者:** Anna Neumann; Elisabeth Kirsten; Muhammad Bilal Zafar; Jatinder Singh
>
> **备注:** Published in Proceedings of ACM FAccT 2025 Update Comment: Fixed the error where user vs. system and implicit vs. explicit labels in the heatmaps were switched. The takeaways remain the same
>
> **摘要:** System prompts in Large Language Models (LLMs) are predefined directives that guide model behaviour, taking precedence over user inputs in text processing and generation. LLM deployers increasingly use them to ensure consistent responses across contexts. While model providers set a foundation of system prompts, deployers and third-party developers can append additional prompts without visibility into others' additions, while this layered implementation remains entirely hidden from end-users. As system prompts become more complex, they can directly or indirectly introduce unaccounted for side effects. This lack of transparency raises fundamental questions about how the position of information in different directives shapes model outputs. As such, this work examines how the placement of information affects model behaviour. To this end, we compare how models process demographic information in system versus user prompts across six commercially available LLMs and 50 demographic groups. Our analysis reveals significant biases, manifesting in differences in user representation and decision-making scenarios. Since these variations stem from inaccessible and opaque system-level configurations, they risk representational, allocative and potential other biases and downstream harms beyond the user's ability to detect or correct. Our findings draw attention to these critical issues, which have the potential to perpetuate harms if left unexamined. Further, we argue that system prompt analysis must be incorporated into AI auditing processes, particularly as customisable system prompts become increasingly prevalent in commercial AI deployments.
>
---
#### [replaced 002] Application of the Cyberinfrastructure Production Function Model to R1 Institutions
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2501.10264v3](http://arxiv.org/pdf/2501.10264v3)**

> **作者:** Preston M. Smith; Jill Gemmill; David Y. Hancock; Brian W. O'Shea; Winona Snapp-Childs; James Wilgenbusch
>
> **摘要:** High-performance computing (HPC) is widely used in higher education for modeling, simulation, and AI applications. A critical piece of infrastructure with which to secure funding, attract and retain faculty, and teach students, supercomputers come with high capital and operating costs that must be considered against other competing priorities. This study applies the concepts of the production function model from economics with two thrusts: 1) to evaluate if previous research on building a model for quantifying the value of investment in research computing is generalizable to a wider set of universities, and 2) to define a model with which to capacity plan HPC investment, based on institutional production - inverting the production function. We show that the production function model does appear to generalize, showing positive institutional returns from the investment in computing resources and staff. We do, however, find that the relative relationships between model inputs and outputs vary across institutions, which can often be attributed to understandable institution-specific factors.
>
---
#### [replaced 003] A Systems Thinking Approach to Algorithmic Fairness
- **分类: cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2412.16641v5](http://arxiv.org/pdf/2412.16641v5)**

> **作者:** Chris Lam
>
> **摘要:** Systems thinking provides us with a way to model the algorithmic fairness problem by allowing us to encode prior knowledge and assumptions about where we believe bias might exist in the data generating process. We can then encode these beliefs as a series of causal graphs, enabling us to link AI/ML systems to politics and the law. This allows us to combine techniques from machine learning, causal inference, and system dynamics in order to capture different emergent aspects of the fairness problem. We can use systems thinking to help policymakers on both sides of the political aisle to understand the complex trade-offs that exist from different types of fairness policies, providing a sociotechnical foundation for designing AI policy that is aligned to their political agendas and with society's shared democratic values.
>
---
#### [replaced 004] The Quantified Body: Identity, Empowerment, and Control in Smart Wearables
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2506.15991v2](http://arxiv.org/pdf/2506.15991v2)**

> **作者:** Maijunxian Wang
>
> **摘要:** In an era where the body is increasingly translated into streams of biometric data, smart wearables have become not merely tools of personal health tracking but infrastructures of predictive governance. This paper examines how wearable technologies reconfigure bodily autonomy by embedding users within feedback-driven systems of self-surveillance, data extraction, and algorithmic control. Drawing on Deleuze's concept of the control society, Zuboff's theory of surveillance capitalism, and Couldry and Mejias's notion of data colonialism, I argue that smart wearables shift the discourse of health empowerment toward a modality of compliance aligned with neoliberal values of productivity, efficiency, and self-discipline. Rather than offering transparent consent, these technologies operate within what scholars describe as a post-consent regime -- where asymmetrical data relations are normalized through seamless design and behavioral nudging. Through interdisciplinary analysis, the paper further explores alternative trajectories for wearable design and governance, from historical examples of care-centered devices to contemporary anti-extractive practices and collective data justice frameworks. Ultimately, it calls for a paradigm shift from individual optimization to democratic accountability and structural reform in the governance of bodily data.
>
---
#### [replaced 005] Operations & Supply Chain Management: Principles and Practice
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2503.05749v2](http://arxiv.org/pdf/2503.05749v2)**

> **作者:** Fotios Petropoulos; Henk Akkermans; O. Zeynep Aksin; Imran Ali; Mohamed Zied Babai; Ana Barbosa-Povoa; Olga Battaïa; Maria Besiou; Nils Boysen; Stephen Brammer; Alistair Brandon-Jones; Dirk Briskorn; Tyson R. Browning; Paul Buijs; Piera Centobelli; Andrea Chiarini; Paul Cousins; Elizabeth A. Cudney; Andrew Davies; Steven J. Day; René de Koster; Rommert Dekker; Juliano Denicol; Mélanie Despeisse; Stephen M. Disney; Alexandre Dolgui; Linh Duong; Malek El-Qallali; Behnam Fahimnia; Fatemeh Fakhredin; Stanley B. Gershwin; Salar Ghamat; Vaggelis Giannikas; Christoph H. Glock; Janet Godsell; Kannan Govindan; Claire Hannibal; Anders Haug; Tomislav Hernaus; Juliana Hsuan; Dmitry Ivanov; Marianne Jahre; Björn Johansson; Madan Shankar Kalidoss; Argyris Kanellopoulos; Devika Kannan; Elif Karul; Konstantinos V. Katsikopoulos; Ayse Begüm Kilic-Ararat; Rainer Kolisch; Maximilian Koppenberg; Maneesh Kumar; Yong-Hong Kuo; Andrew Kusiak; Michael A. Lewis; Stanley Frederick W. T. Lim; Veronique Limère; Jiyin Liu; Omid Maghazei; Matija Marić; Joern Meissner; Miranda Meuwissen; Pietro Micheli; Samudaya Nanayakkara; Bengü Nur Özdemir; Thanos Papadopoulos; Stephen Pavelin; Srinath Perera; Wendy Phillips; Dennis Prak; Hubert Pun; Sharfah Ahmad Qazi; Usha Ramanathan; Gerald Reiner; Ewout Reitsma; Jens K. Roehrich; Nada R. Sanders; Joseph Sarkis; Nico André Schmid; Christoph G. Schmidt; Andreas Schroeder; Kostas Selviaridis; Stefan Seuring; Chuan Shi; Byung-Gak Son; Martin Spring; Brian Squire; Wendy van der Valk; Dirk Pieter van Donk; Geert-Jan van Houtum; Miriam Wilhelm; Finn Wynstra; Ting Zheng
>
> **摘要:** Operations and Supply Chain Management (OSCM) has continually evolved, incorporating a broad array of strategies, frameworks, and technologies to address complex challenges across industries. This encyclopedic article provides a comprehensive overview of contemporary strategies, tools, methods, principles, and best practices that define the field's cutting-edge advancements. It also explores the diverse environments where OSCM principles have been effectively implemented. The article is meant to be read in a nonlinear fashion. It should be used as a point of reference or first-port-of-call for a diverse pool of readers: academics, researchers, students, and practitioners.
>
---
#### [replaced 006] Cross-Camera Distracted Driver Classification through Feature Disentanglement and Contrastive Learning
- **分类: cs.CV; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2411.13181v2](http://arxiv.org/pdf/2411.13181v2)**

> **作者:** Simone Bianco; Luigi Celona; Paolo Napoletano
>
> **摘要:** The classification of distracted drivers is pivotal for ensuring safe driving. Previous studies demonstrated the effectiveness of neural networks in automatically predicting driver distraction, fatigue, and potential hazards. However, recent research has uncovered a significant loss of accuracy in these models when applied to samples acquired under conditions that differ from the training data. In this paper, we introduce a robust model designed to withstand changes in camera position within the vehicle. Our Driver Behavior Monitoring Network (DBMNet) relies on a lightweight backbone and integrates a disentanglement module to discard camera view information from features, coupled with contrastive learning to enhance the encoding of various driver actions. Experiments conducted using a leave-one-camera-out protocol on the daytime and nighttime subsets of the 100-Driver dataset validate the effectiveness of our approach. Cross-dataset and cross-camera experiments conducted on three benchmark datasets, namely AUCDD-V1, EZZ2021 and SFD, demonstrate the superior generalization capabilities of the proposed method. Overall DBMNet achieves an improvement of 7% in Top-1 accuracy compared to existing approaches. Moreover, a quantized version of the DBMNet and all considered methods has been deployed on a Coral Dev Board board. In this deployment scenario, DBMNet outperforms alternatives, achieving the lowest average error while maintaining a compact model size, low memory footprint, fast inference time, and minimal power consumption.
>
---
#### [replaced 007] "I understand why I got this grade": Automatic Short Answer Grading with Feedback
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2407.12818v2](http://arxiv.org/pdf/2407.12818v2)**

> **作者:** Dishank Aggarwal; Pritam Sil; Bhaskaran Raman; Pushpak Bhattacharyya
>
> **摘要:** In recent years, there has been a growing interest in using Artificial Intelligence (AI) to automate student assessment in education. Among different types of assessments, summative assessments play a crucial role in evaluating a student's understanding level of a course. Such examinations often involve short-answer questions. However, grading these responses and providing meaningful feedback manually at scale is both time-consuming and labor-intensive. Feedback is particularly important, as it helps students recognize their strengths and areas for improvement. Despite the importance of this task, there is a significant lack of publicly available datasets that support automatic short-answer grading with feedback generation. To address this gap, we introduce Engineering Short Answer Feedback (EngSAF), a dataset designed for automatic short-answer grading with feedback. The dataset covers a diverse range of subjects, questions, and answer patterns from multiple engineering domains and contains ~5.8k data points. We incorporate feedback into our dataset by leveraging the generative capabilities of state-of-the-art large language models (LLMs) using our Label-Aware Synthetic Feedback Generation (LASFG) strategy. This paper underscores the importance of enhanced feedback in practical educational settings, outlines dataset annotation and feedback generation processes, conducts a thorough EngSAF analysis, and provides different LLMs-based zero-shot and finetuned baselines for future comparison. The best-performing model (Mistral-7B) achieves an overall accuracy of 75.4% and 58.7% on unseen answers and unseen question test sets, respectively. Additionally, we demonstrate the efficiency and effectiveness of our ASAG system through its deployment in a real-world end-semester exam at a reputed institute.
>
---
#### [replaced 008] Compromising Honesty and Harmlessness in Language Models via Deception Attacks
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2502.08301v2](http://arxiv.org/pdf/2502.08301v2)**

> **作者:** Laurène Vaugrante; Francesca Carlon; Maluna Menke; Thilo Hagendorff
>
> **摘要:** Recent research on large language models (LLMs) has demonstrated their ability to understand and employ deceptive behavior, even without explicit prompting. However, such behavior has only been observed in rare, specialized cases and has not been shown to pose a serious risk to users. Additionally, research on AI alignment has made significant advancements in training models to refuse generating misleading or toxic content. As a result, LLMs generally became honest and harmless. In this study, we introduce "deception attacks" that undermine both of these traits, revealing a vulnerability that, if exploited, could have serious real-world consequences. We introduce fine-tuning methods that cause models to selectively deceive users on targeted topics while remaining accurate on others. Through a series of experiments, we show that such targeted deception is effective even in high-stakes domains or ideologically charged subjects. In addition, we find that deceptive fine-tuning often compromises other safety properties: deceptive models are more likely to produce toxic content, including hate speech and stereotypes. Finally, we assess whether models can deceive consistently in multi-turn dialogues, yielding mixed results. Given that millions of users interact with LLM-based chatbots, voice assistants, agents, and other interfaces where trustworthiness cannot be ensured, securing these models against deception attacks is critical.
>
---
#### [replaced 009] Decoding Safety Feedback from Diverse Raters: A Data-driven Lens on Responsiveness to Severity
- **分类: cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2503.05609v2](http://arxiv.org/pdf/2503.05609v2)**

> **作者:** Pushkar Mishra; Charvi Rastogi; Stephen R. Pfohl; Alicia Parrish; Tian Huey Teh; Roma Patel; Mark Diaz; Ding Wang; Michela Paganini; Vinodkumar Prabhakaran; Lora Aroyo; Verena Rieser
>
> **摘要:** Ensuring the safety of Generative AI requires a nuanced understanding of pluralistic viewpoints. In this paper, we introduce a novel data-driven approach for interpreting granular ratings in pluralistic datasets. Specifically, we address the challenge of analyzing nuanced differences in safety feedback from a diverse population expressed via ordinal scales (e.g., a Likert scale). We distill non-parametric responsiveness metrics that quantify the consistency of raters in scoring varying levels of the severity of safety violations. Leveraging a publicly available pluralistic dataset of safety feedback on AI-generated content as our case study, we investigate how raters from different demographic groups (age, gender, ethnicity) use an ordinal scale to express their perceptions of the severity of violations. We apply our metrics across violation types, demonstrating their utility in extracting nuanced insights that are crucial for aligning AI systems reliably in multi-cultural contexts. We show that our approach can inform rater selection and feedback interpretation by capturing nuanced viewpoints across different demographic groups, hence improving the quality of pluralistic data collection and in turn contributing to more robust AI development.
>
---
#### [replaced 010] The World Wide recipe: A community-centred framework for fine-grained data collection and regional bias operationalisation
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2406.09496v4](http://arxiv.org/pdf/2406.09496v4)**

> **作者:** Jabez Magomere; Shu Ishida; Tejumade Afonja; Aya Salama; Daniel Kochin; Foutse Yuehgoh; Imane Hamzaoui; Raesetje Sefala; Aisha Alaagib; Samantha Dalal; Beatrice Marchegiani; Elizaveta Semenova; Lauren Crais; Siobhan Mackenzie Hall
>
> **摘要:** We introduce the World Wide recipe, which sets forth a framework for culturally aware and participatory data collection, and the resultant regionally diverse World Wide Dishes evaluation dataset. We also analyse bias operationalisation to highlight how current systems underperform across several dimensions: (in-)accuracy, (mis-)representation, and cultural (in-)sensitivity, with evidence from qualitative community-based observations and quantitative automated tools. We find that these T2I models generally do not produce quality outputs of dishes specific to various regions. This is true even for the US, which is typically considered more well-resourced in training data -- although the generation of US dishes does outperform that of the investigated African countries. The models demonstrate the propensity to produce inaccurate and culturally misrepresentative, flattening, and insensitive outputs. These representational biases have the potential to further reinforce stereotypes and disproportionately contribute to erasure based on region. The dataset and code are available at https://github.com/oxai/world-wide-dishes.
>
---
#### [replaced 011] ASCenD-BDS: Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2502.02072v2](http://arxiv.org/pdf/2502.02072v2)**

> **作者:** Rajiv Bahl; Venkatesan N; Parimal Aglawe; Aastha Sarasapalli; Bhavya Kancharla; Chaitanya kolukuluri; Harish Mohite; Japneet Hora; Kiran Kakollu; Rahul Dhiman; Shubham Kapale; Sri Bhagya Kathula; Vamsikrishna Motru; Yogeshwar Reddy
>
> **备注:** 17 pages, 6 Figures and this manuscript will be submitted to Q1,Q2 Journals
>
> **摘要:** The rapid evolution of Large Language Models (LLMs) has transformed natural language processing but raises critical concerns about biases inherent in their deployment and use across diverse linguistic and sociocultural contexts. This paper presents a framework named ASCenD BDS (Adaptable, Stochastic and Context-aware framework for Detection of Bias, Discrimination and Stereotyping). The framework presents approach to detecting bias, discrimination, stereotyping across various categories such as gender, caste, age, disability, socioeconomic status, linguistic variations, etc., using an approach which is Adaptive, Stochastic and Context-Aware. The existing frameworks rely heavily on usage of datasets to generate scenarios for detection of Bias, Discrimination and Stereotyping. Examples include datasets such as Civil Comments, Wino Gender, WinoBias, BOLD, CrowS Pairs and BBQ. However, such an approach provides point solutions. As a result, these datasets provide a finite number of scenarios for assessment. The current framework overcomes this limitation by having features which enable Adaptability, Stochasticity, Context Awareness. Context awareness can be customized for any nation or culture or sub-culture (for example an organization's unique culture). In this paper, context awareness in the Indian context has been established. Content has been leveraged from Indian Census 2011 to have a commonality of categorization. A framework has been developed using Category, Sub-Category, STEM, X-Factor, Synonym to enable the features for Adaptability, Stochasticity and Context awareness. The framework has been described in detail in Section 3. Overall 800 plus STEMs, 10 Categories, 31 unique SubCategories were developed by a team of consultants at Saint Fox Consultancy Private Ltd. The concept has been tested out in SFCLabs as part of product development.
>
---
