# 计算机与社会 cs.CY

- **最新发布 25 篇**

- **更新 9 篇**

## 最新发布

#### [new 001] Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams
- **分类: cs.CY; cs.AI**

- **简介: 论文评估LLM在隐私与AI治理考试中的表现，验证其是否能可靠支持AI治理，发现前沿模型如Gemini 2.5 Pro和GPT-5超出专业标准，揭示当前LLM的领域差距，并为隐私从业者提供AI工具评估建议。**

- **链接: [http://arxiv.org/pdf/2508.09036v1](http://arxiv.org/pdf/2508.09036v1)**

> **作者:** Zane Witherspoon; Thet Mon Aye; YingYing Hao
>
> **摘要:** The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technology's strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPP's passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAI's GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.
>
---
#### [new 002] Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change
- **分类: cs.CY; cs.AI**

- **简介: 本文提出一种基于城市理论的时空注意力模型（Urban-STA4CLC），用于预测灾难后商业用地变化，解决现有方法在捕捉人地互动复杂性的不足，通过整合韧性、空间经济和扩散理论模块提升预测精度，效果较非理论基线提升19%。**

- **链接: [http://arxiv.org/pdf/2508.08976v1](http://arxiv.org/pdf/2508.08976v1)**

> **作者:** Ziyi Guo; Yan Wang
>
> **摘要:** Natural disasters such as hurricanes and wildfires increasingly introduce unusual disturbance on economic activities, which are especially likely to reshape commercial land use pattern given their sensitive to customer visitation. However, current modeling approaches are limited in capturing such complex interplay between human activities and commercial land use change under and following disturbances. Such interactions have been more effectively captured in current resilient urban planning theories. This study designs and calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict both the yearly decline and expansion of commercial land use at census block level under cumulative impact of disasters on human activities over two years. Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal attention mechanisms with three theory-informed modules. Resilience theory guides a disaster-aware temporal attention module that captures visitation dynamics. Spatial economic theory informs a multi-relational spatial attention module for inter-block representation. Diffusion theory contributes a regularization term that constrains land use transitions. The model performs significantly better than non-theoretical baselines in predicting commercial land use change under the scenario of recurrent hurricanes, with around 19% improvement in F1 score (0.8763). The effectiveness of the theory-guided modules was further validated through ablation studies. The research demonstrates that embedding urban theory into commercial land use modeling models may substantially enhance the capacity to capture its gains and losses. These advances in commercial land use modeling contribute to land use research that accounts for cumulative impacts of recurrent disasters and shifts in economic activity patterns.
>
---
#### [new 003] ICT Within Limits Is Bound To Be Old-Fashioned By Design
- **分类: cs.CY**

- **简介: 论文提出利用不可靠电子垃圾和可再生能源构建自适应IT架构，应对技术衰退并减少环境影响，解决资源过度消耗与电子废弃物处理问题。**

- **链接: [http://arxiv.org/pdf/2508.08311v1](http://arxiv.org/pdf/2508.08311v1)**

> **作者:** Olivier Michel; Emilie Frenkiel
>
> **备注:** Post-proceedings paper presented at LIMITS 2025: 11th Workshop on Computing within Limits, 2025-06-26/27, Online
>
> **摘要:** Crossing multiple planetary boundaries places us in a zone of uncertainty that is characterized by considerable fluctuations in climatic events. The situation is exacerbated by the relentless use of resources and energy required to develop digital infrastructures that have become pervasive and ubiquitous. We are bound to these infrastructures, dead technologies and negative commons, just as much as they bind us. Although their growth threatens the necessary reduction of our impact, we have a responsibility to maintain them until we can do without them. In university setting, as well as in any public organization, urban mines per se, we propose an IT architecture based on the exclusive use of unreliable waste from electrical and electronic equipment (WEEE) as a frugal alternative to the incessant replacement of devices. Powered by renewable energy, autonomous, robust, adaptable, and built on battle-tested open-source software, we envision this solution for a situation where use is bound to decline eventually, to close this damaging technological chapter. Digital technology, the idol of modern times, is to meet its twilight if we do not want to irrevocably alter the critical zone.
>
---
#### [new 004] Algorithmic Fairness amid Social Determinants: Reflection, Characterization, and Approach
- **分类: cs.CY; cs.AI; cs.LG**

- **简介: 论文研究算法公平性中的社会决定因素，解决现有忽视问题，提出形式化方法与Gamma分布模型，分析大学招生案例，指出仅关注敏感属性可能引发结构性不公。**

- **链接: [http://arxiv.org/pdf/2508.08337v1](http://arxiv.org/pdf/2508.08337v1)**

> **作者:** Zeyu Tang; Alex John London; Atoosa Kasirzadeh; Sanmi Koyejo; Peter Spirtes; Kun Zhang
>
> **摘要:** Social determinants are variables that, while not directly pertaining to any specific individual, capture key aspects of contexts and environments that have direct causal influences on certain attributes of an individual. Previous algorithmic fairness literature has primarily focused on sensitive attributes, often overlooking the role of social determinants. Our paper addresses this gap by introducing formal and quantitative rigor into a space that has been shaped largely by qualitative proposals regarding the use of social determinants. To demonstrate theoretical perspectives and practical applicability, we examine a concrete setting of college admissions, using region as a proxy for social determinants. Our approach leverages a region-based analysis with Gamma distribution parameterization to model how social determinants impact individual outcomes. Despite its simplicity, our method quantitatively recovers findings that resonate with nuanced insights in previous qualitative debates, that are often missed by existing algorithmic fairness approaches. Our findings suggest that mitigation strategies centering solely around sensitive attributes may introduce new structural injustice when addressing existing discrimination. Considering both sensitive attributes and social determinants facilitates a more comprehensive explication of benefits and burdens experienced by individuals from diverse demographic backgrounds as well as contextual environments, which is essential for understanding and achieving fairness effectively and transparently.
>
---
#### [new 005] When the Domain Expert Has No Time and the LLM Developer Has No Clinical Expertise: Real-World Lessons from LLM Co-Design in a Safety-Net Hospital
- **分类: cs.CY; cs.AI; cs.LG**

- **简介: 论文探讨在缺乏领域专家和开发者专业知识时，如何通过分解任务并采用多级验证框架实现LLM共设计，解决资源受限场景下的协作难题。**

- **链接: [http://arxiv.org/pdf/2508.08504v1](http://arxiv.org/pdf/2508.08504v1)**

> **作者:** Avni Kothari; Patrick Vossler; Jean Digitale; Mohammad Forouzannia; Elise Rosenberg; Michele Lee; Jennee Bryant; Melanie Molina; James Marks; Lucas Zier; Jean Feng
>
> **摘要:** Large language models (LLMs) have the potential to address social and behavioral determinants of health by transforming labor intensive workflows in resource-constrained settings. Creating LLM-based applications that serve the needs of underserved communities requires a deep understanding of their local context, but it is often the case that neither LLMs nor their developers possess this local expertise, and the experts in these communities often face severe time/resource constraints. This creates a disconnect: how can one engage in meaningful co-design of an LLM-based application for an under-resourced community when the communication channel between the LLM developer and domain expert is constrained? We explored this question through a real-world case study, in which our data science team sought to partner with social workers at a safety net hospital to build an LLM application that summarizes patients' social needs. Whereas prior works focus on the challenge of prompt tuning, we found that the most critical challenge in this setting is the careful and precise specification of \what information to surface to providers so that the LLM application is accurate, comprehensive, and verifiable. Here we present a novel co-design framework for settings with limited access to domain experts, in which the summary generation task is first decomposed into individually-optimizable attributes and then each attribute is efficiently refined and validated through a multi-tier cascading approach.
>
---
#### [new 006] Dead Zone of Accountability: Why Social Claims in Machine Learning Research Should Be Articulated and Defended
- **分类: cs.CY**

- **简介: 论文探讨机器学习研究中社会声明与现实脱节的问题，提出“dead zone of accountability”框架，旨在通过建立问责机制解决该差距，并提出两项合作研究方向。**

- **链接: [http://arxiv.org/pdf/2508.08739v1](http://arxiv.org/pdf/2508.08739v1)**

> **作者:** Tianqi Kou; Dana Calacci; Cindy Lin
>
> **备注:** Forthcoming in AIES 2025
>
> **摘要:** Many Machine Learning research studies use language that describes potential social benefits or technical affordances of new methods and technologies. Such language, which we call "social claims", can help garner substantial resources and influence for those involved in ML research and technology production. However, there exists a gap between social claims and reality (the claim-reality gap): ML methods often fail to deliver the claimed functionality or social impacts. This paper investigates the claim-reality gap and makes a normative argument for developing accountability mechanisms for it. In making the argument, we make three contributions. First, we show why the symptom - absence of social claim accountability - is problematic. Second, we coin dead zone of accountability - a lens that scholars and practitioners can use to identify opportunities for new forms of accountability. We apply this lens to the claim-reality gap and provide a diagnosis by identifying cognitive and structural resistances to accountability in the claim-reality gap. Finally, we offer a prescription - two potential collaborative research agendas that can help create the condition for social claim accountability.
>
---
#### [new 007] Who pays the RENT? Implications of Spatial Inequality for Prediction-Based Allocation Policies
- **分类: cs.CY; cs.AI**

- **简介: 论文研究预测基于的资源分配政策中空间不平等的影响，旨在解决目标定向与区域化策略效果差异问题，通过构建Mallows模型及RENTR指标，校准美国城市数据，揭示部署成本与风险集中度对策略有效性的影响。**

- **链接: [http://arxiv.org/pdf/2508.08573v1](http://arxiv.org/pdf/2508.08573v1)**

> **作者:** Tasfia Mashiat; Patrick J. Fowler; Sanmay Das
>
> **备注:** This work has been accepted for publication as a full paper at the AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)
>
> **摘要:** AI-powered scarce resource allocation policies rely on predictions to target either specific individuals (e.g., high-risk) or settings (e.g., neighborhoods). Recent research on individual-level targeting demonstrates conflicting results; some models show that targeting is not useful when inequality is high, while other work demonstrates potential benefits. To study and reconcile this apparent discrepancy, we develop a stylized framework based on the Mallows model to understand how the spatial distribution of inequality affects the effectiveness of door-to-door outreach policies. We introduce the RENT (Relative Efficiency of Non-Targeting) metric, which we use to assess the effectiveness of targeting approaches compared with neighborhood-based approaches in preventing tenant eviction when high-risk households are more versus less spatially concentrated. We then calibrate the model parameters to eviction court records collected in a medium-sized city in the USA. Results demonstrate considerable gains in the number of high-risk households canvassed through individually targeted policies, even in a highly segregated metro area with concentrated risks of eviction. We conclude that apparent discrepancies in the prior literature can be reconciled by considering 1) the source of deployment costs and 2) the observed versus modeled concentrations of risk. Our results inform the deployment of AI-based solutions in social service provision that account for particular applications and geographies.
>
---
#### [new 008] Do AI Companies Make Good on Voluntary Commitments to the White House?
- **分类: cs.CY; cs.AI**

- **简介: 论文评估AI公司履行白宫自愿承诺的情况，发现多数公司表现不佳，呼吁公开披露以增强问责。**

- **链接: [http://arxiv.org/pdf/2508.08345v1](http://arxiv.org/pdf/2508.08345v1)**

> **作者:** Jennifer Wang; Kayla Huang; Kevin Klyman; Rishi Bommasani
>
> **摘要:** Voluntary commitments are central to international AI governance, as demonstrated by recent voluntary guidelines from the White House to the G7, from Bletchley Park to Seoul. How do major AI companies make good on their commitments? We score companies based on their publicly disclosed behavior by developing a detailed rubric based on their eight voluntary commitments to the White House in 2023. We find significant heterogeneity: while the highest-scoring company (OpenAI) scores a 83% overall on our rubric, the average score across all companies is just 52%. The companies demonstrate systemically poor performance for their commitment to model weight security with an average score of 17%: 11 of the 16 companies receive 0% for this commitment. Our analysis highlights a clear structural shortcoming that future AI governance initiatives should correct: when companies make public commitments, they should proactively disclose how they meet their commitments to provide accountability, and these disclosures should be verifiable. To advance policymaking on corporate AI governance, we provide three directed recommendations that address underspecified commitments, the role of complex AI supply chains, and public transparency that could be applied towards AI governance initiatives worldwide.
>
---
#### [new 009] Exploring Large Language Model Agents for Piloting Social Experiments
- **分类: cs.CY**

- **简介: 论文提出基于LLM驱动的代理框架，解决社会实验中代理智能不足问题，通过整合干预方法与数据采集工具，验证其与现实证据的高度一致性，首次构建LLM驱动社会实验设计范式。**

- **链接: [http://arxiv.org/pdf/2508.08678v1](http://arxiv.org/pdf/2508.08678v1)**

> **作者:** Jinghua Piao; Yuwei Yan; Nian Li; Jun Zhang; Yong Li
>
> **备注:** Accepted by COLM 2025
>
> **摘要:** Computational social experiments, which typically employ agent-based modeling to create testbeds for piloting social experiments, not only provide a computational solution to the major challenges faced by traditional experimental methods, but have also gained widespread attention in various research fields. Despite their significance, their broader impact is largely limited by the underdeveloped intelligence of their core component, i.e., agents. To address this limitation, we develop a framework grounded in well-established social science theories and practices, consisting of three key elements: (i) large language model (LLM)-driven experimental agents, serving as "silicon participants", (ii) methods for implementing various interventions or treatments, and (iii) tools for collecting behavioral, survey, and interview data. We evaluate its effectiveness by replicating three representative experiments, with results demonstrating strong alignment, both quantitatively and qualitatively, with real-world evidence. This work provides the first framework for designing LLM-driven agents to pilot social experiments, underscoring the transformative potential of LLMs and their agents in computational social science
>
---
#### [new 010] Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment
- **分类: cs.CY; cs.AI**

- **简介: 论文构建教育LLMs攻击分类体系，评估其安全风险并提出应对策略。**

- **链接: [http://arxiv.org/pdf/2508.08629v1](http://arxiv.org/pdf/2508.08629v1)**

> **作者:** Farzana Zahid; Anjalika Sewwandi; Lee Brandon; Vimal Kumar; Roopak Sinha
>
> **摘要:** Due to perceptions of efficiency and significant productivity gains, various organisations, including in education, are adopting Large Language Models (LLMs) into their workflows. Educator-facing, learner-facing, and institution-facing LLMs, collectively, Educational Large Language Models (eLLMs), complement and enhance the effectiveness of teaching, learning, and academic operations. However, their integration into an educational setting raises significant cybersecurity concerns. A comprehensive landscape of contemporary attacks on LLMs and their impact on the educational environment is missing. This study presents a generalised taxonomy of fifty attacks on LLMs, which are categorized as attacks targeting either models or their infrastructure. The severity of these attacks is evaluated in the educational sector using the DREAD risk assessment framework. Our risk assessment indicates that token smuggling, adversarial prompts, direct injection, and multi-step jailbreak are critical attacks on eLLMs. The proposed taxonomy, its application in the educational environment, and our risk assessment will help academic and industrial practitioners to build resilient solutions that protect learners and institutions.
>
---
#### [new 011] Processing of synthetic data in AI development for healthcare and the definition of personal data in EU law
- **分类: cs.CY; cs.AI**

- **简介: 论文探讨合成数据在医疗AI中的应用及GDPR下分类问题，分析其匿名性风险并提出需明确法规以平衡隐私与技术发展。**

- **链接: [http://arxiv.org/pdf/2508.08353v1](http://arxiv.org/pdf/2508.08353v1)**

> **作者:** Vibeke Binz Vallevik; Anne Kjersti C. Befring; Severin Elvatun; Jan Franz Nygaard
>
> **备注:** 55 pages
>
> **摘要:** Artificial intelligence (AI) has the potential to transform healthcare, but it requires access to health data. Synthetic data that is generated through machine learning models trained on real data, offers a way to share data while preserving privacy. However, uncertainties in the practical application of the General Data Protection Regulation (GDPR) create an administrative burden, limiting the benefits of synthetic data. Through a systematic analysis of relevant legal sources and an empirical study, this article explores whether synthetic data should be classified as personal data under the GDPR. The study investigates the residual identification risk through generating synthetic data and simulating inference attacks, challenging common perceptions of technical identification risk. The findings suggest synthetic data is likely anonymous, depending on certain factors, but highlights uncertainties about what constitutes reasonably likely risk. To promote innovation, the study calls for clearer regulations to balance privacy protection with the advancement of AI in healthcare.
>
---
#### [new 012] Between Fear and Desire, the Monster Artificial Intelligence (AI): Analysis through the Lenses of Monster Theory
- **分类: cs.CY; cs.AI**

- **简介: 论文运用怪物理论分析AI的双重形象，探讨其复杂性及社会文化影响，提出AI不应孤立看待，需结合具体社会背景理解。**

- **链接: [http://arxiv.org/pdf/2508.08318v1](http://arxiv.org/pdf/2508.08318v1)**

> **作者:** Ahmed Tlili
>
> **摘要:** With the increasing adoption of Artificial Intelligence (AI) in all fields and daily activities, a heated debate is found about the advantages and challenges of AI and the need for navigating the concerns associated with AI to make the best of it. To contribute to this literature and the ongoing debate related to it, this study draws on the Monster theory to explain the conflicting representation of AI. It suggests that studying monsters in popular culture can provide an in-depth understanding of AI and its monstrous effects. Specifically, this study aims to discuss AI perception and development through the seven theses of Monster theory. The obtained results revealed that, just like monsters, AI is complex in nature, and it should not be studied as a separate entity but rather within a given society or culture. Similarly, readers may perceive and interpret AI differently, just as readers may interpret monsters differently. The relationship between AI and monsters, as depicted in this study, does not seem to be as odd as it might be at first.
>
---
#### [new 013] Resisting AI Solutionism through Workplace Collective Action
- **分类: cs.CY; cs.HC; K.4.3; K.4.2; I.2.0**

- **简介: 论文探讨通过工作场所集体行动抵抗AI解决方案主义，针对大学AI替代威胁，构建跨部门抗争空间，提供技术从业者、学生及员工抵抗AI的策略灵感。**

- **链接: [http://arxiv.org/pdf/2508.08313v1](http://arxiv.org/pdf/2508.08313v1)**

> **作者:** Kevin Zheng; Linda Huber; Aaron Stark; Nathan Kim; Francesca Lameiro; Wells Lucas Santo; Shreya Chowdhary; Eugene Kim; Justine Zhang
>
> **备注:** Presented at "Resisting AI Solutionism: Where Do We Go From Here?" workshop at CHI '25
>
> **摘要:** In the face of increasing austerity and threats of AI-enabled labor replacement at the University of Michigan, a group of workers and students have coalesced around the project of "AI resistance" since Fall 2024. Forming a cross-departmental coalition including librarians, faculty, staff, graduate workers, and undergraduate students, we have hosted a public workshop questioning the techno-deterministic inevitability of AI use at the University and are working with other campus organizations to maintain an ongoing organizing space. This workshop submission incorporates our reflections thus far on the strategies we've employed, the challenges to collective resistance, and our role as workers in resisting AI within the University. Our aim for this work is to provide concrete inspiration for technologists, students, and staff looking to resist AI techno-solutionism within their own universities.
>
---
#### [new 014] Assessing the Quality of AI-Generated Exams: A Large-Scale Field Study
- **分类: cs.CY; cs.AI**

- **简介: 论文评估AI生成考试的质量，解决真实环境中心理测量不足问题，通过迭代策略和大规模实证分析，证明AI生成题目与专家设计相当，凸显其在高效评估中的潜力。**

- **链接: [http://arxiv.org/pdf/2508.08314v1](http://arxiv.org/pdf/2508.08314v1)**

> **作者:** Calvin Isley; Joshua Gilbert; Evangelos Kassos; Michaela Kocher; Allen Nie; Emma Brunskill; Ben Domingue; Jake Hofman; Joscha Legewie; Teddy Svoronos; Charlotte Tuminelli; Sharad Goel
>
> **摘要:** While large language models (LLMs) challenge conventional methods of teaching and learning, they present an exciting opportunity to improve efficiency and scale high-quality instruction. One promising application is the generation of customized exams, tailored to specific course content. There has been significant recent excitement on automatically generating questions using artificial intelligence, but also comparatively little work evaluating the psychometric quality of these items in real-world educational settings. Filling this gap is an important step toward understanding generative AI's role in effective test design. In this study, we introduce and evaluate an iterative refinement strategy for question generation, repeatedly producing, assessing, and improving questions through cycles of LLM-generated critique and revision. We evaluate the quality of these AI-generated questions in a large-scale field study involving 91 classes -- covering computer science, mathematics, chemistry, and more -- in dozens of colleges across the United States, comprising nearly 1700 students. Our analysis, based on item response theory (IRT), suggests that for students in our sample the AI-generated questions performed comparably to expert-created questions designed for standardized exams. Our results illustrate the power of AI to make high-quality assessments more readily available, benefiting both teachers and students.
>
---
#### [new 015] EU Digital Regulation and Guatemala: AI, 5G, and Cybersecurity
- **分类: cs.CY; cs.AI; cs.ET**

- **简介: 论文分析欧盟AI、5G及网络安全法规对加纳的跨国影响，探讨其政策塑造路径及具体挑战，提出五项治理建议。**

- **链接: [http://arxiv.org/pdf/2508.08315v1](http://arxiv.org/pdf/2508.08315v1)**

> **作者:** Victor Lopez Juarez
>
> **摘要:** The paper examines how EU rules in AI, 5G, and cybersecurity operate as transnational governance and shape policy in Guatemala. It outlines the AI Act's risk approach, the 5G Action Plan and Security Toolbox, and the cybersecurity regime built on ENISA, NIS2, the Cybersecurity Act, and the Cyber Resilience Act. It traces extraterritorial channels such as the Brussels effect, private standards, supply chain clauses, and data transfer controls. Guatemala specific impacts include SME compliance costs, procurement limits, environmental trade-offs in rollout, rights risks, and capacity gaps. The paper maps current national measures and proposes five guardrails: digital constitutionalism, green IT duties, third country impact assessment, standards co-design, and recognition of regulatory diversity.
>
---
#### [new 016] Principles for Environmental Justice in Technology: Toward a Regenerative Future
- **分类: cs.CY**

- **简介: 论文提出EJIT原则，旨在解决传统技术忽视社会与生态正义的问题，通过框架引导技术向互dependence、修复与社区自主方向发展，借鉴环境正义原则，构建抵抗掠夺性默认的价值基础设施。**

- **链接: [http://arxiv.org/pdf/2508.09007v1](http://arxiv.org/pdf/2508.09007v1)**

> **作者:** Sanjana Paul
>
> **备注:** Post-proceedings paper presented at LIMITS 2025: 11th Workshop on Computing within Limits, 2025-06-26/27, Online
>
> **摘要:** This paper introduces the Environmental Justice in Technology (EJIT) Principles, a framework to help reorient technological development toward social and ecological justice and collective flourishing. In response to prevailing models of technological innovation that prioritize speed, scale, and profit while neglecting systemic injustice, the EJIT principles offer an alternative: a set of guiding values that foreground interdependence, repair, and community self-determination. Drawing inspiration from the 1991 principles of environmental justice, this framework extends their commitments into the technological domain, treating environmental justice not as a peripheral concern but as a necessary foundation for building equitable and regenerative futures. We situate the EJIT principles within the broader landscape of environmental justice, design justice, and post-growth computing, proposing them as a values infrastructure for resisting extractive defaults and envisioning technological systems that operate in reciprocity with people and the planet. In doing so, this article aims to support collective efforts to transform not only what technologies we build, but how, why, and for whom.
>
---
#### [new 017] AI Agents and the Law
- **分类: cs.CY; cs.AI**

- **简介: 本文探讨AI代理的技术与法律问题，分析代理概念差异及忠诚、第三方挑战，提出解决路径。**

- **链接: [http://arxiv.org/pdf/2508.08544v1](http://arxiv.org/pdf/2508.08544v1)**

> **作者:** Mark O. Riedl; Deven R. Desai
>
> **备注:** 2025 AAAI Conference on AI, Ethics, and Society
>
> **摘要:** As AI becomes more "agentic," it faces technical and socio-legal issues it must address if it is to fulfill its promise of increased economic productivity and efficiency. This paper uses technical and legal perspectives to explain how things change when AI systems start being able to directly execute tasks on behalf of a user. We show how technical conceptions of agents track some, but not all, socio-legal conceptions of agency. That is, both computer science and the law recognize the problems of under-specification for an agent, and both disciplines have robust conceptions of how to address ensuring an agent does what the programmer, or in the law, the principal desires and no more. However, to date, computer science has under-theorized issues related to questions of loyalty and to third parties that interact with an agent, both of which are central parts of the law of agency. First, we examine the correlations between implied authority in agency law and the principle of value-alignment in AI, wherein AI systems must operate under imperfect objective specification. Second, we reveal gaps in the current computer science view of agents pertaining to the legal concepts of disclosure and loyalty, and how failure to account for them can result in unintended effects in AI ecommerce agents. In surfacing these gaps, we show a path forward for responsible AI agent development and deployment.
>
---
#### [new 018] Normative Moral Pluralism for AI: A Framework for Deliberation in Complex Moral Contexts
- **分类: cs.CY; cs.AI**

- **简介: 论文提出基于规范道德多元主义的AI道德推理框架，解决复杂情境下多伦理视角冲突的决策问题，通过双层架构实现结构化推理与实时响应，兼顾透明性与文化适配性。**

- **链接: [http://arxiv.org/pdf/2508.08333v1](http://arxiv.org/pdf/2508.08333v1)**

> **作者:** David-Doron Yaacov
>
> **备注:** Conference version: AIES 2025 (non-archival track), 12 pages
>
> **摘要:** The conceptual framework proposed in this paper centers on the development of a deliberative moral reasoning system - one designed to process complex moral situations by generating, filtering, and weighing normative arguments drawn from diverse ethical perspectives. While the framework is rooted in Machine Ethics, it also makes a substantive contribution to Value Alignment by outlining a system architecture that links structured moral reasoning to action under time constraints. Grounded in normative moral pluralism, this system is not constructed to imitate behavior but is built on reason-sensitive deliberation over structured moral content in a transparent and principled manner. Beyond its role as a deliberative system, it also serves as the conceptual foundation for a novel two-level architecture: functioning as a moral reasoning teacher envisioned to train faster models that support real-time responsiveness without reproducing the full structure of deliberative reasoning. Together, the deliberative and intuitive components are designed to enable both deep reflection and responsive action. A key design feature is the dual-hybrid structure: a universal layer that defines a moral threshold through top-down and bottom-up learning, and a local layer that learns to weigh competing considerations in context while integrating culturally specific normative content, so long as it remains within the universal threshold. By extending the notion of moral complexity to include not only conflicting beliefs but also multifactorial dilemmas, multiple stakeholders, and the integration of non-moral considerations, the framework aims to support morally grounded decision-making in realistic, high-stakes contexts.
>
---
#### [new 019] Where are GIScience Faculty Hired from? Analyzing Faculty Mobility and Research Themes Through Hiring Networks
- **分类: cs.HC; cs.CY; cs.SI**

- **简介: 论文研究GIScience教师招聘网络，分析其流动性和研究主题演变，揭示全球师资分布及学科发展趋势。任务：揭示招聘网络对GIScience的影响；问题：师资流动与研究方向变化；工作：构建全球教师数据集，分析网络结构与主题聚类。**

- **链接: [http://arxiv.org/pdf/2508.09043v1](http://arxiv.org/pdf/2508.09043v1)**

> **作者:** Yanbing Chen; Jonathan Nelson; Bing Zhou; Ryan Zhenqi Zhou; Shan Ye; Haokun Liu; Zhining Gu; Armita Kar; Hoeyun Kwon; Pengyu Chen; Maoran Sun; Yuhao Kang
>
> **备注:** 54 pages, 12 figures
>
> **摘要:** Academia is profoundly influenced by faculty hiring networks, which serve as critical conduits for knowledge dissemination and the formation of collaborative research initiatives. While extensive research in various disciplines has revealed the institutional hierarchies inherent in these networks, their impacts within GIScience remain underexplored. To fill this gap, this study analyzes the placement patterns of 946 GIScience faculty worldwide by mapping the connections between PhD-granting institutions and current faculty affiliations. Our dataset, which is compiled from volunteer-contributed information, is the most comprehensive collection available in this field. While there may be some limitations in its representativeness, its scope and depth provide a unique and valuable perspective on the global placement patterns of GIScience faculty. Our analysis reveals several influential programs in placing GIScience faculty, with hiring concentrated in the western countries. We examined the diversity index to assess the representation of regions and institutions within the global GIScience faculty network. We observe significant internal retention at both the continental and country levels, and a high level of non-self-hired ratio at the institutional level. Over time, research themes have also evolved, with growing research clusters emphasis on spatial data analytics, cartography and geovisualization, geocomputation, and environmental sciences, etc. These results illuminate the influence of hiring practices on global knowledge dissemination and contribute to promoting academic equity within GIScience and Geography.
>
---
#### [new 020] Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition
- **分类: cs.AI; cs.CV; cs.CY**

- **简介: 论文比较了AI与人类在情绪识别中的表现，通过RMET测试发现MLLMs在个体层面优于人类，但集体决策（群体智慧）超越AI，提出协作方法提升效果，揭示集体智慧对情感AI发展的潜力。**

- **链接: [http://arxiv.org/pdf/2508.08830v1](http://arxiv.org/pdf/2508.08830v1)**

> **作者:** Mustafa Akben; Vinayaka Gude; Haya Ajjan
>
> **摘要:** The ability to discern subtle emotional cues is fundamental to human social intelligence. As artificial intelligence (AI) becomes increasingly common, AI's ability to recognize and respond to human emotions is crucial for effective human-AI interactions. In particular, whether such systems can match or surpass human experts remains to be seen. However, the emotional intelligence of AI, particularly multimodal large language models (MLLMs), remains largely unexplored. This study evaluates the emotion recognition abilities of MLLMs using the Reading the Mind in the Eyes Test (RMET) and its multiracial counterpart (MRMET), and compares their performance against human participants. Results show that, on average, MLLMs outperform humans in accurately identifying emotions across both tests. This trend persists even when comparing performance across low, medium, and expert-level performing groups. Yet when we aggregate independent human decisions to simulate collective intelligence, human groups significantly surpass the performance of aggregated MLLM predictions, highlighting the wisdom of the crowd. Moreover, a collaborative approach (augmented intelligence) that combines human and MLLM predictions achieves greater accuracy than either humans or MLLMs alone. These results suggest that while MLLMs exhibit strong emotion recognition at the individual level, the collective intelligence of humans and the synergistic potential of human-AI collaboration offer the most promising path toward effective emotional AI. We discuss the implications of these findings for the development of emotionally intelligent AI systems and future research directions.
>
---
#### [new 021] Sacred or Synthetic? Evaluating LLM Reliability and Abstention for Religious Questions
- **分类: cs.CL; cs.AI; cs.CY**

- **简介: 论文提出首个针对伊斯兰教法学派（四大学派）的LLM可靠性与撤回能力基准FiqhQA，评估其在宗教问答中的准确性与撤回判断，揭示不同模型、语言及学派间的差异，指出阿拉伯语中宗教推理的局限性，强调任务特定评价与谨慎部署的重要性。**

- **链接: [http://arxiv.org/pdf/2508.08287v1](http://arxiv.org/pdf/2508.08287v1)**

> **作者:** Farah Atif; Nursultan Askarbekuly; Kareem Darwish; Monojit Choudhury
>
> **备注:** 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)
>
> **摘要:** Despite the increasing usage of Large Language Models (LLMs) in answering questions in a variety of domains, their reliability and accuracy remain unexamined for a plethora of domains including the religious domains. In this paper, we introduce a novel benchmark FiqhQA focused on the LLM generated Islamic rulings explicitly categorized by the four major Sunni schools of thought, in both Arabic and English. Unlike prior work, which either overlooks the distinctions between religious school of thought or fails to evaluate abstention behavior, we assess LLMs not only on their accuracy but also on their ability to recognize when not to answer. Our zero-shot and abstention experiments reveal significant variation across LLMs, languages, and legal schools of thought. While GPT-4o outperforms all other models in accuracy, Gemini and Fanar demonstrate superior abstention behavior critical for minimizing confident incorrect answers. Notably, all models exhibit a performance drop in Arabic, highlighting the limitations in religious reasoning for languages other than English. To the best of our knowledge, this is the first study to benchmark the efficacy of LLMs for fine-grained Islamic school of thought specific ruling generation and to evaluate abstention for Islamic jurisprudence queries. Our findings underscore the need for task-specific evaluation and cautious deployment of LLMs in religious applications.
>
---
#### [new 022] Out of the Box, into the Clinic? Evaluating State-of-the-Art ASR for Clinical Applications for Older Adults
- **分类: cs.CL; cs.CY**

- **简介: 论文评估最新ASR模型在老年群体临床场景中的表现，解决多语言模型泛化不足与准确性-速度权衡问题，通过对比通用模型与微调模型，发现通用模型性能更优，但部分场景存在高误码率（WET）及幻觉问题。**

- **链接: [http://arxiv.org/pdf/2508.08684v1](http://arxiv.org/pdf/2508.08684v1)**

> **作者:** Bram van Dijk; Tiberon Kuiper; Sirin Aoulad si Ahmed; Armel Levebvre; Jake Johnson; Jan Duin; Simon Mooijaart; Marco Spruit
>
> **摘要:** Voice-controlled interfaces can support older adults in clinical contexts, with chatbots being a prime example, but reliable Automatic Speech Recognition (ASR) for underrepresented groups remains a bottleneck. This study evaluates state-of-the-art ASR models on language use of older Dutch adults, who interacted with the Welzijn.AI chatbot designed for geriatric contexts. We benchmark generic multilingual ASR models, and models fine-tuned for Dutch spoken by older adults, while also considering processing speed. Our results show that generic multilingual models outperform fine-tuned models, which suggests recent ASR models can generalise well out of the box to realistic datasets. Furthermore, our results suggest that truncating existing architectures is helpful in balancing the accuracy-speed trade-off, though we also identify some cases with high WER due to hallucinations.
>
---
#### [new 023] IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization
- **分类: cs.CL; cs.AI; cs.CY**

- **简介: 论文提出IROTE任务，解决LLMs无法稳定提取人类特质的问题，通过自适应优化生成自我反思文本，增强特征关联性，减少冗余，实现稳定、可转移的特质提取。**

- **链接: [http://arxiv.org/pdf/2508.08719v1](http://arxiv.org/pdf/2508.08719v1)**

> **作者:** Yuzhuo Bai; Shitong Duan; Muhua Huang; Jing Yao; Zhenghao Liu; Peng Zhang; Tun Lu; Xiaoyuan Yi; Maosong Sun; Xing Xie
>
> **摘要:** Trained on various human-authored corpora, Large Language Models (LLMs) have demonstrated a certain capability of reflecting specific human-like traits (e.g., personality or values) by prompting, benefiting applications like personalized LLMs and social simulations. However, existing methods suffer from the superficial elicitation problem: LLMs can only be steered to mimic shallow and unstable stylistic patterns, failing to embody the desired traits precisely and consistently across diverse tasks like humans. To address this challenge, we propose IROTE, a novel in-context method for stable and transferable trait elicitation. Drawing on psychological theories suggesting that traits are formed through identity-related reflection, our method automatically generates and optimizes a textual self-reflection within prompts, which comprises self-perceived experience, to stimulate LLMs' trait-driven behavior. The optimization is performed by iteratively maximizing an information-theoretic objective that enhances the connections between LLMs' behavior and the target trait, while reducing noisy redundancy in reflection without any fine-tuning, leading to evocative and compact trait reflection. Extensive experiments across three human trait systems manifest that one single IROTE-generated self-reflection can induce LLMs' stable impersonation of the target trait across diverse downstream tasks beyond simple questionnaire answering, consistently outperforming existing strong baselines.
>
---
#### [new 024] Financial and symbolic incentives promote 'green' charging choices
- **分类: physics.soc-ph; cs.CY; cs.HC**

- **简介: 本研究探讨财务与象征性激励对绿色充电行为的影响，旨在解决因时间成本导致的电动车充电行为偏差问题，通过实验证明两者均有效，但无显著差异。**

- **链接: [http://arxiv.org/pdf/2508.08282v1](http://arxiv.org/pdf/2508.08282v1)**

> **作者:** Celina Kacperski; Florian Kutzner
>
> **备注:** behavior steering techniques, sustainable behavior, e-mobility, incentives
>
> **摘要:** Electromobility can contribute to a reduction in greenhouse gas emissions if usage behavior is aligned with the increasing availability of renewable energy. To achieve this, smart navigation systems can be used to inform drivers of optimal charging times and locations. Yet, required flexibility may impart time penalties. We investigate the impact of financial and symbolic incentive schemes to counteract these additional costs. In a laboratory experiment with real-life time costs, we find that monetary and symbolic incentives are both effective in changing behavior towards 'greener' charging choices, while we find no significant statistical difference between them.
>
---
#### [new 025] Simulating Generative Social Agents via Theory-Informed Workflow Design
- **分类: cs.AI; cs.CY**

- **简介: 论文提出基于社会认知理论的框架，解决现有社会代理行为不一致问题，通过动机、规划和学习模块实现灵活行为模拟，实验显示效果优于传统方法。**

- **链接: [http://arxiv.org/pdf/2508.08726v1](http://arxiv.org/pdf/2508.08726v1)**

> **作者:** Yuwei Yan; Jinghua Piao; Xiaochong Lan; Chenyang Shao; Pan Hui; Yong Li
>
> **摘要:** Recent advances in large language models have demonstrated strong reasoning and role-playing capabilities, opening new opportunities for agent-based social simulations. However, most existing agents' implementations are scenario-tailored, without a unified framework to guide the design. This lack of a general social agent limits their ability to generalize across different social contexts and to produce consistent, realistic behaviors. To address this challenge, we propose a theory-informed framework that provides a systematic design process for LLM-based social agents. Our framework is grounded in principles from Social Cognition Theory and introduces three key modules: motivation, action planning, and learning. These modules jointly enable agents to reason about their goals, plan coherent actions, and adapt their behavior over time, leading to more flexible and contextually appropriate responses. Comprehensive experiments demonstrate that our theory-driven agents reproduce realistic human behavior patterns under complex conditions, achieving up to 75% lower deviation from real-world behavioral data across multiple fidelity metrics compared to classical generative baselines. Ablation studies further show that removing motivation, planning, or learning modules increases errors by 1.5 to 3.2 times, confirming their distinct and essential contributions to generating realistic and coherent social behaviors.
>
---
## 更新

#### [replaced 001] Surviving the Narrative Collapse: Sustainability and Justice in Computing Within Limits
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2508.05992v2](http://arxiv.org/pdf/2508.05992v2)**

> **作者:** Dave Guruge; Samuel Mann; Ruth Myers; Oliver Bates; Mikey Goldweber; Andy Williamson; Jon Lasenby; Ian Brooks
>
> **备注:** Post-proceedings paper presented at LIMITS 2025: 11th Workshop on Computing within Limits, 2025-06-26/27, Online
>
> **摘要:** Sustainability-driven computing research - encompassing equity, diversity, climate change, and social justice - is increasingly dismissed as woke or even dangerous in many sociopolitical contexts. As misinformation, ideological polarisation, deliberate ignorance and reactionary narratives gain ground, how can sustainability research in computing continue to exist and make an impact? This paper explores these tensions through Fictomorphosis, a creative story retelling method that reframes contested topics through different genres and perspectives. By engaging computing researchers in structured narrative transformations, we investigate how sustainability-oriented computing research is perceived, contested, and can adapt in a post-truth world.
>
---
#### [replaced 002] Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention
- **分类: cs.AI; cs.CY; K.3.1; I.2.6; H.4**

- **链接: [http://arxiv.org/pdf/2508.07107v2](http://arxiv.org/pdf/2508.07107v2)**

> **作者:** Timothy Oluwapelumi Adeyemi; Nadiah Fahad AlOtaibi
>
> **备注:** 10 pages, 1 figure, 3 tables
>
> **摘要:** Accurate prediction of student performance is essential for enabling timely academic interventions. However, most machine learning models used in educational settings are static and lack the ability to adapt when new data such as post-intervention outcomes become available. To address this limitation, we propose a Feedback-Driven Decision Support System (DSS) with a closed-loop architecture that enables continuous model refinement. The system employs a LightGBM-based regressor with incremental retraining, allowing educators to input updated student performance data, which automatically triggers model updates. This adaptive mechanism enhances prediction accuracy by learning from real-world academic progress over time. The platform features a Flask-based web interface to support real-time interaction and integrates SHAP (SHapley Additive exPlanations) for model interpretability, ensuring transparency and trustworthiness in predictions. Experimental results demonstrate a 10.7% reduction in RMSE after retraining, with consistent upward adjustments in predicted scores for students who received interventions. By transforming static predictive models into self-improving systems, our approach advances educational analytics toward human-centered, data-driven, and responsive artificial intelligence. The framework is designed for seamless integration into Learning Management Systems (LMS) and institutional dashboards, facilitating practical deployment in real educational environments.
>
---
#### [replaced 003] Effort-aware Fairness: Incorporating a Philosophy-informed, Human-centered Notion of Effort into Algorithmic Fairness Metrics
- **分类: cs.AI; cs.CY; cs.HC; cs.LG**

- **链接: [http://arxiv.org/pdf/2505.19317v2](http://arxiv.org/pdf/2505.19317v2)**

> **作者:** Tin Nguyen; Jiannan Xu; Zora Che; Phuong-Anh Nguyen-Le; Rushil Dandamudi; Donald Braman; Furong Huang; Hal Daumé III; Zubin Jelveh
>
> **备注:** AIES 2025
>
> **摘要:** Although popularized AI fairness metrics, e.g., demographic parity, have uncovered bias in AI-assisted decision-making outcomes, they do not consider how much effort one has spent to get to where one is today in the input feature space. However, the notion of effort is important in how Philosophy and humans understand fairness. We propose a philosophy-informed approach to conceptualize and evaluate Effort-aware Fairness (EaF), grounded in the concept of Force, which represents the temporal trajectory of predictive features coupled with inertia. Besides theoretical formulation, our empirical contributions include: (1) a pre-registered human subjects experiment, which shows that for both stages of the (individual) fairness evaluation process, people consider the temporal trajectory of a predictive feature more than its aggregate value; (2) pipelines to compute Effort-aware Individual/Group Fairness in the criminal justice and personal finance contexts. Our work may enable AI model auditors to uncover and potentially correct unfair decisions against individuals who have spent significant efforts to improve but are still stuck with systemic disadvantages outside their control.
>
---
#### [replaced 004] ChatBench: From Static Benchmarks to Human-AI Evaluation
- **分类: cs.CL; cs.AI; cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2504.07114v2](http://arxiv.org/pdf/2504.07114v2)**

> **作者:** Serina Chang; Ashton Anderson; Jake M. Hofman
>
> **备注:** ACL 2025 (main)
>
> **摘要:** With the rapid adoption of LLM-based chatbots, there is a pressing need to evaluate what humans and LLMs can achieve together. However, standard benchmarks, such as MMLU, measure LLM capabilities in isolation (i.e., "AI-alone"). Here, we design and conduct a user study to convert MMLU questions into user-AI conversations, by seeding the user with the question and having them carry out a conversation with the LLM to answer their question. We release ChatBench, a new dataset with AI-alone, user-alone, and user-AI data for 396 questions and two LLMs, including 144K answers and 7,336 user-AI conversations. We find that AI-alone accuracy fails to predict user-AI accuracy, with significant differences across multiple subjects (math, physics, and moral reasoning), and we analyze the user-AI conversations to provide insight into how they diverge from AI-alone benchmarks. Finally, we show that fine-tuning a user simulator on a subset of ChatBench improves its ability to estimate user-AI accuracies, increasing correlation on held-out questions by more than 20 points, creating possibilities for scaling interactive evaluation.
>
---
#### [replaced 005] An Empirical Inquiry into Surveillance Capitalism: Web Tracking
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2508.07454v2](http://arxiv.org/pdf/2508.07454v2)**

> **作者:** Nils Bonfils
>
> **备注:** Post-proceedings paper presented at LIMITS 2025: 11th Workshop on Computing within Limits, 2025-06-26/27, Online
>
> **摘要:** The modern web is increasingly characterized by the pervasiveness of Surveillance Capitalism. This investigation employs an empirical approach to examine this phenomenon through the web tracking practices of major tech companies -- specifically Google, Apple, Facebook, Amazon, and Microsoft (GAFAM) -- and their relation to financial performance indicators. Using longitudinal data from WhoTracks.Me spanning from 2017 to 2025 and publicly accessible SEC filings, this paper analyzes patterns and trends in web tracking data to establish empirical evidence of Surveillance Capitalism's extraction mechanisms. Our findings reveal Google's omnipresent position on the web, a three-tier stratification among GAFAM companies in the surveillance space, and evidence suggesting an evolution of tracking techniques to evade detection. The investigation further discusses the social and environmental costs of web tracking and how alternative technologies, such as the Gemini protocol, offer pathways to challenge the extractive logic of this new economic order. By closely examining surveillance activities, this research contributes to an ongoing effort to better understand the current state and future trajectory of Surveillance Capitalism.
>
---
#### [replaced 006] From Platform Migration to Cultural Integration: the Ingress and Diffusion of #wlw from TikTok to RedNote in Queer Women Communities
- **分类: cs.SI; cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2508.07579v2](http://arxiv.org/pdf/2508.07579v2)**

> **作者:** Ziqi Pan; Runhua Zhang; Jiehui Luo; Yuanhao Zhang; Yue Deng; Xiaojuan Ma
>
> **摘要:** Hashtags serve as identity markers and connection tools in online queer communities. Recently, the Western-origin #wlw (women-loving-women) hashtag has risen in the Chinese lesbian community on RedNote, coinciding with user migration triggered by the temporary US TikTok ban. This event provides a unique lens to study cross-cultural hashtag ingress and diffusion through the populations' responsive behaviors in cyber-migration. In this paper, we conducted a two-phase content analysis of 418 #wlw posts from January and April, examining different usage patterns during the hashtag's ingress and diffusion. Results indicate that the successful introduction of #wlw was facilitated by TikTok immigrants' bold importation, both populations' mutual interpretation, and RedNote natives' discussions. In current manifestation of diffusion, #wlw becomes a RedNote-recognized queer hashtag for sharing queer life, and semantically expands to support feminism discourse. Our findings provide empirical insights for enhancing the marginalized communities' cross-cultural communication.
>
---
#### [replaced 007] Quantifying Gender Biases Towards Politicians on Reddit
- **分类: cs.CL; cs.CY**

- **链接: [http://arxiv.org/pdf/2112.12014v3](http://arxiv.org/pdf/2112.12014v3)**

> **作者:** Sara Marjanovic; Karolina Stańczak; Isabelle Augenstein
>
> **备注:** PlosONE article
>
> **摘要:** Despite attempts to increase gender parity in politics, global efforts have struggled to ensure equal female representation. This is likely tied to implicit gender biases against women in authority. In this work, we present a comprehensive study of gender biases that appear in online political discussion. To this end, we collect 10 million comments on Reddit in conversations about male and female politicians, which enables an exhaustive study of automatic gender bias detection. We address not only misogynistic language, but also other manifestations of bias, like benevolent sexism in the form of seemingly positive sentiment and dominance attributed to female politicians, or differences in descriptor attribution. Finally, we conduct a multi-faceted study of gender bias towards politicians investigating both linguistic and extra-linguistic cues. We assess 5 different types of gender bias, evaluating coverage, combinatorial, nominal, sentimental, and lexical biases extant in social media language and discourse. Overall, we find that, contrary to previous research, coverage and sentiment biases suggest equal public interest in female politicians. Rather than overt hostile or benevolent sexism, the results of the nominal and lexical analyses suggest this interest is not as professional or respectful as that expressed about male politicians. Female politicians are often named by their first names and are described in relation to their body, clothing, or family; this is a treatment that is not similarly extended to men. On the now banned far-right subreddits, this disparity is greatest, though differences in gender biases still appear in the right and left-leaning subreddits. We release the curated dataset to the public for future studies.
>
---
#### [replaced 008] StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback
- **分类: cs.CV; cs.CY; cs.MA**

- **链接: [http://arxiv.org/pdf/2508.06555v2](http://arxiv.org/pdf/2508.06555v2)**

> **作者:** Hongbo Ma; Fei Shen; Hongbin Xu; Xiaoce Wang; Gang Xu; Jinkai Zheng; Liangqiong Qu; Ming Li
>
> **备注:** 24pages, 5 figures
>
> **摘要:** The advancement of intelligent agents has revolutionized problem-solving across diverse domains, yet solutions for personalized fashion styling remain underexplored, which holds immense promise for promoting shopping experiences. In this work, we present StyleTailor, the first collaborative agent framework that seamlessly unifies personalized apparel design, shopping recommendation, virtual try-on, and systematic evaluation into a cohesive workflow. To this end, StyleTailor pioneers an iterative visual refinement paradigm driven by multi-level negative feedback, enabling adaptive and precise user alignment. Specifically, our framework features two core agents, i.e., Designer for personalized garment selection and Consultant for virtual try-on, whose outputs are progressively refined via hierarchical vision-language model feedback spanning individual items, complete outfits, and try-on efficacy. Counterexamples are aggregated into negative prompts, forming a closed-loop mechanism that enhances recommendation quality. To assess the performance, we introduce a comprehensive evaluation suite encompassing style consistency, visual quality, face similarity, and artistic appraisal. Extensive experiments demonstrate StyleTailor's superior performance in delivering personalized designs and recommendations, outperforming strong baselines without negative feedback and establishing a new benchmark for intelligent fashion systems.
>
---
#### [replaced 009] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference
- **分类: cs.CY; cs.AI; cs.CL**

- **链接: [http://arxiv.org/pdf/2508.04586v2](http://arxiv.org/pdf/2508.04586v2)**

> **作者:** Nuo Chen; Moming Duan; Andre Huikai Lin; Qian Wang; Jiaying Wu; Bingsheng He
>
> **备注:** Preprint
>
> **摘要:** Artificial Intelligence (AI) conferences are essential for advancing research, sharing knowledge, and fostering academic community. However, their rapid expansion has rendered the centralized conference model increasingly unsustainable. This paper offers a data-driven diagnosis of a structural crisis that threatens the foundational goals of scientific dissemination, equity, and community well-being. We identify four key areas of strain: (1) scientifically, with per-author publication rates more than doubling over the past decade to over 4.5 papers annually; (2) environmentally, with the carbon footprint of a single conference exceeding the daily emissions of its host city; (3) psychologically, with 71% of online community discourse reflecting negative sentiment and 35% referencing mental health concerns; and (4) logistically, with attendance at top conferences such as NeurIPS 2024 beginning to outpace venue capacity. These pressures point to a system that is misaligned with its core mission. In response, we propose the Community-Federated Conference (CFC) model, which separates peer review, presentation, and networking into globally coordinated but locally organized components, offering a more sustainable, inclusive, and resilient path forward for AI research.
>
---
