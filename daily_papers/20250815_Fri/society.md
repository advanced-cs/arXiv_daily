# 计算机与社会 cs.CY

- **最新发布 16 篇**

- **更新 9 篇**

## 最新发布

#### [new 001] Traffic Intersection Simulation Using Turning Movement Count Data in SUMO: A Case Study of Toronto Intersections
- **分类: cs.CY; cs.SY; eess.SY; 90B20, 90B06, 68U20; I.6.4; I.6.5**

- **简介: 论文提出使用多伦多TMC数据在SUMO中模拟交通路口，验证数据驱动方法，首次通过GUI整合数据提升仿真准确性。**

- **链接: [http://arxiv.org/pdf/2508.10733v1](http://arxiv.org/pdf/2508.10733v1)**

> **作者:** Harshit Maheshwari; Li Yang; Richard W Pazzi
>
> **备注:** Published in 2025 21st DCOSS-IoT, Code is available at Github: https://github.com/ANTS-OntarioTechU/CrossFlow
>
> **摘要:** Urban traffic simulation is vital in planning, modeling, and analyzing road networks. However, the realism of a simulation depends extensively on the quality of input data. This paper presents an intersection traffic simulation tool that leverages real-world vehicle turning movement count (TMC) data from the City of Toronto to model traffic in an urban environment at an individual or multiple intersections using Simulation of Urban MObility (SUMO). The simulation performed in this research focuses specifically on intersection-level traffic generation without creating full vehicle routes through the network. This also helps keep the network's complexity to a minimum. The simulated traffic is evaluated against actual data to show that the simulation closely reproduces real intersection flows. This validates that the real data can drive practical simulations, and these scenarios can replace synthetic or random generated data, which is prominently used in developing new traffic-related methodologies. This is the first tool to integrate TMC data from Toronto into SUMO via an easy-to-use Graphical User Interface. This work contributes to the research and traffic planning community on data-driven traffic simulation. It provides transportation engineers with a framework to evaluate intersection design and traffic signal optimization strategies using readily available aggregate traffic data.
>
---
#### [new 002] Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems
- **分类: cs.CY; cs.AI**

- **简介: 论文提出“Legal Zero-Days”作为AI风险新向量，构建风险模型识别法律漏洞，通过案例分析揭示小疏忽引发大规模治理危机，并开发“法律谜题”评估AI发现漏洞能力，指出未来系统可能具备此能力。**

- **链接: [http://arxiv.org/pdf/2508.10050v1](http://arxiv.org/pdf/2508.10050v1)**

> **作者:** Greg Sadler; Nathan Sherburn
>
> **备注:** 10 pages, 1 table, 1 figure. Introduces Legal Zero-Days as a novel AI risk vector and provides evaluation framework for measuring AI systems' ability to discover legal vulnerabilities
>
> **摘要:** We introduce the concept of "Legal Zero-Days" as a novel risk vector for advanced AI systems. Legal Zero-Days are previously undiscovered vulnerabilities in legal frameworks that, when exploited, can cause immediate and significant societal disruption without requiring litigation or other processes before impact. We present a risk model for identifying and evaluating these vulnerabilities, demonstrating their potential to bypass safeguards or impede government responses to AI incidents. Using the 2017 Australian dual citizenship crisis as a case study, we illustrate how seemingly minor legal oversights can lead to large-scale governance disruption. We develop a methodology for creating "legal puzzles" as evaluation instruments for assessing AI systems' capabilities to discover such vulnerabilities. Our findings suggest that while current AI models may not reliably find impactful Legal Zero-Days, future systems may develop this capability, presenting both risks and opportunities for improving legal robustness. This work contributes to the broader effort to identify and mitigate previously unrecognized risks from frontier AI systems.
>
---
#### [new 003] Digital Contact Tracing: Examining the Effects of Understanding and Release Organization on Public Trust
- **分类: cs.CY**

- **简介: 论文研究数字接触追踪中理解与发布组织对公众信任的影响，发现隐私保护理解与信任无显著关联，应用来源亦无显著影响。任务为验证相关因素对信任的作用，工作基于美国成人调查数据分析。**

- **链接: [http://arxiv.org/pdf/2508.10198v1](http://arxiv.org/pdf/2508.10198v1)**

> **作者:** Lucas Draper
>
> **摘要:** Contact tracing has existed in various forms for a very long time. With the rise of COVID-19, the concept has become increasingly important to help slow the spread of the virus. One approach to modernizing contact tracing is to introduce applications that detect all close contacts without individuals having to interact knowingly. 101 United States adults were surveyed in June of 2022 regarding their perceptions and trust of COVID-19 contact tracing applications. We see no definitive correlation between an individual's understanding of privacy protection procedures for contact tracing applications and their willingness to trust such an application. We also see that the release of the application by a private entity like Google-Apple or by a public entity like the United States Federal Government has no significant correlation with a person's trust in the application.
>
---
#### [new 004] Ask ChatGPT: Caveats and Mitigations for Individual Users of AI Chatbots
- **分类: cs.CY**

- **简介: 论文任务：评估AI聊天机器人对个人用户的潜在风险及缓解策略。  
问题：个人使用AI chatbot的局限性与危害。  
工作：回顾文献分析风险（如幻觉、偏见），提出 mitigation strategies。**

- **链接: [http://arxiv.org/pdf/2508.10272v1](http://arxiv.org/pdf/2508.10272v1)**

> **作者:** Chengen Wang; Murat Kantarcioglu
>
> **摘要:** As ChatGPT and other Large Language Model (LLM)-based AI chatbots become increasingly integrated into individuals' daily lives, important research questions arise. What concerns and risks do these systems pose for individual users? What potential harms might they cause, and how can these be mitigated? In this work, we review recent literature and reports, and conduct a comprehensive investigation into these questions. We begin by explaining how LLM-based AI chatbots work, providing essential background to help readers understand chatbots' inherent limitations. We then identify a range of risks associated with individual use of these chatbots, including hallucinations, intrinsic biases, sycophantic behavior, cognitive decline from overreliance, social isolation, and privacy leakage. Finally, we propose several key mitigation strategies to address these concerns. Our goal is to raise awareness of the potential downsides of AI chatbot use, and to empower users to enhance, rather than diminish, human intelligence, to enrich, rather than compromise, daily life.
>
---
#### [new 005] Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 论文聚焦NLP从业者在数据公平性中的责任与问责，揭示其在技术、政策与社区间的矛盾，提出多尺度治理框架及结构性改革建议，推动数据公平性实践。**

- **链接: [http://arxiv.org/pdf/2508.10071v1](http://arxiv.org/pdf/2508.10071v1)**

> **作者:** Jay L. Cunningham; Kevin Zhongyang Shao; Rock Yuren Pang; Nathaniel Mengist
>
> **备注:** 10 pages, 6 Pages (References and Appendices). The archival version has been accepted to AAAI (AIES 2025) without the extended Appendices. This extended version includes Appendices
>
> **摘要:** While research has focused on surfacing and auditing algorithmic bias to ensure equitable AI development, less is known about how NLP practitioners - those directly involved in dataset development, annotation, and deployment - perceive and navigate issues of NLP data equity. This study is among the first to center practitioners' perspectives, linking their experiences to a multi-scalar AI governance framework and advancing participatory recommendations that bridge technical, policy, and community domains. Drawing on a 2024 questionnaire and focus group, we examine how U.S.-based NLP data practitioners conceptualize fairness, contend with organizational and systemic constraints, and engage emerging governance efforts such as the U.S. AI Bill of Rights. Findings reveal persistent tensions between commercial objectives and equity commitments, alongside calls for more participatory and accountable data workflows. We critically engage debates on data diversity and diversity washing, arguing that improving NLP equity requires structural governance reforms that support practitioner agency and community consent.
>
---
#### [new 006] STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images
- **分类: cs.CV; cs.CY**

- **简介: 论文提出STAMP框架，通过多模式注意力和多实例学习解决多中心肺腺癌STAS诊断难题，提升诊断准确率。**

- **链接: [http://arxiv.org/pdf/2508.10473v1](http://arxiv.org/pdf/2508.10473v1)**

> **作者:** Liangrui Pan; xiaoyu Li; Guang Zhu; Guanting Li; Ruixin Wang; Jiadi Luo; Yaning Yang; Liang qingchun; Shaoliang Peng
>
> **备注:** Submit to AAAI2026
>
> **摘要:** Spread through air spaces (STAS) constitutes a novel invasive pattern in lung adenocarcinoma (LUAD), associated with tumor recurrence and diminished survival rates. However, large-scale STAS diagnosis in LUAD remains a labor-intensive endeavor, compounded by the propensity for oversight and misdiagnosis due to its distinctive pathological characteristics and morphological features. Consequently, there is a pressing clinical imperative to leverage deep learning models for STAS diagnosis. This study initially assembled histopathological images from STAS patients at the Second Xiangya Hospital and the Third Xiangya Hospital of Central South University, alongside the TCGA-LUAD cohort. Three senior pathologists conducted cross-verification annotations to construct the STAS-SXY, STAS-TXY, and STAS-TCGA datasets. We then propose a multi-pattern attention-aware multiple instance learning framework, named STAMP, to analyze and diagnose the presence of STAS across multi-center histopathology images. Specifically, the dual-branch architecture guides the model to learn STAS-associated pathological features from distinct semantic spaces. Transformer-based instance encoding and a multi-pattern attention aggregation modules dynamically selects regions closely associated with STAS pathology, suppressing irrelevant noise and enhancing the discriminative power of global representations. Moreover, a similarity regularization constraint prevents feature redundancy across branches, thereby improving overall diagnostic accuracy. Extensive experiments demonstrated that STAMP achieved competitive diagnostic results on STAS-SXY, STAS-TXY and STAS-TCGA, with AUCs of 0.8058, 0.8017, and 0.7928, respectively, surpassing the clinical level.
>
---
#### [new 007] Welfare-Centric Clustering
- **分类: cs.LG; cs.AI; cs.CY; cs.DS**

- **简介: 论文提出福利导向聚类方法，解决传统公平聚类的不合理结果，通过建模组效用并提出Rawlsian和Utilitarian目标，设计算法并验证有效性。**

- **链接: [http://arxiv.org/pdf/2508.10345v1](http://arxiv.org/pdf/2508.10345v1)**

> **作者:** Claire Jie Zhang; Seyed A. Esmaeili; Jamie Morgenstern
>
> **摘要:** Fair clustering has traditionally focused on ensuring equitable group representation or equalizing group-specific clustering costs. However, Dickerson et al. (2025) recently showed that these fairness notions may yield undesirable or unintuitive clustering outcomes and advocated for a welfare-centric clustering approach that models the utilities of the groups. In this work, we model group utilities based on both distances and proportional representation and formalize two optimization objectives based on welfare-centric clustering: the Rawlsian (Egalitarian) objective and the Utilitarian objective. We introduce novel algorithms for both objectives and prove theoretical guarantees for them. Empirical evaluations on multiple real-world datasets demonstrate that our methods significantly outperform existing fair clustering baselines.
>
---
#### [new 008] Benchmark-Driven Selection of AI: Evidence from DeepSeek-R1
- **分类: cs.LG; cs.CY**

- **简介: 论文提出基准驱动的AI选择概念，通过DeepSeek-R1案例证明基准可作为训练曲目提升模型泛化能力，权衡评价与学习。**

- **链接: [http://arxiv.org/pdf/2508.10173v1](http://arxiv.org/pdf/2508.10173v1)**

> **作者:** Petr Spelda; Vit Stritecky
>
> **备注:** 17 pages, 5 figures, 2 tables
>
> **摘要:** Evaluation of reasoning language models gained importance after it was observed that they can combine their existing capabilities into novel traces of intermediate steps before task completion and that the traces can sometimes help them to generalize better than past models. As reasoning becomes the next scaling dimension of large language models, careful study of their capabilities in critical tasks is needed. We show that better performance is not always caused by test-time algorithmic improvements or model sizes but also by using impactful benchmarks as curricula for learning. We call this benchmark-driven selection of AI and show its effects on DeepSeek-R1 using our sequential decision-making problem from Humanity's Last Exam. Steering development of AI by impactful benchmarks trades evaluation for learning and makes novelty of test tasks key for measuring generalization capabilities of reasoning models. Consequently, some benchmarks could be seen as curricula for training rather than unseen test sets.
>
---
#### [new 009] Beyond Self-Regulated Learning Processes: Unveiling Hidden Tactics in Generative AI-Assisted Writing
- **分类: cs.HC; cs.CY**

- **简介: 论文研究GenAI辅助写作中SRL的动态策略，揭示隐藏战术，通过HMM分析三类群体差异，提升学习支持技术。**

- **链接: [http://arxiv.org/pdf/2508.10310v1](http://arxiv.org/pdf/2508.10310v1)**

> **作者:** Kaixun Yang; Yizhou Fan; Luzhen Tang; Mladen Raković; Xinyu Li; Dragan Gašević; Guanliang Chen
>
> **摘要:** The integration of Generative AI (GenAI) into education is reshaping how students learn, making self-regulated learning (SRL) - the ability to plan, monitor, and adapt one's learning - more important than ever. To support learners in these new contexts, it is essential to understand how SRL unfolds during interaction with GenAI tools. Learning analytics offers powerful techniques for analyzing digital trace data to infer SRL behaviors. However, existing approaches often assume SRL processes are linear, segmented, and non-overlapping-assumptions that overlook the dynamic, recursive, and non-linear nature of real-world learning. We address this by conceptualizing SRL as a layered system: observable learning patterns reflect hidden tactics (short, purposeful action states), which combine into broader SRL strategies. Using Hidden Markov Models (HMMs), we analyzed trace data from higher education students engaged in GenAI-assisted academic writing. We identified three distinct groups of learners, each characterized by different SRL strategies. These groups showed significant differences in performance, indicating that students' use of different SRL strategies in GenAI-assisted writing led to varying task outcomes. Our findings advance the methodological toolkit for modeling SRL and inform the design of adaptive learning technologies that more effectively support learners in GenAI-enhanced educational environments.
>
---
#### [new 010] Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling
- **分类: cs.CL; cs.CY**

- **简介: 论文通过层次化主题建模对K-12生成式AI使用进行内容与任务双维度分类，基于真实课堂数据揭示其应用特征，弥补传统方法不足，推动教育AI研究。**

- **链接: [http://arxiv.org/pdf/2508.09997v1](http://arxiv.org/pdf/2508.09997v1)**

> **作者:** Johannes Schneider; Béatrice S. Hasler; Michaela Varrone; Fabian Hoya; Thomas Schroffenegger; Dana-Kristin Mah; Karl Peböck
>
> **备注:** Accepted at the International Conference on Computer-Human Interaction Research and Applications (CHIRA), 2025
>
> **摘要:** We analyze anonymous interaction data of minors in class-rooms spanning several months, schools, and subjects employing a novel, simple topic modeling approach. Specifically, we categorize more than 17,000 messages generated by students, teachers, and ChatGPT in two dimensions: content (such as nature and people) and tasks (such as writing and explaining). Our hierarchical categorization done separately for each dimension includes exemplary prompts, and provides both a high-level overview as well as tangible insights. Prior works mostly lack a content or thematic categorization. While task categorizations are more prevalent in education, most have not been supported by real-world data for K-12. In turn, it is not surprising that our analysis yielded a number of novel applications. In deriving these insights, we found that many of the well-established classical and emerging computational methods, i.e., topic modeling, for analysis of large amounts of texts underperform, leading us to directly apply state-of-the-art LLMs with adequate pre-processing to achieve hierarchical topic structures with better human alignment through explicit instructions than prior approaches. Our findings support fellow researchers, teachers and students in enriching the usage of GenAI, while our discussion also highlights a number of concerns and open questions for future research.
>
---
#### [new 011] An Architecture for Distributed Digital Identities in the Physical World
- **分类: cs.CR; cs.CY; cs.NI**

- **简介: 论文提出分布式数字身份架构，解决中心化管理的可用性与隐私问题，结合传感器、身份权威及PIA实现去中心化身份验证，协议经形式化验证，展示实际可行性。**

- **链接: [http://arxiv.org/pdf/2508.10185v1](http://arxiv.org/pdf/2508.10185v1)**

> **作者:** René Mayrhofer; Michael Roland; Tobias Höller; Philipp Hofer; Mario Lins
>
> **摘要:** Digital identities are increasingly important for mediating not only digital but also physical service transactions. Managing such identities through centralized providers can cause both availability and privacy concerns: single points of failure and control are ideal targets for global attacks on technical, organizational, or legal fronts. We design, analyze, and build a distributed digital identity architecture for physical world transactions in common scenarios like unlocking doors, public transport, or crossing country borders. This architecture combines (biometric and other) sensors, (established and upcoming) identity authorities, attribute verifiers, and a new core component we call the \emph{Personal Identity Agent (PIA)} that represents individuals with their identity attributes in the digital domain. All transactions are conducted in a completely decentralized manner, and the components for which we currently assume central coordination are optional and only used for assisting with service discovery and latency reduction. We present a first protocol between these parties and formally verify that it achieves relevant security properties based on a realistic threat model including strong global adversaries. A proof-of-concept implementation demonstrates practical feasibility of both architecture and initial protocol for applications that can tolerate end-to-end latencies in the range of a few seconds.
>
---
#### [new 012] "I Want My Chart to Be Just for Me": Community-Engaged Design to Support Outpatient Healthcare for Resettled Communities
- **分类: cs.HC; cs.CY**

- **简介: 论文通过社区参与设计解决重新安置社区门诊医疗问题，识别资产并提出利用现有优势的技术方案。**

- **链接: [http://arxiv.org/pdf/2508.10757v1](http://arxiv.org/pdf/2508.10757v1)**

> **作者:** Zhanming Chen; Juan F. Maestre; May Hang; Alisha Ghaju; Ji Youn Shin
>
> **摘要:** Individuals resettled in a new environment often face challenges in accessing adequate healthcare services, particularly within the complex processes of outpatient clinic care. Cultural differences, language barriers, and low socioeconomic status contribute to these difficulties. While previous studies have identified barriers and proposed technology-mediated solutions for resettled populations, many focus on addressing deficits rather than building on the strengths these communities already possess, which limits the sustainability and relevance of these solutions in everyday life. We conducted two community-based participatory design workshops with 30 Hmong community members in a large metropolitan area in the US. Through this process, we identified four types of assets the community has gradually developed, including intergenerational support for health management and storytelling-based communication practices that facilitate relatable and culturally grounded interactions. We show how participatory design workshops can foster asset-based approaches, and discuss design implications for technologies that leverage patients' existing strengths to support their health management during outpatient visits.
>
---
#### [new 013] PakBBQ: A Culturally Adapted Bias Benchmark for QA
- **分类: cs.CL; cs.AI; cs.CY; cs.LG**

- **简介: 论文提出PakBBQ，一个针对巴基斯坦文化背景的问答偏差基准测试，解决跨文化偏见问题。通过构建包含8类偏见维度的多语言数据集，评估LLMs在模糊与明确上下文及负面提问框架下的表现，揭示文化适配对偏差缓解的重要性。**

- **链接: [http://arxiv.org/pdf/2508.10186v1](http://arxiv.org/pdf/2508.10186v1)**

> **作者:** Abdullah Hashmat; Muhammad Arham Mirza; Agha Ali Raza
>
> **备注:** 8 pages, 7 figures, 2 tables, Submitted to EMNLP 2025
>
> **摘要:** With the widespread adoption of Large Language Models (LLMs) across various applications, it is empirical to ensure their fairness across all user communities. However, most LLMs are trained and evaluated on Western centric data, with little attention paid to low-resource languages and regional contexts. To address this gap, we introduce PakBBQ, a culturally and regionally adapted extension of the original Bias Benchmark for Question Answering (BBQ) dataset. PakBBQ comprises over 214 templates, 17180 QA pairs across 8 categories in both English and Urdu, covering eight bias dimensions including age, disability, appearance, gender, socio-economic status, religious, regional affiliation, and language formality that are relevant in Pakistan. We evaluate multiple multilingual LLMs under both ambiguous and explicitly disambiguated contexts, as well as negative versus non negative question framings. Our experiments reveal (i) an average accuracy gain of 12\% with disambiguation, (ii) consistently stronger counter bias behaviors in Urdu than in English, and (iii) marked framing effects that reduce stereotypical responses when questions are posed negatively. These findings highlight the importance of contextualized benchmarks and simple prompt engineering strategies for bias mitigation in low resource settings.
>
---
#### [new 014] Online Homogeneity Can Emerge Without Filtering Algorithms or Homophily Preferences
- **分类: cs.SI; cs.CY**

- **简介: 论文探讨在线同质化形成机制，挑战算法过滤与用户偏好主导论，通过代理模型揭示弱偏好与群体互动可引发同质化，算法过滤或维持多样性。**

- **链接: [http://arxiv.org/pdf/2508.10466v1](http://arxiv.org/pdf/2508.10466v1)**

> **作者:** Petter Törnberg
>
> **摘要:** Ideologically homogeneous online environments - often described as "echo chambers" or "filter bubbles" - are widely seen as drivers of polarization, radicalization, and misinformation. A central debate asks whether such homophily stems primarily from algorithmic curation or users' preference for like-minded peers. This study challenges that view by showing that homogeneity can emerge in the absence of both filtering algorithms and user preferences. Using an agent-based model inspired by Schelling's model of residential segregation, we demonstrate that weak individual preferences, combined with simple group-based interaction structures, can trigger feedback loops that drive communities toward segregation. Once a small imbalance forms, cascades of user exits and regrouping amplify homogeneity across the system. Counterintuitively, algorithmic filtering - often blamed for "filter bubbles" - can in fact sustain diversity by stabilizing mixed communities. These findings highlight online polarization as an emergent system-level dynamic and underscore the importance of applying a complexity lens to the study of digital public spheres.
>
---
#### [new 015] Motive-level Analysis of Form-functions Association in Korean Folk song
- **分类: cs.SD; cs.CY**

- **简介: 论文提出基于微调模型的自动动机分割方法，利用歌词与动机边界数据提取结构特征，分析不同社会功能下的结构差异，提供可扩展的定量分析工具。**

- **链接: [http://arxiv.org/pdf/2508.10472v1](http://arxiv.org/pdf/2508.10472v1)**

> **作者:** Danbinaerin Han; Dasaem Jeong; Juhan Nam
>
> **摘要:** Computational analysis of folk song audio is challenging due to structural irregularities and the need for manual annotation. We propose a method for automatic motive segmentation in Korean folk songs by fine-tuning a speech transcription model on audio lyric with motif boundary annotation. Applying this to 856 songs, we extracted motif count and duration entropy as structural features. Statistical analysis revealed that these features vary systematically according to the social function of the songs. Songs associated with collective labor, for instance, showed different structural patterns from those for entertainment or personal settings. This work offers a scalable approach for quantitative structural analysis of oral music traditions.
>
---
#### [new 016] Facilitating Longitudinal Interaction Studies of AI Systems
- **分类: cs.HC; cs.AI; cs.CY**

- **简介: 论文提出解决长期AI系统交互研究的挑战，通过工作坊提供策略，促进社区建设并推广长期研究方法。**

- **链接: [http://arxiv.org/pdf/2508.10252v1](http://arxiv.org/pdf/2508.10252v1)**

> **作者:** Tao Long; Sitong Wang; Émilie Fabre; Tony Wang; Anup Sathya; Jason Wu; Savvas Petridis; Dingzeyu Li; Tuhin Chakrabarty; Yue Jiang; Jingyi Li; Tiffany Tseng; Ken Nakagaki; Qian Yang; Nikolas Martelaro; Jeffrey V. Nickerson; Lydia B. Chilton
>
> **备注:** Accepted workshop proposal @ UIST 2025 Busan, Korea. Workshop website: https://longitudinal-workshop.github.io/
>
> **摘要:** UIST researchers develop tools to address user challenges. However, user interactions with AI evolve over time through learning, adaptation, and repurposing, making one time evaluations insufficient. Capturing these dynamics requires longer-term studies, but challenges in deployment, evaluation design, and data collection have made such longitudinal research difficult to implement. Our workshop aims to tackle these challenges and prepare researchers with practical strategies for longitudinal studies. The workshop includes a keynote, panel discussions, and interactive breakout groups for discussion and hands-on protocol design and tool prototyping sessions. We seek to foster a community around longitudinal system research and promote it as a more embraced method for designing, building, and evaluating UIST tools.
>
---
## 更新

#### [replaced 001] A Moral Agency Framework for Legitimate Integration of AI in Bureaucracies
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2508.08231v2](http://arxiv.org/pdf/2508.08231v2)**

> **作者:** Chris Schmitz; Joanna Bryson
>
> **备注:** Accepted (non-archival) to AIES2025
>
> **摘要:** Public-sector bureaucracies seek to reap the benefits of artificial intelligence (AI), but face important concerns about accountability and transparency when using AI systems. In particular, perception or actuality of AI agency might create ethics sinks - constructs that facilitate dissipation of responsibility when AI systems of disputed moral status interface with bureaucratic structures. Here, we reject the notion that ethics sinks are a necessary consequence of introducing AI systems into bureaucracies. Rather, where they appear, they are the product of structural design decisions across both the technology and the institution deploying it. We support this claim via a systematic application of conceptions of moral agency in AI ethics to Weberian bureaucracy. We establish that it is both desirable and feasible to render AI systems as tools for the generation of organizational transparency and legibility, which continue the processes of Weberian rationalization initiated by previous waves of digitalization. We present a three-point Moral Agency Framework for legitimate integration of AI in bureaucratic structures: (a) maintain clear and just human lines of accountability, (b) ensure humans whose work is augmented by AI systems can verify the systems are functioning correctly, and (c) introduce AI only where it doesn't inhibit the capacity of bureaucracies towards either of their twin aims of legitimacy and stewardship. We suggest that AI introduced within this framework can not only improve efficiency and productivity while avoiding ethics sinks, but also improve the transparency and even the legitimacy of a bureaucracy.
>
---
#### [replaced 002] Biased AI improves human decision-making but reduces trust
- **分类: cs.HC; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2508.09297v2](http://arxiv.org/pdf/2508.09297v2)**

> **作者:** Shiyang Lai; Junsol Kim; Nadav Kunievsky; Yujin Potter; James Evans
>
> **摘要:** Current AI systems minimize risk by enforcing ideological neutrality, yet this may introduce automation bias by suppressing cognitive engagement in human decision-making. We conducted randomized trials with 2,500 participants to test whether culturally biased AI enhances human decision-making. Participants interacted with politically diverse GPT-4o variants on information evaluation tasks. Partisan AI assistants enhanced human performance, increased engagement, and reduced evaluative bias compared to non-biased counterparts, with amplified benefits when participants encountered opposing views. These gains carried a trust penalty: participants underappreciated biased AI and overcredited neutral systems. Exposing participants to two AIs whose biases flanked human perspectives closed the perception-performance gap. These findings complicate conventional wisdom about AI neutrality, suggesting that strategic integration of diverse cultural biases may foster improved and resilient human decision-making.
>
---
#### [replaced 003] Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods
- **分类: cs.CR; cs.AI; cs.CL; cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2506.10236v2](http://arxiv.org/pdf/2506.10236v2)**

> **作者:** Yeonwoo Jang; Shariqah Hossain; Ashwin Sreevatsa; Diogo Cruz
>
> **备注:** 19 pages, 6 figures. Accepted at COLM 2025 SoLaR Workshop
>
> **摘要:** In this work, we demonstrate that certain machine unlearning methods may fail under straightforward prompt attacks. We systematically evaluate eight unlearning techniques across three model families using output-based, logit-based, and probe analysis to assess the extent to which supposedly unlearned knowledge can be retrieved. While methods like RMU and TAR exhibit robust unlearning, ELM remains vulnerable to specific prompt attacks (e.g., prepending Hindi filler text to the original prompt recovers 57.3% accuracy). Our logit analysis further indicates that unlearned models are unlikely to hide knowledge through changes in answer formatting, given the strong correlation between output and logit accuracy. These findings challenge prevailing assumptions about unlearning effectiveness and highlight the need for evaluation frameworks that can reliably distinguish between genuine knowledge removal and superficial output suppression. To facilitate further research, we publicly release our evaluation framework to easily evaluate prompting techniques to retrieve unlearned knowledge.
>
---
#### [replaced 004] A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models
- **分类: cs.CY; cs.CL; cs.LG**

- **链接: [http://arxiv.org/pdf/2506.22493v3](http://arxiv.org/pdf/2506.22493v3)**

> **作者:** Sadia Kamal; Lalu Prasad Yadav Prakash; S M Rafiuddin; Mohammed Rakib; Atriya Sen; Sagnik Ray Choudhury
>
> **摘要:** Political Compass Test (PCT) or similar questionnaires have been used to quantify LLM's political leanings. Building on a recent line of work that examines the validity of PCT tests, we demonstrate that variation in standard generation parameters does not significantly impact the models' PCT scores. However, external factors such as prompt variations and fine-tuning individually and in combination affect the same. Finally, we demonstrate that when models are fine-tuned on text datasets with higher political content than others, the PCT scores are not differentially affected. This calls for a thorough investigation into the validity of PCT and similar tests, as well as the mechanism by which political leanings are encoded in LLMs.
>
---
#### [replaced 005] AI Across Borders: Exploring Perceptions and Interactions in Higher Education
- **分类: cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2501.00017v2](http://arxiv.org/pdf/2501.00017v2)**

> **作者:** Juliana Gerard; Sahajpreet Singh; Morgan Macleod; Michael McKay; Antoine Rivoire; Tanmoy Chakraborty; Muskaan Singh
>
> **摘要:** This study investigates students' perceptions of Generative Artificial Intelligence (GenAI), with a focus on Higher Education institutions in Northern Ireland and India. We collect quantitative Likert ratings and qualitative comments from 1211 students on their awareness and perceptions of AI and investigate variations in attitudes toward AI across institutions and subject areas, as well as interactions between these variables with demographic variables (focusing on gender). We found the following: (a) while perceptions varied across institutions, responses for Computer Sciences students were similar, both in terms of topics and degree of positivity; and (b) after controlling for institution and subject area, we observed no effect of gender. These results are consistent with previous studies, which find that students' perceptions are predicted by prior experience; crucially, however, the results of this study contribute to the literature by identifying important interactions between key factors that can influence experience, revealing a more nuanced picture of students' perceptions and the role of experience. We consider the implications of these relations, and further considerations for the role of experience.
>
---
#### [replaced 006] The Effect of Warm-Glow on User Behavioral Intention to Adopt Technology: Extending the UTAUT2 Model
- **分类: cs.HC; cs.CY**

- **链接: [http://arxiv.org/pdf/2210.01242v3](http://arxiv.org/pdf/2210.01242v3)**

> **作者:** Antonios Saravanos; Neil Stott; Dongnanzi Zheng; Stavros Zervoudakis
>
> **摘要:** In this study, we enhance the Unified Theory of Acceptance and Use of Technology (UTAUT2) by incorporating the warm-glow phenomenon to clarify its impact on user decisions regarding the adoption of technology. We introduce two additional constructs aimed at capturing both the external and internal aspects of warm-glow, thus creating what we refer to as the UTAUT2 + WG model. To evaluate the effectiveness of our model, we conducted an experimental study in which participants were presented with a scenario describing a hypothetical technology designed to evoke warm-glow sensations. Using the partial least squares method, we analyzed the collected data to assess our expanded model. Our findings indicate that warm-glow significantly influences user behavior, with the internal aspect having the strongest influence, followed by hedonic motivation, performance expectancy, and finally the external aspect of warm-glow. We conclude by discussing the implications of our research, acknowledging its limitations, and suggesting directions for future exploration.
>
---
#### [replaced 007] Two Means to an End Goal: Connecting Explainability and Contestability in the Regulation of Public Sector AI
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2504.18236v3](http://arxiv.org/pdf/2504.18236v3)**

> **作者:** Timothée Schmude; Mireia Yurrita; Kars Alfrink; Thomas Le Goff; Sebastian Tschiatschek; Tiphaine Viard
>
> **备注:** 19 pages main text, 4 figures. Supplementary material is provided
>
> **摘要:** Explainability and its emerging counterpart contestability have become important normative and design principles for trustworthy AI as they enable users and subjects to understand and challenge AI decisions. However, realizing these principles is difficult, as they assume different meanings in technical, legal, and organizational dimensions of AI regulation. To resolve this conceptual polysemy, in this paper, we present the findings of an interview study with 14 experts to examine the intersection and implementation of explainability and contestability, and their understanding in different research communities. We outline differentiations between descriptive and normative explainability, judicial and non-judicial channels of contestation, and individual and collective contestation action. We further describe the main points of friction in the realization of both principles, including the alignment between top-down and bottom-up regulation, the assignment of responsibility, and the need for interdisciplinary collaboration. Lastly, we formulate three recommendations for AI policy to implement both principles through a Regulation by Design perspective. We believe our contributions can inform policy-making and regulation of these core principles and enable more effective and equitable design, development, and deployment of trustworthy public AI systems.
>
---
#### [replaced 008] Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference
- **分类: cs.CY; cs.AI; cs.CL**

- **链接: [http://arxiv.org/pdf/2508.04586v3](http://arxiv.org/pdf/2508.04586v3)**

> **作者:** Nuo Chen; Moming Duan; Andre Huikai Lin; Qian Wang; Jiaying Wu; Bingsheng He
>
> **备注:** Preprint
>
> **摘要:** Artificial Intelligence (AI) conferences are essential for advancing research, sharing knowledge, and fostering academic community. However, their rapid expansion has rendered the centralized conference model increasingly unsustainable. This paper offers a data-driven diagnosis of a structural crisis that threatens the foundational goals of scientific dissemination, equity, and community well-being. We identify four key areas of strain: (1) scientifically, with per-author publication rates more than doubling over the past decade to over 4.5 papers annually; (2) environmentally, with the carbon footprint of a single conference exceeding the daily emissions of its host city; (3) psychologically, with 71% of online community discourse reflecting negative sentiment and 35% referencing mental health concerns; and (4) logistically, with attendance at top conferences such as NeurIPS 2024 beginning to outpace venue capacity. These pressures point to a system that is misaligned with its core mission. In response, we propose the Community-Federated Conference (CFC) model, which separates peer review, presentation, and networking into globally coordinated but locally organized components, offering a more sustainable, inclusive, and resilient path forward for AI research.
>
---
#### [replaced 009] Robustness tests for biomedical foundation models should tailor to specifications
- **分类: cs.SE; cs.CY**

- **链接: [http://arxiv.org/pdf/2502.10374v3](http://arxiv.org/pdf/2502.10374v3)**

> **作者:** R. Patrick Xian; Noah R. Baker; Tom David; Qiming Cui; A. Jay Holmgren; Stefan Bauer; Madhumita Sushil; Reza Abbasi-Asl
>
> **备注:** 17 pages, accepted version with SI, repo at https://github.com/RealPolitiX/bfm-robust
>
> **摘要:** The rise of biomedical foundation models creates new hurdles in model testing and authorization, given their broad capabilities and susceptibility to complex distribution shifts. We suggest tailoring robustness tests according to task-dependent priorities and propose to integrate granular notions of robustness in a predefined specification to guide implementation. Our approach facilitates the standardization of robustness assessments in the model lifecycle and connects abstract AI regulatory frameworks with concrete testing procedures.
>
---
