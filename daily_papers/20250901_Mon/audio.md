# 音频 cs.SD;  eess.SP

- **最新发布 7 篇**

- **更新 6 篇**

## 最新发布

#### [new 001] Full-Frequency Temporal Patching and Structured Masking for Enhanced Audio Classification
- **分类: cs.SD; cs.AI**

- **简介: 该论文针对音频分类中现有块分割方法导致效率低下的问题，提出Full-Frequency Temporal Patching（FFTP）和SpecMask，优化时间-频率分割与掩码策略，提升性能并减少计算量。**

- **链接: [http://arxiv.org/pdf/2508.21243v1](http://arxiv.org/pdf/2508.21243v1)**

> **作者:** Aditya Makineni; Baocheng Geng; Qing Tian
>
> **摘要:** Transformers and State-Space Models (SSMs) have advanced audio classification by modeling spectrograms as sequences of patches. However, existing models such as the Audio Spectrogram Transformer (AST) and Audio Mamba (AuM) adopt square patching from computer vision, which disrupts continuous frequency patterns and produces an excessive number of patches, slowing training, and increasing computation. We propose Full-Frequency Temporal Patching (FFTP), a patching strategy that better matches the time-frequency asymmetry of spectrograms by spanning full frequency bands with localized temporal context, preserving harmonic structure, and significantly reducing patch count and computation. We also introduce SpecMask, a patch-aligned spectrogram augmentation that combines full-frequency and localized time-frequency masks under a fixed masking budget, enhancing temporal robustness while preserving spectral continuity. When applied on both AST and AuM, our patching method with SpecMask improves mAP by up to +6.76 on AudioSet-18k and accuracy by up to +8.46 on SpeechCommandsV2, while reducing computation by up to 83.26%, demonstrating both performance and efficiency gains.
>
---
#### [new 002] DRASP: A Dual-Resolution Attentive Statistics Pooling Framework for Automatic MOS Prediction
- **分类: cs.SD; cs.AI**

- **简介: 该论文提出DRASP框架，解决自动MOS预测中单一粒度池化忽视感知细节的问题。通过融合粗粒度全局统计与细粒度注意力分析，实现对语音质量的更全面建模，显著提升预测性能。**

- **链接: [http://arxiv.org/pdf/2508.21407v1](http://arxiv.org/pdf/2508.21407v1)**

> **作者:** Cheng-Yeh Yang; Kuan-Tang Huang; Chien-Chun Wang; Hung-Shin Lee; Hsin-Min Wang; Berlin Chen
>
> **备注:** Accepted to APSIPA ASC 2025
>
> **摘要:** A pooling mechanism is essential for mean opinion score (MOS) prediction, facilitating the transformation of variable-length audio features into a concise fixed-size representation that effectively encodes speech quality. Existing pooling methods typically operate at a singular granularity, concentrating either on a comprehensive global perspective or a detailed frame-level analysis, which may overlook complementary perceptual insights. To address this limitation, we introduce the Dual-Resolution Attentive Statistics Pooling (DRASP) framework. DRASP integrates both coarse-grained, global statistical summaries and fine-grained, attentive analyses of perceptually significant segments. This dual-view architecture empowers our model to formulate a more thorough and robust representation, capturing both the overarching structural context and salient local details concurrently. Extensive experiments validate the effectiveness and strong generalization ability of the proposed framework. It consistently outperforms various baseline methods across diverse datasets (MusicEval and AES-Natural), MOS prediction backbones (including a CLAP-based model and AudioBox-Aesthetics), and different audio generation systems, achieving a relative improvement of 10.39% in system-level Spearman's rank correlation coefficient (SRCC) over the widely-used average pooling approach.
>
---
#### [new 003] RARR : Robust Real-World Activity Recognition with Vibration by Scavenging Near-Surface Audio Online
- **分类: cs.SD; cs.LG; I.5.4**

- **简介: 该论文提出RARR框架，通过合成近表面音频数据预训练模型，结合少量数据微调，解决真实环境中隐私保护、活动识别及模型泛化问题，实现鲁棒的日常活动跟踪。**

- **链接: [http://arxiv.org/pdf/2508.21167v1](http://arxiv.org/pdf/2508.21167v1)**

> **作者:** Dong Yoon Lee; Alyssa Weakley; Hui Wei; Blake Brown; Keyana Carrion; Shijia Pan
>
> **摘要:** One in four people dementia live alone, leading family members to take on caregiving roles from a distance. Many researchers have developed remote monitoring solutions to lessen caregiving needs; however, limitations remain including privacy preserving solutions, activity recognition, and model generalizability to new users and environments. Structural vibration sensor systems are unobtrusive solutions that have been proven to accurately monitor human information, such as identification and activity recognition, in controlled settings by sensing surface vibrations generated by activities. However, when deploying in an end user's home, current solutions require a substantial amount of labeled data for accurate activity recognition. Our scalable solution adapts synthesized data from near-surface acoustic audio to pretrain a model and allows fine tuning with very limited data in order to create a robust framework for daily routine tracking.
>
---
#### [new 004] WaveLLDM: Design and Development of a Lightweight Latent Diffusion Model for Speech Enhancement and Restoration
- **分类: cs.SD; cs.AI; eess.AS**

- **简介: 该论文提出WaveLLDM，一种轻量级潜在扩散模型，用于语音增强与修复。针对传统方法计算成本高、处理长缺失段困难的问题，通过集成高效神经音频编解码器与潜在扩散框架，在压缩空间处理音频，降低复杂度并保持重建质量。**

- **链接: [http://arxiv.org/pdf/2508.21153v1](http://arxiv.org/pdf/2508.21153v1)**

> **作者:** Kevin Putra Santoso; Rizka Wakhidatus Sholikah; Raden Venantius Hari Ginardi
>
> **摘要:** High-quality audio is essential in a wide range of applications, including online communication, virtual assistants, and the multimedia industry. However, degradation caused by noise, compression, and transmission artifacts remains a major challenge. While diffusion models have proven effective for audio restoration, they typically require significant computational resources and struggle to handle longer missing segments. This study introduces WaveLLDM (Wave Lightweight Latent Diffusion Model), an architecture that integrates an efficient neural audio codec with latent diffusion for audio restoration and denoising. Unlike conventional approaches that operate in the time or spectral domain, WaveLLDM processes audio in a compressed latent space, reducing computational complexity while preserving reconstruction quality. Empirical evaluations on the Voicebank+DEMAND test set demonstrate that WaveLLDM achieves accurate spectral reconstruction with low Log-Spectral Distance (LSD) scores (0.48 to 0.60) and good adaptability to unseen data. However, it still underperforms compared to state-of-the-art methods in terms of perceptual quality and speech clarity, with WB-PESQ scores ranging from 1.62 to 1.71 and STOI scores between 0.76 and 0.78. These limitations are attributed to suboptimal architectural tuning, the absence of fine-tuning, and insufficient training duration. Nevertheless, the flexible architecture that combines a neural audio codec and latent diffusion model provides a strong foundation for future development.
>
---
#### [new 005] Zero-Shot KWS for Children's Speech using Layer-Wise Features from SSL Models
- **分类: eess.AS; cs.AI; cs.HC; cs.SD; eess.SP**

- **简介: 该论文提出基于SSL模型层特征的零样本KWS方法，解决儿童语音声学与语言差异问题，通过多模型实验和噪声测试提升检测性能。**

- **链接: [http://arxiv.org/pdf/2508.21248v1](http://arxiv.org/pdf/2508.21248v1)**

> **作者:** Subham Kutum; Abhijit Sinha; Hemant Kumar Kathania; Sudarsana Reddy Kadiri; Mahesh Chandra Govil
>
> **备注:** Accepted
>
> **摘要:** Numerous methods have been proposed to enhance Keyword Spotting (KWS) in adult speech, but children's speech presents unique challenges for KWS systems due to its distinct acoustic and linguistic characteristics. This paper introduces a zero-shot KWS approach that leverages state-of-the-art self-supervised learning (SSL) models, including Wav2Vec2, HuBERT and Data2Vec. Features are extracted layer-wise from these SSL models and used to train a Kaldi-based DNN KWS system. The WSJCAM0 adult speech dataset was used for training, while the PFSTAR children's speech dataset was used for testing, demonstrating the zero-shot capability of our method. Our approach achieved state-of-the-art results across all keyword sets for children's speech. Notably, the Wav2Vec2 model, particularly layer 22, performed the best, delivering an ATWV score of 0.691, a MTWV score of 0.7003 and probability of false alarm and probability of miss of 0.0164 and 0.0547 respectively, for a set of 30 keywords. Furthermore, age-specific performance evaluation confirmed the system's effectiveness across different age groups of children. To assess the system's robustness against noise, additional experiments were conducted using the best-performing layer of the best-performing Wav2Vec2 model. The results demonstrated a significant improvement over traditional MFCC-based baseline, emphasizing the potential of SSL embeddings even in noisy conditions. To further generalize the KWS framework, the experiments were repeated for an additional CMU dataset. Overall the results highlight the significant contribution of SSL features in enhancing Zero-Shot KWS performance for children's speech, effectively addressing the challenges associated with the distinct characteristics of child speakers.
>
---
#### [new 006] Remarks on stochastic cloning and delayed-state filtering
- **分类: cs.RO; eess.SP; math.ST; stat.TH**

- **简介: 该论文针对机器人导航中的延迟状态测量问题，比较随机克隆与延迟卡尔曼滤波器，证明后者无需状态增强即可实现相同估计效果，提升计算效率和内存使用。**

- **链接: [http://arxiv.org/pdf/2508.21260v1](http://arxiv.org/pdf/2508.21260v1)**

> **作者:** Tara Mina; Lindsey Marinello; John Christian
>
> **摘要:** Many estimation problems in robotics and navigation involve measurements that depend on prior states. A prominent example is odometry, which measures the relative change between states over time. Accurately handling these delayed-state measurements requires capturing their correlations with prior state estimates, and a widely used approach is stochastic cloning (SC), which augments the state vector to account for these correlations. This work revisits a long-established but often overlooked alternative--the delayed-state Kalman filter--and demonstrates that a properly derived filter yields exactly the same state and covariance update as SC, without requiring state augmentation. Moreover, the generalized Kalman filter formulation provides computational advantages, while also reducing memory requirements for higher-dimensional states. Our findings clarify a common misconception that Kalman filter variants are inherently unable to handle correlated delayed-state measurements, demonstrating that an alternative formulation achieves the same results more efficiently.
>
---
#### [new 007] Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?
- **分类: eess.AS; cs.AI; cs.LG; cs.SD; eess.SP**

- **简介: 该论文研究利用SSL模型的层特征提升儿童语音零样本ASR性能。通过分析Wav2Vec2等模型的层特征，发现第22层在WSJCAM0训练下，PFSTAR测试中实现5.15% WER，较直接解码提升51.64%。结果在CMU Kids数据集上验证，显示方法对不同年龄段儿童有效。**

- **链接: [http://arxiv.org/pdf/2508.21225v1](http://arxiv.org/pdf/2508.21225v1)**

> **作者:** Abhijit Sinha; Hemant Kumar Kathania; Sudarsana Reddy Kadiri; Shrikanth Narayanan
>
> **备注:** Accepted
>
> **摘要:** Automatic Speech Recognition (ASR) systems often struggle to accurately process children's speech due to its distinct and highly variable acoustic and linguistic characteristics. While recent advancements in self-supervised learning (SSL) models have greatly enhanced the transcription of adult speech, accurately transcribing children's speech remains a significant challenge. This study investigates the effectiveness of layer-wise features extracted from state-of-the-art SSL pre-trained models - specifically, Wav2Vec2, HuBERT, Data2Vec, and WavLM in improving the performance of ASR for children's speech in zero-shot scenarios. A detailed analysis of features extracted from these models was conducted, integrating them into a simplified DNN-based ASR system using the Kaldi toolkit. The analysis identified the most effective layers for enhancing ASR performance on children's speech in a zero-shot scenario, where WSJCAM0 adult speech was used for training and PFSTAR children speech for testing. Experimental results indicated that Layer 22 of the Wav2Vec2 model achieved the lowest Word Error Rate (WER) of 5.15%, representing a 51.64% relative improvement over the direct zero-shot decoding using Wav2Vec2 (WER of 10.65%). Additionally, age group-wise analysis demonstrated consistent performance improvements with increasing age, along with significant gains observed even in younger age groups using the SSL features. Further experiments on the CMU Kids dataset confirmed similar trends, highlighting the generalizability of the proposed approach.
>
---
## 更新

#### [replaced 001] Spatio-spectral diarization of meetings by combining TDOA-based segmentation and speaker embedding-based clustering
- **分类: eess.AS; cs.SD**

- **链接: [http://arxiv.org/pdf/2506.16228v2](http://arxiv.org/pdf/2506.16228v2)**

> **作者:** Tobias Cord-Landwehr; Tobias Gburrek; Marc Deegen; Reinhold Haeb-Umbach
>
> **备注:** Proceedings of INTERSPEECH
>
> **摘要:** We propose a spatio-spectral, combined model-based and data-driven diarization pipeline consisting of TDOA-based segmentation followed by embedding-based clustering. The proposed system requires neither access to multi-channel training data nor prior knowledge about the number or placement of microphones. It works for both a compact microphone array and distributed microphones, with minor adjustments. Due to its superior handling of overlapping speech during segmentation, the proposed pipeline significantly outperforms the single-channel pyannote approach, both in a scenario with a compact microphone array and in a setup with distributed microphones. Additionally, we show that, unlike fully spatial diarization pipelines, the proposed system can correctly track speakers when they change positions.
>
---
#### [replaced 002] Efficient Sparse Coding with the Adaptive Locally Competitive Algorithm for Speech Classification
- **分类: eess.AS; cs.SD**

- **链接: [http://arxiv.org/pdf/2409.08188v4](http://arxiv.org/pdf/2409.08188v4)**

> **作者:** Soufiyan Bahadi; Eric Plourde; Jean Rouat
>
> **备注:** Internal technical report, Department of Electrical Engineering, University of Sherbrooke
>
> **摘要:** Researchers are exploring novel computational paradigms such as sparse coding and neuromorphic computing to bridge the efficiency gap between the human brain and conventional computers in complex tasks. A key area of focus is neuromorphic audio processing. While the Locally Competitive Algorithm has emerged as a promising solution for sparse coding, offering potential for real-time and low-power processing on neuromorphic hardware, its applications in neuromorphic speech classification have not been thoroughly studied. The Adaptive Locally Competitive Algorithm builds upon the Locally Competitive Algorithm by dynamically adjusting the modulation parameters of the filter bank to fine-tune the filters' sensitivity. This adaptability enhances lateral inhibition, improving reconstruction quality, sparsity, and convergence time, which is crucial for real-time applications. This paper demonstrates the potential of the Locally Competitive Algorithm and its adaptive variant as robust feature extractors for neuromorphic speech classification. Results show that the Locally Competitive Algorithm achieves better speech classification accuracy at the expense of higher power consumption compared to the LAUSCHER cochlea model used for benchmarking. On the other hand, the Adaptive Locally Competitive Algorithm mitigates this power consumption issue without compromising the accuracy. The dynamic power consumption is reduced to a range of 4 to 13 milliwatts on neuromorphic hardware, three orders of magnitude less than setups using Graphics Processing Units. These findings position the Adaptive Locally Competitive Algorithm as a compelling solution for efficient speech classification systems, promising substantial advancements in balancing speech classification accuracy and power efficiency.
>
---
#### [replaced 003] Robust Localization of Partially Fake Speech: Metrics and Out-of-Domain Evaluation
- **分类: cs.SD; eess.AS**

- **链接: [http://arxiv.org/pdf/2507.03468v3](http://arxiv.org/pdf/2507.03468v3)**

> **作者:** Hieu-Thi Luong; Inbal Rimon; Haim Permuter; Kong Aik Lee; Eng Siong Chng
>
> **备注:** APSIPA 2025
>
> **摘要:** Partial audio deepfake localization poses unique challenges and remain underexplored compared to full-utterance spoofing detection. While recent methods report strong in-domain performance, their real-world utility remains unclear. In this analysis, we critically examine the limitations of current evaluation practices, particularly the widespread use of Equal Error Rate (EER), which often obscures generalization and deployment readiness. We propose reframing the localization task as a sequential anomaly detection problem and advocate for the use of threshold-dependent metrics such as accuracy, precision, recall, and F1-score, which better reflect real-world behavior. Specifically, we analyze the performance of the open-source Coarse-to-Fine Proposal Refinement Framework (CFPRF), which achieves a 20-ms EER of 7.61% on the in-domain PartialSpoof evaluation set, but 43.25% and 27.59% on the LlamaPartialSpoof and Half-Truth out-of-domain test sets. Interestingly, our reproduced version of the same model performs worse on in-domain data (9.84%) but better on the out-of-domain sets (41.72% and 14.98%, respectively). This highlights the risks of over-optimizing for in-domain EER, which can lead to models that perform poorly in real-world scenarios. It also suggests that while deep learning models can be effective on in-domain data, they generalize poorly to out-of-domain scenarios, failing to detect novel synthetic samples and misclassifying unfamiliar bona fide audio. Finally, we observe that adding more bona fide or fully synthetic utterances to the training data often degrades performance, whereas adding partially fake utterances improves it.
>
---
#### [replaced 004] Adaptive Central Frequencies Locally Competitive Algorithm for Speech
- **分类: cs.SD; eess.AS**

- **链接: [http://arxiv.org/pdf/2502.06989v2](http://arxiv.org/pdf/2502.06989v2)**

> **作者:** Soufiyan Bahadi; Eric Plourde; Jean Rouat
>
> **备注:** This is the preprint version of the paper accepted at IEEE ICASSP 2025. The final published version is available at IEEE Xplore: https://doi.org/10.1109/ICASSP49660.2025.10887648
>
> **摘要:** Neuromorphic computing, inspired by nervous systems, revolutionizes information processing with its focus on efficiency and low power consumption. Using sparse coding, this paradigm enhances processing efficiency, which is crucial for edge devices with power constraints. The Locally Competitive Algorithm (LCA), adapted for audio with Gammatone and Gammachirp filter banks, provides an efficient sparse coding method for neuromorphic speech processing. Adaptive LCA (ALCA) further refines this method by dynamically adjusting modulation parameters, thereby improving reconstruction quality and sparsity. This paper introduces an enhanced ALCA version, the ALCA Central Frequency (ALCA-CF), which dynamically adapts both modulation parameters and central frequencies, optimizing the speech representation. Evaluations show that this approach improves reconstruction quality and sparsity while significantly reducing the power consumption of speech classification, without compromising classification accuracy, particularly on Intel's Loihi 2 neuromorphic chip.
>
---
#### [replaced 005] mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar
- **分类: eess.SP; cs.CV**

- **链接: [http://arxiv.org/pdf/2507.07331v2](http://arxiv.org/pdf/2507.07331v2)**

> **作者:** Anurag Pallaprolu; Winston Hurst; Yasamin Mostofi
>
> **摘要:** In this paper, we present mmFlux: a novel framework for extracting underlying crowd motion patterns and inferring crowd semantics using mmWave radar. First, our proposed signal processing pipeline combines optical flow estimation concepts from vision with novel statistical and morphological noise filtering. This approach generates high-fidelity mmWave flow fields-compact 2D vector representations of crowd motion. We then introduce a novel approach that transforms these fields into directed geometric graphs. In these graphs, edges capture dominant flow currents, vertices mark crowd splitting or merging, and flow distribution is quantified across edges. Finally, we show that analyzing the local Jacobian and computing the corresponding curl and divergence enables extraction of key crowd semantics for both structured and diffused crowds. We conduct 21 experiments on crowds of up to 20 people across 3 areas, using commodity mmWave radar. Our framework achieves high-fidelity graph reconstruction of the underlying flow structure, even for complex crowd patterns, demonstrating strong spatial alignment and precise quantitative characterization of flow split ratios. Finally, our curl and divergence analysis accurately infers key crowd semantics, e.g., abrupt turns, boundaries where flow directions shift, dispersions, and gatherings. Overall, these findings validate mmFlux, underscoring its potential for various crowd analytics applications.
>
---
#### [replaced 006] Adaptive Duration Model for Text Speech Alignment
- **分类: cs.SD; cs.AI; eess.AS**

- **链接: [http://arxiv.org/pdf/2507.22612v2](http://arxiv.org/pdf/2507.22612v2)**

> **作者:** Junjie Cao
>
> **备注:** 4 pages
>
> **摘要:** Speech-to-text alignment is a critical component of neural text to speech (TTS) models. Autoregressive TTS models typically use an attention mechanism to learn these alignments on-line, while non-autoregressive end to end TTS models rely on durations extracted from external sources. In this paper, we propose a novel duration prediction framework that can give promising phoneme-level duration distribution with given text. In our experiments, the proposed duration model has more precise prediction and adaptation ability to conditions, compared to previous baseline models. Specifically, it makes a considerable improvement on phoneme-level alignment accuracy and makes the performance of zero-shot TTS models more robust to the mismatch between prompt audio and input audio.
>
---
