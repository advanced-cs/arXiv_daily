# 计算机与社会 cs.CY

- **最新发布 8 篇**

- **更新 6 篇**

## 最新发布

#### [new 001] Catching Dark Signals in Algorithms: Unveiling Audiovisual and Thematic Markers of Unsafe Content Recommended for Children and Teenagers
- **分类: cs.CY; cs.MM**

- **简介: 该论文属于内容安全任务，旨在解决儿童和青少年接触有害内容的问题。通过分析推荐视频的视觉和主题特征，识别潜在风险并提出在线伤害框架。**

- **链接: [http://arxiv.org/pdf/2507.12571v1](http://arxiv.org/pdf/2507.12571v1)**

> **作者:** Haoning Xue; Brian Nishimine; Martin Hilbert; Drew Cingel; Samantha Vigil; Jane Shawcroft; Arti Thakur; Zubair Shafiq; Jingwen Zhang
>
> **摘要:** The prevalence of short form video platforms, combined with the ineffectiveness of age verification mechanisms, raises concerns about the potential harms facing children and teenagers in an algorithm-moderated online environment. We conducted multimodal feature analysis and thematic topic modeling of 4,492 short videos recommended to children and teenagers on Instagram Reels, TikTok, and YouTube Shorts, collected as a part of an algorithm auditing experiment. This feature-level and content-level analysis revealed that unsafe (i.e., problematic, mentally distressing) short videos (a) possess darker visual features and (b) contain explicitly harmful content and implicit harm from anxiety-inducing ordinary content. We introduce a useful framework of online harm (i.e., explicit, implicit, unintended), providing a unique lens for understanding the dynamic, multifaceted online risks facing children and teenagers. The findings highlight the importance of protecting younger audiences in critical developmental stages from both explicit and implicit risks on social media, calling for nuanced content moderation, age verification, and platform regulation.
>
---
#### [new 002] The Case for Contextual Copyleft: Licensing Open Source Training Data and Generative AI
- **分类: cs.CY; cs.SE**

- **简介: 该论文属于AI与开源软件结合的研究任务，旨在解决传统开源许可在AI训练数据中的适用性问题，提出CCAI许可证以增强开发者控制并促进负责任的AI发展。**

- **链接: [http://arxiv.org/pdf/2507.12713v1](http://arxiv.org/pdf/2507.12713v1)**

> **作者:** Grant Shanklin; Emmie Hine; Claudio Novelli; Tyler Schroder; Luciano Floridi
>
> **备注:** 19 pages
>
> **摘要:** The proliferation of generative AI systems has created new challenges for the Free and Open Source Software (FOSS) community, particularly regarding how traditional copyleft principles should apply when open source code is used to train AI models. This article introduces the Contextual Copyleft AI (CCAI) license, a novel licensing mechanism that extends copyleft requirements from training data to the resulting generative AI models. The CCAI license offers significant advantages, including enhanced developer control, incentivization of open source AI development, and mitigation of openwashing practices. This is demonstrated through a structured three-part evaluation framework that examines (1) legal feasibility under current copyright law, (2) policy justification comparing traditional software and AI contexts, and (3) synthesis of cross-contextual benefits and risks. However, the increased risk profile of open source AI, particularly the potential for direct misuse, necessitates complementary regulatory approaches to achieve an appropriate risk-benefit balance. The paper concludes that when implemented within a robust regulatory environment focused on responsible AI usage, the CCAI license provides a viable mechanism for preserving and adapting core FOSS principles to the evolving landscape of generative AI development.
>
---
#### [new 003] The Goldilocks zone of governing technology: Leveraging uncertainty for responsible quantum practices
- **分类: cs.CY**

- **简介: 论文属于科技治理研究，旨在解决量子技术不确定性带来的治理难题。提出基于概率的治理框架与量子风险模拟器，探索灵活负责任的技术监管路径。**

- **链接: [http://arxiv.org/pdf/2507.12957v1](http://arxiv.org/pdf/2507.12957v1)**

> **作者:** Miriam Meckel; Philipp Hacker; Lea Steinacker; Aurelija Lukoseviciene; Surjo R. Soekadar; Jacob Slosser; Gina-Maria Poehlmann
>
> **备注:** Paper is accepted and will be published
>
> **摘要:** Emerging technologies challenge conventional governance approaches, especially when uncertainty is not a temporary obstacle but a foundational feature as in quantum computing. This paper reframes uncertainty from a governance liability to a generative force, using the paradigms of quantum mechanics to propose adaptive, probabilistic frameworks for responsible innovation. We identify three interdependent layers of uncertainty--physical, technical, and societal--central to the evolution of quantum technologies. The proposed Quantum Risk Simulator (QRS) serves as a conceptual example, an imaginative blueprint rather than a prescriptive tool, meant to illustrate how probabilistic reasoning could guide dynamic, uncertainty-based governance. By foregrounding epistemic and ontological ambiguity, and drawing analogies from cognitive neuroscience and predictive processing, we suggest a new model of governance aligned with the probabilistic essence of quantum systems. This model, we argue, is especially promising for the European Union as a third way between laissez-faire innovation and state-led control, offering a flexible yet responsible pathway for regulating quantum and other frontier technologies.
>
---
#### [new 004] Quantifying the Improvement of Accessibility achieved via Shared Mobility on Demand
- **分类: cs.CY; econ.GN; q-fin.EC**

- **简介: 该论文属于交通规划任务，旨在量化共享出行对可达性的影响。解决如何用等时线指标评估共享出行提升的可达性问题，提出基于克里金法的空间时间分析方法。**

- **链接: [http://arxiv.org/pdf/2507.13100v1](http://arxiv.org/pdf/2507.13100v1)**

> **作者:** Severin Diepolder; Andrea Araldo; Tarek Chouaki; Santa Maiti; Sebastian Hörl; Constantinos Antoniou
>
> **摘要:** Shared Mobility Services (SMS), e.g., demand-responsive transport or ride-sharing, can improve mobility in low-density areas, which are often poorly served by conventional Public Transport (PT). Such improvement is generally measured via basic performance indicators, such as waiting or travel time. However, such basic indicators do not account for the most important contribution that SMS can provide to territories, i.e., increasing the potential, for users, to reach surrounding opportunities, such as jobs, schools, businesses, etc. Such potential can be measured by isochrone-based accessibility indicators, which count the number of opportunities reachable in a limited time, and are thus easy for the public to understand. % The potential impact of SMS on accessibility has been qualitatively discussed and implications on equity have been empirically studied. However, to date, there are no quantitative methods to compute isochrone-based indicators of the accessibility achieved via SMS. This work fills this gap by proposing a first method to compute isochrone accessibility of PT systems composed of conventional PT and SMS, acting as a feeder for access and egress trips to/from PT hubs. This method is grounded on spatial-temporal statistical analysis, performed via Kriging. It takes as input observed trips of SMS and summarizes them in a graph. On such a graph, isochrone accessibility indicators are computed. We apply the proposed method to a MATSim simulation study concerning demand-responsive transport integrated into PT, in the suburban area of Paris-Saclay.
>
---
#### [new 005] Bridging Boundaries: How to Foster Effective Research Collaborations Across Affiliations in the Field of Trust and Safety
- **分类: cs.CY; cs.HC; J.4; K.4.1; K.4.2**

- **简介: 该论文属于跨领域协作研究任务，旨在解决不同机构间合作难题。通过分析差异并提出协作框架，促进信任与安全领域的有效合作。**

- **链接: [http://arxiv.org/pdf/2507.13008v1](http://arxiv.org/pdf/2507.13008v1)**

> **作者:** Amanda Menking; Mona Elswah; David J. Grüning; Lasse H. Hansen; Irene Huang; Julia Kamin; Catrine Normann
>
> **备注:** 19 pages, no figures
>
> **摘要:** As the field of Trust and Safety in digital spaces continues to grow, it has become increasingly necessary - but also increasingly complex - to collaborate on research across the academic, industry, governmental and non-governmental sectors. This paper examines how cross-affiliation research partnerships can be structured to overcome misaligned incentives, timelines and constraints while delivering on the unique strengths of each stakeholder. Drawing on our own experience of cross-sector collaboration, we define the main types of affiliation and highlight the common differences in research priorities, operational pressures and evaluation metrics across sectors. We then propose a practical, step-by-step framework for initiating and managing effective collaborations, including strategies for building trust, aligning goals, and distributing roles. We emphasize the critical yet often invisible work of articulation and argue that cross-sector partnerships are essential for developing more ethical, equitable and impactful research in trust and safety. Ultimately, we advocate collaborative models that prioritize inclusivity, transparency and real-world relevance in order to meet the interdisciplinary demands of this emerging field.
>
---
#### [new 006] Rookie Mistakes: Measuring Software Quality in Student Projects to Guide Educational Enhancement
- **分类: cs.CY; cs.SE**

- **简介: 该论文属于软件质量评估任务，旨在解决学生项目中软件质量关注不足的问题。通过分析83个团队项目，识别常见质量问题，为教学改进提供依据。**

- **链接: [http://arxiv.org/pdf/2507.12488v1](http://arxiv.org/pdf/2507.12488v1)**

> **作者:** Marco De Luca; Sergio Di Martino; Sergio Di Meglio; Anna Rita Fasolino; Luigi Libero Lucio Starace; Porfirio Tramontana
>
> **备注:** Manuscript accepted for the 51st Euromicro Conference Series on Software Engineering and Advanced Applications (SEAA)
>
> **摘要:** When teaching Programming and Software Engineering in Bachelor's Degree programs, the emphasis on creating functional software projects often overshadows the focus on software quality, a trend that aligns with ACM curricula recommendations. Software Engineering courses are typically introduced later in the curriculum, and can generally allocate only limited time to quality-related topics, leaving educators with the challenge of deciding which quality aspects to prioritize. In this decision, the literature offers limited guidance, as most existing studies focus on code written by novice students and small code units, making it unclear whether those findings extend to intermediate-level students with foundational object-oriented programming skills working on more complex software projects. To address this gap, we analyze 83 object-oriented team projects developed by 172 university students across 4 different editions of the Object-Oriented Programming course. We apply a static analysis pipeline used in prior research to assess software quality, combining SonarQube and ArchUnit to detect code smells and architectural anti-patterns. Our findings highlight recurring quality issues and offer concrete evidence of the challenges students face at this stage, providing valuable guidance for educators aiming to continuously improve Software Engineering curricula and promote quality-oriented development practices.
>
---
#### [new 007] ParaStudent: Generating and Evaluating Realistic Student Code by Teaching LLMs to Struggle
- **分类: cs.CY; cs.AI; cs.SE**

- **简介: 该论文属于编程任务，旨在生成类似真实学生的代码。通过微调LLM，研究学生代码的错误模式和风格变化，提升代码生成的真实性。**

- **链接: [http://arxiv.org/pdf/2507.12674v1](http://arxiv.org/pdf/2507.12674v1)**

> **作者:** Mihran Miroyan; Rose Niousha; Joseph E. Gonzalez; Gireeja Ranade; Narges Norouzi
>
> **摘要:** Large Language Models (LLMs) have shown strong performance on programming tasks, but can they generate student-like code like real students - imperfect, iterative, and stylistically diverse? We present ParaStudent, a systematic study of LLM-based "student-like" code generation in an introductory programming course setting. Using a dataset of timestamped student submissions across multiple semesters, we design low- and high-resolution experiments to model student progress and evaluate code outputs along semantic, functional, and stylistic dimensions. Our results show that fine-tuning significantly improves alignment with real student trajectories and captures error patterns, incremental improvements, and stylistic variations more faithfully. This study shows that modeling realistic student code requires capturing learning dynamics through context-aware generation, temporal modeling, and multi-dimensional evaluation. Code for experiments and evaluation is available at \href{https://github.com/mmiroyan/ParaStudent}{\texttt{github.com/mmiroyan/ParaStudent}}.
>
---
#### [new 008] Best Practices and Considerations for Child Speech Corpus Collection and Curation in Educational, Clinical, and Forensic Scenarios
- **分类: cs.SD; cs.CY; eess.AS**

- **简介: 该论文属于儿童语音语料库构建任务，解决如何在教育、临床和法医场景中有效收集和管理儿童语音数据的问题。工作包括提出最佳实践和操作指南。**

- **链接: [http://arxiv.org/pdf/2507.12870v1](http://arxiv.org/pdf/2507.12870v1)**

> **作者:** John Hansen; Satwik Dutta; Ellen Grand
>
> **备注:** 5 pages, 0 figures, accepted at the 10th Workshop on Speech and Language Technology in Education (SLaTE 2025), a Satellite Workshop of the 2025 Interspeech Conference
>
> **摘要:** A child's spoken ability continues to change until their adult age. Until 7-8yrs, their speech sound development and language structure evolve rapidly. This dynamic shift in their spoken communication skills and data privacy make it challenging to curate technology-ready speech corpora for children. This study aims to bridge this gap and provide researchers and practitioners with the best practices and considerations for developing such a corpus based on an intended goal. Although primarily focused on educational goals, applications of child speech data have spread across fields including clinical and forensics fields. Motivated by this goal, we describe the WHO, WHAT, WHEN, and WHERE of data collection inspired by prior collection efforts and our experience/knowledge. We also provide a guide to establish collaboration, trust, and for navigating the human subjects research protocol. This study concludes with guidelines for corpus quality check, triage, and annotation.
>
---
## 更新

#### [replaced 001] Prompt Perturbations Reveal Human-Like Biases in LLM Survey Responses
- **分类: cs.CL; cs.AI; cs.CY; J.4**

- **链接: [http://arxiv.org/pdf/2507.07188v2](http://arxiv.org/pdf/2507.07188v2)**

> **作者:** Jens Rupprecht; Georg Ahnert; Markus Strohmaier
>
> **备注:** 18 pages, 17 figures
>
> **摘要:** Large Language Models (LLMs) are increasingly used as proxies for human subjects in social science surveys, but their reliability and susceptibility to known response biases are poorly understood. This paper investigates the response robustness of LLMs in normative survey contexts - we test nine diverse LLMs on questions from the World Values Survey (WVS), applying a comprehensive set of 11 perturbations to both question phrasing and answer option structure, resulting in over 167,000 simulated interviews. In doing so, we not only reveal LLMs' vulnerabilities to perturbations but also show that all tested models exhibit a consistent recency bias varying in intensity, disproportionately favoring the last-presented answer option. While larger models are generally more robust, all models remain sensitive to semantic variations like paraphrasing and to combined perturbations. By applying a set of perturbations, we reveal that LLMs partially align with survey response biases identified in humans. This underscores the critical importance of prompt design and robustness testing when using LLMs to generate synthetic survey data.
>
---
#### [replaced 002] Revisiting the Berkeley Admissions data: Statistical Tests for Causal Hypotheses
- **分类: stat.ME; cs.CY; math.ST; stat.ML; stat.TH**

- **链接: [http://arxiv.org/pdf/2502.10161v2](http://arxiv.org/pdf/2502.10161v2)**

> **作者:** Sourbh Bhadane; Joris M. Mooij; Philip Boeken; Onno Zoeter
>
> **备注:** Accepted to UAI 2025
>
> **摘要:** Reasoning about fairness through correlation-based notions is rife with pitfalls. The 1973 University of California, Berkeley graduate school admissions case from Bickel et. al. (1975) is a classic example of one such pitfall, namely Simpson's paradox. The discrepancy in admission rates among males and female applicants, in the aggregate data over all departments, vanishes when admission rates per department are examined. We reason about the Berkeley graduate school admissions case through a causal lens. In the process, we introduce a statistical test for causal hypothesis testing based on Pearl's instrumental-variable inequalities (Pearl 1995). We compare different causal notions of fairness that are based on graphical, counterfactual and interventional queries on the causal model, and develop statistical tests for these notions that use only observational data. We study the logical relations between notions, and show that while notions may not be equivalent, their corresponding statistical tests coincide for the case at hand. We believe that a thorough case-based causal analysis helps develop a more principled understanding of both causal hypothesis testing and fairness.
>
---
#### [replaced 003] Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening
- **分类: cs.CY; cs.AI; cs.CL; I.2.1; K.4.2; I.2.6; K.4.1**

- **链接: [http://arxiv.org/pdf/2507.11548v2](http://arxiv.org/pdf/2507.11548v2)**

> **作者:** Kevin T Webster
>
> **备注:** 34 pages, 4 figures
>
> **摘要:** The increasing use of generative AI for resume screening is predicated on the assumption that it offers an unbiased alternative to biased human decision-making. However, this belief fails to address a critical question: are these AI systems fundamentally competent at the evaluative tasks they are meant to perform? This study investigates the question of competence through a two-part audit of eight major AI platforms. Experiment 1 confirmed complex, contextual racial and gender biases, with some models penalizing candidates merely for the presence of demographic signals. Experiment 2, which evaluated core competence, provided a critical insight: some models that appeared unbiased were, in fact, incapable of performing a substantive evaluation, relying instead on superficial keyword matching. This paper introduces the "Illusion of Neutrality" to describe this phenomenon, where an apparent lack of bias is merely a symptom of a model's inability to make meaningful judgments. This study recommends that organizations and regulators adopt a dual-validation framework, auditing AI hiring tools for both demographic bias and demonstrable competence to ensure they are both equitable and effective.
>
---
#### [replaced 004] AI Governance InternationaL Evaluation Index (AGILE Index) 2024
- **分类: cs.CY; cs.AI; 68T01; A.1**

- **链接: [http://arxiv.org/pdf/2502.15859v4](http://arxiv.org/pdf/2502.15859v4)**

> **作者:** Yi Zeng; Enmeng Lu; Xin Guan; Cunqing Huangfu; Zizhe Ruan; Ammar Younas; Kang Sun; Xuan Tang; Yuwei Wang; Hongjie Suo; Dongqi Liang; Zhengqiang Han; Aorigele Bao; Xiaoyang Guo; Jin Wang; Jiawei Xie; Yao Liang
>
> **备注:** Evaluation Report. 85 pages, 30 Figures
>
> **摘要:** The rapid advancement of Artificial Intelligence (AI) technology is profoundly transforming human society and concurrently presenting a series of ethical, legal, and social issues. The effective governance of AI has become a crucial global concern. Since 2022, the extensive deployment of generative AI, particularly large language models, marked a new phase in AI governance. Continuous efforts are being made by the international community in actively addressing the novel challenges posed by these AI developments. As consensus on international governance continues to be established and put into action, the practical importance of conducting a global assessment of the state of AI governance is progressively coming to light. In this context, we initiated the development of the AI Governance InternationaL Evaluation Index (AGILE Index). Adhering to the design principle, "the level of governance should match the level of development," the inaugural evaluation of the AGILE Index commences with an exploration of four foundational pillars: the development level of AI, the AI governance environment, the AI governance instruments, and the AI governance effectiveness. It covers 39 indicators across 18 dimensions to comprehensively assess the AI governance level of 14 representative countries globally. The index is utilized to delve into the status of AI governance to date in 14 countries for the first batch of evaluation. The aim is to depict the current state of AI governance in these countries through data scoring, assist them in identifying their governance stage and uncovering governance issues, and ultimately offer insights for the enhancement of their AI governance systems.
>
---
#### [replaced 005] Dataset resulting from the user study on comprehensibility of explainable AI algorithms
- **分类: cs.CY; cs.AI; cs.LG**

- **链接: [http://arxiv.org/pdf/2411.02419v2](http://arxiv.org/pdf/2411.02419v2)**

> **作者:** Szymon Bobek; Paloma Korycińska; Monika Krakowska; Maciej Mozolewski; Dorota Rak; Magdalena Zych; Magdalena Wójcik; Grzegorz J. Nalepa
>
> **摘要:** This paper introduces a dataset that is the result of a user study on the comprehensibility of explainable artificial intelligence (XAI) algorithms. The study participants were recruited from 149 candidates to form three groups representing experts in the domain of mycology (DE), students with a data science and visualization background (IT) and students from social sciences and humanities (SSH). The main part of the dataset contains 39 transcripts of interviews during which participants were asked to complete a series of tasks and questions related to the interpretation of explanations of decisions of a machine learning model trained to distinguish between edible and inedible mushrooms. The transcripts were complemented with additional data that includes visualizations of explanations presented to the user, results from thematic analysis, recommendations of improvements of explanations provided by the participants, and the initial survey results that allow to determine the domain knowledge of the participant and data analysis literacy. The transcripts were manually tagged to allow for automatic matching between the text and other data related to particular fragments. In the advent of the area of rapid development of XAI techniques, the need for a multidisciplinary qualitative evaluation of explainability is one of the emerging topics in the community. Our dataset allows not only to reproduce the study we conducted, but also to open a wide range of possibilities for the analysis of the material we gathered.
>
---
#### [replaced 006] DomainDemo: a dataset of domain-sharing activities among different demographic groups on Twitter
- **分类: cs.SI; cs.CY**

- **链接: [http://arxiv.org/pdf/2501.09035v2](http://arxiv.org/pdf/2501.09035v2)**

> **作者:** Kai-Cheng Yang; Pranav Goel; Alexi Quintana-Mathé; Luke Horgan; Stefan D. McCabe; Nir Grinberg; Kenneth Joseph; David Lazer
>
> **备注:** 24 pages, 3 figures
>
> **摘要:** Social media play a pivotal role in disseminating web content, particularly during elections, yet our understanding of the association between demographic factors and information sharing online remains limited. Here, we introduce a unique dataset, DomainDemo, linking domains shared on Twitter (X) with the demographic characteristics of associated users, including age, gender, race, political affiliation, and geolocation, from 2011 to 2022. This new resource was derived from a panel of over 1.5 million Twitter users matched against their U.S. voter registration records, facilitating a better understanding of a decade of information flows on one of the most prominent social media platforms and trends in political and public discourse among registered U.S. voters from different sociodemographic groups. By aggregating user demographic information onto the domains, we derive five metrics that provide critical insights into over 129,000 websites. In particular, the localness and partisan audience metrics quantify the domains' geographical reach and ideological orientation, respectively. These metrics show substantial agreement with existing classifications, suggesting the effectiveness and reliability of DomainDemo's approach.
>
---
