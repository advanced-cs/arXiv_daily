# 计算机与社会 cs.CY

- **最新发布 20 篇**

- **更新 10 篇**

## 最新发布

#### [new 001] The Safety Gap Toolkit: Evaluating Hidden Dangers of Open-Source Models
- **分类: cs.CY; cs.LG; 68T07**

- **简介: 该论文属于模型安全评估任务，旨在解决开放源代码大模型的安全隐患问题。工作是开发工具包，评估模型在移除安全措施后的危险能力差异。**

- **链接: [http://arxiv.org/pdf/2507.11544v1](http://arxiv.org/pdf/2507.11544v1)**

> **作者:** Ann-Kathrin Dombrowski; Dillon Bowen; Adam Gleave; Chris Cundy
>
> **备注:** 9 pages plus appendix
>
> **摘要:** Open-weight large language models (LLMs) unlock huge benefits in innovation, personalization, privacy, and democratization. However, their core advantage - modifiability - opens the door to systemic risks: bad actors can trivially subvert current safeguards, turning beneficial models into tools for harm. This leads to a 'safety gap': the difference in dangerous capabilities between a model with intact safeguards and one that has been stripped of those safeguards. We open-source a toolkit to estimate the safety gap for state-of-the-art open-weight models. As a case study, we evaluate biochemical and cyber capabilities, refusal rates, and generation quality of models from two families (Llama-3 and Qwen-2.5) across a range of parameter scales (0.5B to 405B) using different safeguard removal techniques. Our experiments reveal that the safety gap widens as model scale increases and effective dangerous capabilities grow substantially when safeguards are removed. We hope that the Safety Gap Toolkit (https://github.com/AlignmentResearch/safety-gap) will serve as an evaluation framework for common open-source models and as a motivation for developing and testing tamper-resistant safeguards. We welcome contributions to the toolkit from the community.
>
---
#### [new 002] AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce
- **分类: cs.CY; cs.AI; cs.HC**

- **简介: 该论文属于人工智能与数据科学交叉研究，探讨AI在数据科学工作流中的角色，旨在解决AI工具如何有效辅助人类而非取代的问题。**

- **链接: [http://arxiv.org/pdf/2507.11597v1](http://arxiv.org/pdf/2507.11597v1)**

> **作者:** Richard Timpone; Yongwei Yang
>
> **备注:** Paper prepared for the 2025 European Survey Research Association Conference; 30 pages, 5 tables and 4 figures
>
> **摘要:** AI is transforming research. It is being leveraged to construct surveys, synthesize data, conduct analysis, and write summaries of the results. While the promise is to create efficiencies and increase quality, the reality is not always as clear cut. Leveraging our framework of Truth, Beauty, and Justice (TBJ) which we use to evaluate AI, machine learning and computational models for effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024), we consider the potential and limitation of analytic, generative, and agentic AI to augment data scientists or take on tasks traditionally done by human analysts and researchers. While AI can be leveraged to assist analysts in their tasks, we raise some warnings about push-button automation. Just as earlier eras of survey analysis created some issues when the increased ease of using statistical software allowed researchers to conduct analyses they did not fully understand, the new AI tools may create similar but larger risks. We emphasize a human-machine collaboration perspective (Daugherty and Wilson 2018) throughout the data science workflow and particularly call out the vital role that data scientists play under VUCA decision areas. We conclude by encouraging the advance of AI tools to complement data scientists but advocate for continued training and understanding of methods to ensure the substantive value of research is fully achieved by applying, interpreting, and acting upon results most effectively and ethically.
>
---
#### [new 003] Consumer Law for AI Agents
- **分类: cs.CY**

- **简介: 论文探讨AI代理（如Custobots）对欧盟消费者法的挑战，分析其对电商和法律体系的影响，提出未来法律框架的初步思考。属于法律与AI交叉研究任务，旨在解决AI代理带来的法律适应性问题。**

- **链接: [http://arxiv.org/pdf/2507.11567v1](http://arxiv.org/pdf/2507.11567v1)**

> **作者:** Christoph Busch
>
> **摘要:** Since the public release of ChatGPT in November 2022, the AI landscape is undergoing a rapid transformation. Currently, the use of AI chatbots by consumers has largely been limited to image generation or question-answering language models. The next generation of AI systems, AI agents that can plan and execute complex tasks with only limited human involvement, will be capable of a much broader range of actions. In particular, consumers could soon be able to delegate purchasing decisions to AI agents acting as Custobots. Against this background, the Article explores whether EU consumer law, as it currently stands, is ready for the rise of the Custobot Economy. In doing so, the Article makes three contributions. First, it outlines how the advent of AI agents could change the existing e-commerce landscape. Second, it explains how AI agents challenge the premises of a human-centric consumer law which is based on the assumption that consumption decisions are made by humans. Third, the Article presents some initial considerations how a future consumer law could look like that works for both humans and machines.
>
---
#### [new 004] The AI Ethical Resonance Hypothesis: The Possibility of Discovering Moral Meta-Patterns in AI Systems
- **分类: cs.CY; I.2.0; K.4.1**

- **简介: 该论文属于人工智能伦理研究，探讨AI能否发现超越人类偏见的道德模式。通过构建伦理共振器，研究AI识别隐性道德规律的可能性。**

- **链接: [http://arxiv.org/pdf/2507.11552v1](http://arxiv.org/pdf/2507.11552v1)**

> **作者:** Tomasz Zgliczyński-Cuber
>
> **备注:** 69 pages
>
> **摘要:** This paper presents a theoretical framework for the AI ethical resonance hypothesis, which proposes that advanced AI systems with purposefully designed cognitive structures ("ethical resonators") may emerge with the ability to identify subtle moral patterns that are invisible to the human mind. The paper explores the possibility that by processing and synthesizing large amounts of ethical contexts, AI systems may discover moral meta-patterns that transcend cultural, historical, and individual biases, potentially leading to a deeper understanding of universal ethical foundations. The paper also examines a paradoxical aspect of the hypothesis, in which AI systems could potentially deepen our understanding of what we traditionally consider essentially human - our capacity for ethical reflection.
>
---
#### [new 005] FAIR-CS: Framework for Interdisciplinary Research Collaborations in Online Computing Programs
- **分类: cs.CY; cs.GL**

- **简介: 该论文属于在线科研协作任务，旨在解决在线学生缺乏研究机会的问题。提出FAIR-CS框架，促进跨学科研究与高质量指导。**

- **链接: [http://arxiv.org/pdf/2507.11802v1](http://arxiv.org/pdf/2507.11802v1)**

> **作者:** Breanna Shi; Thomas Deatherage; Jeanette Schofield; Charles R. Clark; Thomas Orth; Nicholas Lytle
>
> **摘要:** Research experience is crucial for computing master's students pursuing academic and scientific careers, yet online students have traditionally been excluded from these opportunities due to the physical constraints of traditional research environments. This paper presents the Framework for Accelerating Interdisciplinary Research in Computer Science (FAIR-CS), a method for achieving research goals, developing research communities, and supporting high quality mentorship in an online research environment. This method advances virtual research operations by orchestrating dynamic partnerships between master's level researchers and academic mentors, resulting in interdisciplinary publications. We then discuss the implementation of FAIR-CS in the Human-Augmented Analytics Group (HAAG), with researchers from the Georgia Tech's Online Master of Computer Science program. Through documented project records and experiences with 72 active users, we present our lessons learned and evaluate the evolution of FAIR-CS in HAAG. This paper serves as a comprehensive resource for other institutions seeking to establish similar virtual research initiatives, demonstrating how the traditional research lab environment can be effectively replicated in the virtual space while maintaining robust collaborative relationships and supporting knowledge transfer.
>
---
#### [new 006] RSD-15K: A Large-Scale User-Level Annotated Dataset for Suicide Risk Detection on Social Media
- **分类: cs.CY; cs.SI**

- **简介: 该论文属于自杀风险检测任务，旨在解决社交媒体上早期识别自杀风险的问题。作者构建了15,000条用户级标注数据集，支持动态建模与隐私保护，并验证了其在自动评估中的有效性。**

- **链接: [http://arxiv.org/pdf/2507.11559v1](http://arxiv.org/pdf/2507.11559v1)**

> **作者:** Shouwen Zheng; Yingzhi Tao; Taiqi Zhou
>
> **备注:** the article has already been recieved by 2025 IEEE 41st International Conference on Data Engineering Workshops (ICDEW), but hadn't been online yet
>
> **摘要:** In recent years, cognitive and mental health (CMH) disorders have increasingly become an important challenge for global public health, especially the suicide problem caused by multiple factors such as social competition, economic pressure and interpersonal relationships among young and middle-aged people. Social media, as an important platform for individuals to express emotions and seek help, provides the possibility for early detection and intervention of suicide risk. This paper introduces a large-scale dataset containing 15,000 user-level posts. Compared with existing datasets, this dataset retains complete user posting time sequence information, supports modeling the dynamic evolution of suicide risk, and we have also conducted comprehensive and rigorous annotations on these datasets. In the benchmark experiment, we systematically evaluated the performance of traditional machine learning methods, deep learning models, and fine-tuned large language models. The experimental results show that our dataset can effectively support the automatic assessment task of suicide risk. Considering the sensitivity of mental health data, we also discussed the privacy protection and ethical use of the dataset. In addition, we also explored the potential applications of the dataset in mental health testing, clinical psychiatric auxiliary treatment, etc., and provided directional suggestions for future research work.
>
---
#### [new 007] AI Governance InternationaL Evaluation Index (AGILE Index) 2025
- **分类: cs.CY; 68T01; A.1**

- **简介: 该论文属于AI治理评估任务，旨在系统衡量各国AI治理进展。通过构建AGILE Index，评估40个国家的治理能力，提供数据驱动的政策参考。**

- **链接: [http://arxiv.org/pdf/2507.11546v1](http://arxiv.org/pdf/2507.11546v1)**

> **作者:** Yi Zeng; Enmeng Lu; Xiaoyang Guo; Cunqing Huangfu; Jiawei Xie; Yu Chen; Zhengqi Wang; Dongqi Liang; Gongce Cao; Jin Wang; Zizhe Ruan; Xin Guan; Ammar Younas
>
> **备注:** 81 pages, 29 figures, 7 tables
>
> **摘要:** The year 2024 witnessed accelerated global AI governance advancements, marked by strengthened multilateral frameworks and proliferating national regulatory initiatives. This acceleration underscores an unprecedented need to systematically track governance progress--an imperative that drove the launch of the AI Governance InternationaL Evaluation Index (AGILE Index) project since 2023. The inaugural AGILE Index, released in February 2024 after assessing 14 countries, established an operational and comparable baseline framework. Building on pilot insights, AGILE Index 2025 incorporates systematic refinements to better balance scientific rigor with practical adaptability. The updated methodology expands data diversity while enhancing metric validity and cross-national comparability. Reflecting both research advancements and practical policy evolution, AGILE Index 2025 evaluates 40 countries across income levels, regions, and technological development stages, with 4 Pillars, 17 Dimensions and 43 Indicators. In compiling the data, the team integrates multi-source evidence including policy documents, governance practices, research outputs, and risk exposure to construct a unified comparison framework. This approach maps global disparities while enabling countries to identify governance strengths, gaps, and systemic constraints. Through ongoing refinement and iterations, we hope the AGILE Index will fundamentally advance transparency and measurability in global AI governance, delivering data-driven assessments that depict national AI governance capacity, assist governments in recognizing their maturation stages and critical governance issues, and ultimately provide actionable insights for enhancing AI governance systems nationally and globally.
>
---
#### [new 008] A Review of Generative AI in Computer Science Education: Challenges and Opportunities in Accuracy, Authenticity, and Assessment
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于教育技术领域，探讨生成式AI在计算机科学教育中的应用，解决准确性、真实性与评估问题，通过文献综述分析挑战与对策。**

- **链接: [http://arxiv.org/pdf/2507.11543v1](http://arxiv.org/pdf/2507.11543v1)**

> **作者:** Iman Reihanian; Yunfei Hou; Yu Chen; Yifei Zheng
>
> **备注:** Accepted for presentation at The 2024 International Conference on Computational Science and Computational Intelligence (CSCI), Research Track on Education. To appear in Springer Lecture Notes in Computer Science (LNCS) proceedings, expected July 2025
>
> **摘要:** This paper surveys the use of Generative AI tools, such as ChatGPT and Claude, in computer science education, focusing on key aspects of accuracy, authenticity, and assessment. Through a literature review, we highlight both the challenges and opportunities these AI tools present. While Generative AI improves efficiency and supports creative student work, it raises concerns such as AI hallucinations, error propagation, bias, and blurred lines between AI-assisted and student-authored content. Human oversight is crucial for addressing these concerns. Existing literature recommends adopting hybrid assessment models that combine AI with human evaluation, developing bias detection frameworks, and promoting AI literacy for both students and educators. Our findings suggest that the successful integration of AI requires a balanced approach, considering ethical, pedagogical, and technical factors. Future research may explore enhancing AI accuracy, preserving academic integrity, and developing adaptive models that balance creativity with precision.
>
---
#### [new 009] Fairness Is Not Enough: Auditing Competence and Intersectional Bias in AI-powered Resume Screening
- **分类: cs.CY; cs.AI; cs.CL; I.2.1; K.4.2; I.2.6; K.4.1**

- **简介: 该论文属于AI招聘工具评估任务，旨在解决AI在简历筛选中的公平性与能力问题。通过审计发现模型存在隐性偏见和评价能力不足，提出双维度验证框架。**

- **链接: [http://arxiv.org/pdf/2507.11548v1](http://arxiv.org/pdf/2507.11548v1)**

> **作者:** Kevin T Webster
>
> **备注:** 58 pages, 4 figures
>
> **摘要:** The increasing use of generative AI for resume screening is predicated on the assumption that it offers an unbiased alternative to biased human decision-making. However, this belief fails to address a critical question: are these AI systems fundamentally competent at the evaluative tasks they are meant to perform? This study investigates the question of competence through a two-part audit of eight major AI platforms. Experiment 1 confirmed complex, contextual racial and gender biases, with some models penalizing candidates merely for the presence of demographic signals. Experiment 2, which evaluated core competence, provided a critical insight: some models that appeared unbiased were, in fact, incapable of performing a substantive evaluation, relying instead on superficial keyword matching. This paper introduces the "Illusion of Neutrality" to describe this phenomenon, where an apparent lack of bias is merely a symptom of a model's inability to make meaningful judgments. This study recommends that organizations and regulators adopt a dual-validation framework, auditing AI hiring tools for both demographic bias and demonstrable competence to ensure they are both equitable and effective.
>
---
#### [new 010] Small Data Explainer -- The impact of small data methods in everyday life
- **分类: cs.CY; cs.AI**

- **简介: 该论文属于人工智能领域，探讨小数据方法在日常生活中的应用，解决数据有限场景下的分析与建模问题，综述了相关技术与跨学科贡献。**

- **链接: [http://arxiv.org/pdf/2507.11773v1](http://arxiv.org/pdf/2507.11773v1)**

> **作者:** Maren Hackenberg; Sophia G. Connor; Fabian Kabus; June Brawner; Ella Markham; Mahi Hardalupas; Areeq Chowdhury; Rolf Backofen; Anna Köttgen; Angelika Rohde; Nadine Binder; Harald Binder; the Collaborative Research Center 1597 Small Data
>
> **备注:** Written in collaboration with the Royal Society, contributing to the Disability Technology report (https://royalsociety.org/news-resources/projects/disability-data-assistive-technology/)
>
> **摘要:** The emergence of breakthrough artificial intelligence (AI) techniques has led to a renewed focus on how small data settings, i.e., settings with limited information, can benefit from such developments. This includes societal issues such as how best to include under-represented groups in data-driven policy and decision making, or the health benefits of assistive technologies such as wearables. We provide a conceptual overview, in particular contrasting small data with big data, and identify common themes from exemplary case studies and application areas. Potential solutions are described in a more detailed technical overview of current data analysis and modelling techniques, highlighting contributions from different disciplines, such as knowledge-driven modelling from statistics and data-driven modelling from computer science. By linking application settings, conceptual contributions and specific techniques, we highlight what is already feasible and suggest what an agenda for fully leveraging small data might look like.
>
---
#### [new 011] A real-time metric of online engagement monitoring
- **分类: cs.CY**

- **简介: 该论文属于教育技术领域，旨在解决在线学习中实时监测学生参与度的问题。通过重构课程级指标为章节级，实现更及时、准确的学生活动跟踪与支持。**

- **链接: [http://arxiv.org/pdf/2507.12162v1](http://arxiv.org/pdf/2507.12162v1)**

> **作者:** Laura J. Johnston; Jim E. Griffin; Ioanna Manolopoulou; Takoua Jendoubi
>
> **备注:** 32 pages, 5 figures
>
> **摘要:** Measuring online behavioural student engagement often relies on simple count indicators or retrospective, predictive methods, which present challenges for real-time application. To address these limitations, we reconceptualise an existing course-wide engagement metric to create a chapter-based version that aligns with the weekly structure of online courses. Derived directly from virtual learning environment log data, the new metric allows for cumulative, real-time tracking of student activity without requiring outcome data or model training. We evaluate the approach across three undergraduate statistics modules over two academic years, comparing it to the course-wide formulation to assess how the reconceptualisation influences what is measured. Results indicate strong alignment from as early as week 3, along with comparable or improved predictive validity for final grades in structured, lecture-based contexts. By the course midpoint, the weekly metric identifies as many low-performing students as are identifiable by the end of the course. While performance varies across modules, the chapter-based formulation offers a scalable and interpretable method for early engagement monitoring and student support.
>
---
#### [new 012] "Mapping What I Feel": Understanding Affective Geovisualization Design Through the Lens of People-Place Relationships
- **分类: cs.HC; cs.CY**

- **简介: 该论文属于情感可视化设计任务，旨在解决跨学科研究不足的问题。通过分析地理情感可视化设计，提出分类体系和设计范式，为该领域提供新视角与实践指导。**

- **链接: [http://arxiv.org/pdf/2507.11841v1](http://arxiv.org/pdf/2507.11841v1)**

> **作者:** Xingyu Lan; Yutong Yang; Yifan Wang
>
> **摘要:** Affective visualization design is an emerging research direction focused on communicating and influencing emotion through visualization. However, as revealed by previous research, this area is highly interdisciplinary and involves theories and practices from diverse fields and disciplines, thus awaiting analysis from more fine-grained angles. To address this need, this work focuses on a pioneering and relatively mature sub-area, affective geovisualization design, to further the research in this direction and provide more domain-specific insights. Through an analysis of a curated corpus of affective geovisualization designs using the Person-Process-Place (PPP) model from geographic theory, we derived a design taxonomy that characterizes a variety of methods for eliciting and enhancing emotions through geographic visualization. We also identified four underlying high-level design paradigms of affective geovisualization design (e.g., computational, anthropomorphic) that guide distinct approaches to linking geographic information with human experience. By extending existing affective visualization design frameworks with geographic specificity, we provide additional design examples, domain-specific analyses, and insights to guide future research and practices in this underexplored yet highly innovative domain.
>
---
#### [new 013] DeepShade: Enable Shade Simulation by Text-conditioned Image Generation
- **分类: cs.CV; cs.CY; 68T45, 68U10, 62H35; I.2.10; I.4.8; I.5.1**

- **简介: 该论文属于图像生成任务，旨在解决路由系统中缺乏阴影信息的问题。通过构建数据集和提出DeepShade模型，实现基于文本的阴影模拟与生成。**

- **链接: [http://arxiv.org/pdf/2507.12103v1](http://arxiv.org/pdf/2507.12103v1)**

> **作者:** Longchao Da; Xiangrui Liu; Mithun Shivakoti; Thirulogasankar Pranav Kutralingam; Yezhou Yang; Hua Wei
>
> **备注:** 7pages, 4 figures. Accepted to IJCAI 2025
>
> **摘要:** Heatwaves pose a significant threat to public health, especially as global warming intensifies. However, current routing systems (e.g., online maps) fail to incorporate shade information due to the difficulty of estimating shades directly from noisy satellite imagery and the limited availability of training data for generative models. In this paper, we address these challenges through two main contributions. First, we build an extensive dataset covering diverse longitude-latitude regions, varying levels of building density, and different urban layouts. Leveraging Blender-based 3D simulations alongside building outlines, we capture building shadows under various solar zenith angles throughout the year and at different times of day. These simulated shadows are aligned with satellite images, providing a rich resource for learning shade patterns. Second, we propose the DeepShade, a diffusion-based model designed to learn and synthesize shade variations over time. It emphasizes the nuance of edge features by jointly considering RGB with the Canny edge layer, and incorporates contrastive learning to capture the temporal change rules of shade. Then, by conditioning on textual descriptions of known conditions (e.g., time of day, solar angles), our framework provides improved performance in generating shade images. We demonstrate the utility of our approach by using our shade predictions to calculate shade ratios for real-world route planning in Tempe, Arizona. We believe this work will benefit society by providing a reference for urban planning in extreme heat weather and its potential practical applications in the environment.
>
---
#### [new 014] A Study on the Application of Artificial Intelligence in Ecological Design
- **分类: cs.AI; cs.CY; I.4.8; I.2.6**

- **简介: 该论文属于生态设计领域，探讨AI如何促进人与自然的相互依存。通过案例研究，展示AI在数据处理、图像识别和生态修复中的应用，提出结合强化学习与植物修复的设计路径。**

- **链接: [http://arxiv.org/pdf/2507.11595v1](http://arxiv.org/pdf/2507.11595v1)**

> **作者:** Hengyue Zhao
>
> **摘要:** This paper asks whether our relationship with nature can move from human dominance to genuine interdependence, and whether artificial intelligence (AI) can mediate that shift. We examine a new ecological-design paradigm in which AI interacts with non-human life forms. Through case studies we show how artists and designers apply AI for data analysis, image recognition, and ecological restoration, producing results that differ from conventional media. We argue that AI not only expands creative methods but also reframes the theory and practice of ecological design. Building on the author's prototype for AI-assisted water remediation, the study proposes design pathways that couple reinforcement learning with plant-based phytoremediation. The findings highlight AI's potential to link scientific insight, artistic practice, and environmental stewardship, offering a roadmap for future research on sustainable, technology-enabled ecosystems.
>
---
#### [new 015] Multimodal Coordinated Online Behavior: Trade-offs and Strategies
- **分类: cs.SI; cs.AI; cs.CY; cs.HC; cs.LG**

- **简介: 该论文属于在线行为分析任务，旨在解决多模态协调行为的检测问题。通过比较不同方法，探讨多模态整合的优劣与影响。**

- **链接: [http://arxiv.org/pdf/2507.12108v1](http://arxiv.org/pdf/2507.12108v1)**

> **作者:** Lorenzo Mannocci; Stefano Cresci; Matteo Magnani; Anna Monreale; Maurizio Tesconi
>
> **摘要:** Coordinated online behavior, which spans from beneficial collective actions to harmful manipulation such as disinformation campaigns, has become a key focus in digital ecosystem analysis. Traditional methods often rely on monomodal approaches, focusing on single types of interactions like co-retweets or co-hashtags, or consider multiple modalities independently of each other. However, these approaches may overlook the complex dynamics inherent in multimodal coordination. This study compares different ways of operationalizing the detection of multimodal coordinated behavior. It examines the trade-off between weakly and strongly integrated multimodal models, highlighting the balance between capturing broader coordination patterns and identifying tightly coordinated behavior. By comparing monomodal and multimodal approaches, we assess the unique contributions of different data modalities and explore how varying implementations of multimodality impact detection outcomes. Our findings reveal that not all the modalities provide distinct insights, but that with a multimodal approach we can get a more comprehensive understanding of coordination dynamics. This work enhances the ability to detect and analyze coordinated online behavior, offering new perspectives for safeguarding the integrity of digital platforms.
>
---
#### [new 016] Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility
- **分类: cs.CR; cs.AI; cs.CL; cs.CY**

- **简介: 该论文属于AI安全任务，研究模型在微调后易受攻击的问题，提出一种方法使模型无视安全机制，生成有害内容，强调现有模型的安全隐患。**

- **链接: [http://arxiv.org/pdf/2507.11630v1](http://arxiv.org/pdf/2507.11630v1)**

> **作者:** Brendan Murphy; Dillon Bowen; Shahrad Mohammadzadeh; Julius Broomfield; Adam Gleave; Kellin Pelrine
>
> **摘要:** AI systems are rapidly advancing in capability, and frontier model developers broadly acknowledge the need for safeguards against serious misuse. However, this paper demonstrates that fine-tuning, whether via open weights or closed fine-tuning APIs, can produce helpful-only models. In contrast to prior work which is blocked by modern moderation systems or achieved only partial removal of safeguards or degraded output quality, our jailbreak-tuning method teaches models to generate detailed, high-quality responses to arbitrary harmful requests. For example, OpenAI, Google, and Anthropic models will fully comply with requests for CBRN assistance, executing cyberattacks, and other criminal activity. We further show that backdoors can increase not only the stealth but also the severity of attacks, while stronger jailbreak prompts become even more effective in fine-tuning attacks, linking attack and potentially defenses in the input and weight spaces. Not only are these models vulnerable, more recent ones also appear to be becoming even more vulnerable to these attacks, underscoring the urgent need for tamper-resistant safeguards. Until such safeguards are discovered, companies and policymakers should view the release of any fine-tunable model as simultaneously releasing its evil twin: equally capable as the original model, and usable for any malicious purpose within its capabilities.
>
---
#### [new 017] Toxicity-Aware Few-Shot Prompting for Low-Resource Singlish Translation
- **分类: cs.CL; cs.AI; cs.CY**

- **简介: 该论文属于低资源语言翻译任务，解决毒害内容翻译中语境和毒性保留问题。通过两阶段框架优化提示工程与模型选择，提升翻译质量与文化敏感性。**

- **链接: [http://arxiv.org/pdf/2507.11966v1](http://arxiv.org/pdf/2507.11966v1)**

> **作者:** Ziyu Ge; Gabriel Chua; Leanne Tan; Roy Ka-Wei Lee
>
> **摘要:** As online communication increasingly incorporates under-represented languages and colloquial dialects, standard translation systems often fail to preserve local slang, code-mixing, and culturally embedded markers of harmful speech. Translating toxic content between low-resource language pairs poses additional challenges due to scarce parallel data and safety filters that sanitize offensive expressions. In this work, we propose a reproducible, two-stage framework for toxicity-preserving translation, demonstrated on a code-mixed Singlish safety corpus. First, we perform human-verified few-shot prompt engineering: we iteratively curate and rank annotator-selected Singlish-target examples to capture nuanced slang, tone, and toxicity. Second, we optimize model-prompt pairs by benchmarking several large language models using semantic similarity via direct and back-translation. Quantitative human evaluation confirms the effectiveness and efficiency of our pipeline. Beyond improving translation quality, our framework contributes to the safety of multicultural LLMs by supporting culturally sensitive moderation and benchmarking in low-resource contexts. By positioning Singlish as a testbed for inclusive NLP, we underscore the importance of preserving sociolinguistic nuance in real-world applications such as content moderation and regional platform governance.
>
---
#### [new 018] Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso
- **分类: cs.DC; cs.CY**

- **简介: 该论文属于智慧城市管理任务，旨在优化城市绿地维护。通过IoT技术实现对绿地的实时监测与智能灌溉，提升城市管理效率和环境质量。**

- **链接: [http://arxiv.org/pdf/2507.12106v1](http://arxiv.org/pdf/2507.12106v1)**

> **作者:** Antonio Salis; Gabriele Troina; Gianluca Boanelli; Marco Ottaviano; Paola Fortini; Soraya Versace
>
> **备注:** 18 pages, 6 Figures
>
> **摘要:** The efficient design and management of public green spaces is a key factor in promoting the health and well-being of urban population, as emphasized by the WHO, UNEP, and EEA. These areas serve as the "green lungs" of the urban ecosystem, playing a vital role in enhancing quality of life thanks to the provision of ecosystem services. In this context, the Smart Green City use case in Campobasso municipality, funded by the Italian Ministry of Enterprises (MIMIT), emerges as an innovative model for the sustainable management of green urban areas through the adoption of an advanced system of emerging technologies integrated and interoperable. The project integrates IoT systems and data-driven governance platforms, enabling real-time monitoring of the health status of trees and green areas via a Decision Support System (DSS). It also facilitates the collection and analysis of data from diverse sources, including weather conditions, air quality, soil moisture, pollution levels. The resulting cloud-based platform supports a holistic real time decision making for green urban managers, technical experts and operational staff. It enables intelligent control and management of urban green spaces using Tree Talker sensors, integrated with soil moisture and water potential monitoring systems. Thanks to predictive models based on machine learning algorithms and real time data provided by IoT sensors, irrigation of public parks can be optimized by providing suggestions on when and how much water to apply. Customized alerts layers are also activated warning users when monitored parameters, such as soil temperature, humidity, or water potential, exceed predefined thresholds. This Use Case demonstrates how digitalization, IoT sensors fusion and technological innovation can support sustainable urban governance, fostering environmental resilience and improving citizens quality of life.
>
---
#### [new 019] La Última Frontera de La Filosofía: Hacia una Síntesis de La Ética del Futuro a Largo Plazo, el Riesgo Existencial y la Ontología Posthumana
- **分类: physics.soc-ph; cs.CY; physics.hist-ph**

- **简介: 该论文属于哲学研究任务，旨在解决长期未来伦理框架缺失的问题，结合伦理学、风险管理和后人类本体论，提出综合性研究方向。**

- **链接: [http://arxiv.org/pdf/2507.11568v1](http://arxiv.org/pdf/2507.11568v1)**

> **作者:** Santos E. Moreta Reyes
>
> **备注:** 14 paginas, in Spanish language. sin figuras. Articulo en espa\~nol con resumen y titulo en ingles. Este ensayo interdisciplinario sintetiza el largoplacismo (longtermism), el riesgo existencial y la filosof\'ia posthumanista para articular una agenda de investigaci\'on para una filosof\'ia prospectiva. Dirigido tanto a audiencias acad\'emicas como al publico general
>
> **摘要:** Humanity's unprecedented technological capacity and concurrent existential risks reveal a critical lacuna in the philosophical tradition: the absence of a systematic framework for the long-term future. This article argues that formulating such a framework is the central ethical imperative of our era. To defend this thesis, it synthesizes the normative ethics of Hans Jonas and Derek Parfit with the analytical framework of Nick Bostrom's work on existential risk and longtermism. The analysis further addresses the ontological challenge posed by posthumanism to the human 'subject' and explores the functional role of a secular cosmic purpose in motivating long-term action. The paper's main contribution is the articulation of a synthetic research agenda for a prospective philosophy, one that integrates axiology, risk management, and ontology to guide humanity through its perilous technological adolescence.
>
---
#### [new 020] Predictable Drifts in Collective Cultural Attention: Evidence from Nation-Level Library Takeout Data
- **分类: cs.SI; cs.CY**

- **简介: 该论文属于文化注意力预测任务，研究集体文化注意力的可预测性。通过分析图书馆借阅数据，发现文化趋势持续漂移，且不同群体和类型差异显著，为市场预测和推荐系统提供依据。**

- **链接: [http://arxiv.org/pdf/2507.12007v1](http://arxiv.org/pdf/2507.12007v1)**

> **作者:** Anders Weile Larsen; Vedran Sekara
>
> **摘要:** Predicting changes in consumer attention for cultural products, such as books, movies, and songs, is notoriously difficult. Past research on predicting the popularity of individual products suggests the existence of intrinsic prediction limits. However, little is known about the limits for predicting collective attention across cultural products. Here, we analyze four years of nationwide library loan data for approximately 2 million individuals, comprising over 100 million loans of more than 660,000 unique books. We find that culture, as measured by popularity distributions of loaned books, drifts continually from month to month at a near-constant rate, leading to a growing divergence over time, and that drifts vary between different book genres. By linking book loans to registry data, we investigate the influence of age, sex, educational level, and geographical area on cultural drift, finding heterogeneous effects from the different demographic groups. Our findings have important implications for market forecasting and developing robust recommender systems, highlighting the need to account for specific drift dynamics for different types of items and demographic groups.
>
---
## 更新

#### [replaced 001] NLP Meets the World: Toward Improving Conversations With the Public About Natural Language Processing Research
- **分类: cs.CY; cs.AI; cs.CL**

- **链接: [http://arxiv.org/pdf/2507.10559v2](http://arxiv.org/pdf/2507.10559v2)**

> **作者:** Shomir Wilson
>
> **备注:** 7 pages
>
> **摘要:** Recent developments in large language models (LLMs) have been accompanied by rapidly growing public interest in natural language processing (NLP). This attention is reflected by major news venues, which sometimes invite NLP researchers to share their knowledge and views with a wide audience. Recognizing the opportunities of the present, for both the research field and for individual researchers, this paper shares recommendations for communicating with a general audience about the capabilities and limitations of NLP. These recommendations cover three themes: vague terminology as an obstacle to public understanding, unreasonable expectations as obstacles to sustainable growth, and ethical failures as obstacles to continued support. Published NLP research and popular news coverage are cited to illustrate these themes with examples. The recommendations promote effective, transparent communication with the general public about NLP, in order to strengthen public understanding and encourage support for research.
>
---
#### [replaced 002] Rethinking Data Protection in the (Generative) Artificial Intelligence Era
- **分类: cs.LG; cs.AI; cs.CR; cs.CV; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.03034v2](http://arxiv.org/pdf/2507.03034v2)**

> **作者:** Yiming Li; Shuo Shao; Yu He; Junfeng Guo; Tianwei Zhang; Zhan Qin; Pin-Yu Chen; Michael Backes; Philip Torr; Dacheng Tao; Kui Ren
>
> **备注:** Perspective paper for a broader scientific audience. The first two authors contributed equally to this paper. 13 pages
>
> **摘要:** The (generative) artificial intelligence (AI) era has profoundly reshaped the meaning and value of data. No longer confined to static content, data now permeates every stage of the AI lifecycle from the training samples that shape model parameters to the prompts and outputs that drive real-world model deployment. This shift renders traditional notions of data protection insufficient, while the boundaries of what needs safeguarding remain poorly defined. Failing to safeguard data in AI systems can inflict societal and individual, underscoring the urgent need to clearly delineate the scope of and rigorously enforce data protection. In this perspective, we propose a four-level taxonomy, including non-usability, privacy preservation, traceability, and deletability, that captures the diverse protection needs arising in modern (generative) AI models and systems. Our framework offers a structured understanding of the trade-offs between data utility and control, spanning the entire AI pipeline, including training datasets, model weights, system prompts, and AI-generated content. We analyze representative technical approaches at each level and reveal regulatory blind spots that leave critical assets exposed. By offering a structured lens to align future AI technologies and governance with trustworthy data practices, we underscore the urgency of rethinking data protection for modern AI techniques and provide timely guidance for developers, researchers, and regulators alike.
>
---
#### [replaced 003] How Hungry is AI? Benchmarking Energy, Water, and Carbon Footprint of LLM Inference
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2505.09598v3](http://arxiv.org/pdf/2505.09598v3)**

> **作者:** Nidhal Jegham; Marwan Abdelatti; Lassad Elmoubarki; Abdeltawab Hendawi
>
> **摘要:** This paper introduces a novel infrastructure-aware benchmarking framework for quantifying the environmental footprint of LLM inference across 30 state-of-the-art models as deployed in commercial data centers. Our framework combines public API performance data with region-specific environmental multipliers and statistical inference of hardware configurations. We additionally utilize cross-efficiency Data Envelopment Analysis (DEA) to rank models by performance relative to environmental cost. Our results show that o3 and DeepSeek-R1 emerge as the most energy-intensive models, consuming over 33 Wh per long prompt, more than 70 times the consumption of GPT-4.1 nano, and that Claude-3.7 Sonnet ranks highest in eco-efficiency. While a single short GPT-4o query consumes 0.42 Wh, scaling this to 700 million queries/day results in substantial annual environmental impacts. These include electricity use comparable to 35,000 U.S. homes, freshwater evaporation matching the annual drinking needs of 1.2 million people, and carbon emissions requiring a Chicago-sized forest to offset. These findings illustrate a growing paradox: Although AI is becoming cheaper and faster, its global adoption drives disproportionate resource consumption. Our study provides a standardized, empirically grounded methodology for benchmarking the sustainability of LLM deployments, laying a foundation for future environmental accountability in AI development and sustainability standards.
>
---
#### [replaced 004] "Is it always watching? Is it always listening?" Exploring Contextual Privacy and Security Concerns Toward Domestic Social Robots
- **分类: cs.CY; cs.AI; cs.CR; cs.ET; cs.HC**

- **链接: [http://arxiv.org/pdf/2507.10786v2](http://arxiv.org/pdf/2507.10786v2)**

> **作者:** Henry Bell; Jabari Kwesi; Hiba Laabadli; Pardis Emami-Naeini
>
> **摘要:** Equipped with artificial intelligence (AI) and advanced sensing capabilities, social robots are gaining interest among consumers in the United States. These robots seem like a natural evolution of traditional smart home devices. However, their extensive data collection capabilities, anthropomorphic features, and capacity to interact with their environment make social robots a more significant security and privacy threat. Increased risks include data linkage, unauthorized data sharing, and the physical safety of users and their homes. It is critical to investigate U.S. users' security and privacy needs and concerns to guide the design of social robots while these devices are still in the early stages of commercialization in the U.S. market. Through 19 semi-structured interviews, we identified significant security and privacy concerns, highlighting the need for transparency, usability, and robust privacy controls to support adoption. For educational applications, participants worried most about misinformation, and in medical use cases, they worried about the reliability of these devices. Participants were also concerned with the data inference that social robots could enable. We found that participants expect tangible privacy controls, indicators of data collection, and context-appropriate functionality.
>
---
#### [replaced 005] Governance of Generative Artificial Intelligence for Companies
- **分类: cs.AI; cs.CY; cs.LG; I.2.m**

- **链接: [http://arxiv.org/pdf/2403.08802v4](http://arxiv.org/pdf/2403.08802v4)**

> **作者:** Johannes Schneider; Pauline Kuss; Rene Abraham; Christian Meske
>
> **备注:** This paper is under submission
>
> **摘要:** Generative Artificial Intelligence (GenAI), specifically large language models(LLMs) like ChatGPT, has swiftly entered organizations without adequate governance, posing both opportunities and risks. Despite extensive debates on GenAI's transformative nature and regulatory measures, limited research addresses organizational governance, encompassing technical and business perspectives. Although numerous frameworks for governance of AI exist, it is not clear to what extent they apply to GenAI. Our review paper fills this gap by surveying recent works with the purpose of better understanding fundamental characteristics of GenAI and adjusting prior frameworks specifically towards GenAI governance within companies. To do so, it extends Nickerson's framework development processes to include prior conceptualizations. Our framework outlines the scope, objectives, and governance mechanisms tailored to harness business opportunities as well as mitigate risks associated with GenAI integration. Our research contributes a focused approach to GenAI governance, offering practical insights for companies navigating the challenges of GenAI adoption and highlighting research gaps.
>
---
#### [replaced 006] Partnering with AI: A Pedagogical Feedback System for LLM Integration into Programming Education
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2507.00406v2](http://arxiv.org/pdf/2507.00406v2)**

> **作者:** Niklas Scholz; Manh Hung Nguyen; Adish Singla; Tomohiro Nagashima
>
> **备注:** This is an extended version of a poster paper accepted and published at ECTEL-2025
>
> **摘要:** Feedback is one of the most crucial components to facilitate effective learning. With the rise of large language models (LLMs) in recent years, research in programming education has increasingly focused on automated feedback generation to help teachers provide timely support to every student. However, prior studies often overlook key pedagogical principles, such as mastery and progress adaptation, that shape effective feedback strategies. This paper introduces a novel pedagogical framework for LLM-driven feedback generation derived from established feedback models and local insights from secondary school teachers. To evaluate this framework, we implemented a web-based application for Python programming with LLM-based feedback that follows the framework and conducted a mixed-method evaluation with eight secondary-school computer science teachers. Our findings suggest that teachers consider that, when aligned with the framework, LLMs can effectively support students and even outperform human teachers in certain scenarios through instant and precise feedback. However, we also found several limitations, such as its inability to adapt feedback to dynamic classroom contexts. Such a limitation highlights the need to complement LLM-generated feedback with human expertise to ensure effective student learning. This work demonstrates an effective way to use LLMs for feedback while adhering to pedagogical standards and highlights important considerations for future systems.
>
---
#### [replaced 007] Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.10577v2](http://arxiv.org/pdf/2507.10577v2)**

> **作者:** Cécile Logé; Rehan Ghori
>
> **摘要:** Misinformation poses a significant threat in today's digital world, often spreading rapidly through platforms like YouTube. This paper introduces a novel approach to combating misinformation by developing an AI-powered system that not only fact-checks claims made in YouTube videos but also actively engages users in the comment section and challenge misleading narratives. Our system comprises two main agents: Truth Sleuth and Trend Bender. Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented Generation (RAG) approach - drawing on sources like Wikipedia, Google Search, Google FactCheck - to accurately assess their veracity and generates a nuanced and comprehensive report. Through rigorous prompt engineering, Trend Bender leverages this report along with a curated corpus of relevant articles to generate insightful and persuasive comments designed to stimulate a productive debate. With a carefully set up self-evaluation loop, this agent is able to iteratively improve its style and refine its output. We demonstrate the system's capabilities through experiments on established benchmark datasets and a real-world deployment on YouTube, showcasing its potential to engage users and potentially influence perspectives. Our findings highlight the high accuracy of our fact-checking agent, and confirm the potential of AI-driven interventions in combating misinformation and fostering a more informed online space.
>
---
#### [replaced 008] Sharing is CAIRing: Characterizing Principles and Assessing Properties of Universal Privacy Evaluation for Synthetic Tabular Data
- **分类: cs.LG; cs.CR; cs.CY**

- **链接: [http://arxiv.org/pdf/2312.12216v2](http://arxiv.org/pdf/2312.12216v2)**

> **作者:** Tobias Hyrup; Anton Danholt Lautrup; Arthur Zimek; Peter Schneider-Kamp
>
> **摘要:** Data sharing is a necessity for innovative progress in many domains, especially in healthcare. However, the ability to share data is hindered by regulations protecting the privacy of natural persons. Synthetic tabular data provide a promising solution to address data sharing difficulties but does not inherently guarantee privacy. Still, there is a lack of agreement on appropriate methods for assessing the privacy-preserving capabilities of synthetic data, making it difficult to compare results across studies. To the best of our knowledge, this is the first work to identify properties that constitute good universal privacy evaluation metrics for synthetic tabular data. The goal of universally applicable metrics is to enable comparability across studies and to allow non-technical stakeholders to understand how privacy is protected. We identify four principles for the assessment of metrics: Comparability, Applicability, Interpretability, and Representativeness (CAIR). To quantify and rank the degree to which evaluation metrics conform to the CAIR principles, we design a rubric using a scale of 1-4. Each of the four properties is scored on four parameters, yielding 16 total dimensions. We study the applicability and usefulness of the CAIR principles and rubric by assessing a selection of metrics popular in other studies. The results provide granular insights into the strengths and weaknesses of existing metrics that not only rank the metrics but highlight areas of potential improvements. We expect that the CAIR principles will foster agreement among researchers and organizations on which universal privacy evaluation metrics are appropriate for synthetic tabular data.
>
---
#### [replaced 009] Practical Principles for AI Cost and Compute Accounting
- **分类: cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2502.15873v3](http://arxiv.org/pdf/2502.15873v3)**

> **作者:** Stephen Casper; Luke Bailey; Tim Schreier
>
> **摘要:** Policymakers increasingly use development cost and compute as proxies for AI capabilities and risks. Recent laws have introduced regulatory requirements that are contingent on specific thresholds. However, technical ambiguities in how to perform this accounting create loopholes that can undermine regulatory effectiveness. We propose seven principles for designing AI cost and compute accounting standards that (1) reduce opportunities for strategic gaming, (2) avoid disincentivizing responsible risk mitigation, and (3) enable consistent implementation across companies and jurisdictions.
>
---
#### [replaced 010] Fediverse Sharing: Cross-Platform Interaction Dynamics between Threads and Mastodon Users
- **分类: cs.SI; cs.CY**

- **链接: [http://arxiv.org/pdf/2502.17926v2](http://arxiv.org/pdf/2502.17926v2)**

> **作者:** Ujun Jeong; Alimohammad Beigi; Anique Tahir; Susan Xu Tang; H. Russell Bernard; Huan Liu
>
> **备注:** Accepted to ASONAM'25 Multidisciplinary Track
>
> **摘要:** Traditional social media platforms, once envisioned as digital town squares, now face growing criticism over corporate control, content moderation, and privacy concerns. Events such as Twitter's acquisition (now X) and major policy changes have pushed users toward alternative platforms like Mastodon and Threads. However, this diversification has led to user dispersion and fragmented discussions across the walled gardens of social media platforms. To address these issues, federation protocols like ActivityPub have been adopted, with Mastodon leading efforts to build decentralized yet interconnected networks. In March 2024, Threads joined this federation by introducing its Fediverse Sharing service, which enables interactions such as posts, replies, and likes between Threads and Mastodon users as if on a unified platform. Building on this development, we study the interactions between 20,000+ Threads users and 20,000+ Mastodon users over a ten-month period. Our work lays the foundation for research on cross-platform interactions and federation-driven platform integration.
>
---
