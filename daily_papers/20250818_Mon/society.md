# 计算机与社会 cs.CY

- **最新发布 17 篇**

- **更新 4 篇**

## 最新发布

#### [new 001] Intergenerational Support for Deepfake Scams Targeting Older Adults
- **分类: cs.CY**

- **简介: 该论文属于网络安全任务，探讨如何通过代际支持防范针对老年人的深度伪造诈骗。研究分析了老年人对这类骗局的认知及应对策略，并提出利用年轻人参与提升家庭网络安全的方案。**

- **链接: [http://arxiv.org/pdf/2508.11579v1](http://arxiv.org/pdf/2508.11579v1)**

> **作者:** Karina LaRubbio; Alyssa Lanter; Seihyun Lee; Mahima Ramesh; Diana Freed
>
> **备注:** 3 pages, poster at the Twenty-First Symposium on Usable Privacy and Security (SOUPS) at https://www.usenix.org/conference/soups2025/presentation/larubbio-poster
>
> **摘要:** AI-enhanced scams now employ deepfake technology to produce convincing audio and visual impersonations of trusted family members, often grandchildren, in real time. These attacks fabricate urgent scenarios, such as legal or medical emergencies, to socially engineer older adults into transferring money. The realism of these AI-generated impersonations undermines traditional cues used to detect fraud, making them a powerful tool for financial exploitation. In this study, we explore older adults' perceptions of these emerging threats and their responses, with a particular focus on the role of youth, who may also be impacted by having their identities exploited, in supporting older family members' online safety. We conducted focus groups with 37 older adults (ages 65+) to examine their understanding of deepfake impersonation scams and the value of intergenerational technology support. Findings suggest that older adults frequently rely on trusted relationships to detect scams and develop protective practices. Based on this, we identify opportunities to engage youth as active partners in enhancing resilience across generations.
>
---
#### [new 002] JobPulse: A Big Data Approach to Real-Time Engineering Workforce Analysis and National Industrial Policy
- **分类: cs.CY; cs.IR**

- **简介: 该论文属于就业市场分析任务，旨在解决技能匹配不足的问题。通过分析招聘数据，提供实时 workforce 需求洞察，聚焦半导体行业。**

- **链接: [http://arxiv.org/pdf/2508.11014v1](http://arxiv.org/pdf/2508.11014v1)**

> **作者:** Karen S. Markel; Mihir Tale; Andrea Belz
>
> **摘要:** Employment on a societal scale contributes heavily to national and global affairs; consequently, job openings and unemployment estimates provide important information to financial markets and governments alike. However, such reports often describe only the supply (employee job seeker) side of the job market, and skill mismatches are poorly understood. Job postings aggregated on recruiting platforms illuminate marketplace demand, but to date have primarily focused on candidate skills described in their personal profiles. In this paper, we report on a big data approach to estimating job market mismatches by focusing on demand, as represented in publicly available job postings. We use commercially available web scraping tools and a new data processing scheme to build a job posting data set for the semiconductor industry, a strategically critical sector of the United States economy; we focus on Southern California as a central hub of advanced technologies. We report on the employer base and relative needs of various job functions. Our work contributes on three fronts: First, we provide nearly real-time insight into workforce demand; second, we discuss disambiguation and semantic challenges in analysis of employer data bases at scale; and third, we report on the Southern California semiconductor engineering ecosystem.
>
---
#### [new 003] A Knowledge Graph Informing Soil Carbon Modeling
- **分类: cs.CY; cs.SC**

- **链接: [http://arxiv.org/pdf/2508.10965v1](http://arxiv.org/pdf/2508.10965v1)**

> **作者:** Nasim Shirvani-Mahdavi; Devin Wingfield; Juan Guajardo Gutierrez; Mai Tran; Zhengyuan Zhu; Zeyu Zhang; Haiqi Zhang; Abhishek Divakar Goudar; Chengkai Li; Virginia Jin; Timothy Propst; Dan Roberts; Catherine Stewart; Jianzhong Su; Jennifer Woodward-Greene
>
> **摘要:** Soil organic carbon is crucial for climate change mitigation and agricultural sustainability. However, understanding its dynamics requires integrating complex, heterogeneous data from multiple sources. This paper introduces the Soil Organic Carbon Knowledge Graph (SOCKG), a semantic infrastructure designed to transform agricultural research data into a queryable knowledge representation. SOCKG features a robust ontological model of agricultural experimental data, enabling precise mapping of datasets from the Agricultural Collaborative Research Outcomes System. It is semantically aligned with the National Agricultural Library Thesaurus for consistent terminology and improved interoperability. The knowledge graph, constructed in GraphDB and Neo4j, provides advanced querying capabilities and RDF access. A user-friendly dashboard allows easy exploration of the knowledge graph and ontology. SOCKG supports advanced analyses, such as comparing soil organic carbon changes across fields and treatments, advancing soil carbon research, and enabling more effective agricultural strategies to mitigate climate change.
>
---
#### [new 004] Bias is a Math Problem, AI Bias is a Technical Problem: 10-year Literature Review of AI/LLM Bias Research Reveals Narrow [Gender-Centric] Conceptions of 'Bias', and Academia-Industry Gap
- **分类: cs.CY**

- **简介: 该论文属于AI公平性研究任务，旨在分析过去十年AI/LLM偏见研究的现状与问题。通过文献综述，发现研究多聚焦性别偏见，忽视多元群体，并存在学术与工业应用脱节。**

- **链接: [http://arxiv.org/pdf/2508.11067v1](http://arxiv.org/pdf/2508.11067v1)**

> **作者:** Sourojit Ghosh; Kyra Wilson
>
> **备注:** Upcoming Publication, AIES 2025
>
> **摘要:** The rapid development of AI tools and implementation of LLMs within downstream tasks has been paralleled by a surge in research exploring how the outputs of such AI/LLM systems embed biases, a research topic which was already being extensively explored before the era of ChatGPT. Given the high volume of research around the biases within the outputs of AI systems and LLMs, it is imperative to conduct systematic literature reviews to document throughlines within such research. In this paper, we conduct such a review of research covering AI/LLM bias in four premier venues/organizations -- *ACL, FAccT, NeurIPS, and AAAI -- published over the past 10 years. Through a coverage of 189 papers, we uncover patterns of bias research and along what axes of human identity they commonly focus. The first emergent pattern within the corpus was that 82% (155/189) papers did not establish a working definition of "bias" for their purposes, opting instead to simply state that biases and stereotypes exist that can have harmful downstream effects while establishing only mathematical and technical definition of bias. 94 of these 155 papers have been published in the past 5 years, after Blodgett et al. (2020)'s literature review with a similar finding about NLP research and recommendation to consider how such researchers should conceptualize bias, going beyond strictly technical definitions. Furthermore, we find that a large majority of papers -- 79.9% or 151/189 papers -- focus on gender bias (mostly, gender and occupation bias) within the outputs of AI systems and LLMs. By demonstrating a strong focus within the field on gender, race/ethnicity (30.2%; 57/189), age (20.6%; 39/189), religion (19.1%; 36/189) and nationality (13.2%; 25/189) bias, we document how researchers adopt a fairly narrow conception of AI bias by overlooking several non-Western communities in fairness research, as we advocate for a stronger coverage of such populations. Finally, we note that while our corpus contains several examples of innovative debiasing methods across the aforementioned aspects of human identity, only 10.6% (20/189) include recommendations for how to implement their findings or contributions in real-world AI systems or design processes. This indicates a concerning academia-industry gap, especially since many of the biases that our corpus contains several successful mitigation methods that still persist within the outputs of AI systems and LLMs commonly used today. We conclude with recommendations towards future AI/LLM fairness research, with stronger focus on diverse marginalized populations.
>
---
#### [new 005] CLMIR: A Textual Dataset for Rumor Identification and Marking
- **分类: cs.CY**

- **简介: 该论文属于谣言识别任务，解决现有数据集缺乏细粒度谣言标记的问题，构建了CLMIR数据集，可标记谣言具体内容。**

- **链接: [http://arxiv.org/pdf/2508.11138v1](http://arxiv.org/pdf/2508.11138v1)**

> **作者:** Bin Ma; Yifei Zhang; Yongjin Xian; Qi Li; Linna Zhou; Gongxun Miao
>
> **摘要:** With the rise of social media, rumor detection has drawn increasing attention. Although numerous methods have been proposed with the development of rumor classification datasets, they focus on identifying whether a post is a rumor, lacking the ability to mark the specific rumor content. This limitation largely stems from the lack of fine-grained marks in existing datasets. Constructing a rumor dataset with rumor content information marking is of great importance for fine-grained rumor identification. Such a dataset can facilitate practical applications, including rumor tracing, content moderation, and emergency response. Beyond being utilized for overall performance evaluation, this dataset enables the training of rumor detection algorithms to learn content marking, and thus improves their interpretability and reasoning ability, enabling systems to effectively address specific rumor segments. This paper constructs a dataset for rumor detection with fine-grained markings, named CLMIR (Content-Level Marking Dataset for Identifying Rumors). In addition to determining whether a post is a rumor, this dataset further marks the specific content upon which the rumor is based.
>
---
#### [new 006] Banking 2.0: The Stablecoin Banking Revolution -- How Digital Assets Are Reshaping Global Finance
- **分类: cs.ET; cs.CE; cs.CR; cs.CY; econ.GN; q-fin.EC**

- **简介: 该论文属于金融科技领域，探讨稳定币如何重塑传统银行业，解决金融系统稳定性与效率问题，分析其技术优势及市场应用。**

- **链接: [http://arxiv.org/pdf/2508.11395v1](http://arxiv.org/pdf/2508.11395v1)**

> **作者:** Kevin McNamara; Rhea Pritham Marpu
>
> **摘要:** The global financial system stands at an inflection point. Stablecoins represent the most significant evolution in banking since the abandonment of the gold standard, positioned to enable "Banking 2.0" by seamlessly integrating cryptocurrency innovation with traditional finance infrastructure. This transformation rivals artificial intelligence as the next major disruptor in the financial sector. Modern fiat currencies derive value entirely from institutional trust rather than physical backing, creating vulnerabilities that stablecoins address through enhanced stability, reduced fraud risk, and unified global transactions that transcend national boundaries. Recent developments demonstrate accelerating institutional adoption: landmark U.S. legislation including the GENIUS Act of 2025, strategic industry pivots from major players like JPMorgan's crypto-backed loan initiatives, and PayPal's comprehensive "Pay with Crypto" service. Widespread stablecoin implementation addresses critical macroeconomic imbalances, particularly the inflation-productivity gap plaguing modern monetary systems, through more robust and diversified backing mechanisms. Furthermore, stablecoins facilitate deregulation and efficiency gains, paving the way for a more interconnected international financial system. This whitepaper comprehensively explores how stablecoins are poised to reshape banking, supported by real-world examples, current market data, and analysis of their transformative potential.
>
---
#### [new 007] ToxiFrench: Benchmarking and Enhancing Language Models via CoT Fine-Tuning for French Toxicity Detection
- **分类: cs.CL; cs.AI; cs.CY; 68T50; I.2.7**

- **简介: 该论文属于法语毒性检测任务，旨在解决法语数据不足和模型效果不佳的问题。工作包括构建TOXIFRENCH数据集，发现小模型更优，并提出CoT微调方法提升性能。**

- **链接: [http://arxiv.org/pdf/2508.11281v1](http://arxiv.org/pdf/2508.11281v1)**

> **作者:** Axel Delaval; Shujian Yang; Haicheng Wang; Han Qiu; Jialiang Lu
>
> **备注:** 14 pages, 5 figures, 8 tables. This paper introduces TOXIFRENCH, a new large-scale benchmark for French toxicity detection, and proposes a Chain-of-Thought (CoT) fine-tuning method with a dynamic weighted loss. The resulting fine-tuned 4B parameter model, ToxiFrench, achieves state-of-the-art performance, outperforming larger models like GPT-4o
>
> **摘要:** Detecting toxic content using language models is crucial yet challenging. While substantial progress has been made in English, toxicity detection in French remains underdeveloped, primarily due to the lack of culturally relevant, large-scale datasets. In this work, we introduce TOXIFRENCH, a new public benchmark of 53,622 French online comments, constructed via a semi-automated annotation pipeline that reduces manual labeling to only 10% through high-confidence LLM-based pre-annotation and human verification. Then, we benchmark a broad range of models and uncover a counterintuitive insight: Small Language Models (SLMs) outperform many larger models in robustness and generalization under the toxicity detection task. Motivated by this finding, we propose a novel Chain-of-Thought (CoT) fine-tuning strategy using a dynamic weighted loss that progressively emphasizes the model's final decision, significantly improving faithfulness. Our fine-tuned 4B model achieves state-of-the-art performance, improving its F1 score by 13% over its baseline and outperforming LLMs such as GPT-40 and Gemini-2.5. Further evaluation on a cross-lingual toxicity benchmark demonstrates strong multilingual ability, suggesting that our methodology can be effectively extended to other languages and safety-critical classification tasks.
>
---
#### [new 008] Speciesism in AI: Evaluating Discrimination Against Animals in Large Language Models
- **分类: cs.CL; cs.CY**

- **简介: 该论文属于AI伦理研究任务，探讨大语言模型中的物种歧视问题，分析其对非人类动物的态度与道德判断，旨在揭示并减少AI系统中的物种偏见。**

- **链接: [http://arxiv.org/pdf/2508.11534v1](http://arxiv.org/pdf/2508.11534v1)**

> **作者:** Monika Jotautaitė; Lucius Caviola; David A. Brewster; Thilo Hagendorff
>
> **摘要:** As large language models (LLMs) become more widely deployed, it is crucial to examine their ethical tendencies. Building on research on fairness and discrimination in AI, we investigate whether LLMs exhibit speciesist bias -- discrimination based on species membership -- and how they value non-human animals. We systematically examine this issue across three paradigms: (1) SpeciesismBench, a 1,003-item benchmark assessing recognition and moral evaluation of speciesist statements; (2) established psychological measures comparing model responses with those of human participants; (3) text-generation tasks probing elaboration on, or resistance to, speciesist rationalizations. In our benchmark, LLMs reliably detected speciesist statements but rarely condemned them, often treating speciesist attitudes as morally acceptable. On psychological measures, results were mixed: LLMs expressed slightly lower explicit speciesism than people, yet in direct trade-offs they more often chose to save one human over multiple animals. A tentative interpretation is that LLMs may weight cognitive capacity rather than species per se: when capacities were equal, they showed no species preference, and when an animal was described as more capable, they tended to prioritize it over a less capable human. In open-ended text generation tasks, LLMs frequently normalized or rationalized harm toward farmed animals while refusing to do so for non-farmed animals. These findings suggest that while LLMs reflect a mixture of progressive and mainstream human views, they nonetheless reproduce entrenched cultural norms around animal exploitation. We argue that expanding AI fairness and alignment frameworks to explicitly include non-human moral patients is essential for reducing these biases and preventing the entrenchment of speciesist attitudes in AI systems and the societies they influence.
>
---
#### [new 009] Online Anti-sexist Speech: Identifying Resistance to Gender Bias in Political Discourse
- **分类: cs.CL; cs.CY**

- **链接: [http://arxiv.org/pdf/2508.11434v1](http://arxiv.org/pdf/2508.11434v1)**

> **作者:** Aditi Dutta; Susan Banducci
>
> **摘要:** Anti-sexist speech, i.e., public expressions that challenge or resist gendered abuse and sexism, plays a vital role in shaping democratic debate online. Yet automated content moderation systems, increasingly powered by large language models (LLMs), may struggle to distinguish such resistance from the sexism it opposes. This study examines how five LLMs classify sexist, anti-sexist, and neutral political tweets from the UK, focusing on high-salience trigger events involving female Members of Parliament in the year 2022. Our analysis show that models frequently misclassify anti-sexist speech as harmful, particularly during politically charged events where rhetorical styles of harm and resistance converge. These errors risk silencing those who challenge sexism, with disproportionate consequences for marginalised voices. We argue that moderation design must move beyond binary harmful/not-harmful schemas, integrate human-in-the-loop review during sensitive events, and explicitly include counter-speech in training data. By linking feminist scholarship, event-based analysis, and model evaluation, this work highlights the sociotechnical challenges of safeguarding resistance speech in digital political spaces.
>
---
#### [new 010] Element and Everything Tokens: Two-Tier Architecture for Mobilizing Alternative Assets
- **分类: cs.DC; cs.CY**

- **简介: 该论文属于资产证券化任务，旨在解决传统框架下替代资产流动性差的问题。提出双层代币架构，通过Element和Everything Tokens实现资产的分拆与整合交易。**

- **链接: [http://arxiv.org/pdf/2508.11266v1](http://arxiv.org/pdf/2508.11266v1)**

> **作者:** Ailiya Borjigin; Cong He; Charles CC Lee; Wei Zhou
>
> **备注:** 8 Pages, Submitted to RASSE 2025
>
> **摘要:** Alternative assets such as mines, power plants, or infrastructure projects are often large, heterogeneous bundles of resources, rights, and outputs whose value is difficult to trade or fractionalize under traditional frameworks. This paper proposes a novel two-tier tokenization architecture to enhance the liquidity and transparency of such complex assets. We introduce the concepts of Element Tokens and Everything Tokens: elemental tokens represent standardized, fully collateralized components of an asset (e.g., outputs, rights, or credits), while an everything token represents the entire asset as a fixed combination of those elements. The architecture enables both fine-grained partial ownership and integrated whole-asset ownership through a system of two-way convertibility. We detail the design and mechanics of this system, including an arbitrage mechanism that keeps the price of the composite token aligned with the net asset value of its constituents. Through illustrative examples in the energy and industrial sectors, we demonstrate that our approach allows previously illiquid, high-value projects to be fractionalized and traded akin to stocks or exchange-traded funds (ETFs). We discuss the benefits for investors and asset owners, such as lower entry barriers, improved price discovery, and flexible financing, as well as the considerations for implementation and regulation.
>
---
#### [new 011] Retrieval-augmented reasoning with lean language models
- **分类: cs.CL; cs.AI; cs.CY**

- **简介: 该论文属于自然语言处理任务，旨在解决资源受限环境下高效、隐私保护的问答问题。通过结合检索与推理，使用轻量模型实现高精度回答。**

- **链接: [http://arxiv.org/pdf/2508.11386v1](http://arxiv.org/pdf/2508.11386v1)**

> **作者:** Ryan Sze-Yin Chan; Federico Nanni; Tomas Lazauskas; Rosie Wood; Penelope Yong; Lionel Tarassenko; Mark Girolami; James Geddes; Andrew Duncan
>
> **摘要:** This technical report details a novel approach to combining reasoning and retrieval augmented generation (RAG) within a single, lean language model architecture. While existing RAG systems typically rely on large-scale models and external APIs, our work addresses the increasing demand for performant and privacy-preserving solutions deployable in resource-constrained or secure environments. Building on recent developments in test-time scaling and small-scale reasoning models, we develop a retrieval augmented conversational agent capable of interpreting complex, domain-specific queries using a lightweight backbone model. Our system integrates a dense retriever with fine-tuned Qwen2.5-Instruct models, using synthetic query generation and reasoning traces derived from frontier models (e.g., DeepSeek-R1) over a curated corpus, in this case, the NHS A-to-Z condition pages. We explore the impact of summarisation-based document compression, synthetic data design, and reasoning-aware fine-tuning on model performance. Evaluation against both non-reasoning and general-purpose lean models demonstrates that our domain-specific fine-tuning approach yields substantial gains in answer accuracy and consistency, approaching frontier-level performance while remaining feasible for local deployment. All implementation details and code are publicly released to support reproducibility and adaptation across domains.
>
---
#### [new 012] How do Data Journalists Design Maps to Tell Stories?
- **分类: cs.HC; cs.CY**

- **简介: 该论文属于数据新闻任务，研究新闻地图设计过程。解决数据记者如何平衡设计与传播的问题，通过分析462张地图和访谈，构建了地图设计空间。**

- **链接: [http://arxiv.org/pdf/2508.10903v1](http://arxiv.org/pdf/2508.10903v1)**

> **作者:** Arlindo Gomes; Emilly Brito; Luis Morais; Nivan Ferreira
>
> **备注:** IEEE VIS 2025
>
> **摘要:** Maps are essential to news media as they provide a familiar way to convey spatial context and present engaging narratives. However, the design of journalistic maps may be challenging, as editorial teams need to balance multiple aspects, such as aesthetics, the audience's expected data literacy, tight publication deadlines, and the team's technical skills. Data journalists often come from multiple areas and lack a cartography, data visualization, and data science background, limiting their competence in creating maps. While previous studies have examined spatial visualizations in data stories, this research seeks to gain a deeper understanding of the map design process employed by news outlets. To achieve this, we strive to answer two specific research questions: what is the design space of journalistic maps? and how do editorial teams produce journalistic map articles? To answer the first one, we collected and analyzed a large corpus of 462 journalistic maps used in news articles from five major news outlets published over three months. As a result, we created a design space comprised of eight dimensions that involved both properties describing the articles' aspects and the visual/interactive features of maps. We approach the second research question via semi-structured interviews with four data journalists who create data-driven articles daily. Through these interviews, we identified the most common design rationales made by editorial teams and potential gaps in current practices. We also collected the practitioners' feedback on our design space to externally validate it. With these results, we aim to provide researchers and journalists with empirical data to design and study journalistic maps.
>
---
#### [new 013] Group Fairness Meets the Black Box: Enabling Fair Algorithms on Closed LLMs via Post-Processing
- **分类: cs.LG; cs.CL; cs.CY**

- **简介: 该论文属于公平性学习任务，解决在封闭大模型上实现群体公平的问题。通过提示工程提取特征并训练轻量公平分类器，提升模型公平性与效率。**

- **链接: [http://arxiv.org/pdf/2508.11258v1](http://arxiv.org/pdf/2508.11258v1)**

> **作者:** Ruicheng Xian; Yuxuan Wan; Han Zhao
>
> **摘要:** Instruction fine-tuned large language models (LLMs) enable a simple zero-shot or few-shot prompting paradigm, also known as in-context learning, for building prediction models. This convenience, combined with continued advances in LLM capability, has the potential to drive their adoption across a broad range of domains, including high-stakes applications where group fairness -- preventing disparate impacts across demographic groups -- is essential. The majority of existing approaches to enforcing group fairness on LLM-based classifiers rely on traditional fair algorithms applied via model fine-tuning or head-tuning on final-layer embeddings, but they are no longer applicable to closed-weight LLMs under the in-context learning setting, which include some of the most capable commercial models today, such as GPT-4, Gemini, and Claude. In this paper, we propose a framework for deriving fair classifiers from closed-weight LLMs via prompting: the LLM is treated as a feature extractor, and features are elicited from its probabilistic predictions (e.g., token log probabilities) using prompts strategically designed for the specified fairness criterion to obtain sufficient statistics for fair classification; a fair algorithm is then applied to these features to train a lightweight fair classifier in a post-hoc manner. Experiments on five datasets, including three tabular ones, demonstrate strong accuracy-fairness tradeoffs for the classifiers derived by our framework from both open-weight and closed-weight LLMs; in particular, our framework is data-efficient and outperforms fair classifiers trained on LLM embeddings (i.e., head-tuning) or from scratch on raw tabular features.
>
---
#### [new 014] Multimodal Quantitative Measures for Multiparty Behaviour Evaluation
- **分类: cs.HC; cs.AI; cs.CY; cs.MA**

- **链接: [http://arxiv.org/pdf/2508.10916v1](http://arxiv.org/pdf/2508.10916v1)**

> **作者:** Ojas Shirekar; Wim Pouw; Chenxu Hao; Vrushank Phadnis; Thabo Beeler; Chirag Raman
>
> **摘要:** Digital humans are emerging as autonomous agents in multiparty interactions, yet existing evaluation metrics largely ignore contextual coordination dynamics. We introduce a unified, intervention-driven framework for objective assessment of multiparty social behaviour in skeletal motion data, spanning three complementary dimensions: (1) synchrony via Cross-Recurrence Quantification Analysis, (2) temporal alignment via Multiscale Empirical Mode Decompositionbased Beat Consistency, and (3) structural similarity via Soft Dynamic Time Warping. We validate metric sensitivity through three theory-driven perturbations -- gesture kinematic dampening, uniform speech-gesture delays, and prosodic pitch-variance reduction-applied to $\approx 145$ 30-second thin slices of group interactions from the DnD dataset. Mixed-effects analyses reveal predictable, joint-independent shifts: dampening increases CRQA determinism and reduces beat consistency, delays weaken cross-participant coupling, and pitch flattening elevates F0 Soft-DTW costs. A complementary perception study ($N=27$) compares judgments of full-video and skeleton-only renderings to quantify representation effects. Our three measures deliver orthogonal insights into spatial structure, timing alignment, and behavioural variability. Thereby forming a robust toolkit for evaluating and refining socially intelligent agents. Code available on \href{https://github.com/tapri-lab/gig-interveners}{GitHub}.
>
---
#### [new 015] Uncovering Latent Connections in Indigenous Heritage: Semantic Pipelines for Cultural Preservation in Brazil
- **分类: cs.HC; cs.CY; cs.LG; I.2.m**

- **简介: 该论文属于文化保护任务，旨在解决 indigenous 文化遗产的保存与访问问题。通过构建视觉和文本语义管道，利用AI增强文化资源的探索与理解。**

- **链接: [http://arxiv.org/pdf/2508.10911v1](http://arxiv.org/pdf/2508.10911v1)**

> **作者:** Luis Vitor Zerkowski; Nina S. T. Hirata
>
> **备注:** 8 tables, 7 figures, submitted to AAAI2026
>
> **摘要:** Indigenous communities face ongoing challenges in preserving their cultural heritage, particularly in the face of systemic marginalization and urban development. In Brazil, the Museu Nacional dos Povos Indigenas through the Tainacan platform hosts the country's largest online collection of Indigenous objects and iconographies, providing a critical resource for cultural engagement. Using publicly available data from this repository, we present a data-driven initiative that applies artificial intelligence to enhance accessibility, interpretation, and exploration. We develop two semantic pipelines: a visual pipeline that models image-based similarity and a textual pipeline that captures semantic relationships from item descriptions. These embedding spaces are projected into two dimensions and integrated into an interactive visualization tool we also developed. In addition to similarity-based navigation, users can explore the collection through temporal and geographic lenses, enabling both semantic and contextualized perspectives. The system supports curatorial tasks, aids public engagement, and reveals latent connections within the collection. This work demonstrates how AI can ethically contribute to cultural preservation practices.
>
---
#### [new 016] Predicting and Explaining Traffic Crash Severity Through Crash Feature Selection
- **分类: cs.LG; cs.CY**

- **简介: 该论文属于交通事故严重性预测任务，旨在识别影响事故严重性的关键因素。通过AutoML和SHAP方法进行特征选择与模型解释，构建了高精度的预测模型，并提出了可解释的交通安全管理框架。**

- **链接: [http://arxiv.org/pdf/2508.11504v1](http://arxiv.org/pdf/2508.11504v1)**

> **作者:** Andrea Castellani; Zacharias Papadovasilakis; Giorgos Papoutsoglou; Mary Cole; Brian Bautsch; Tobias Rodemann; Ioannis Tsamardinos; Angela Harden
>
> **备注:** Preprint. Manuscript under review at "Accident Analysis & Prevention" journal
>
> **摘要:** Motor vehicle crashes remain a leading cause of injury and death worldwide, necessitating data-driven approaches to understand and mitigate crash severity. This study introduces a curated dataset of more than 3 million people involved in accidents in Ohio over six years (2017-2022), aggregated to more than 2.3 million vehicle-level records for predictive analysis. The primary contribution is a transparent and reproducible methodology that combines Automated Machine Learning (AutoML) and explainable artificial intelligence (AI) to identify and interpret key risk factors associated with severe crashes. Using the JADBio AutoML platform, predictive models were constructed to distinguish between severe and non-severe crash outcomes. The models underwent rigorous feature selection across stratified training subsets, and their outputs were interpreted using SHapley Additive exPlanations (SHAP) to quantify the contribution of individual features. A final Ridge Logistic Regression model achieved an AUC-ROC of 85.6% on the training set and 84.9% on a hold-out test set, with 17 features consistently identified as the most influential predictors. Key features spanned demographic, environmental, vehicle, human, and operational categories, including location type, posted speed, minimum occupant age, and pre-crash action. Notably, certain traditionally emphasized factors, such as alcohol or drug impairment, were less influential in the final model compared to environmental and contextual variables. Emphasizing methodological rigor and interpretability over mere predictive performance, this study offers a scalable framework to support Vision Zero with aligned interventions and advanced data-informed traffic safety policy.
>
---
#### [new 017] Designing for Engaging Communication Between Parents and Young Adult Children Through Shared Music Experiences
- **分类: cs.HC; cs.CY**

- **简介: 该论文属于人机交互任务，旨在解决异地父母与成年子女沟通不足的问题。通过开发DJ-Fam应用，促进音乐共享和对话，增强互动与理解。**

- **链接: [http://arxiv.org/pdf/2508.10907v1](http://arxiv.org/pdf/2508.10907v1)**

> **作者:** Euihyeok Lee; Souneil Park; Jin Yu; Seungchul Lee; Seungwoo Kang
>
> **摘要:** This paper aims to foster social interaction between parents and young adult children living apart via music. Our approach transforms their music-listening moment into an opportunity to listen to the other's favorite songs and enrich interaction in their daily lives. To this end, we explore the current practice and needs of parent-child communication and the experience and perception of music-mediated interaction. Based on the findings, we developed DJ-Fam, a mobile application that enables parents and children to listen to their favorite songs and use them as conversation starters to foster parent-child interaction. From our deployment study with seven families over four weeks in South Korea, we show the potential of DJ-Fam to influence parent-child interaction and their mutual understanding and relationship positively. Specifically, DJ-Fam considerably increases the frequency of communication and diversifies the communication channels and topics, all of which are satisfactory to the participants.
>
---
## 更新

#### [replaced 001] Audit Cards: Contextualizing AI Evaluations
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2504.13839v2](http://arxiv.org/pdf/2504.13839v2)**

> **作者:** Leon Staufer; Mick Yang; Anka Reuel; Stephen Casper
>
> **摘要:** AI governance frameworks increasingly rely on audits, yet the results of their underlying evaluations require interpretation and context to be meaningfully informative. Even technically rigorous evaluations can offer little useful insight if reported selectively or obscurely. Current literature focuses primarily on technical best practices, but evaluations are an inherently sociotechnical process, and there is little guidance on reporting procedures and context. Through literature review, stakeholder interviews, and analysis of governance frameworks, we propose "audit cards" to make this context explicit. We identify six key types of contextual features to report and justify in audit cards: auditor identity, evaluation scope, methodology, resource access, process integrity, and review mechanisms. Through analysis of existing evaluation reports, we find significant variation in reporting practices, with most reports omitting crucial contextual information such as auditors' backgrounds, conflicts of interest, and the level and type of access to models. We also find that most existing regulations and frameworks lack guidance on rigorous reporting. In response to these shortcomings, we argue that audit cards can provide a structured format for reporting key claims alongside their justifications, enhancing transparency, facilitating proper interpretation, and establishing trust in reporting.
>
---
#### [replaced 002] Google's Chrome Antitrust Paradox
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2406.11856v3](http://arxiv.org/pdf/2406.11856v3)**

> **作者:** Shaoor Munir; Konrad Kollnig; Anastasia Shuba; Zubair Shafiq
>
> **备注:** Published in Vanderbilt Journal of Entertainment & Technology Law, Vol. 27, No. 3, pp. 419-521 (2025) 103 pages
>
> **摘要:** This Article examines Google's dominance of the browser market, highlighting how Google's Chrome browser plays a critical role in reinforcing Google's dominance in other markets. While Google portrays Chrome as a neutral platform built on open-source technologies, this Article shows that Chrome is instrumental in Google's strategy to reinforce its dominance in the online advertising, publishing, and browser markets. The examination of Google's strategic acquisitions, anticompetitive practices, and implementation of so-called "privacy controls" underlines that Chrome is far from a neutral gateway to the web. Rather, it serves as a key tool for Google to maintain and extend its market power, often to the detriment of competition and innovation in the digital economy. This Article illustrates how Chrome not only bolsters Google's position in online advertising and publishing through practices such as coercion and self-preferencing, but also leverages its advertising clout to engage in a "pay-to-play" paradigm--the cornerstone of Google's larger strategy of market control. It also outlines potential regulatory interventions and remedies by drawing on historical antitrust precedents. Lastly, this Article proposes a triad of solutions motivated by an analysis of Google's abuse of Chrome, including behavioral remedies targeting specific anticompetitive practices, structural remedies involving an internal separation of Google's divisions, and divestiture of Chrome from Google into an independent organization. (Abstract abridged for arXiv. Full abstract available in published version.)
>
---
#### [replaced 003] From Autonomy to Agency: Agentic Vehicles for Human-Centered Mobility Systems
- **分类: cs.CY; cs.CE; cs.CL; cs.HC; cs.RO**

- **链接: [http://arxiv.org/pdf/2507.04996v3](http://arxiv.org/pdf/2507.04996v3)**

> **作者:** Jiangbo Yu
>
> **摘要:** Autonomy, from the Greek autos (self) and nomos (law), refers to the capacity to operate according to internal rules without external control. Accordingly, autonomous vehicles (AuVs) are viewed as vehicular systems capable of perceiving their environment and executing pre-programmed tasks independently of external input. However, both research and real-world deployments increasingly showcase vehicles that demonstrate behaviors beyond this definition (including the SAE levels 0 to 5); Examples of this outpace include the interaction with humans with natural language, goal adaptation, contextual reasoning, external tool use, and unseen ethical dilemma handling, largely empowered by multi-modal large language models (LLMs). These developments reveal a conceptual gap between technical autonomy and the broader cognitive and social capabilities needed for future human-centered mobility systems. To address this gap, this paper introduces the concept of agentic vehicles (AgVs), referring to vehicles that integrate agentic AI systems to reason, adapt, and interact within complex environments. This paper proposes the term AgVs and their distinguishing characteristics from conventional AuVs. It synthesizes relevant advances in integrating LLMs and AuVs and highlights how AgVs might transform future mobility systems and ensure the systems are human-centered. The paper concludes by identifying key challenges in the development and governance of AgVs, and how they can play a significant role in future agentic transportation systems.
>
---
#### [replaced 004] Dead Zone of Accountability: Why Social Claims in Machine Learning Research Should Be Articulated and Defended
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2508.08739v3](http://arxiv.org/pdf/2508.08739v3)**

> **作者:** Tianqi Kou; Dana Calacci; Cindy Lin
>
> **备注:** Forthcoming in AIES 2025
>
> **摘要:** Many Machine Learning research studies use language that describes potential social benefits or technical affordances of new methods and technologies. Such language, which we call "social claims", can help garner substantial resources and influence for those involved in ML research and technology production. However, there exists a gap between social claims and reality (the claim-reality gap): ML methods often fail to deliver the claimed functionality or social impacts. This paper investigates the claim-reality gap and makes a normative argument for developing accountability mechanisms for it. In making the argument, we make three contributions. First, we show why the symptom - absence of social claim accountability - is problematic. Second, we coin dead zone of accountability - a lens that scholars and practitioners can use to identify opportunities for new forms of accountability. We apply this lens to the claim-reality gap and provide a diagnosis by identifying cognitive and structural resistances to accountability in the claim-reality gap. Finally, we offer a prescription - two potential collaborative research agendas that can help create the condition for social claim accountability.
>
---
