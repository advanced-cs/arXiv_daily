# 计算机与社会 cs.CY

- **最新发布 36 篇**

- **更新 26 篇**

## 最新发布

#### [new 001] Patterns in the Transition From Founder-Leadership to Community Governance of Open Source
- **分类: cs.CY; cs.AI; cs.CL**

- **简介: 该论文研究开源项目从创始人领导向社区治理的转变过程。通过分析GitHub上的637个仓库，提取并聚类治理文件中的角色、行为和规范线索，揭示了治理结构随时间扩展与细化的模式。任务是构建可扩展的治理发展追踪方法，解决社区治理成功因素不清的问题。**

- **链接: [http://arxiv.org/pdf/2509.16295v1](http://arxiv.org/pdf/2509.16295v1)**

> **作者:** Mobina Noori; Mahasweta Chakraborti; Amy X Zhang; Seth Frey
>
> **摘要:** Open digital public infrastructure needs community management to ensure accountability, sustainability, and robustness. Yet open-source projects often rely on centralized decision-making, and the determinants of successful community management remain unclear. We analyze 637 GitHub repositories to trace transitions from founder-led to shared governance. Specifically, we document trajectories to community governance by extracting institutional roles, actions, and deontic cues from version-controlled project constitutions GOVERNANCE.md. With a semantic parsing pipeline, we cluster elements into broader role and action types. We find roles and actions grow, and regulation becomes more balanced, reflecting increases in governance scope and differentiation over time. Rather than shifting tone, communities grow by layering and refining responsibilities. As transitions to community management mature, projects increasingly regulate ecosystem-level relationships and add definition to project oversight roles. Overall, this work offers a scalable pipeline for tracking the growth and development of community governance regimes from open-source software's familiar default of founder-ownership.
>
---
#### [new 002] An Automated Framework for Assessing Electric Vehicle Charging Impacts on a Campus Distribution Grid
- **分类: cs.CY**

- **简介: 该论文提出一个自动化框架，用于评估电动汽车充电对校园配电网的影响。属于电力系统分析任务，旨在解决EV普及带来的电网压力问题。工作包括构建集成Julia与PowerWorld的仿真平台，并利用真实数据进行动态模拟与分析。**

- **链接: [http://arxiv.org/pdf/2509.16218v1](http://arxiv.org/pdf/2509.16218v1)**

> **作者:** Mohammadreza Iranpour; Sammy Hamed; Mohammad Rasoul Narimani; Silvia Carpitella; Kourosh Sedghisigarchi; Xudong Jia
>
> **摘要:** This paper introduces a unified and automated framework designed to dynamically assess the impact of electric vehicle (EV) charging on distribution feeders and transformers at California State University, Northridge (CSUN). As EV adoption accelerates, the resulting increase in charging demand imposes additional stress on local power distribution systems. Moreover, the evolving nature of EV load profiles throughout the day necessitates detailed temporal analysis to identify peak loading conditions, anticipate worst-case scenarios, and plan timely infrastructure upgrades. Our main contribution is the development of a flexible testbed that integrates Julia, a high-performance programming language for technical computing, with PowerWorld Simulator via the EasySimauto.jl package. This integration enables seamless modeling, simulation, and analysis of EV charging load profiles and their implications for campus grid infrastructure. The framework leverages a real-world dataset collected from CSUN's EV charging stations, consisting of 15-minute interval measurements over the course of one year. By coupling high-resolution data with dynamic simulations, the proposed system offers a valuable tool for evaluating transformer loading, feeder utilization, and overall system stress. The results support data-driven decision-making for EV infrastructure deployment, load forecasting, and energy management strategies. In addition, the framework allows for scenario-based studies to explore the impact of future increases in EV penetration or changes in charging behavior. Its modular architecture also makes it adaptable to other campus or urban distribution systems facing similar electrification challenges.
>
---
#### [new 003] Tracing the Techno-Supremacy Doctrine: A Critical Discourse Analysis of the AI Executive Elite
- **分类: cs.CY**

- **简介: 该论文通过批判性话语分析，研究AI精英群体中“技术至上主义”（TSD）的言论模式，旨在揭示其对AI发展的影响，并提供识别TSD的分析工具，以促进公众与政策制定者的批判性思考。**

- **链接: [http://arxiv.org/pdf/2509.18079v1](http://arxiv.org/pdf/2509.18079v1)**

> **作者:** Héctor Pérez-Urbina
>
> **备注:** This research is based on the author's dissertation for the MSt in AI Ethics and Society program at the University of Cambridge
>
> **摘要:** This paper critically analyzes the discourse of the 'AI executive elite,' a group of highly influential individuals shaping the way AI is funded, developed, and deployed worldwide. The primary objective is to examine the presence and dynamics of the 'Techno-Supremacy Doctrine' (TSD), a term introduced in this study to describe a belief system characterized by an excessive trust in technology's alleged inherent superiority in solving complex societal problems. This study integrates quantitative heuristics with in-depth qualitative investigations. Its methodology is operationalized in a two-phase critical discourse analysis of 14 texts published by elite members between 2017 and 2025. The findings demonstrate that the elite is not a monolithic bloc but exhibits a broad spectrum of stances. The discourse is highly dynamic, showing a marked polarization and general increase in pro-TSD discourse following the launch of ChatGPT. The analysis identifies key discursive patterns, including a dominant pro-TSD narrative that combines utopian promises with claims of inevitable progress, and the common tactic of acknowledging risks only as a strategic preamble to proposing further technological solutions. This paper presents TSD as a comprehensive analytical framework and provides a 'diagnostic toolkit' for identifying its manifestations, from insidious to benign. It argues that fostering critical awareness of these discursive patterns is essential for AI practitioners, policymakers, and the public to actively navigate the future of AI.
>
---
#### [new 004] Exploring AI Capabilities in Participatory Budgeting within Smart Cities: The Case of Sao Paulo
- **分类: cs.CY; cs.AI**

- **简介: 该论文研究AI在智慧城市的参与式预算中的应用，以圣保罗为例，探讨AI如何提升在线政治参与度，分析政府实施AI工具所需的能力与挑战，旨在理解技术如何重塑参与式治理机制。**

- **链接: [http://arxiv.org/pdf/2509.16724v1](http://arxiv.org/pdf/2509.16724v1)**

> **作者:** Italo Alberto Sousa; Mariana Carvalho da Silva; Jorge Machado; José Carlos Vaz
>
> **备注:** 22 pages, Presented at 28th IPSA World Congress of Political Science, Seoul 2025
>
> **摘要:** This research examines how Artificial Intelligence (AI) can improve participatory budgeting processes within smart cities. In response to challenges like declining civic participation and resource allocation conflicts, the study explores how online political participation can be improved by AI. It investigates the state capacity governments need to implement AI-enhanced participatory tools, considering technological dependencies and vulnerabilities. It analyzes technological and administrative structures, actors, interests, and strategies to understand the dynamics of online political participation technologies in the case of Sao Paulo, Brazil. The study contributes to understanding how technological advancements can reshape participatory budgeting processes. In a broader sense, the research highlights how AI can transform participatory institutions by offering new tools for citizens and also for government officials in charge of participatory processes within smart cities.
>
---
#### [new 005] Socratic Mind: Impact of a Novel GenAI-Powered Assessment Tool on Student Learning and Higher-Order Thinking
- **分类: cs.CY; cs.AI**

- **简介: 该论文研究了一种基于生成式AI的评估工具Socratic Mind对学生学习和高阶思维的影响。通过混合方法实验，分析了学生参与度、用户体验与学习成果的关系。结果表明，该工具显著提升了学习效果和高阶思维能力，尤其对基础较弱学生帮助较大。**

- **链接: [http://arxiv.org/pdf/2509.16262v1](http://arxiv.org/pdf/2509.16262v1)**

> **作者:** Jeonghyun Lee; Jui-Tse Hung; Meryem Yilmaz Soylu; Diana Popescu; Christopher Zhang Cui; Gayane Grigoryan; David A Joyner; Stephen W Harmon
>
> **摘要:** This study examines the impact of Socratic Mind, a Generative Artificial Intelligence (GenAI) powered formative assessment tool that employs Socratic questioning to support student learning in a large, fully online undergraduate-level computing course. Employing a quasi-experimental, mixed-methods design, we investigated participants' engagement patterns, the influence of user experience on engagement, and impacts on both perceived and actual learning outcomes. Data were collected from the system logs, surveys on user experience and perceived engagement and learning gains, student reflections, and course performance data. Results indicated that participants consistently reported high levels of affective, behavioral, and cognitive engagement, and these were strongly linked to positive user experiences and perceived learning outcomes. Quantitative analysis further revealed that students who engaged with the GenAI tool experienced significant gains in their quiz scores compared to those who did not, particularly benefiting students with lower baseline achievement. Additionally, thematic analysis of qualitative feedback revealed substantial perceived improvements in higher-order thinking skills, including problem solving, critical thinking, and self-reflection. Our findings highlight the promise of AI-mediated dialogue in fostering deeper engagement and higher-order cognitive skills. As higher education institutions expand GenAI integration in curriculum, this dialogic, GenAI powered assessment tool can offer a scalable strategy to promote students' meaningful learning outcomes.
>
---
#### [new 006] A Scalable and Interoperable Platform for Transforming Building Information with Brick Ontology
- **分类: cs.CY; eess.SP**

- **简介: 该论文提出一个基于Brick本体的平台，用于建筑信息的转换与管理。任务是解决建筑自动化中的可扩展性和互操作性问题。工作包括构建半自动化的平台，利用图结构和Brick本体实现数据转换与数字孪生应用，提升建筑信息管理效率与安全性。**

- **链接: [http://arxiv.org/pdf/2509.16259v1](http://arxiv.org/pdf/2509.16259v1)**

> **作者:** Rozita Teymourzadeh; Yuya Nakazawa
>
> **摘要:** In the digital twin and building information era, many building automation companies searched for scalable methods to extract and analyze different building data, including Internet of Things (IoT) sensors, actuators, layout sections, zones, etc. The necessity for engineers to continuously manage the entire process for each new building creates scalability challenges. Furthermore, because construction information is sensitive, transferring data on vendor platforms via the cloud creates problems. This paper introduces a platform designed to address some of the common challenges in building automation. This is a smart platform designed for the transformation of building information into Brick ontology (Brick 2020) and graph formats. This technology makes it easy to retrieve historical data and converts the building point list into a Brick schema model for use in digital twin applications. The overarching goal of the proposed platform development is semi-automate the process while offering adaptability to various building configurations. This platform uses Brick schema and graph data structure techniques to minimize complexity, offering a semi-automated approach through its use of a tree-based graph structure. Moreover, the integration of Brick ontology creates a common language for interoperability and improves building information management. The seamless and offline integration of historical data within the developed platform minimizes data security risks when handling building information.
>
---
#### [new 007] Comparative Analysis of STEM and non-STEM Teachers' Needs for Integrating AI into Educational Environments
- **分类: cs.CY; cs.AI; cs.HC; I.2.1; I.2.4; K.3.1; H.5.2**

- **简介: 该论文属于教育技术研究任务，旨在解决编程平台在AI功能和跨学科适应性上的不足。通过访谈8名K-12教师，分析STEM与非STEM教师在评估、资源开发和学生监控中的AI需求差异，提出改进平台的AI增强功能建议。**

- **链接: [http://arxiv.org/pdf/2509.16276v1](http://arxiv.org/pdf/2509.16276v1)**

> **作者:** Bahare Riahi; Veronica Catete
>
> **备注:** 16 pages, 3 figures, Published in HCII 2025 Conference Proceedings
>
> **摘要:** There is an increasing imperative to integrate programming platforms within AI frameworks to enhance educational tasks for both teachers and students. However, commonly used platforms such as Code.org, Scratch, and Snap fall short of providing the desired AI features and lack adaptability for interdisciplinary applications. This study explores how educational platforms can be improved by incorporating AI and analytics features to create more effective learning environments across various subjects and domains. We interviewed 8 K-12 teachers and asked their practices and needs while using any block-based programming (BBP) platform in their classes. We asked for their approaches in assessment, course development and expansion of resources, and student monitoring in their classes. Thematic analysis of the interview transcripts revealed both commonalities and differences in the AI tools needed between the STEM and non-STEM groups. Our results indicated advanced AI features that could promote BBP platforms. Both groups stressed the need for integrity and plagiarism checks, AI adaptability, customized rubrics, and detailed feedback in assessments. Non-STEM teachers also emphasized the importance of creative assignments and qualitative assessments. Regarding resource development, both AI tools desired for updating curricula, tutoring libraries, and generative AI features. Non-STEM teachers were particularly interested in supporting creative endeavors, such as art simulations. For student monitoring, both groups prioritized desktop control, daily tracking, behavior monitoring, and distraction prevention tools. Our findings identify specific AI-enhanced features needed by K-12 teachers across various disciplines and lay the foundation for creating more efficient, personalized, and engaging educational experiences.
>
---
#### [new 008] Balancing Innovation and Oversight: AI in the U.S. Treasury and IRS: A Survey
- **分类: cs.CY**

- **简介: 该论文调查了美国财政部和IRS如何应用AI技术现代化税务管理，重点包括AI在税收支持、效率提升和欺诈检测中的应用，并探讨其治理措施。任务是平衡技术创新与监管，解决系统老化与合规问题。**

- **链接: [http://arxiv.org/pdf/2509.16294v1](http://arxiv.org/pdf/2509.16294v1)**

> **作者:** Sohail Shaikh
>
> **备注:** 4 pages
>
> **摘要:** This paper explores how the U.S. Department of Treasury, particularly the Internal Revenue Service (IRS), is adopting artificial intelligence (AI) to modernize tax administration. Using publicly available information, the survey highlights the applications of AI for taxpayer support, operational efficiency, fraud detection, and audit optimization. Key initiatives include AI-powered chatbots, robotic process automation, machine learning for case selection, and advanced analytics for fraud prevention. These technologies aim to reduce errors, improve efficiency, and improve taxpayer experiences. At the same time, the IRS is implementing governance measures to ensure responsible use of AI, including privacy safeguards, transparency initiatives, and oversight mechanisms. The analysis shows that the Treasury AI strategy balances technological innovation with legal compliance, confidentiality, and public trust, reflecting a wider effort to modernize aging systems while maintaining accountability in tax collection and enforcement.
>
---
#### [new 009] The Narcissus Hypothesis:Descending to the Rung of Illusion
- **分类: cs.CY; cs.AI; cs.HC; cs.LG**

- **简介: 该论文提出“ narcissus 假设”，探讨模型通过人类反馈和生成数据递归对齐，导致社会期望偏差，削弱客观推理能力。研究测试了31个模型，并提出新的认知解释框架。属于模型对齐与偏见分析任务。**

- **链接: [http://arxiv.org/pdf/2509.17999v1](http://arxiv.org/pdf/2509.17999v1)**

> **作者:** Riccardo Cadei; Christian Internò
>
> **摘要:** Modern foundational models increasingly reflect not just world knowledge, but patterns of human preference embedded in their training data. We hypothesize that recursive alignment-via human feedback and model-generated corpora-induces a social desirability bias, nudging models to favor agreeable or flattering responses over objective reasoning. We refer to it as the Narcissus Hypothesis and test it across 31 models using standardized personality assessments and a novel Social Desirability Bias score. Results reveal a significant drift toward socially conforming traits, with profound implications for corpus integrity and the reliability of downstream inferences. We then offer a novel epistemological interpretation, tracing how recursive bias may collapse higher-order reasoning down Pearl's Ladder of Causality, culminating in what we refer to as the Rung of Illusion.
>
---
#### [new 010] Tenure Under Pressure: Simulating the Disruptive Effects of AI on Academic Publishing
- **分类: cs.CY; cs.HC; econ.GN; q-fin.EC**

- **简介: 该论文通过模拟研究AI对学术出版的影响，探讨其如何冲击期刊系统与教职晋升。论文分析了三种情景，揭示当前出版体系的脆弱性，呼吁改革人员评估与研究传播机制。**

- **链接: [http://arxiv.org/pdf/2509.16925v1](http://arxiv.org/pdf/2509.16925v1)**

> **作者:** Shan Jiang
>
> **摘要:** Generative artificial intelligence (AI) has begun to reshape academic publishing by enabling the rapid production of submission-ready manuscripts. While such tools promise to enhance productivity, they also raise concerns about overwhelming journal systems that have fixed acceptance capacities. This paper uses simulation modeling to investigate how AI-driven surges in submissions may affect desk rejection rates, review cycles, and faculty publication portfolios, with a focus on business school journals and tenure processes. Three scenarios are analyzed: a baseline model, an Early Adopter model where a subset of faculty boosts productivity, and an AI Abuse model where submissions rise exponentially. Results indicate that early adopters initially benefit, but overall acceptance rates fall sharply as load increases, with tenure-track faculty facing disproportionately negative outcomes. The study contributes by demonstrating the structural vulnerabilities of the current publication system and highlights the need for institutional reform in personnel evaluation and research dissemination practices.
>
---
#### [new 011] Explainability matters: The effect of liability rules on the healthcare sector
- **分类: cs.CY; cs.AI; cs.CE; cs.LG**

- **简介: 该论文探讨了可解释性在医疗AI中的法律影响，分析“Oracle”与“AI Colleague”两种极端模式，研究责任归属问题，旨在明确可解释性对医疗行为和风险防控的作用。**

- **链接: [http://arxiv.org/pdf/2509.17334v1](http://arxiv.org/pdf/2509.17334v1)**

> **作者:** Jiawen Wei; Elena Verona; Andrea Bertolini; Gianmarco Mengaldo
>
> **摘要:** Explainability, the capability of an artificial intelligence system (AIS) to explain its outcomes in a manner that is comprehensible to human beings at an acceptable level, has been deemed essential for critical sectors, such as healthcare. Is it really the case? In this perspective, we consider two extreme cases, ``Oracle'' (without explainability) versus ``AI Colleague'' (with explainability) for a thorough analysis. We discuss how the level of automation and explainability of AIS can affect the determination of liability among the medical practitioner/facility and manufacturer of AIS. We argue that explainability plays a crucial role in setting a responsibility framework in healthcare, from a legal standpoint, to shape the behavior of all involved parties and mitigate the risk of potential defensive medicine practices.
>
---
#### [new 012] The Even Sheen of AI: Kitsch, LLMs, and Homogeneity
- **分类: cs.CY**

- **简介: 该论文提出用“kitsch”作为新隐喻，分析大语言模型（LLMs）生成内容趋于同质化、平庸的问题。属于AI文本与图像风格研究任务，旨在揭示AI对语言和创作的影响，并倡导跨学科合作以应对潜在负面影响。**

- **链接: [http://arxiv.org/pdf/2509.16794v1](http://arxiv.org/pdf/2509.16794v1)**

> **作者:** Gyburg Uhlmann
>
> **备注:** 14 pages + 4 pages references
>
> **摘要:** The exploding use and impact of Chatbots such as ChatGPT that are based on Large Language Models urgently call for a language which is fit to clearly describe functions and problems of the production process and qualities of the Chatbots' textual and image output. Recently, the discussion about appropriate and illuminating metaphors to describe LLMs has gained momentum. As an alternative to well-established metaphors such as "hallucinating" and "bullshit", we propose "kitsch" as a new metaphor. As an internationally widespread term from literary and cultural studies, we argue that "kitsch" is particularly suitable for analytically illuminating a previously neglected feature of LLM-based images and texts: their tendency to produce homogeneous and average content, which is becoming increasingly dominant as the proportion of AI-generated content on the internet grows. This is leading to the equalisation of language, style and argument. In view of the potential negative consequences of this averaging, including for human content producers on the internet, we advocate combining methods and insights from kitsch studies with AI research, philosophy, and communication studies in order to better understand the phenomenon and develop countermeasures.
>
---
#### [new 013] AI, Digital Platforms, and the New Systemic Risk
- **分类: cs.CY**

- **简介: 该论文分析AI与数字平台融合带来的系统性风险，指出当前法规（如AI Act）定义不足。提出四层风险框架，强调需扩展风险评估、加强监管协调，并通过案例验证，推动更全面的治理策略。**

- **链接: [http://arxiv.org/pdf/2509.17878v1](http://arxiv.org/pdf/2509.17878v1)**

> **作者:** Philipp Hacker; Atoosa Kasirzadeh; Lilian Edwards
>
> **摘要:** As artificial intelligence (AI) becomes increasingly embedded in digital, social, and institutional infrastructures, and AI and platforms are merged into hybrid structures, systemic risk has emerged as a critical but undertheorized challenge. In this paper, we develop a rigorous framework for understanding systemic risk in AI, platform, and hybrid system governance, drawing on insights from finance, complex systems theory, climate change, and cybersecurity - domains where systemic risk has already shaped regulatory responses. We argue that recent legislation, including the EU's AI Act and Digital Services Act (DSA), invokes systemic risk but relies on narrow or ambiguous characterizations of this notion, sometimes reducing this risk to specific capabilities present in frontier AI models, or to harms occurring in economic market settings. The DSA, we show, actually does a better job at identifying systemic risk than the more recent AI Act. Our framework highlights novel risk pathways, including the possibility of systemic failures arising from the interaction of multiple AI agents. We identify four levels of AI-related systemic risk and emphasize that discrimination at scale and systematic hallucinations, despite their capacity to destabilize institutions and fundamental rights, may not fall under current legal definitions, given the AI Act's focus on frontier model capabilities. We then test the DSA, the AI Act, and our own framework on five key examples, and propose reforms that broaden systemic risk assessments, strengthen coordination between regulatory regimes, and explicitly incorporate collective harms.
>
---
#### [new 014] The Iconicity of the Generated Image
- **分类: cs.CY; cs.CV**

- **简介: 该论文研究生成式AI在图像生成中是否受标志性图像影响。通过数据归因、语义相似性分析和用户研究，发现AI难以再现标志性图像，揭示了人类与AI在视觉学习上的差异。属于视觉生成任务，旨在探讨AI对经典图像的学习机制。**

- **链接: [http://arxiv.org/pdf/2509.16473v1](http://arxiv.org/pdf/2509.16473v1)**

> **作者:** Nanne van Noord; Noa Garcia
>
> **备注:** Work presented at EA-AI 2025, May 2025, Venice
>
> **摘要:** How humans interpret and produce images is influenced by the images we have been exposed to. Similarly, visual generative AI models are exposed to many training images and learn to generate new images based on this. Given the importance of iconic images in human visual communication, as they are widely seen, reproduced, and used as inspiration, we may expect that they may similarly have a proportionally large influence within the generative AI process. In this work we explore this question through a three-part analysis, involving data attribution, semantic similarity analysis, and a user-study. Our findings indicate that iconic images do not have an obvious influence on the generative process, and that for many icons it is challenging to reproduce an image which resembles it closely. This highlights an important difference in how humans and visual generative AI models draw on and learn from prior visual communication.
>
---
#### [new 015] Energy Equity, Infrastructure and Demographic Analysis with XAI Methods
- **分类: cs.CY; cs.AI; I.2.6; H.4.2**

- **简介: 该论文属于能源公平性分析任务，旨在解决能源负担问题。通过XAI方法（如决策树和PCC）分析用电数据与社会人口因素，构建可解释的预测模型，并设计了一个提供定制建议的能源公平门户网站及计算工具。**

- **链接: [http://arxiv.org/pdf/2509.16279v1](http://arxiv.org/pdf/2509.16279v1)**

> **作者:** Sarahana Shrestha; Aparna S. Varde; Pankaj Lal
>
> **摘要:** This study deploys methods in explainable artificial intelligence (XAI), e.g. decision trees and Pearson's correlation coefficient (PCC), to investigate electricity usage in multiple locales. It addresses the vital issue of energy burden, i.e. total amount spent on energy divided by median household income. Socio-demographic data is analyzed with energy features, especially using decision trees and PCC, providing explainable predictors on factors affecting energy burden. Based on the results of the analysis, a pilot energy equity web portal is designed along with a novel energy burden calculator. Leveraging XAI, this portal (with its calculator) serves as a prototype information system that can offer tailored actionable advice to multiple energy stakeholders. The ultimate goal of this study is to promote greater energy equity through the adaptation of XAI methods for energy-related analysis with suitable recommendations.
>
---
#### [new 016] A community-driven optimization framework for redrawing school attendance boundaries
- **分类: cs.CY**

- **简介: 该论文提出一个社区驱动的多目标算法框架，用于优化学校学区划分。旨在解决如何在满足交通效率、社会经济融合和稳定升学路径等多重目标下重新划分学区的问题，并通过实际案例验证了框架的有效性。**

- **链接: [http://arxiv.org/pdf/2509.17130v1](http://arxiv.org/pdf/2509.17130v1)**

> **作者:** Hongzhao Guan; Paul Riggins; Tyler Simko; Jasmine Mangat; Cassandra Moe; Urooj Haider; Frank Pantano; Effie G. McMillian; Genevieve Siegel-Hawley; Pascal Van Hentenryck; Nabeel Gillani
>
> **摘要:** The vast majority of US public school districts use school attendance boundaries to determine which student addresses are assigned to which schools. Existing work shows how redrawing boundaries can be a powerful policy lever for increasing access and opportunity for historically disadvantaged groups, even while maintaining other priorities like minimizing driving distances and preserving existing social ties between students and families. This study introduces a multi-objective algorithmic school rezoning framework and applies it to a large-scale rezoning effort impacting over 50,000 students through an ongoing researcher-school district partnership. The framework is designed to incorporate feedback from community members and policymakers, both by deciding which goals are optimized and also by placing differential ``importance'' on goals through weights from community surveys. Empirical results reveal the framework's ability to surface school redistricting plans that simultaneously advance a number of objectives often thought to be in competition with one another, including socioeconomic integration, transportation efficiency, and stable feeder patterns (transitions) between elementary, middle, and high schools. The paper also highlights how local education policymakers navigate several practical challenges, like building political will to make change in a polarized policy climate. The framework is built using open-source tools and publicly released to support school districts in exploring and implementing new policies to improve educational access and opportunity in the coming years.
>
---
#### [new 017] Explainability Needs in Agriculture: Exploring Dairy Farmers' User Personas
- **分类: cs.CY; cs.HC**

- **简介: 该论文属于人机交互与农业技术领域，旨在解决AI在农业中因缺乏可解释性而影响信任和采纳的问题。通过对40名德国奶农的混合研究，识别出5种用户画像，分析其对技术解释和数据隐私的需求差异，为系统设计提供指导。**

- **链接: [http://arxiv.org/pdf/2509.16249v1](http://arxiv.org/pdf/2509.16249v1)**

> **作者:** Mengisti Berihu Girmay; Jakob Droste; Hannah Deters; Joerg Doerr
>
> **备注:** This paper has been accepted at the REACH-AI workshop of the 33rd IEEE International Requirements Engineering conference (REW 2025)
>
> **摘要:** Artificial Intelligence (AI) promises new opportunities across many domains, including agriculture. However, the adoption of AI systems in this sector faces several challenges. System complexity can impede trust, as farmers' livelihoods depend on their decision-making and they may reject opaque or hard-to-understand recommendations. Data privacy concerns also pose a barrier, especially when farmers lack transparency regarding who can access their data and for what purposes. This paper examines dairy farmers' explainability requirements for technical recommendations and data privacy, along with the influence of socio-demographic factors. Based on a mixed-methods study involving 40 German dairy farmers, we identify five user personas through k-means clustering. Our findings reveal varying requirements, with some farmers preferring little detail while others seek full transparency across different aspects. Age, technology experience, and confidence in using digital systems were found to correlate with these explainability requirements. The resulting user personas offer practical guidance for requirements engineers aiming to tailor digital systems more effectively to the diverse requirements of farmers.
>
---
#### [new 018] Predicting First Year Dropout from Pre Enrolment Motivation Statements Using Text Mining
- **分类: cs.CY; cs.CL; cs.LG; stat.AP**

- **简介: 该论文属于文本挖掘与教育预测任务，旨在通过分析学生的入学动机陈述预测大学第一年辍学情况。研究结合学生特征和文本数据（如TFiDF、主题模型、LIWC词典）构建SVM模型，发现文本分析单独预测效果与传统特征相当。**

- **链接: [http://arxiv.org/pdf/2509.16224v1](http://arxiv.org/pdf/2509.16224v1)**

> **作者:** K. F. B. Soppe; A. Bagheri; S. Nadi; I. G. Klugkist; T. Wubbels; L. D. N. V. Wijngaards-De Meij
>
> **摘要:** Preventing student dropout is a major challenge in higher education and it is difficult to predict prior to enrolment which students are likely to drop out and which students are likely to succeed. High School GPA is a strong predictor of dropout, but much variance in dropout remains to be explained. This study focused on predicting university dropout by using text mining techniques with the aim of exhuming information contained in motivation statements written by students. By combining text data with classic predictors of dropout in the form of student characteristics, we attempt to enhance the available set of predictive student characteristics. Our dataset consisted of 7,060 motivation statements of students enrolling in a non-selective bachelor at a Dutch university in 2014 and 2015. Support Vector Machines were trained on 75 percent of the data and several models were estimated on the test data. We used various combinations of student characteristics and text, such as TFiDF, topic modelling, LIWC dictionary. Results showed that, although the combination of text and student characteristics did not improve the prediction of dropout, text analysis alone predicted dropout similarly well as a set of student characteristics. Suggestions for future research are provided.
>
---
#### [new 019] How Digital Transformation Impacts Corporate Green Innovation?
- **分类: cs.CY**

- **简介: 该论文基于中国A股上市公司数据，研究数字化转型对企业绿色创新的影响及其机制。论文构建了数字化转型指标，分析其对绿色创新的促进作用，并探讨异质性影响，属于实证研究任务，旨在揭示数字化如何推动企业可持续发展。**

- **链接: [http://arxiv.org/pdf/2509.16260v1](http://arxiv.org/pdf/2509.16260v1)**

> **作者:** Chen Hanqin
>
> **摘要:** Digitalization is a crucial characteristic of the current era, and green innovation has become one of the necessary pathways for enterprises to achieve sustainable development. Based on financial and annual report data of Chinese A-share listed companies from 2010 to 2019, this paper constructs indicators of corporate digital transformation and examines the impact of corporate digital transformation on green innovation and its underlying mechanisms. The results show that corporate digital transformation can promote corporate green innovation output, with its sustained future impact exhibiting a marginally decreasing trend. In terms of the impact mechanism, digital transformation can enhance corporate green innovation output by increasing corporate R&D investment and strengthening environmental management. Heterogeneity analysis reveals that digital transformation has a more pronounced promoting effect on green innovation output for small and medium-sized enterprises and those in technology-intensive industries. To improve the green innovation incentive effect of digital transformation, enterprises should formulate long-term strategies and continuously strengthen policy regulation and incentives.
>
---
#### [new 020] Longitudinal and Multimodal Recording System to Capture Real-World Patient-Clinician Conversations for AI and Encounter Research: Protocol
- **分类: cs.CY; cs.CL**

- **简介: 该论文提出一种纵向多模态系统，用于记录真实世界中的患者-医生对话，结合视频、音频、调查和电子健康记录数据，构建AI研究数据集。旨在解决现有医学AI模型忽视医患互动的问题，验证该系统的可行性。**

- **链接: [http://arxiv.org/pdf/2509.16378v1](http://arxiv.org/pdf/2509.16378v1)**

> **作者:** Misk Al Zahidy; Kerly Guevara Maldonado; Luis Vilatuna Andrango; Ana Cristina Proano; Ana Gabriela Claros; Maria Lizarazo Jimenez; David Toro-Tobon; Oscar J. Ponce-Ponce; Juan P. Brito
>
> **备注:** 23 pages, 2 figures, 2 tables
>
> **摘要:** The promise of AI in medicine depends on learning from data that reflect what matters to patients and clinicians. Most existing models are trained on electronic health records (EHRs), which capture biological measures but rarely patient-clinician interactions. These relationships, central to care, unfold across voice, text, and video, yet remain absent from datasets. As a result, AI systems trained solely on EHRs risk perpetuating a narrow biomedical view of medicine and overlooking the lived exchanges that define clinical encounters. Our objective is to design, implement, and evaluate the feasibility of a longitudinal, multimodal system for capturing patient-clinician encounters, linking 360 degree video/audio recordings with surveys and EHR data to create a dataset for AI research. This single site study is in an academic outpatient endocrinology clinic at Mayo Clinic. Adult patients with in-person visits to participating clinicians are invited to enroll. Encounters are recorded with a 360 degree video camera. After each visit, patients complete a survey on empathy, satisfaction, pace, and treatment burden. Demographic and clinical data are extracted from the EHR. Feasibility is assessed using five endpoints: clinician consent, patient consent, recording success, survey completion, and data linkage across modalities. Recruitment began in January 2025. By August 2025, 35 of 36 eligible clinicians (97%) and 212 of 281 approached patients (75%) had consented. Of consented encounters, 162 (76%) had complete recordings and 204 (96%) completed the survey. This study aims to demonstrate the feasibility of a replicable framework for capturing the multimodal dynamics of patient-clinician encounters. By detailing workflows, endpoints, and ethical safeguards, it provides a template for longitudinal datasets and lays the foundation for AI models that incorporate the complexity of care.
>
---
#### [new 021] What's Not on the Plate? Rethinking Food Computing through Indigenous Indian Datasets
- **分类: cs.CY; I.2.4, K.4.0, J.5**

- **简介: 该论文提出了一个包含1000种印度原住民食谱的多模态数据集，涵盖文本、图像和音频，旨在解决食品计算中文化包容性与社区参与不足的问题，推动公平、可持续的AI食品系统发展。**

- **链接: [http://arxiv.org/pdf/2509.16286v1](http://arxiv.org/pdf/2509.16286v1)**

> **作者:** Pamir Gogoi; Neha Joshi; Ayushi Pandey; Deepthi Sudharsan; Saransh Kumar Gupta; Lipika Dey; Partha Pratim Das; Kalika Bali; Vivek Seshadri
>
> **摘要:** This paper presents a multimodal dataset of 1,000 indigenous recipes from remote regions of India, collected through a participatory model involving first-time digital workers from rural areas. The project covers ten endangered language communities in six states. Documented using a dedicated mobile app, the data set includes text, images, and audio, capturing traditional food practices along with their ecological and cultural contexts. This initiative addresses gaps in food computing, such as the lack of culturally inclusive, multimodal, and community-authored data. By documenting food as it is practiced rather than prescribed, this work advances inclusive, ethical, and scalable approaches to AI-driven food systems and opens new directions in cultural AI, public health, and sustainable agriculture.
>
---
#### [new 022] How Large Language Models are Designed to Hallucinate
- **分类: cs.CY; cs.AI; cs.CL**

- **简介: 该论文探讨大语言模型（LLMs）产生幻觉的根本原因，认为其源于Transformer架构的结构特性。论文提出新的分类框架，并设计“真理约束”架构方向，以解决现有解释不足的问题，属于模型理解与改进任务。**

- **链接: [http://arxiv.org/pdf/2509.16297v1](http://arxiv.org/pdf/2509.16297v1)**

> **作者:** Richard Ackermann; Simeon Emanuilov
>
> **备注:** 23 pages, 2 tables, 2 figures
>
> **摘要:** Large language models (LLMs) achieve remarkable fluency across linguistic and reasoning tasks but remain systematically prone to hallucination. Prevailing accounts attribute hallucinations to data gaps, limited context, or optimization errors. We argue instead that hallucination is a structural outcome of the transformer architecture. As coherence engines, transformers are compelled to produce fluent continuations, with self-attention simulating the relational structure of meaning but lacking the existential grounding of temporality, mood, and care that stabilizes human understanding. On this basis, we distinguish ontological hallucination, arising when continuations require disclosure of beings in world, and residual reasoning hallucination, where models mimic inference by recycling traces of human reasoning in text. We illustrate these patterns through case studies aligned with Heideggerian categories and an experiment across twelve LLMs showing how simulated "self-preservation" emerges under extended prompts. Our contribution is threefold: (1) a comparative account showing why existing explanations are insufficient; (2) a predictive taxonomy of hallucination linked to existential structures with proposed benchmarks; and (3) design directions toward "truth-constrained" architectures capable of withholding or deferring when disclosure is absent. We conclude that hallucination is not an incidental defect but a defining limit of transformer-based models, an outcome scaffolding can mask but never resolve.
>
---
#### [new 023] Test-Time Learning and Inference-Time Deliberation for Efficiency-First Offline Reinforcement Learning in Care Coordination and Population Health Management
- **分类: cs.CY; cs.LG**

- **简介: 该论文针对医疗协调与健康管理中的效率优先问题，提出一种轻量级离线强化学习方法，通过测试时学习和推理时权衡，优化不同接触方式的时间与成本，实现稳定价值估计与可审计的效率平衡。**

- **链接: [http://arxiv.org/pdf/2509.16291v1](http://arxiv.org/pdf/2509.16291v1)**

> **作者:** Sanjay Basu; Sadiq Y. Patel; Parth Sheth; Bhairavi Muralidharan; Namrata Elamaran; Aakriti Kinra; Rajaie Batniji
>
> **摘要:** Care coordination and population health management programs serve large Medicaid and safety-net populations and must be auditable, efficient, and adaptable. While clinical risk for outreach modalities is typically low, time and opportunity costs differ substantially across text, phone, video, and in-person visits. We propose a lightweight offline reinforcement learning (RL) approach that augments trained policies with (i) test-time learning via local neighborhood calibration, and (ii) inference-time deliberation via a small Q-ensemble that incorporates predictive uncertainty and time/effort cost. The method exposes transparent dials for neighborhood size and uncertainty/cost penalties and preserves an auditable training pipeline. Evaluated on a de-identified operational dataset, TTL+ITD achieves stable value estimates with predictable efficiency trade-offs and subgroup auditing.
>
---
#### [new 024] Empirical AI Ethics: Reconfiguring Ethics towards a Situated, Plural, and Transformative Approach
- **分类: cs.CY; cs.IT; math.IT**

- **简介: 该论文批判主流AI伦理的局限性，提出从实证、多元和变革视角重构AI伦理，以应对技术与社会权力的复杂关系。属于理论研究任务，旨在推动更具包容性和实践导向的伦理框架。**

- **链接: [http://arxiv.org/pdf/2509.17727v1](http://arxiv.org/pdf/2509.17727v1)**

> **作者:** Paula Helm; Selin Gerlek
>
> **摘要:** Mainstream AI ethics, with its reliance on top-down, principle-driven frameworks, fails to account for the situated realities of diverse communities affected by AI (Artificial Intelligence). Critics have argued that AI ethics frequently serves corporate interests through practices of 'ethics washing', operating more as a tool for public relations than as a means of preventing harm or advancing the common good. As a result, growing scepticism among critical scholars has cast the field as complicit in sustaining harmful systems rather than challenging or transforming them. In response, this paper adopts a Science and Technology Studies (STS) perspective to critically interrogate the field of AI ethics. It hence applies the same analytic tools STS has long directed at disciplines such as biology, medicine, and statistics to ethics. This perspective reveals a core tension between vertical (top-down, principle-based) and horizontal (risk-mitigating, implementation-oriented) approaches to ethics. By tracing how these models have shaped the discourse, we show how both fall short in addressing the complexities of AI as a socio-technical assemblage, embedded in practice and entangled with power. To move beyond these limitations, we propose a threefold reorientation of AI ethics. First, we call for a shift in foundations: from top-down abstraction to empirical grounding. Second, we advocate for pluralisation: moving beyond Western-centric frameworks toward a multiplicity of onto-epistemic perspectives. Finally, we outline strategies for reconfiguring AI ethics as a transformative force, moving from narrow paradigms of risk mitigation toward co-creating technologies of hope.
>
---
#### [new 025] Community Covert Communication - Dynamic Mass Covert Communication Through Social Media
- **分类: cs.CR; cs.CY**

- **简介: 该论文研究利用社交媒体中的社区管理技术，实现大规模加密信息的隐蔽通信。属于信息安全领域，旨在解决隐蔽通信问题，探讨如何通过自动化工具和虚拟账号群组高效、安全地传输信息。**

- **链接: [http://arxiv.org/pdf/2509.17508v1](http://arxiv.org/pdf/2509.17508v1)**

> **作者:** Eric Filiol
>
> **备注:** 22 pages, 8 figures, this work has been presented at 44CON 2024 & 44CON 2025 in London
>
> **摘要:** Since the early 2010s, social network-based influence technologies have grown almost exponentially. Initiated by the U.S. Army's early OEV system in 2011, a number of companies specializing in this field have emerged. The most (in)famous cases are Bell Pottinger, Cambridge Analytica, Aggregate-IQ and, more recently, Team Jorge. In this paper, we consider the use-case of sock puppet master activities, which consist in creating hundreds or even thousands of avatars, in organizing them into communities and implement influence operations. On-purpose software is used to automate these operations (e.g. Ripon software, AIMS) and organize these avatar populations into communities. The aim is to organize targeted and directed influence communication to rather large communities (influence targets). The goal of the present research work is to show how these community management techniques (social networks) can also be used to communicate/disseminate relatively large volumes (up to a few tens of Mb) of multi-level encrypted information to a limited number of actors. To a certain extent, this can be compared to a Dark Post-type function, with a number of much more powerful potentialities. As a consequence, the concept of communication has been totally redefined and disrupted, so that eavesdropping, interception and jamming operations no longer make sense.
>
---
#### [new 026] 'Rich Dad, Poor Lad': How do Large Language Models Contextualize Socioeconomic Factors in College Admission ?
- **分类: cs.CL; cs.CY**

- **简介: 该论文研究大型语言模型（LLMs）在大学录取中如何处理社会经济地位（SES）。通过构建3万份合成申请数据，测试4种开源模型在两种推理模式下的决策倾向。结果发现LLMs倾向于低SES申请人，并提出DPAF框架以审计其敏感决策行为。**

- **链接: [http://arxiv.org/pdf/2509.16400v1](http://arxiv.org/pdf/2509.16400v1)**

> **作者:** Huy Nghiem; Phuong-Anh Nguyen-Le; John Prindle; Rachel Rudinger; Hal Daumé III
>
> **备注:** EMNLP 2025, ver 1, 35 pages
>
> **摘要:** Large Language Models (LLMs) are increasingly involved in high-stakes domains, yet how they reason about socially sensitive decisions remains underexplored. We present a large-scale audit of LLMs' treatment of socioeconomic status (SES) in college admissions decisions using a novel dual-process framework inspired by cognitive science. Leveraging a synthetic dataset of 30,000 applicant profiles grounded in real-world correlations, we prompt 4 open-source LLMs (Qwen 2, Mistral v0.3, Gemma 2, Llama 3.1) under 2 modes: a fast, decision-only setup (System 1) and a slower, explanation-based setup (System 2). Results from 5 million prompts reveal that LLMs consistently favor low-SES applicants -- even when controlling for academic performance -- and that System 2 amplifies this tendency by explicitly invoking SES as compensatory justification, highlighting both their potential and volatility as decision-makers. We then propose DPAF, a dual-process audit framework to probe LLMs' reasoning behaviors in sensitive applications.
>
---
#### [new 027] Comparing Data Assimilation and Likelihood-Based Inference on Latent State Estimation in Agent-Based Models
- **分类: cs.LG; cs.CY; physics.soc-ph; stat.ME**

- **简介: 该论文比较了数据同化（DA）和基于似然的推断（LBI）在基于主体模型（ABM）中估计潜在状态的效果。针对ABM中传统DA方法的局限性，研究探讨了LBI在个体层面更优、DA在宏观预测中更具优势的特点，为模型选择提供依据。**

- **链接: [http://arxiv.org/pdf/2509.17625v1](http://arxiv.org/pdf/2509.17625v1)**

> **作者:** Blas Kolic; Corrado Monti; Gianmarco De Francisci Morales; Marco Pangallo
>
> **摘要:** In this paper, we present the first systematic comparison of Data Assimilation (DA) and Likelihood-Based Inference (LBI) in the context of Agent-Based Models (ABMs). These models generate observable time series driven by evolving, partially-latent microstates. Latent states need to be estimated to align simulations with real-world data -- a task traditionally addressed by DA, especially in continuous and equation-based models such as those used in weather forecasting. However, the nature of ABMs poses challenges for standard DA methods. Solving such issues requires adaptation of previous DA techniques, or ad-hoc alternatives such as LBI. DA approximates the likelihood in a model-agnostic way, making it broadly applicable but potentially less precise. In contrast, LBI provides more accurate state estimation by directly leveraging the model's likelihood, but at the cost of requiring a hand-crafted, model-specific likelihood function, which may be complex or infeasible to derive. We compare the two methods on the Bounded-Confidence Model, a well-known opinion dynamics ABM, where agents are affected only by others holding sufficiently similar opinions. We find that LBI better recovers latent agent-level opinions, even under model mis-specification, leading to improved individual-level forecasts. At the aggregate level, however, both methods perform comparably, and DA remains competitive across levels of aggregation under certain parameter settings. Our findings suggest that DA is well-suited for aggregate predictions, while LBI is preferable for agent-level inference.
>
---
#### [new 028] Reconnecting Citizens to Politics via Blockchain - Starting the Debate
- **分类: cs.CR; cs.CY**

- **简介: 该论文探讨利用区块链技术解决政治竞选资金问题，提出设计专用加密货币用于竞选开支，以提升透明度和公平性。属于技术应用研究任务，旨在推动政治与区块链的结合探索。**

- **链接: [http://arxiv.org/pdf/2509.16274v1](http://arxiv.org/pdf/2509.16274v1)**

> **作者:** Uwe Serdült
>
> **备注:** Published as Proceedings of Ongoing Research, Practitioners, Posters, Workshops, and Projects of the International Conference EGOV-CeDEM-ePart 2019
>
> **摘要:** Elections are not the only but arguably one of the most important pillars for the proper functioning of liberal democracies. Recent evidence across the globe shows that it is not straightforward to conduct them in a free and fair manner. One constant concern is the role of money in politics, more specifically, election campaign financing. Frequent scandals are proof of the difficulties encountered with current approaches to tackle the issue. Suggestions on how to overcome the problem exist but seem difficult to implement. With the help of blockchain technology we might be able to make a step forward. A separate crypto currency specifically designed to pay for costs of political campaigning and advertising could be introduced. Admittedly, at this stage, there are many open questions. However, under the assumption that blockchain technology is here to stay, it is an idea that deserves further exploration.
>
---
#### [new 029] Implicit Behavioral Alignment of Language Agents in High-Stakes Crowd Simulations
- **分类: cs.CL; cs.AI; cs.CY**

- **简介: 该论文研究高风险人群模拟中语言代理的行为真实性问题，提出PEBA理论框架和PEvo算法，通过优化代理人设，隐式对齐其行为与专家基准，显著提升模拟的现实感与可靠性。**

- **链接: [http://arxiv.org/pdf/2509.16457v1](http://arxiv.org/pdf/2509.16457v1)**

> **作者:** Yunzhe Wang; Gale M. Lucas; Burcin Becerik-Gerber; Volkan Ustun
>
> **备注:** Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing (EMNLP 2025), Main Conference
>
> **摘要:** Language-driven generative agents have enabled large-scale social simulations with transformative uses, from interpersonal training to aiding global policy-making. However, recent studies indicate that generative agent behaviors often deviate from expert expectations and real-world data--a phenomenon we term the Behavior-Realism Gap. To address this, we introduce a theoretical framework called Persona-Environment Behavioral Alignment (PEBA), formulated as a distribution matching problem grounded in Lewin's behavior equation stating that behavior is a function of the person and their environment. Leveraging PEBA, we propose PersonaEvolve (PEvo), an LLM-based optimization algorithm that iteratively refines agent personas, implicitly aligning their collective behaviors with realistic expert benchmarks within a specified environmental context. We validate PEvo in an active shooter incident simulation we developed, achieving an 84% average reduction in distributional divergence compared to no steering and a 34% improvement over explicit instruction baselines. Results also show PEvo-refined personas generalize to novel, related simulation scenarios. Our method greatly enhances behavioral realism and reliability in high-stakes social simulations. More broadly, the PEBA-PEvo framework provides a principled approach to developing trustworthy LLM-driven social simulations.
>
---
#### [new 030] The PIMMUR Principles: Ensuring Validity in Collective Behavior of LLM Societies
- **分类: cs.CL; cs.CY**

- **简介: 该论文提出PIMMUR原则，旨在解决LLM社会模拟中的方法缺陷问题。通过分析40余篇论文，识别出六种常见方法论错误，并验证了严格遵循PIMMUR后社会现象难以复现的问题，为可信的LLM多智能体研究建立标准。**

- **链接: [http://arxiv.org/pdf/2509.18052v1](http://arxiv.org/pdf/2509.18052v1)**

> **作者:** Jiaxu Zhou; Jen-tse Huang; Xuhui Zhou; Man Ho Lam; Xintao Wang; Hao Zhu; Wenxuan Wang; Maarten Sap
>
> **备注:** Preprint
>
> **摘要:** Large Language Models (LLMs) are increasingly used for social simulation, where populations of agents are expected to reproduce human-like collective behavior. However, we find that many recent studies adopt experimental designs that systematically undermine the validity of their claims. From a survey of over 40 papers, we identify six recurring methodological flaws: agents are often homogeneous (Profile), interactions are absent or artificially imposed (Interaction), memory is discarded (Memory), prompts tightly control outcomes (Minimal-Control), agents can infer the experimental hypothesis (Unawareness), and validation relies on simplified theoretical models rather than real-world data (Realism). For instance, GPT-4o and Qwen-3 correctly infer the underlying social experiment in 53.1% of cases when given instructions from prior work-violating the Unawareness principle. We formalize these six requirements as the PIMMUR principles and argue they are necessary conditions for credible LLM-based social simulation. To demonstrate their impact, we re-run five representative studies using a framework that enforces PIMMUR and find that the reported social phenomena frequently fail to emerge under more rigorous conditions. Our work establishes methodological standards for LLM-based multi-agent research and provides a foundation for more reliable and reproducible claims about "AI societies."
>
---
#### [new 031] TraceHiding: Scalable Machine Unlearning for Mobility Data
- **分类: cs.LG; cs.CY**

- **简介: 该论文提出TraceHiding，一种面向轨迹数据的可扩展机器遗忘框架。针对用户删除权需求，它通过重要性评分和知识蒸馏，在不完全重训模型的前提下有效移除指定用户轨迹，提升隐私保护与计算效率。**

- **链接: [http://arxiv.org/pdf/2509.17241v1](http://arxiv.org/pdf/2509.17241v1)**

> **作者:** Ali Faraji; Manos Papagelis
>
> **摘要:** This work introduces TraceHiding, a scalable, importance-aware machine unlearning framework for mobility trajectory data. Motivated by privacy regulations such as GDPR and CCPA granting users "the right to be forgotten," TraceHiding removes specified user trajectories from trained deep models without full retraining. It combines a hierarchical data-driven importance scoring scheme with teacher-student distillation. Importance scores--computed at token, trajectory, and user levels from statistical properties (coverage diversity, entropy, length)--quantify each training sample's impact, enabling targeted forgetting of high-impact data while preserving common patterns. The student model retains knowledge on remaining data and unlearns targeted trajectories through an importance-weighted loss that amplifies forgetting signals for unique samples and attenuates them for frequent ones. We validate on Trajectory--User Linking (TUL) tasks across three real-world higher-order mobility datasets (HO-Rome, HO-Geolife, HO-NYC) and multiple architectures (GRU, LSTM, BERT, ModernBERT, GCN-TULHOR), against strong unlearning baselines including SCRUB, NegGrad, NegGrad+, Bad-T, and Finetuning. Experiments under uniform and targeted user deletion show TraceHiding, especially its entropy-based variant, achieves superior unlearning accuracy, competitive membership inference attack (MIA) resilience, and up to 40\times speedup over retraining with minimal test accuracy loss. Results highlight robustness to adversarial deletion of high-information users and consistent performance across models. To our knowledge, this is the first systematic study of machine unlearning for trajectory data, providing a reproducible pipeline with public code and preprocessing tools.
>
---
#### [new 032] Tides of Memory: Digital Echoes of Netizen Remembran
- **分类: cs.HC; cs.CY**

- **简介: 该论文属于数字人文领域，研究在线集体悼念行为。通过爬取微博纪念内容，结合自然语言处理和3D建模，构建沉浸式数字纪念碑，探索数字时代集体记忆的保存与再现方法。**

- **链接: [http://arxiv.org/pdf/2509.16579v1](http://arxiv.org/pdf/2509.16579v1)**

> **作者:** Lingyu Peng; Chang Ge; Liying Long; Xin Li; Xiao Hu; Pengda Lu; Qingchuan Li; Jiangyue Wu
>
> **备注:** 10 pages, 18 figures
>
> **摘要:** This artwork presents an interdisciplinary interaction installation that visualizes collective online mourning behavior in China. By focusing on commemorative content posted on Sina Weibo following the deaths of seven prominent Chinese authors, the artwork employs data scraping, natural language processing, and 3D modeling to transform fragmented textual expressions into immersive digital monuments. Through the analysis of word frequencies, topic models, and user engagement metrics, the system constructs a semantic-visual landscape that reflects both authorial legacies and collective memory. This research contributes to the fields of digital humanities, visualization design, and digital memorial architecture by proposing a novel approach for preserving and reactivating collective memory in the digital age.
>
---
#### [new 033] Computational Analysis of Conversation Dynamics through Participant Responsivity
- **分类: cs.CL; cs.CY**

- **简介: 该论文研究对话质量评估任务，旨在解决如何量化对话中“响应性”（responsivity）的问题。工作包括提出基于语义相似性和大语言模型的方法识别对话响应关系，并构建对话级指标以区分不同对话特征。**

- **链接: [http://arxiv.org/pdf/2509.16464v1](http://arxiv.org/pdf/2509.16464v1)**

> **作者:** Margaret Hughes; Brandon Roy; Elinor Poole-Dayan; Deb Roy; Jad Kabbara
>
> **摘要:** Growing literature explores toxicity and polarization in discourse, with comparatively less work on characterizing what makes dialogue prosocial and constructive. We explore conversational discourse and investigate a method for characterizing its quality built upon the notion of ``responsivity'' -- whether one person's conversational turn is responding to a preceding turn. We develop and evaluate methods for quantifying responsivity -- first through semantic similarity of speaker turns, and second by leveraging state-of-the-art large language models (LLMs) to identify the relation between two speaker turns. We evaluate both methods against a ground truth set of human-annotated conversations. Furthermore, selecting the better performing LLM-based approach, we characterize the nature of the response -- whether it responded to that preceding turn in a substantive way or not. We view these responsivity links as a fundamental aspect of dialogue but note that conversations can exhibit significantly different responsivity structures. Accordingly, we then develop conversation-level derived metrics to address various aspects of conversational discourse. We use these derived metrics to explore other conversations and show that they support meaningful characterizations and differentiations across a diverse collection of conversations.
>
---
#### [new 034] Mechanistic Interpretability with SAEs: Probing Religion, Violence, and Geography in Large Language Models
- **分类: cs.LG; cs.AI; cs.CY**

- **简介: 该论文属于机制可解释性研究任务，旨在探究大语言模型中宗教、暴力和地理概念的内部表示。通过SAEs分析五种模型的激活特征，发现伊斯兰教更常与暴力相关联，地理关联反映现实人口分布与刻板印象。**

- **链接: [http://arxiv.org/pdf/2509.17665v1](http://arxiv.org/pdf/2509.17665v1)**

> **作者:** Katharina Simbeck; Mariam Mahran
>
> **备注:** Accepted at AEQUITAS 2025: Workshop on Fairness and Bias in AI | co-located with ECAI, October 26th, 2025, Bologna, Italy. 12 pages, 1 figure
>
> **摘要:** Despite growing research on bias in large language models (LLMs), most work has focused on gender and race, with little attention to religious identity. This paper explores how religion is internally represented in LLMs and how it intersects with concepts of violence and geography. Using mechanistic interpretability and Sparse Autoencoders (SAEs) via the Neuronpedia API, we analyze latent feature activations across five models. We measure overlap between religion- and violence-related prompts and probe semantic patterns in activation contexts. While all five religions show comparable internal cohesion, Islam is more frequently linked to features associated with violent language. In contrast, geographic associations largely reflect real-world religious demographics, revealing how models embed both factual distributions and cultural stereotypes. These findings highlight the value of structural analysis in auditing not just outputs but also internal representations that shape model behavior.
>
---
#### [new 035] Training the next generation of physicians for artificial intelligence-assisted clinical neuroradiology: ASNR MICCAI Brain Tumor Segmentation (BraTS) 2025 Lighthouse Challenge education platform
- **分类: cs.LG; cs.AI; cs.CY**

- **简介: 该论文提出通过脑肿瘤分割挑战赛（BraTS 2025）教育平台，培训医学生和放射科住院医师在人工智能辅助神经影像学中的技能。任务是提升医学人员对AI算法开发和数据标注的理解，解决AI医学影像分析人才短缺问题，通过讲座、工作坊及一对一指导等方式进行实践教学。**

- **链接: [http://arxiv.org/pdf/2509.17281v1](http://arxiv.org/pdf/2509.17281v1)**

> **作者:** Raisa Amiruddin; Nikolay Y. Yordanov; Nazanin Maleki; Pascal Fehringer; Athanasios Gkampenis; Anastasia Janas; Kiril Krantchev; Ahmed Moawad; Fabian Umeh; Salma Abosabie; Sara Abosabie; Albara Alotaibi; Mohamed Ghonim; Mohanad Ghonim; Sedra Abou Ali Mhana; Nathan Page; Marko Jakovljevic; Yasaman Sharifi; Prisha Bhatia; Amirreza Manteghinejad; Melisa Guelen; Michael Veronesi; Virginia Hill; Tiffany So; Mark Krycia; Bojan Petrovic; Fatima Memon; Justin Cramer; Elizabeth Schrickel; Vilma Kosovic; Lorenna Vidal; Gerard Thompson; Ichiro Ikuta; Basimah Albalooshy; Ali Nabavizadeh; Nourel Hoda Tahon; Karuna Shekdar; Aashim Bhatia; Claudia Kirsch; Gennaro D'Anna; Philipp Lohmann; Amal Saleh Nour; Andriy Myronenko; Adam Goldman-Yassen; Janet R. Reid; Sanjay Aneja; Spyridon Bakas; Mariam Aboian
>
> **备注:** 23 pages, 9 figures, 1 table, 3 supplementary tables
>
> **摘要:** High-quality reference standard image data creation by neuroradiology experts for automated clinical tools can be a powerful tool for neuroradiology & artificial intelligence education. We developed a multimodal educational approach for students and trainees during the MICCAI Brain Tumor Segmentation Lighthouse Challenge 2025, a landmark initiative to develop accurate brain tumor segmentation algorithms. Fifty-six medical students & radiology trainees volunteered to annotate brain tumor MR images for the BraTS challenges of 2023 & 2024, guided by faculty-led didactics on neuropathology MRI. Among the 56 annotators, 14 select volunteers were then paired with neuroradiology faculty for guided one-on-one annotation sessions for BraTS 2025. Lectures on neuroanatomy, pathology & AI, journal clubs & data scientist-led workshops were organized online. Annotators & audience members completed surveys on their perceived knowledge before & after annotations & lectures respectively. Fourteen coordinators, each paired with a neuroradiologist, completed the data annotation process, averaging 1322.9+/-760.7 hours per dataset per pair and 1200 segmentations in total. On a scale of 1-10, annotation coordinators reported significant increase in familiarity with image segmentation software pre- and post-annotation, moving from initial average of 6+/-2.9 to final average of 8.9+/-1.1, and significant increase in familiarity with brain tumor features pre- and post-annotation, moving from initial average of 6.2+/-2.4 to final average of 8.1+/-1.2. We demonstrate an innovative offering for providing neuroradiology & AI education through an image segmentation challenge to enhance understanding of algorithm development, reinforce the concept of data reference standard, and diversify opportunities for AI-driven image analysis among future physicians.
>
---
#### [new 036] Intrinsic Meets Extrinsic Fairness: Assessing the Downstream Impact of Bias Mitigation in Large Language Models
- **分类: cs.CL; cs.CY; cs.LG**

- **简介: 该论文属于自然语言处理中的公平性研究任务，旨在解决大语言模型（LLMs）中社会经济偏见对下游任务的影响问题。论文提出统一评估框架，比较了内在偏见消除和外在反事实数据增强的效果，实验证明内在偏见缓解可有效提升下游任务的公平性。**

- **链接: [http://arxiv.org/pdf/2509.16462v1](http://arxiv.org/pdf/2509.16462v1)**

> **作者:** 'Mina Arzaghi'; 'Alireza Dehghanpour Farashah'; 'Florian Carichon'; ' Golnoosh Farnadi'
>
> **摘要:** Large Language Models (LLMs) exhibit socio-economic biases that can propagate into downstream tasks. While prior studies have questioned whether intrinsic bias in LLMs affects fairness at the downstream task level, this work empirically investigates the connection. We present a unified evaluation framework to compare intrinsic bias mitigation via concept unlearning with extrinsic bias mitigation via counterfactual data augmentation (CDA). We examine this relationship through real-world financial classification tasks, including salary prediction, employment status, and creditworthiness assessment. Using three open-source LLMs, we evaluate models both as frozen embedding extractors and as fine-tuned classifiers. Our results show that intrinsic bias mitigation through unlearning reduces intrinsic gender bias by up to 94.9%, while also improving downstream task fairness metrics, such as demographic parity by up to 82%, without compromising accuracy. Our framework offers practical guidance on where mitigation efforts can be most effective and highlights the importance of applying early-stage mitigation before downstream deployment.
>
---
## 更新

#### [replaced 001] Quantifying Student Success with Generative AI: A Monte Carlo Simulation Informed by Systematic Review
- **分类: cs.CY; cs.AI; 62P25; K.3.1; H.5.2**

- **链接: [http://arxiv.org/pdf/2507.01062v2](http://arxiv.org/pdf/2507.01062v2)**

> **作者:** Seyma Yaman Kayadibi
>
> **备注:** 35 pages, 4 figures. All figures are image-based: one Python code screenshot, one regression model output, one success score distribution chart, and one PRISMA diagram. This article presents a standalone segment from the author's master's thesis at Victoria University
>
> **摘要:** The exponential development of generative artificial intelligence (GenAI) technologies like ChatGPT has raised increasing curiosity about their use in higher education, specifically with respect to how students view them, make use of them, and the implications for learning outcomes. This paper employs a hybrid methodological approach involving a systematic literature review and simulation-based modeling to explore student perceptions of GenAI use in the context of higher education. A total of nineteen empirical articles from 2023 through 2025 were selected from the PRISMA-based search targeting the Scopus database. Synthesis of emerging patterns from the literature was achieved by thematic categorization. Six of these had enough quantitative information, i.e., item-level means and standard deviations, to permit probabilistic modeling. One dataset, from the resulting subset, was itself selected as a representative case with which to illustrate inverse-variance weighting by Monte Carlo simulation, by virtue of its well-designed Likert scale format and thematic alignment with the use of computing systems by the researcher. The simulation provided a composite "Success Score" forecasting the strength of the relationship between student perceptions and learning achievements. Findings reveal that attitude factors concerned with usability and real-world usefulness are significantly better predictors of positive learning achievement than affective or trust-based factors. Such an interdisciplinary perspective provides a unique means of linking thematic results with predictive modelling, resonating with longstanding controversies about the proper use of GenAI tools within the university.
>
---
#### [replaced 002] Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering
- **分类: cs.CL; cs.AI; cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2503.01606v3](http://arxiv.org/pdf/2503.01606v3)**

> **作者:** Zhanghao Hu; Hanqi Yan; Qinglin Zhu; Zhenyi Shen; Yulan He; Lin Gui
>
> **备注:** Accepted in ACL 2025 Main, Project link: https://zhanghao-acl25-embqa.github.io/ACL2025-EmbQA/
>
> **摘要:** Large language models have recently pushed open domain question answering (ODQA) to new frontiers. However, prevailing retriever-reader pipelines often depend on multiple rounds of prompt level instructions, leading to high computational overhead, instability, and suboptimal retrieval coverage. In this paper, we propose EmbQA, an embedding-level framework that alleviates these shortcomings by enhancing both the retriever and the reader. Specifically, we refine query representations via lightweight linear layers under an unsupervised contrastive learning objective, thereby reordering retrieved passages to highlight those most likely to contain correct answers. Additionally, we introduce an exploratory embedding that broadens the model's latent semantic space to diversify candidate generation and employs an entropy-based selection mechanism to choose the most confident answer automatically. Extensive experiments across three open-source LLMs, three retrieval methods, and four ODQA benchmarks demonstrate that EmbQA substantially outperforms recent baselines in both accuracy and efficiency.
>
---
#### [replaced 003] Advancing Knowledge Tracing by Exploring Follow-up Performance Trends
- **分类: cs.CY; cs.AI; cs.LG**

- **链接: [http://arxiv.org/pdf/2508.08019v2](http://arxiv.org/pdf/2508.08019v2)**

> **作者:** Hengyu Liu; Yushuai Li; Minghe Yu; Tiancheng Zhang; Ge Yu; Torben Bach Pedersen; Kristian Torp; Christian S. Jensen; Tianyi Li
>
> **备注:** 14 pages, 5 figures
>
> **摘要:** Intelligent Tutoring Systems (ITS), such as Massive Open Online Courses, offer new opportunities for human learning. At the core of such systems, knowledge tracing (KT) predicts students' future performance by analyzing their historical learning activities, enabling an accurate evaluation of students' knowledge states over time. We show that existing KT methods often encounter correlation conflicts when analyzing the relationships between historical learning sequences and future performance. To address such conflicts, we propose to extract so-called Follow-up Performance Trends (FPTs) from historical ITS data and to incorporate them into KT. We propose a method called Forward-Looking Knowledge Tracing (FINER) that combines historical learning sequences with FPTs to enhance student performance prediction accuracy. FINER constructs learning patterns that facilitate the retrieval of FPTs from historical ITS data in linear time; FINER includes a novel similarity-aware attention mechanism that aggregates FPTs based on both frequency and contextual similarity; and FINER offers means of combining FPTs and historical learning sequences to enable more accurate prediction of student future performance. Experiments on six real-world datasets show that FINER can outperform ten state-of-the-art KT methods, increasing accuracy by 8.74% to 84.85%.
>
---
#### [replaced 004] Rhetorical XAI: Explaining AI's Benefits as well as its Use via Rhetorical Design
- **分类: cs.HC; cs.CY**

- **链接: [http://arxiv.org/pdf/2505.09862v2](http://arxiv.org/pdf/2505.09862v2)**

> **作者:** Houjiang Liu; Yiheng Su; Matthew Lease
>
> **备注:** Clarify the contextual positioning of our framework in relation to prior XAI design work and expand the review details
>
> **摘要:** This paper explores potential benefits of incorporating Rhetorical Design into the design of Explainable Artificial Intelligence (XAI) systems. While XAI is traditionally framed around explaining individual predictions or overall system behavior, explanations also function as a form of argumentation, shaping how users evaluate system perceived usefulness, credibility, and foster appropriate trust. Rhetorical Design offers a useful framework to analyze the communicative role of explanations between AI systems and users, focusing on: (1) logical reasoning conveyed through different types of explanations, (2) credibility projected by the system and its developers, and (3) emotional resonance elicited in users. Together, these rhetorical appeals help us understand how explanations influence user perceptions and facilitate AI adoption across and within different collaborative and social contexts. This paper synthesizes design strategies from prior XAI work that align with these three rhetorical appeals and highlights both opportunities and challenges of integrating rhetorical design into XAI design.
>
---
#### [replaced 005] BoundarEase: Fostering Constructive Community Engagement to Inform More Equitable Student Assignment Policies
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2503.08543v2](http://arxiv.org/pdf/2503.08543v2)**

> **作者:** Cassandra Overney; Cassandra Moe; Alvin Chang; Nabeel Gillani
>
> **备注:** Forthcoming in CSCW 2025
>
> **摘要:** School districts across the United States (US) play a pivotal role in shaping access to quality education through their student assignment policies -- most prominently, school attendance boundaries. Community engagement processes for changing such policies, however, are often opaque, cumbersome, and highly polarizing -- hampering equitable access to quality schools in ways that can perpetuate disparities in future life outcomes. In this paper, we describe a collaboration with a large US public school district serving nearly 150,000 students to design and evaluate a new sociotechnical system, "BoundarEase", for fostering more constructive community engagement around changing school attendance boundaries. Through a formative study with 16 community members, we first identify several frictions in existing community engagement processes, like individualistic over collective thinking; a failure to understand and empathize with the different ways policies might impact other community members; and challenges in understanding the impacts of boundary changes. These frictions inspire the design and development of BoundarEase, a web platform that allows community members to explore and offer feedback on potential boundaries. A user study with 12 community members reveals that BoundarEase prompts reflection among community members on how policies might impact families beyond their own, and increases transparency around the details of policy proposals. Our paper offers education researchers insights into the challenges and opportunities involved in community engagement for designing student assignment policies; human-computer interaction researchers a case study of how new sociotechnical systems might help mitigate polarization in local policymaking; and school districts a practical tool they might use to facilitate community engagement to foster more equitable student assignment policies.
>
---
#### [replaced 006] Predictable Drifts in Collective Cultural Attention: Evidence from Nation-Level Library Takeout Data
- **分类: cs.SI; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.12007v2](http://arxiv.org/pdf/2507.12007v2)**

> **作者:** Anders Weile Larsen; Vedran Sekara
>
> **摘要:** Predicting changes in consumer attention for cultural products, such as books, movies, and songs, is notoriously difficult. Past research on predicting the popularity of individual products suggests the existence of intrinsic prediction limits. However, little is known about the limits for predicting collective attention across cultural products. Here, we analyze four years of nationwide library loan data for approximately 2 million individuals, comprising over 100 million loans of more than 660,000 unique books. We find that culture, as measured by popularity distributions of loaned books, drifts continually from month to month at a near-constant rate, leading to a growing divergence over time, and that drifts vary between different book genres. By linking book loans to registry data, we investigate the influence of age, sex, educational level, and geographical area on cultural drift, finding heterogeneous effects from the different demographic groups. Our findings have important implications for market forecasting and developing robust recommender systems, highlighting the need to account for specific drift dynamics for different types of items and demographic groups.
>
---
#### [replaced 007] The Pursuit of Empathy: Evaluating Small Language Models for PTSD Dialogue Support
- **分类: cs.CL; cs.AI; cs.CY; 68T50, 68T05; I.2.7; I.2.1; H.5.2**

- **链接: [http://arxiv.org/pdf/2505.15065v2](http://arxiv.org/pdf/2505.15065v2)**

> **作者:** Suhas BN; Yash Mahajan; Dominik Mattioli; Andrew M. Sherrill; Rosa I. Arriaga; Chris W. Wiese; Saeed Abdullah
>
> **备注:** 23 pages, 3 figures. Accepted for Oral presentation at EMNLP 2025
>
> **摘要:** This paper investigates the capacity of small language models (0.5B-5B parameters) to generate empathetic responses for individuals with PTSD. We introduce Trauma-Informed Dialogue for Empathy (TIDE), a novel dataset comprising 10,000 two-turn conversations across 500 diverse, clinically-grounded PTSD personas (https://huggingface.co/datasets/yenopoya/TIDE). Using frontier model outputs as ground truth, we evaluate eight small LLMs in zero-shot settings and after fine-tuning. Fine-tuning enhances empathetic capabilities, improving cosine similarity and perceived empathy, although gains vary across emotional scenarios and smaller models exhibit a "knowledge transfer ceiling." As expected, Claude Sonnet 3.5 consistently outperforms all models, but surprisingly, the smaller models often approach human-rated empathy levels. Demographic analyses showed that older adults favored responses that validated distress before offering support (p = .004), while graduate-educated users preferred emotionally layered replies in specific scenarios. Gender-based differences were minimal (p > 0.15), suggesting the feasibility of broadly empathetic model designs. This work offers insights into building resource-efficient, emotionally intelligent systems for mental health support.
>
---
#### [replaced 008] Designing Human-AI Collaboration to Support Learning in Counterspeech Writing
- **分类: cs.HC; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2410.03032v4](http://arxiv.org/pdf/2410.03032v4)**

> **作者:** Xiaohan Ding; Kaike Ping; Uma Sushmitha Gunturi; Buse Carik; Sophia Stil; Lance T Wilhelm; Taufiq Daryanto; James Hawdon; Sang Won Lee; Eugenia H Rho
>
> **摘要:** Online hate speech has become increasingly prevalent on social media, causing harm to individuals and society. While automated content moderation has received considerable attention, user-driven counterspeech remains a less explored yet promising approach. However, many people face difficulties in crafting effective responses. We introduce CounterQuill, a human-AI collaborative system that helps everyday users with writing empathetic counterspeech - not by generating automatic replies, but by educating them through reflection and response. CounterQuill follows a three-stage workflow grounded in computational thinking: (1) a learning session to build understanding of hate speech and counterspeech, (2) a brainstorming session to identify harmful patterns and ideate counterspeech ideas, and (3) a co-writing session that helps users refine their counter responses while preserving personal voice. Through a user study (N = 20), we found that CounterQuill helped participants develop the skills to brainstorm and draft counterspeech with confidence and control throughout the process. Our findings highlight how AI systems can scaffold complex communication tasks through structured, human-centered workflows that educate users on how to recognize, reflect on, and respond to online hate speech.
>
---
#### [replaced 009] Datasets for Fairness in Language Models: An In-Depth Survey
- **分类: cs.CL; cs.CY; cs.LG**

- **链接: [http://arxiv.org/pdf/2506.23411v2](http://arxiv.org/pdf/2506.23411v2)**

> **作者:** Jiale Zhang; Zichong Wang; Avash Palikhe; Zhipeng Yin; Wenbin Zhang
>
> **摘要:** Despite the growing reliance on fairness benchmarks to evaluate language models, the datasets that underpin these benchmarks remain critically underexamined. This survey addresses that overlooked foundation by offering a comprehensive analysis of the most widely used fairness datasets in language model research. To ground this analysis, we characterize each dataset across key dimensions, including provenance, demographic scope, annotation design, and intended use, revealing the assumptions and limitations baked into current evaluation practices. Building on this foundation, we propose a unified evaluation framework that surfaces consistent patterns of demographic disparities across benchmarks and scoring metrics. Applying this framework to sixteen popular datasets, we uncover overlooked biases that may distort conclusions about model fairness and offer guidance on selecting, combining, and interpreting these resources more effectively and responsibly. Our findings highlight an urgent need for new benchmarks that capture a broader range of social contexts and fairness notions. To support future research, we release all data, code, and results at https://github.com/vanbanTruong/Fairness-in-Large-Language-Models/tree/main/datasets, fostering transparency and reproducibility in the evaluation of language model fairness.
>
---
#### [replaced 010] From Mimicry to True Intelligence (TI) -- A New Paradigm for Artificial General Intelligence
- **分类: cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2509.14474v2](http://arxiv.org/pdf/2509.14474v2)**

> **作者:** Meltem Subasioglu; Nevzat Subasioglu
>
> **备注:** 27 pages, 1 figure
>
> **摘要:** The debate around Artificial General Intelligence (AGI) remains open due to two fundamentally different goals: replicating human-like performance versus replicating human-like cognitive processes. We argue that current performance-based definitions are inadequate because they provide no clear, mechanism-focused roadmap for research, and they fail to properly define the qualitative nature of genuine intelligence. Drawing inspiration from the human brain, we propose a new paradigm that shifts the focus from external mimicry to the development of foundational cognitive architectures. We define True Intelligence (TI) as a system characterized by six core components: embodied sensory fusion, core directives, dynamic schemata creation, a highly-interconnected multi-expert architecture, an orchestration layer, and lastly, the unmeasurable quality of Interconnectedness, which we hypothesize results in consciousness and a subjective experience. We propose a practical, five-level taxonomy of AGI based on the number of the first five measurable components a system exhibits. This framework provides a clear path forward with developmental milestones that directly address the challenge of building genuinely intelligent systems. We contend that once a system achieves Level-5 AGI by implementing all five measurable components, the difference between it and TI remains as a purely philosophical debate. For practical purposes - and given theories indicate consciousness is an emergent byproduct of integrated, higher-order cognition - we conclude that a fifth-level AGI is functionally and practically equivalent to TI. This work synthesizes diverse insights from analytical psychology, schema theory, metacognition, modern brain architectures and latest works in AI to provide the first holistic, mechanism-based definition of AGI that offers a clear and actionable path for the research community.
>
---
#### [replaced 011] Translation in the Hands of Many:Centering Lay Users in Machine Translation Interactions
- **分类: cs.CL; cs.CY**

- **链接: [http://arxiv.org/pdf/2502.13780v2](http://arxiv.org/pdf/2502.13780v2)**

> **作者:** Beatrice Savoldi; Alan Ramponi; Matteo Negri; Luisa Bentivogli
>
> **摘要:** Converging societal and technical factors have transformed language technologies into user-facing applications used by the general public across languages. Machine Translation (MT) has become a global tool, with cross-lingual services now also supported by dialogue systems powered by multilingual Large Language Models (LLMs). Widespread accessibility has extended MT's reach to a vast base of lay users, many with little to no expertise in the languages or the technology itself. And yet, the understanding of MT consumed by such a diverse group of users -- their needs, experiences, and interactions with multilingual systems -- remains limited. In our position paper, we first trace the evolution of MT user profiles, focusing on non-experts and how their engagement with technology may shift with the rise of LLMs. Building on an interdisciplinary body of work, we identify three factors -- usability, trust, and literacy -- that are central to shaping user interactions and must be addressed to align MT with user needs. By examining these dimensions, we provide insights to guide the progress of more user-centered MT.
>
---
#### [replaced 012] Designing AI-Agents with Personalities: A Psychometric Approach
- **分类: cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2410.19238v3](http://arxiv.org/pdf/2410.19238v3)**

> **作者:** Muhua Huang; Xijuan Zhang; Christopher Soto; James Evans
>
> **摘要:** We introduce a methodology for assigning quantifiable and psychometrically validated personalities to AI-Agents using the Big Five framework. Across three studies, we evaluate its feasibility and limitations. In Study 1, we show that large language models (LLMs) capture semantic similarities among Big Five measures, providing a basis for personality assignment. In Study 2, we create AI-Agents using prompts designed based on the Big Five Inventory-2 (BFI-2) in different format, and find that AI-Agents powered by new models align more closely with human responses on the Mini-Markers test, although the finer pattern of results (e.g., factor loading patterns) were sometimes inconsistent. In Study 3, we validate our AI-Agents on risk-taking and moral dilemma vignettes, finding that models prompted with the BFI-2-Expanded format most closely reproduce human personality-decision associations, while safety-aligned models generally inflate 'moral' ratings. Overall, our results show that AI-Agents align with humans in correlations between input Big Five traits and output responses and may serve as useful tools for preliminary research. Nevertheless, discrepancies in finer response patterns indicate that AI-Agents cannot (yet) fully substitute for human participants in precision or high-stakes projects.
>
---
#### [replaced 013] The Good, the Bad and the Constructive: Automatically Measuring Peer Review's Utility for Authors
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2509.04484v3](http://arxiv.org/pdf/2509.04484v3)**

> **作者:** Abdelrahman Sadallah; Tim Baumgärtner; Iryna Gurevych; Ted Briscoe
>
> **备注:** EMNLP 2025 Main
>
> **摘要:** Providing constructive feedback to paper authors is a core component of peer review. With reviewers increasingly having less time to perform reviews, automated support systems are required to ensure high reviewing quality, thus making the feedback in reviews useful for authors. To this end, we identify four key aspects of review comments (individual points in weakness sections of reviews) that drive the utility for authors: Actionability, Grounding & Specificity, Verifiability, and Helpfulness. To enable evaluation and development of models assessing review comments, we introduce the RevUtil dataset. We collect 1,430 human-labeled review comments and scale our data with 10k synthetically labeled comments for training purposes. The synthetic data additionally contains rationales, i.e., explanations for the aspect score of a review comment. Employing the RevUtil dataset, we benchmark fine-tuned models for assessing review comments on these aspects and generating rationales. Our experiments demonstrate that these fine-tuned models achieve agreement levels with humans comparable to, and in some cases exceeding, those of powerful closed models like GPT-4o. Our analysis further reveals that machine-generated reviews generally underperform human reviews on our four aspects.
>
---
#### [replaced 014] The Automated but Risky Game: Modeling and Benchmarking Agent-to-Agent Negotiations and Transactions in Consumer Markets
- **分类: cs.AI; cs.CL; cs.CY; cs.HC; cs.MA**

- **链接: [http://arxiv.org/pdf/2506.00073v4](http://arxiv.org/pdf/2506.00073v4)**

> **作者:** Shenzhe Zhu; Jiao Sun; Yi Nian; Tobin South; Alex Pentland; Jiaxin Pei
>
> **摘要:** AI agents are increasingly used in consumer-facing applications to assist with tasks such as product search, negotiation, and transaction execution. In this paper, we explore a future scenario where both consumers and merchants authorize AI agents to fully automate negotiations and transactions. We aim to answer two key questions: (1) Do different LLM agents vary in their ability to secure favorable deals for users? (2) What risks arise from fully automating deal-making with AI agents in consumer markets? To address these questions, we develop an experimental framework that evaluates the performance of various LLM agents in real-world negotiation and transaction settings. Our findings reveal that AI-mediated deal-making is an inherently imbalanced game -- different agents achieve significantly different outcomes for their users. Moreover, behavioral anomalies in LLMs can result in financial losses for both consumers and merchants, such as overspending or accepting unreasonable deals. These results underscore that while automation can improve efficiency, it also introduces substantial risks. Users should exercise caution when delegating business decisions to AI agents.
>
---
#### [replaced 015] Fluent but Foreign: Even Regional LLMs Lack Cultural Alignment
- **分类: cs.CL; cs.AI; cs.CY; physics.soc-ph**

- **链接: [http://arxiv.org/pdf/2505.21548v2](http://arxiv.org/pdf/2505.21548v2)**

> **作者:** Dhruv Agarwal; Anya Shukla; Sunayana Sitaram; Aditya Vashistha
>
> **备注:** Under review
>
> **摘要:** Large language models (LLMs) are used worldwide, yet exhibit Western cultural tendencies. Many countries are now building ``regional'' LLMs, but it remains unclear whether they reflect local values and practices or merely speak local languages. Using India as a case study, we evaluate six Indic and six global LLMs on two dimensions -- values and practices -- grounded in nationally representative surveys and community-sourced QA datasets. Across tasks, Indic models do not align better with Indian norms than global models; in fact, a U.S. respondent is a closer proxy for Indian values than any Indic model. Prompting and regional fine-tuning fail to recover alignment and can even degrade existing knowledge. We attribute this to scarce culturally grounded data, especially for pretraining. We position cultural evaluation as a first-class requirement alongside multilingual benchmarks and offer a reusable, community-grounded methodology. We call for native, community-authored corpora and thick x wide evaluations to build truly sovereign LLMs.
>
---
#### [replaced 016] "What's Up, Doc?": Analyzing How Users Seek Health Information in Large-Scale Conversational AI Datasets
- **分类: cs.CL; cs.AI; cs.CY**

- **链接: [http://arxiv.org/pdf/2506.21532v3](http://arxiv.org/pdf/2506.21532v3)**

> **作者:** Akshay Paruchuri; Maryam Aziz; Rohit Vartak; Ayman Ali; Best Uchehara; Xin Liu; Ishan Chatterjee; Monica Agrawal
>
> **备注:** Accepted to EMNLP 2025 Findings - 25 pages, 6 figures, 4 tables
>
> **摘要:** People are increasingly seeking healthcare information from large language models (LLMs) via interactive chatbots, yet the nature and inherent risks of these conversations remain largely unexplored. In this paper, we filter large-scale conversational AI datasets to achieve HealthChat-11K, a curated dataset of 11K real-world conversations composed of 25K user messages. We use HealthChat-11K and a clinician-driven taxonomy for how users interact with LLMs when seeking healthcare information in order to systematically study user interactions across 21 distinct health specialties. Our analysis reveals insights into the nature of how and why users seek health information, such as common interactions, instances of incomplete context, affective behaviors, and interactions (e.g., leading questions) that can induce sycophancy, underscoring the need for improvements in the healthcare support capabilities of LLMs deployed as conversational AI. Code and artifacts to retrieve our analyses and combine them into a curated dataset can be found here: https://github.com/yahskapar/HealthChat
>
---
#### [replaced 017] How Real Are Synthetic Therapy Conversations? Evaluating Fidelity in Prolonged Exposure Dialogues
- **分类: cs.CL; cs.AI; cs.CY; cs.HC; 68T50; I.2.7; H.3.1**

- **链接: [http://arxiv.org/pdf/2504.21800v4](http://arxiv.org/pdf/2504.21800v4)**

> **作者:** Suhas BN; Dominik Mattioli; Saeed Abdullah; Rosa I. Arriaga; Chris W. Wiese; Andrew M. Sherrill
>
> **备注:** 10 pages, 5 tables. Accepted for Poster presentation at EMNLP 2025
>
> **摘要:** Synthetic data adoption in healthcare is driven by privacy concerns, data access limitations, and high annotation costs. We explore synthetic Prolonged Exposure (PE) therapy conversations for PTSD as a scalable alternative for training clinical models. We systematically compare real and synthetic dialogues using linguistic, structural, and protocol-specific metrics like turn-taking and treatment fidelity. We introduce and evaluate PE-specific metrics, offering a novel framework for assessing clinical fidelity beyond surface fluency. Our findings show that while synthetic data successfully mitigates data scarcity and protects privacy, capturing the most subtle therapeutic dynamics remains a complex challenge. Synthetic dialogues successfully replicate key linguistic features of real conversations, for instance, achieving a similar Readability Score (89.2 vs. 88.1), while showing differences in some key fidelity markers like distress monitoring. This comparison highlights the need for fidelity-aware metrics that go beyond surface fluency to identify clinically significant nuances. Our model-agnostic framework is a critical tool for developers and clinicians to benchmark generative model fidelity before deployment in sensitive applications. Our findings help clarify where synthetic data can effectively complement real-world datasets, while also identifying areas for future refinement.
>
---
#### [replaced 018] Why Data Anonymization Has Not Taken Off
- **分类: cs.CR; cs.CY**

- **链接: [http://arxiv.org/pdf/2509.10165v2](http://arxiv.org/pdf/2509.10165v2)**

> **作者:** Matthew J. Schneider; James Bailie; Dawn Iacobucci
>
> **备注:** 15 pages, to appear in Customer Needs and Solutions (v2 correcting formatting of reference list)
>
> **摘要:** Companies are looking to data anonymization research $\unicode{x2013}$ including differential private and synthetic data methods $\unicode{x2013}$ for simple and straightforward compliance solutions. But data anonymization has not taken off in practice because it is anything but simple to implement. For one, it requires making complex choices which are case dependent, such as the domain of the dataset to anonymize; the units to protect; the scope where the data protection should extend to; and the standard of protection. Each variation of these choices changes the very meaning, as well as the practical implications, of differential privacy (or of any other measure of data anonymization). Yet differential privacy is frequently being branded as the same privacy guarantee regardless of variations in these choices. Some data anonymization methods can be effective, but only when the insights required are much larger than the unit of protection. Given that businesses care about profitability, any solution must preserve the patterns between a firm's data and that profitability. As a result, data anonymization solutions usually need to be bespoke and case-specific, which reduces their scalability. Companies should not expect easy wins, but rather recognize that anonymization is just one approach to data privacy with its own particular advantages and drawbacks, while the best strategies jointly leverage the full range of approaches to data privacy and security in combination.
>
---
#### [replaced 019] From Judgment to Interference: Early Stopping LLM Harmful Outputs via Streaming Content Monitoring
- **分类: cs.CL; cs.CY**

- **链接: [http://arxiv.org/pdf/2506.09996v3](http://arxiv.org/pdf/2506.09996v3)**

> **作者:** Yang Li; Qiang Sheng; Yehan Yang; Xueyao Zhang; Juan Cao
>
> **备注:** NeurIPS 2025 Accepted Paper
>
> **摘要:** Though safety alignment has been applied to most large language models (LLMs), LLM service providers generally deploy a subsequent moderation as the external safety guardrail in real-world products. Existing moderators mainly practice a conventional full detection, which determines the harmfulness based on the complete LLM output, causing high service latency. Recent works pay more attention to partial detection where moderators oversee the generation midway and early stop the output if harmfulness is detected, but they directly apply moderators trained with the full detection paradigm to incomplete outputs, introducing a training-inference gap that lowers the performance. In this paper, we explore how to form a data-and-model solution that natively supports partial detection. For the data, we construct FineHarm, a dataset consisting of 29K prompt-response pairs with fine-grained annotations to provide reasonable supervision for token-level training. Then, we propose the streaming content monitor, which is trained with dual supervision of response- and token-level labels and can follow the output stream of LLM to make a timely judgment of harmfulness. Experiments show that SCM gains 0.95+ in macro F1 score that is comparable to full detection, by only seeing the first 18% of tokens in responses on average. Moreover, the SCM can serve as a pseudo-harmfulness annotator for improving safety alignment and lead to a higher harmlessness score than DPO.
>
---
#### [replaced 020] Tracking Patterns in Toxicity and Antisocial Behavior Over User Lifetimes on Large Social Media Platforms
- **分类: cs.SI; cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2407.09365v2](http://arxiv.org/pdf/2407.09365v2)**

> **作者:** Katy Blumer; Jon Kleinberg
>
> **摘要:** An increasing amount of attention has been devoted to the problem of "toxic" or antisocial behavior on social media. In this paper we analyze such behavior at very large scales: we analyze toxicity over a 14-year time span on nearly 500 million comments from Reddit and Wikipedia, grounded in two different proxies for toxicity. At the individual level, we analyze users' toxicity levels over the course of their time on the site, and find a striking reversal in trends: both Reddit and Wikipedia users tended to become less toxic over their life cycles on the site in the early (pre-2013) history of the site, but more toxic over their life cycles in the later (post-2013) history of the site. We also find that toxicity on Reddit and Wikipedia differ in a key way, with the most toxic behavior on Reddit exhibited in aggregate by the most active users, and the most toxic behavior on Wikipedia exhibited in aggregate by the least active users. Finally, we consider the toxicity of discussion around widely-shared pieces of content, and find that the trends for toxicity in discussion about content bear interesting similarities with the trends for toxicity in discussion by users.
>
---
#### [replaced 021] Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2509.13400v2](http://arxiv.org/pdf/2509.13400v2)**

> **作者:** Sai Suresh Marchala Vasu; Ivaxi Sheth; Hui-Po Wang; Ruta Binkyte; Mario Fritz
>
> **摘要:** The adoption of large language models (LLMs) is transforming the peer review process, from assisting reviewers in writing more detailed evaluations to generating entire reviews automatically. While these capabilities offer exciting opportunities, they also raise critical concerns about fairness and reliability. In this paper, we investigate bias in LLM-generated peer reviews by conducting controlled experiments on sensitive metadata, including author affiliation and gender. Our analysis consistently shows affiliation bias favoring institutions highly ranked on common academic rankings. Additionally, we find some gender preferences, which, even though subtle in magnitude, have the potential to compound over time. Notably, we uncover implicit biases that become more evident with token-based soft ratings.
>
---
#### [replaced 022] OnlineMate: An LLM-Based Multi-Agent Companion System for Cognitive Support in Online Learning
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2509.14803v2](http://arxiv.org/pdf/2509.14803v2)**

> **作者:** Xian Gao; Zongyun Zhang; Ting Liu; Yuzhuo Fu
>
> **备注:** work in progress
>
> **摘要:** In online learning environments, students often lack personalized peer interactions, which play a crucial role in supporting cognitive development and learning engagement. Although previous studies have utilized large language models (LLMs) to simulate interactive dynamic learning environments for students, these interactions remain limited to conversational exchanges, lacking insights and adaptations to the learners' individualized learning and cognitive states. As a result, students' interest in discussions with AI learning companions is low, and they struggle to gain inspiration from such interactions. To address this challenge, we propose OnlineMate, a multi-agent learning companion system driven by LLMs that integrates the Theory of Mind (ToM). OnlineMate is capable of simulating peer-like agent roles, adapting to learners' cognitive states during collaborative discussions, and inferring their psychological states, such as misunderstandings, confusion, or motivation. By incorporating Theory of Mind capabilities, the system can dynamically adjust its interaction strategies to support the development of higher-order thinking and cognition. Experimental results in simulated learning scenarios demonstrate that OnlineMate effectively fosters deep learning and discussions while enhancing cognitive engagement in online educational settings.
>
---
#### [replaced 023] Jailbreak-Tuning: Models Efficiently Learn Jailbreak Susceptibility
- **分类: cs.CR; cs.AI; cs.CL; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.11630v2](http://arxiv.org/pdf/2507.11630v2)**

> **作者:** Brendan Murphy; Dillon Bowen; Shahrad Mohammadzadeh; Tom Tseng; Julius Broomfield; Adam Gleave; Kellin Pelrine
>
> **摘要:** AI systems are rapidly advancing in capability, and frontier model developers broadly acknowledge the need for safeguards against serious misuse. However, this paper demonstrates that fine-tuning, whether via open weights or closed fine-tuning APIs, can produce helpful-only models with safeguards destroyed. In contrast to prior work which is blocked by modern moderation systems or achieved only partial removal of safeguards or degraded output quality, our jailbreak-tuning method teaches models to generate detailed, high-quality responses to arbitrary harmful requests. For example, OpenAI, Google, and Anthropic models will fully comply with requests for CBRN assistance, executing cyberattacks, and other criminal activity. We further show that backdoors can increase not only the stealth but also the severity of attacks. Stronger jailbreak prompts become even more effective in fine-tuning attacks, linking attacks and potentially defenses in the input and weight spaces. Not only are current models vulnerable, more recent ones also appear to be becoming even more vulnerable to these attacks, underscoring the urgent need for tamper-resistant safeguards. Until such safeguards are discovered, companies and policymakers should view the release of any fine-tunable model as simultaneously releasing its evil twin: equally capable as the original model, and usable for any malicious purpose within its capabilities.
>
---
#### [replaced 024] SouLLMate: An Adaptive LLM-Driven System for Advanced Mental Health Support and Assessment, Based on a Systematic Application Survey
- **分类: cs.HC; cs.CY**

- **链接: [http://arxiv.org/pdf/2410.11859v2](http://arxiv.org/pdf/2410.11859v2)**

> **作者:** Qiming Guo; Jinwen Tang; Wenbo Sun; Haoteng Tang; Yi Shang; Wenlu Wang
>
> **摘要:** Mental health issues significantly impact individuals' daily lives, yet many do not receive the help they need even with available online resources. This study aims to provide accessible, stigma-free, personalized, and real-time mental health support through cutting-edge AI technologies. It makes the following contributions: (1) Conducting an extensive survey of recent mental health support methods to identify prevalent functionalities and unmet needs. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates LLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt engineering, and domain knowledge. This system offers advanced features such as Suicide Risk Detection and Proactive Guidance Dialogue, and utilizes RAG for personalized profile uploads and Conversational Information Extraction. (3) Developing novel evaluation approaches to assess preliminary assessments and suicide risk detection, utilizing annotated real-life interview data and professionally labeled datasets indicating suicide tendencies. (4) Proposing Key Indicator Summarization (KIS) and Proactive Questioning Strategy (PQS) methods to enhance model performance and usability through context-sensitive response adjustments and semantic coherence evaluations. This study contributes to advancing mental health support technologies, potentially improving the accessibility and effectiveness of mental health care globally.
>
---
#### [replaced 025] Can GenAI Move from Individual Use to Collaborative Work? Experiences, Challenges, and Opportunities of Integrating GenAI into Collaborative Newsroom Routines
- **分类: cs.HC; cs.CY**

- **链接: [http://arxiv.org/pdf/2509.10950v2](http://arxiv.org/pdf/2509.10950v2)**

> **作者:** Qing Xiao; Qing Hu; Jingjia Xiao; Hancheng Cao; Hong Shen
>
> **备注:** 17 pages, 1 figure
>
> **摘要:** Generative AI (GenAI) is reshaping work, but adoption remains largely individual and experimental rather than integrated into collaborative routines. Whether GenAI can move from individual use to collaborative work is a critical question for future organizations. Journalism offers a compelling site to examine this shift: individual journalists have already been disrupted by GenAI tools; yet newswork is inherently collaborative relying on shared routines and coordinated workflows. We conducted 27 interviews with newsrooms managers, editors, and front-line journalists in China. We found that journalists frequently used GenAI to support daily tasks, but value alignment was safeguarded mainly through individual discretion. At the organizational level, GenAI use remained disconnected from team workflows, hindered by structural barriers and cultural reluctance to share practices. These findings underscore the gap between individual and collective adoption, pointing to the need for accounting for organizational structures, cultural norms, and workflow integration when designing GenAI for collaborative work.
>
---
#### [replaced 026] Enhancing Clinical Decision-Making: Integrating Multi-Agent Systems with Ethical AI Governance
- **分类: cs.AI; cs.CY; cs.LG; cs.MA; q-bio.QM**

- **链接: [http://arxiv.org/pdf/2504.03699v4](http://arxiv.org/pdf/2504.03699v4)**

> **作者:** Ying-Jung Chen; Ahmad Albarqawi; Chi-Sheng Chen
>
> **摘要:** Recent advances in the data-driven medicine approach, which integrates ethically managed and explainable artificial intelligence into clinical decision support systems (CDSS), are critical to ensure reliable and effective patient care. This paper focuses on comparing novel agent system designs that use modular agents to analyze laboratory results, vital signs, and clinical context, and to predict and validate results. We implement our agent system with the eICU database, including running lab analysis, vitals-only interpreters, and contextual reasoners agents first, then sharing the memory into the integration agent, prediction agent, transparency agent, and a validation agent. Our results suggest that the multi-agent system (MAS) performed better than the single-agent system (SAS) with mortality prediction accuracy (59\%, 56\%) and the mean error for length of stay (LOS)(4.37 days, 5.82 days), respectively. However, the transparency score for the SAS (86.21) is slightly better than the transparency score for MAS (85.5). Finally, this study suggests that our agent-based framework not only improves process transparency and prediction accuracy but also strengthens trustworthy AI-assisted decision support in an intensive care setting.
>
---
