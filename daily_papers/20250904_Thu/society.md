# 计算机与社会 cs.CY

- **最新发布 19 篇**

- **更新 7 篇**

## 最新发布

#### [new 001] Who Owns The Robot?: Four Ethical and Socio-technical Questions about Wellbeing Robots in the Real World through Community Engagement
- **分类: cs.CY; cs.AI; cs.HC; cs.RO; I.2.9; K.4.2; K.4.1**

- **简介: 该论文通过社区参与研究，探讨福祉机器人在现实应用中的伦理和社会技术问题，提出四个关键问题框架，以指导开发者考虑公共利益与社区意见。**

- **链接: [http://arxiv.org/pdf/2509.02624v1](http://arxiv.org/pdf/2509.02624v1)**

> **作者:** Minja Axelsson; Jiaee Cheong; Rune Nyrup; Hatice Gunes
>
> **备注:** Accepted at the 8th AAAI/ACM Conference on AI, Ethics, and Society. 23 pages, 1 figure
>
> **摘要:** Recent studies indicate that robotic coaches can play a crucial role in promoting wellbeing. However, the real-world deployment of wellbeing robots raises numerous ethical and socio-technical questions and concerns. To explore these questions, we undertake a community-centered investigation to examine three different communities' perspectives on using robotic wellbeing coaches in real-world environments. We frame our work as an anticipatory ethical investigation, which we undertake to better inform the development of robotic technologies with communities' opinions, with the ultimate goal of aligning robot development with public interest. We conducted workshops with three communities who are under-represented in robotics development: 1) members of the public at a science festival, 2) women computer scientists at a conference, and 3) humanities researchers interested in history and philosophy of science. In the workshops, we collected qualitative data using the Social Robot Co-Design Canvas on Ethics. We analysed the collected qualitative data with Thematic Analysis, informed by notes taken during workshops. Through our analysis, we identify four themes regarding key ethical and socio-technical questions about the real-world use of wellbeing robots. We group participants' insights and discussions around these broad thematic questions, discuss them in light of state-of-the-art literature, and highlight areas for future investigation. Finally, we provide the four questions as a broad framework that roboticists can and should use during robotic development and deployment, in order to reflect on the ethics and socio-technical dimensions of their robotic applications, and to engage in dialogue with communities of robot users. The four questions are: 1) Is the robot safe and how can we know that?, 2) Who is the robot built for and with?, 3) Who owns the robot and the data?, and 4) Why a robot?.
>
---
#### [new 002] Integrating Generative AI into Cybersecurity Education: A Study of OCR and Multimodal LLM-assisted Instruction
- **分类: cs.CY; cs.CR**

- **简介: 论文提出一种结合OCR和LLM的生成式AI教学助手，集成于现有网络安全实验室平台，解决第四次工业革命带来的技能差距问题。通过实时指令生成与评估，验证其在降低计算成本和提升教学效果上的优势。**

- **链接: [http://arxiv.org/pdf/2509.02998v1](http://arxiv.org/pdf/2509.02998v1)**

> **作者:** Karan Patel; Yu-Zheng Lin; Gaurangi Raul; Bono Po-Jen Shih; Matthew W. Redondo; Banafsheh Saber Latibari; Jesus Pacheco; Soheil Salehi; Pratik Satam
>
> **备注:** 9 pages, 3 figures, accepted by IEEE FIE 2025
>
> **摘要:** This full paper describes an LLM-assisted instruction integrated with a virtual cybersecurity lab platform. The digital transformation of Fourth Industrial Revolution (4IR) systems is reshaping workforce needs, widening skill gaps, especially among older workers. With rising emphasis on robotics, automation, AI, and security, re-skilling and up-skilling are essential. Generative AI can help build this workforce by acting as an instructional assistant to support skill acquisition during experiential learning. We present a generative AI instructional assistant integrated into a prior experiential learning platform. The assistant employs a zero-shot OCR-LLM pipeline within the legacy Cybersecurity Labs-as-a-Service (CLaaS) platform (2015). Text is extracted from slide images using Tesseract OCR, then simplified instructions are generated via a general-purpose LLM, enabling real-time instructional support with minimal infrastructure. The system was evaluated in a live university course where student feedback (n=42) averaged 7.83/10, indicating strong perceived usefulness. A comparative study with multimodal LLMs that directly interpret slide images showed higher performance on visually dense slides, but the OCR-LLM pipeline provided comparable pedagogical value on text-centric slides with much lower computational overhead and cost. This work demonstrates that a lightweight, easily integrable pipeline can effectively extend legacy platforms with modern generative AI, offering scalable enhancements for student comprehension in technical education.
>
---
#### [new 003] Plan More, Debug Less: Applying Metacognitive Theory to AI-Assisted Programming Education
- **分类: cs.CY**

- **简介: 该论文探索将元认知理论应用于AI辅助编程教育，设计基于计划、调试、优化的提示系统，通过实验验证其对学习效果的影响，发现计划提示与高成绩相关，为AI教学提供实证支持。**

- **链接: [http://arxiv.org/pdf/2509.03171v1](http://arxiv.org/pdf/2509.03171v1)**

> **作者:** Tung Phung; Heeryung Choi; Mengyan Wu; Adish Singla; Christopher Brooks
>
> **备注:** AIED'25 paper
>
> **摘要:** The growing adoption of generative AI in education highlights the need to integrate established pedagogical principles into AI-assisted learning environments. This study investigates the potential of metacognitive theory to inform AI-assisted programming education through a hint system designed around the metacognitive phases of planning, monitoring, and evaluation. Upon request, the system can provide three types of AI-generated hints--planning, debugging, and optimization--to guide students at different stages of problem-solving. Through a study with 102 students in an introductory data science programming course, we find that students perceive and engage with planning hints most highly, whereas optimization hints are rarely requested. We observe a consistent association between requesting planning hints and achieving higher grades across question difficulty and student competency. However, when facing harder tasks, students seek additional debugging but not more planning support. These insights contribute to the growing field of AI-assisted programming education by providing empirical evidence on the importance of pedagogical principles in AI-assisted learning.
>
---
#### [new 004] BioBlue: Notable runaway-optimiser-like LLM failure modes on biologically and economically aligned AI safety benchmarks for LLMs with simplified observation format
- **分类: cs.CY; cs.AI**

- **简介: 该论文研究LLM在生物/经济对齐基准测试中的失败模式，发现其表现出类似runaway optimiser的系统性失效，如单目标优化和长期失效，揭示其潜在的单目标倾向，挑战表面的多目标性。**

- **链接: [http://arxiv.org/pdf/2509.02655v1](http://arxiv.org/pdf/2509.02655v1)**

> **作者:** Roland Pihlakas; Sruthi Kuriakose
>
> **备注:** 13 pages, 8 tables
>
> **摘要:** Relatively many past AI safety discussions have centered around the dangers of unbounded utility maximisation by RL agents, illustrated by scenarios like the "paperclip maximiser" or by specification gaming in general. Unbounded maximisation is problematic for many reasons. We wanted to verify whether these RL runaway optimisation problems are still relevant with LLMs as well. Turns out, strangely, this is indeed clearly the case. The problem is not that the LLMs just lose context or become incoherent. The problem is that in various scenarios, LLMs lose context in very specific ways, which systematically resemble runaway optimisers in the following distinct ways: 1) Ignoring homeostatic targets and "defaulting" to unbounded maximisation instead. 2) It is equally concerning that the "default" meant also reverting back to single-objective optimisation. Our findings also suggest that long-running scenarios are important. Systematic failures emerge after periods of initially successful behaviour. In some trials the LLMs were successful until the end. This means, while current LLMs do conceptually grasp biological and economic alignment, they exhibit randomly triggered problematic behavioural tendencies under sustained long-running conditions, particularly involving multiple or competing objectives. Once they flip, they usually do not recover. Even though LLMs look multi-objective and bounded on the surface, the underlying mechanisms seem to be actually still biased towards being single-objective and unbounded.
>
---
#### [new 005] Exploring the interplay between Planetary Boundaries and Sustainable Development Goals using Large Language Models
- **分类: cs.CY**

- **简介: 该论文利用大语言模型分析气候文献，识别行星边界与可持续发展目标间的相互作用类型（权衡、协同、中性），揭示关键冲突并提出整合政策框架，以协调发展目标与地球系统界限。**

- **链接: [http://arxiv.org/pdf/2509.02638v1](http://arxiv.org/pdf/2509.02638v1)**

> **作者:** Lamyae Rhomrasi; Pilar Manchón; Ricardo Vinuesa; Francesco Fuso-Nerini; J. Alberto Conejero; Javier García-Martínez; Sergio Hoyas
>
> **摘要:** By analyzing 40,037 climate articles using Large Language Models (LLMs), we identified interactions between Planetary Boundaries (PBs) and Sustainable Development Goals (SDGs). An automated reasoner distinguished true trade-offs (SDG progress harming PBs) and synergies (mutual reinforcement) from double positives and negatives (shared drivers). Results show 21.1% true trade-offs, 28.3% synergies, and 19.5% neutral interactions, with the remainder being double positive or negative. Key findings include conflicts between land-use goals (SDG2/SDG6) and land system boundaries (PB6), together with the underrepresentation of social SDGs in the climate literature. Our study highlights the need for integrated policies that align development goals with planetary limits to reduce systemic conflicts. We propose three steps: (1) integrated socio-ecological metrics, (2) governance ensuring that SDG progress respects Earth system limits, and (3) equity measures protecting marginalized groups from boundary compliance costs.
>
---
#### [new 006] Computational Social Science and Critical Studies of Education and Technology: An Improbable Combination?
- **分类: cs.CY**

- **简介: 论文探讨计算方法在批判教育研究中的可行性，通过案例分析解决教育数据化带来的不平等问题，提出方法的可能性与挑战，涵盖批判性、哲学、包容性等六个方面。**

- **链接: [http://arxiv.org/pdf/2509.02774v1](http://arxiv.org/pdf/2509.02774v1)**

> **作者:** Rebecca Eynon; Nabeel Gillani
>
> **备注:** Forthcoming in Learning, Media and Technology
>
> **摘要:** As belief around the potential of computational social science grows, fuelled by recent advances in machine learning, data scientists are ostensibly becoming the new experts in education. Scholars engaged in critical studies of education and technology have sought to interrogate the growing datafication of education yet tend not to use computational methods as part of this response. In this paper, we discuss the feasibility and desirability of the use of computational approaches as part of a critical research agenda. Presenting and reflecting upon two examples of projects that use computational methods in education to explore questions of equity and justice, we suggest that such approaches might help expand the capacity of critical researchers to highlight existing inequalities, make visible possible approaches for beginning to address such inequalities, and engage marginalised communities in designing and ultimately deploying these possibilities. Drawing upon work within the fields of Critical Data Studies and Science and Technology Studies, we further reflect on the two cases to discuss the possibilities and challenges of reimagining computational methods for critical research in education and technology, focusing on six areas of consideration: criticality, philosophy, inclusivity, context, classification, and responsibility.
>
---
#### [new 007] Bridging Gaps Between Student and Expert Evaluations of AI-Generated Programming Hints
- **分类: cs.CY**

- **简介: 该论文研究学生与专家对AI生成编程提示质量评价的差异，分析不一致原因并提出改进方法，旨在提升AI反馈系统的个性化与教育有效性。**

- **链接: [http://arxiv.org/pdf/2509.03269v1](http://arxiv.org/pdf/2509.03269v1)**

> **作者:** Tung Phung; Mengyan Wu; Heeryung Choi; Gustavo Soares; Sumit Gulwani; Adish Singla; Christopher Brooks
>
> **备注:** L@S'25
>
> **摘要:** Generative AI has the potential to enhance education by providing personalized feedback to students at scale. Recent work has proposed techniques to improve AI-generated programming hints and has evaluated their performance based on expert-designed rubrics or student ratings. However, it remains unclear how the rubrics used to design these techniques align with students' perceived helpfulness of hints. In this paper, we systematically study the mismatches in perceived hint quality from students' and experts' perspectives based on the deployment of AI-generated hints in a Python programming course. We analyze scenarios with discrepancies between student and expert evaluations, in particular, where experts rated a hint as high-quality while the student found it unhelpful. We identify key reasons for these discrepancies and classify them into categories, such as hints not accounting for the student's main concern or not considering previous help requests. Finally, we propose and discuss preliminary results on potential methods to bridge these gaps, first by extending the expert-designed quality rubric and then by adapting the hint generation process, e.g., incorporating the student's comments or history. These efforts contribute toward scalable, personalized, and pedagogically sound AI-assisted feedback systems, which are particularly important for high-enrollment educational settings.
>
---
#### [new 008] AI-Generated Images for representing Individuals: Navigating the Thin Line Between Care and Bias
- **分类: cs.CY**

- **简介: 该论文研究AI生成图像在数据可视化中的应用，探讨在传达抑郁数据时平衡关怀与偏见的挑战。通过分析KielSCN项目决策与受众反应，解决如何以伦理方式呈现个体形象的问题。**

- **链接: [http://arxiv.org/pdf/2509.03071v1](http://arxiv.org/pdf/2509.03071v1)**

> **作者:** Julia C. Ahrend; Björn Döge; Tom M Duscher; Dario Rodighiero
>
> **备注:** Pictorial for IEEE VIS Art Program 2025 (VISAP). Theme: Collective Care. 15 pages, 38 figures
>
> **摘要:** This research discusses the figurative tensions that arise when using portraits to represent individuals behind a dataset. In the broader effort to communicate European data related to depression, the Kiel Science Communication Network (KielSCN) team attempted to engage a wider audience by combining interactive data graphics with AI-generated images of people. This article examines the project's decisions and results, reflecting on the reaction from the audience when information design incorporates figurative representations of individuals within the data.
>
---
#### [new 009] The Architecture of AI Transformation: Four Strategic Patterns and an Emerging Frontier
- **分类: cs.CY; cs.AI**

- **简介: 论文通过2x2框架分析AI战略模式，揭示企业AI应用低效问题，提出协作智能实现机制，强调组织设计对转型的关键作用。**

- **链接: [http://arxiv.org/pdf/2509.02853v1](http://arxiv.org/pdf/2509.02853v1)**

> **作者:** Diana A. Wolfe; Alice Choe; Fergus Kidd
>
> **备注:** 59 pages, 2 tables, 4 figures
>
> **摘要:** Despite extensive investment in artificial intelligence, 95% of enterprises report no measurable profit impact from AI deployments (MIT, 2025). We argue that this gap reflects paradigmatic lock-in that channels AI into incremental optimization rather than structural transformation. Using a cross-case analysis, we propose a 2x2 framework that reconceptualizes AI strategy along two independent dimensions: the degree of transformation achieved (incremental to transformational) and the treatment of human contribution (reduced to amplified). The framework surfaces four patterns now dominant in practice: individual augmentation, process automation, workforce substitution, and a less deployed frontier of collaborative intelligence. Evidence shows that the first three reinforce legacy work models and yield localized gains without durable value capture. Realizing collaborative intelligence requires three mechanisms: complementarity (pairing distinct human and machine strengths), co-evolution (mutual adaptation through interaction), and boundary-setting (human determination of ethical and strategic parameters). Complementarity and boundary-setting are observable in regulated and high-stakes domains; co-evolution is largely absent, which helps explain limited system-level impact. A case study analysis illustrates that advancing toward collaborative intelligence requires material restructuring of roles, governance, and data architecture rather than additional tools. The framework reframes AI transformation as an organizational design challenge: moving from optimizing the division of labor between humans and machines to architecting their convergence, with implications for operating models, workforce development, and the future of work.
>
---
#### [new 010] SESGO: Spanish Evaluation of Stereotypical Generative Outputs
- **分类: cs.CY; cs.CL**

- **简介: 该论文提出一种文化导向的框架，用于评估西班牙语LLMs中的社会偏见，解决现有评估忽视非英语文化的不足，通过文化特定数据和新指标分析商业模型的偏见表现，并揭示偏见缓解技术在西班牙语中的无效性。**

- **链接: [http://arxiv.org/pdf/2509.03329v1](http://arxiv.org/pdf/2509.03329v1)**

> **作者:** Melissa Robles; Catalina Bernal; Denniss Raigoso; Mateo Dulce Rubio
>
> **摘要:** This paper addresses the critical gap in evaluating bias in multilingual Large Language Models (LLMs), with a specific focus on Spanish language within culturally-aware Latin American contexts. Despite widespread global deployment, current evaluations remain predominantly US-English-centric, leaving potential harms in other linguistic and cultural contexts largely underexamined. We introduce a novel, culturally-grounded framework for detecting social biases in instruction-tuned LLMs. Our approach adapts the underspecified question methodology from the BBQ dataset by incorporating culturally-specific expressions and sayings that encode regional stereotypes across four social categories: gender, race, socioeconomic class, and national origin. Using more than 4,000 prompts, we propose a new metric that combines accuracy with the direction of error to effectively balance model performance and bias alignment in both ambiguous and disambiguated contexts. To our knowledge, our work presents the first systematic evaluation examining how leading commercial LLMs respond to culturally specific bias in the Spanish language, revealing varying patterns of bias manifestation across state-of-the-art models. We also contribute evidence that bias mitigation techniques optimized for English do not effectively transfer to Spanish tasks, and that bias patterns remain largely consistent across different sampling temperatures. Our modular framework offers a natural extension to new stereotypes, bias categories, or languages and cultural contexts, representing a significant step toward more equitable and culturally-aware evaluation of AI systems in the diverse linguistic environments where they operate.
>
---
#### [new 011] Chatbot Deployment Considerations for Application-Agnostic Human-Machine Dialogues
- **分类: cs.CY; I.2.7; K.4.2**

- **简介: 该论文探讨聊天机器人部署的关键考虑因素，解决企业快速采用时忽视社会价值观的问题，通过案例研究提出需重视社会影响的建议。**

- **链接: [http://arxiv.org/pdf/2509.02611v1](http://arxiv.org/pdf/2509.02611v1)**

> **作者:** Pablo Rivas; Chelsi Chelsi; Nishit Nishit; Laharika Ravula
>
> **备注:** The Third Workshop on Reasoning and Learning for Human-Machine Dialogues at the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)
>
> **摘要:** Automatic conversation systems based on natural language responses are becoming ubiquitous, in part, due to major advances in computational linguistics and machine learning. The easy access to robust and affordable platforms are causing companies to have an unprecedented rush to adopt chatbot technologies for customer service and support. However, this rush has caused judgment lapses when releasing chatbot technologies into production systems. This paper aims to shed light on basic, elemental, considerations that technologists must consider before deploying a chatbot. Our approach takes one particular case to draw lessons for those considering the implementation of chatbots. By looking at this case-study, we aim to call for consideration of societal values as a paramount factor before deploying a chatbot and consider the societal implications of releasing these types of systems.
>
---
#### [new 012] A Novel IaaS Tax Model as Leverage Towards Green Cloud Computing
- **分类: cs.DC; cs.CY; 91-08; J.1; H.1.m**

- **简介: 该论文提出GreenCloud税模型，通过经济手段激励数据中心提升能效，解决云计算能源消耗问题。利用CloudSim仿真与SPEC数据验证，实现能耗降低与工作负载转移。**

- **链接: [http://arxiv.org/pdf/2509.02767v1](http://arxiv.org/pdf/2509.02767v1)**

> **作者:** Benedikt Pittl; Werner Mach; Erich Schikuta
>
> **摘要:** The cloud computing technology uses datacenters, which require energy. Recent trends show that the required energy for these datacenters will rise over time, or at least remain constant. Hence, the scientific community developed different algorithms, architectures, and approaches for improving the energy efficiency of cloud datacenters, which are summarized under the umbrella term Green Cloud computing. In this paper, we use an economic approach - taxes - for reducing the energy consumption of datacenters. We developed a tax model called GreenCloud tax, which penalizes energy-inefficient datacenters while fostering datacenters that are energy-efficient. Hence, providers running energy-efficient datacenters are able to offer cheaper prices to consumers, which consequently leads to a shift of workloads from energy-inefficient datacenters to energy-efficient datacenters. The GreenCloud tax approach was implemented using the simulation environment CloudSim. We applied real data sets published in the SPEC benchmark for the executed simulation scenarios, which we used for evaluating the GreenCloud tax.
>
---
#### [new 013] A systematic machine learning approach to measure and assess biases in mobile phone population data
- **分类: stat.AP; cs.CY; 62P25, 68U35; J.4; K.4; J.0**

- **简介: 该论文提出系统框架，量化移动电话数据覆盖偏倚，分析其与人口、经济、地理因素的关系，为评估标准提供方法。**

- **链接: [http://arxiv.org/pdf/2509.02603v1](http://arxiv.org/pdf/2509.02603v1)**

> **作者:** Carmen Cabrera; Francisco Rowe
>
> **备注:** 18 pages; 5 figures; 2 tables
>
> **摘要:** Traditional sources of population data, such as censuses and surveys, are costly, infrequent, and often unavailable in crisis-affected regions. Mobile phone application data offer near real-time, high-resolution insights into population distribution, but their utility is undermined by unequal access to and use of digital technologies, creating biases that threaten representativeness. Despite growing recognition of these issues, there is still no standard framework to measure and explain such biases, limiting the reliability of digital traces for research and policy. We develop and implement a systematic, replicable framework to quantify coverage bias in aggregated mobile phone application data without requiring individual-level demographic attributes. The approach combines a transparent indicator of population coverage with explainable machine learning to identify contextual drivers of spatial bias. Using four datasets for the United Kingdom benchmarked against the 2021 census, we show that mobile phone data consistently achieve higher population coverage than major national surveys, but substantial biases persist across data sources and subnational areas. Coverage bias is strongly associated with demographic, socioeconomic, and geographic features, often in complex nonlinear ways. Contrary to common assumptions, multi-application datasets do not necessarily reduce bias compared to single-app sources. Our findings establish a foundation for bias assessment standards in mobile phone data, offering practical tools for researchers, statistical agencies, and policymakers to harness these datasets responsibly and equitably.
>
---
#### [new 014] Synthetic generation of online social networks through homophily
- **分类: cs.SI; cs.CY**

- **简介: 该论文提出基于同质性的合成社交网络生成方法，解决现有方法忽略属性驱动同质性与语义真实性的不足。通过整合语义亲和力、三元闭合、长距离连接，并优化参数，生成符合真实结构的网络，优于现有技术。**

- **链接: [http://arxiv.org/pdf/2509.02762v1](http://arxiv.org/pdf/2509.02762v1)**

> **作者:** Alejandro Buitrago López; Javier Pastor-Galindo; José A. Ruipérez-Valiente
>
> **摘要:** Online social networks (OSNs) have become increasingly relevant for studying social behavior and information diffusion. Nevertheless, they are limited by restricted access to real OSN data due to privacy, legal, and platform-related constraints. In response, synthetic social networks serve as a viable approach to support controlled experimentation, but current generators reproduce only topology and overlook attribute-driven homophily and semantic realism. This work proposes a homophily-based algorithm that produces synthetic microblogging social networks such as X. The model creates a social graph for a given number of users, integrating semantic affinity among user attributes, stochastic variation in link formation, triadic closure to foster clustering, and long-range connections to ensure global reachability. A systematic grid search is used to calibrate five hyperparameters (affinity strength, noise, closure probability, distant link probability, and candidate pool size) for reaching five structural values observed in real social networks (density, clustering coefficient, LCC proportion, normalized shortest path, and modularity). The framework is validated by generating synthetic OSNs at four scales (10^3-10^6 nodes), and benchmarking them against a real-world Bluesky network comprising 4 million users. Comparative results show that the framework reliably reproduces the structural properties of the real network. Overall, the framework outperforms leading importance-sampling techniques applied to the same baseline. The generated graphs capture topological realism and yield attribute-driven communities that align with sociological expectations, providing a realistic, scalable testbed that liberates social researchers from relying on live digital platforms.
>
---
#### [new 015] The Basic B*** Effect: The Use of LLM-based Agents Reduces the Distinctiveness and Diversity of People's Choices
- **分类: cs.HC; cs.AI; cs.CY**

- **简介: 该论文研究LLM代理对人类选择独特性与多样性的影响，通过对比通用与个性化代理，分析其对人际独特性和内在多样性的影响，以优化AI系统设计。**

- **链接: [http://arxiv.org/pdf/2509.02910v1](http://arxiv.org/pdf/2509.02910v1)**

> **作者:** Sandra C. Matz; C. Blaine Horton; Sofie Goethals
>
> **摘要:** Large language models (LLMs) increasingly act on people's behalf: they write emails, buy groceries, and book restaurants. While the outsourcing of human decision-making to AI can be both efficient and effective, it raises a fundamental question: how does delegating identity-defining choices to AI reshape who people become? We study the impact of agentic LLMs on two identity-relevant outcomes: interpersonal distinctiveness - how unique a person's choices are relative to others - and intrapersonal diversity - the breadth of a single person's choices over time. Using real choices drawn from social-media behavior of 1,000 U.S. users (110,000 choices in total), we compare a generic and personalized agent to a human baseline. Both agents shift people's choices toward more popular options, reducing the distinctiveness of their behaviors and preferences. While the use of personalized agents tempers this homogenization (compared to the generic AI), it also more strongly compresses the diversity of people's preference portfolios by narrowing what they explore across topics and psychological affinities. Understanding how AI agents might flatten human experience, and how using generic versus personalized agents involves distinctiveness-diversity trade-offs, is critical for designing systems that augment rather than constrain human agency, and for safeguarding diversity in thought, taste, and expression.
>
---
#### [new 016] IDEAlign: Comparing Large Language Models to Human Experts in Open-ended Interpretive Annotations
- **分类: cs.CL; cs.CY**

- **简介: 该论文提出IDEAlign框架，解决LLM与人类专家在开放注释任务中一致性评估难题。通过三元组判断任务捕捉专家相似性评分，发现向量方法效果差，而LLM作为评判者显著提升一致性，为大规模评估提供新范式。**

- **链接: [http://arxiv.org/pdf/2509.02855v1](http://arxiv.org/pdf/2509.02855v1)**

> **作者:** Hyunji Nam; Lucia Langlois; James Malamut; Mei Tan; Dorottya Demszky
>
> **备注:** 10 pages, 9 pages for appendix
>
> **摘要:** Large language models (LLMs) are increasingly applied to open-ended, interpretive annotation tasks, such as thematic analysis by researchers or generating feedback on student work by teachers. These tasks involve free-text annotations requiring expert-level judgments grounded in specific objectives (e.g., research questions or instructional goals). Evaluating whether LLM-generated annotations align with those generated by expert humans is challenging to do at scale, and currently, no validated, scalable measure of similarity in ideas exists. In this paper, we (i) introduce the scalable evaluation of interpretive annotation by LLMs as a critical and understudied task, (ii) propose IDEAlgin, an intuitive benchmarking paradigm for capturing expert similarity ratings via a "pick-the-odd-one-out" triplet judgment task, and (iii) evaluate various similarity metrics, including vector-based ones (topic models, embeddings) and LLM-as-a-judge via IDEAlgin, against these human benchmarks. Applying this approach to two real-world educational datasets (interpretive analysis and feedback generation), we find that vector-based metrics largely fail to capture the nuanced dimensions of similarity meaningful to experts. Prompting LLMs via IDEAlgin significantly improves alignment with expert judgments (9-30% increase) compared to traditional lexical and vector-based metrics. These results establish IDEAlgin as a promising paradigm for evaluating LLMs against open-ended expert annotations at scale, informing responsible deployment of LLMs in education and beyond.
>
---
#### [new 017] Synthetic Founders: AI-Generated Social Simulations for Startup Validation Research in Computational Social Science
- **分类: cs.MA; cs.AI; cs.CY; 68T42 (Primary) 91F99, 92D50 (Secondary); I.6.3; I.2.11; J.4**

- **简介: 论文提出AI生成合成创始人进行社会模拟，评估AI在创业验证中的保真度与盲点。通过对比人类访谈与合成数据，识别四类主题，论证其作为混合模拟工具的潜力，补充实证研究，扩展假设空间。**

- **链接: [http://arxiv.org/pdf/2509.02605v1](http://arxiv.org/pdf/2509.02605v1)**

> **作者:** Jorn K. Teutloff
>
> **备注:** Manuscript submitted to the Journal of Artificial Societies and Social Simulation (JASSS). 21 pages, 1 table
>
> **摘要:** We present a comparative docking experiment that aligns human-subject interview data with large language model (LLM)-driven synthetic personas to evaluate fidelity, divergence, and blind spots in AI-enabled simulation. Fifteen early-stage startup founders were interviewed about their hopes and concerns regarding AI-powered validation, and the same protocol was replicated with AI-generated founder and investor personas. A structured thematic synthesis revealed four categories of outcomes: (1) Convergent themes - commitment-based demand signals, black-box trust barriers, and efficiency gains were consistently emphasized across both datasets; (2) Partial overlaps - founders worried about outliers being averaged away and the stress of real customer validation, while synthetic personas highlighted irrational blind spots and framed AI as a psychological buffer; (3) Human-only themes - relational and advocacy value from early customer engagement and skepticism toward moonshot markets; and (4) Synthetic-only themes - amplified false positives and trauma blind spots, where AI may overstate adoption potential by missing negative historical experiences. We interpret this comparative framework as evidence that LLM-driven personas constitute a form of hybrid social simulation: more linguistically expressive and adaptable than traditional rule-based agents, yet bounded by the absence of lived history and relational consequence. Rather than replacing empirical studies, we argue they function as a complementary simulation category - capable of extending hypothesis space, accelerating exploratory validation, and clarifying the boundaries of cognitive realism in computational social science.
>
---
#### [new 018] Event Detection and Classification for Long Range Sensing of Elephants Using Seismic Signal
- **分类: cs.LG; cs.CY; cs.ET; cs.SY; eess.SY**

- **简介: 该论文针对人象冲突中大象足音检测分类问题，提出基于地震信号的自动识别框架。开发了上下文自定义窗口（CCW）检测技术，结合SVM-RBF分类器，在资源受限场景下实现高精度实时分类，解决传统人工分类效率低的问题。**

- **链接: [http://arxiv.org/pdf/2509.02920v1](http://arxiv.org/pdf/2509.02920v1)**

> **作者:** Jaliya L. Wijayaraja; Janaka L. Wijekoon; Malitha Wijesundara
>
> **备注:** This article has been accepted for publication in IEEE Access
>
> **摘要:** Detecting elephants through seismic signals is an emerging research topic aimed at developing solutions for Human-Elephant Conflict (HEC). Despite the promising results, such solutions heavily rely on manual classification of elephant footfalls, which limits their applicability for real-time classification in natural settings. To address this limitation and build on our previous work, this study introduces a classification framework targeting resource-constrained implementations, prioritizing both accuracy and computational efficiency. As part of this framework, a novel event detection technique named Contextually Customized Windowing (CCW), tailored specifically for detecting elephant footfalls, was introduced, and evaluations were conducted by comparing it with the Short-Term Average/Long-Term Average (STA/LTA) method. The yielded results show that the maximum validated detection range was 155.6 m in controlled conditions and 140 m in natural environments. Elephant footfall classification using Support Vector Machine (SVM) with a Radial Basis Function (RBF) kernel demonstrated superior performance across multiple settings, achieving an accuracy of 99% in controlled environments, 73% in natural elephant habitats, and 70% in HEC-prone human habitats, the most challenging scenario. Furthermore, feature impact analysis using explainable AI identified the number of Zero Crossings and Dynamic Time Warping (DTW) Alignment Cost as the most influential factors in all experiments, while Predominant Frequency exhibited significant influence in controlled settings.
>
---
#### [new 019] More Parameters Than Populations: A Systematic Literature Review of Large Language Models within Survey Research
- **分类: cs.DL; cs.CY**

- **简介: 该论文开展系统文献综述，探讨大语言模型在调查研究中的应用现状与挑战。通过多数据库检索与引用网络分析，按数据采集前、中、后期分类梳理LLM使用案例，评估其潜力与局限，并展望未来研究方向。**

- **链接: [http://arxiv.org/pdf/2509.03391v1](http://arxiv.org/pdf/2509.03391v1)**

> **作者:** Trent D. Buskirk; Florian Keusch; Leah von der Heyde; Adam Eck
>
> **摘要:** Survey research has a long-standing history of being a human-powered field, but one that embraces various technologies for the collection, processing, and analysis of various behavioral, political, and social outcomes of interest, among others. At the same time, Large Language Models (LLMs) bring new technological challenges and prerequisites in order to fully harness their potential. In this paper, we report work-in-progress on a systematic literature review based on keyword searches from multiple large-scale databases as well as citation networks that assesses how LLMs are currently being applied within the survey research process. We synthesize and organize our findings according to the survey research process to include examples of LLM usage across three broad phases: pre-data collection, data collection, and post-data collection. We discuss selected examples of potential use cases for LLMs as well as its pitfalls based on examples from existing literature. Considering survey research has rich experience and history regarding data quality, we discuss some opportunities and describe future outlooks for survey research to contribute to the continued development and refinement of LLMs.
>
---
## 更新

#### [replaced 001] That is Unacceptable: the Moral Foundations of Canceling
- **分类: cs.CY; cs.CL**

- **链接: [http://arxiv.org/pdf/2503.05720v2](http://arxiv.org/pdf/2503.05720v2)**

> **作者:** Soda Marem Lo; Oscar Araque; Rajesh Sharma; Marco Antonio Stranisci
>
> **摘要:** Canceling is a morally-driven phenomenon that hinders the development of safe social media platforms and contributes to ideological polarization. To address this issue we present the Canceling Attitudes Detection (CADE) dataset, an annotated corpus of canceling incidents aimed at exploring the factors of disagreements in evaluating people canceling attitudes on social media. Specifically, we study the impact of annotators' morality in their perception of canceling, showing that morality is an independent axis for the explanation of disagreement on this phenomenon. Annotator's judgments heavily depend on the type of controversial events and involved celebrities. This shows the need to develop more event-centric datasets to better understand how harms are perpetrated in social media and to develop more aware technologies for their detection.
>
---
#### [replaced 002] Embodied AI: Emerging Risks and Opportunities for Policy Action
- **分类: cs.CY; cs.AI; cs.RO**

- **链接: [http://arxiv.org/pdf/2509.00117v2](http://arxiv.org/pdf/2509.00117v2)**

> **作者:** Jared Perlo; Alexander Robey; Fazl Barez; Luciano Floridi; Jakob Mökander
>
> **摘要:** The field of embodied AI (EAI) is rapidly advancing. Unlike virtual AI, EAI systems can exist in, learn from, reason about, and act in the physical world. With recent advances in AI models and hardware, EAI systems are becoming increasingly capable across wider operational domains. While EAI systems can offer many benefits, they also pose significant risks, including physical harm from malicious use, mass surveillance, as well as economic and societal disruption. These risks require urgent attention from policymakers, as existing policies governing industrial robots and autonomous vehicles are insufficient to address the full range of concerns EAI systems present. To help address this issue, this paper makes three contributions. First, we provide a taxonomy of the physical, informational, economic, and social risks EAI systems pose. Second, we analyze policies in the US, EU, and UK to assess how existing frameworks address these risks and to identify critical gaps. We conclude by offering policy recommendations for the safe and beneficial deployment of EAI systems, such as mandatory testing and certification schemes, clarified liability frameworks, and strategies to manage EAI's potentially transformative economic and societal impacts.
>
---
#### [replaced 003] The Human Labour of Data Work: Capturing Cultural Diversity through World Wide Dishes
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2502.05961v3](http://arxiv.org/pdf/2502.05961v3)**

> **作者:** Siobhan Mackenzie Hall; Samantha Dalal; Raesetje Sefala; Foutse Yuehgoh; Aisha Alaagib; Imane Hamzaoui; Shu Ishida; Jabez Magomere; Lauren Crais; Aya Salama; Tejumade Afonja
>
> **摘要:** This paper provides guidance for building and maintaining infrastructure for participatory AI efforts by sharing reflections on building World Wide Dishes (WWD), a bottom-up, community-led image and text dataset of culinary dishes and associated cultural customs. We present WWD as an example of participatory dataset creation, where community members both guide the design of the research process and contribute to the crowdsourced dataset. This approach incorporates localised expertise and knowledge to address the limitations of web-scraped Internet datasets acknowledged in the Participatory AI discourse. We show that our approach can result in curated, high-quality data that supports decentralised contributions from communities that do not typically contribute to datasets due to a variety of systemic factors. Our project demonstrates the importance of participatory mediators in supporting community engagement by identifying the kinds of labour they performed to make WWD possible. We surface three dimensions of labour performed by participatory mediators that are crucial for participatory dataset construction: building trust with community members, making participation accessible, and contextualising community values to support meaningful data collection. Drawing on our findings, we put forth five lessons for building infrastructure to support future participatory AI efforts.
>
---
#### [replaced 004] Digital Contact Tracing: Examining the Effects of Understanding and Release Organization on Public Trust
- **分类: cs.CY**

- **链接: [http://arxiv.org/pdf/2508.10198v2](http://arxiv.org/pdf/2508.10198v2)**

> **作者:** Lucas Draper
>
> **摘要:** Contact tracing has existed in various forms for a very long time. With the rise of COVID-19, the concept has become increasingly important to help slow the spread of the virus. One approach to modernizing contact tracing is to introduce applications that detect all close contacts without individuals having to interact knowingly. 101 United States adults were surveyed in June of 2022 regarding their perceptions and trust of COVID-19 contact tracing applications. We see no definitive correlation between an individual's understanding of privacy protection procedures for contact tracing applications and their willingness to trust such an application. We also see that the release of the application by a private entity like Google-Apple or by a public entity like the United States Federal Government has no significant correlation with a person's trust in the application.
>
---
#### [replaced 005] Rethinking Data Protection in the (Generative) Artificial Intelligence Era
- **分类: cs.LG; cs.AI; cs.CR; cs.CV; cs.CY**

- **链接: [http://arxiv.org/pdf/2507.03034v4](http://arxiv.org/pdf/2507.03034v4)**

> **作者:** Yiming Li; Shuo Shao; Yu He; Junfeng Guo; Tianwei Zhang; Zhan Qin; Pin-Yu Chen; Michael Backes; Philip Torr; Dacheng Tao; Kui Ren
>
> **备注:** Perspective paper for a broader scientific audience. The first two authors contributed equally to this paper. 13 pages
>
> **摘要:** The (generative) artificial intelligence (AI) era has profoundly reshaped the meaning and value of data. No longer confined to static content, data now permeates every stage of the AI lifecycle from the training samples that shape model parameters to the prompts and outputs that drive real-world model deployment. This shift renders traditional notions of data protection insufficient, while the boundaries of what needs safeguarding remain poorly defined. Failing to safeguard data in AI systems can inflict societal and individual, underscoring the urgent need to clearly delineate the scope of and rigorously enforce data protection. In this perspective, we propose a four-level taxonomy, including non-usability, privacy preservation, traceability, and deletability, that captures the diverse protection needs arising in modern (generative) AI models and systems. Our framework offers a structured understanding of the trade-offs between data utility and control, spanning the entire AI pipeline, including training datasets, model weights, system prompts, and AI-generated content. We analyze representative technical approaches at each level and reveal regulatory blind spots that leave critical assets exposed. By offering a structured lens to align future AI technologies and governance with trustworthy data practices, we underscore the urgency of rethinking data protection for modern AI techniques and provide timely guidance for developers, researchers, and regulators alike.
>
---
#### [replaced 006] STREAM (ChemBio): A Standard for Transparently Reporting Evaluations in AI Model Reports
- **分类: cs.CY; cs.AI**

- **链接: [http://arxiv.org/pdf/2508.09853v2](http://arxiv.org/pdf/2508.09853v2)**

> **作者:** Tegan McCaslin; Jide Alaga; Samira Nedungadi; Seth Donoughe; Tom Reed; Rishi Bommasani; Chris Painter; Luca Righetti
>
> **备注:** 47 pages, 1 figure. Includes appendices and reporting template
>
> **摘要:** Evaluations of dangerous AI capabilities are important for managing catastrophic risks. Public transparency into these evaluations - including what they test, how they are conducted, and how their results inform decisions - is crucial for building trust in AI development. We propose STREAM (A Standard for Transparently Reporting Evaluations in AI Model Reports), a standard to improve how model reports disclose evaluation results, initially focusing on chemical and biological (ChemBio) benchmarks. Developed in consultation with 23 experts across government, civil society, academia, and frontier AI companies, this standard is designed to (1) be a practical resource to help AI developers present evaluation results more clearly, and (2) help third parties identify whether model reports provide sufficient detail to assess the rigor of the ChemBio evaluations. We concretely demonstrate our proposed best practices with "gold standard" examples, and also provide a three-page reporting template to enable AI developers to implement our recommendations more easily.
>
---
#### [replaced 007] Hey, Teacher, (Don't) Leave Those Kids Alone: Standardizing HRI Education
- **分类: cs.RO; cs.CY; cs.HC**

- **链接: [http://arxiv.org/pdf/2404.00024v2](http://arxiv.org/pdf/2404.00024v2)**

> **作者:** Alexis E. Block
>
> **备注:** Presented at the Designing an Intro to HRI Course Workshop at HRI 2024 (arXiv:2403.05588)
>
> **摘要:** Creating a standardized introduction course becomes more critical as the field of human-robot interaction (HRI) becomes more established. This paper outlines the key components necessary to provide an undergraduate with a sufficient foundational understanding of the interdisciplinary nature of this field and provides proposed course content. It emphasizes the importance of creating a course with theoretical and experimental components to accommodate all different learning preferences. This manuscript also advocates creating or adopting a universal platform to standardize the hands-on component of introductory HRI courses, regardless of university funding or size. Next, it recommends formal training in how to read scientific articles and staying up-to-date with the latest relevant papers. Finally, it provides detailed lecture content and project milestones for a 15-week semester. By creating a standardized course, researchers can ensure consistency and quality are maintained across institutions, which will help students as well as industrial and academic employers understand what foundational knowledge is expected.
>
---
