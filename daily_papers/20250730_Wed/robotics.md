# 机器人 cs.RO

- **最新发布 31 篇**

- **更新 22 篇**

## 最新发布

#### [new 001] A Nonlinear MPC Framework for Loco-Manipulation of Quadrupedal Robots with Non-Negligible Manipulator Dynamics
- **分类: cs.RO; math.OC**

- **简介: 论文研究四足机器人操作任务的控制方法，提出一种高效的非线性模型预测控制（NMPC）框架，解决机械臂动力学不可忽略时的运动与操作协调问题。通过分解策略结合模板模型与机械臂完整动力学模型，实现高速实时控制，验证于带机械臂的四足机器人平台，具备抗干扰和适应复杂环境的能力。**

- **链接: [http://arxiv.org/pdf/2507.22042v1](http://arxiv.org/pdf/2507.22042v1)**

> **作者:** Ruturaj Sambhus; Kapi Ketan Mehta; Ali MirMohammad Sadeghi; Basit Muhammad Imran; Jeeseop Kim; Taizoon Chunawala; Vittorio Pastore; Sujith Vijayan; Kaveh Akbari Hamed
>
> **摘要:** Model predictive control (MPC) combined with reduced-order template models has emerged as a powerful tool for trajectory optimization in dynamic legged locomotion. However, loco-manipulation tasks performed by legged robots introduce additional complexity, necessitating computationally efficient MPC algorithms capable of handling high-degree-of-freedom (DoF) models. This letter presents a computationally efficient nonlinear MPC (NMPC) framework tailored for loco-manipulation tasks of quadrupedal robots equipped with robotic manipulators whose dynamics are non-negligible relative to those of the quadruped. The proposed framework adopts a decomposition strategy that couples locomotion template models -- such as the single rigid body (SRB) model -- with a full-order dynamic model of the robotic manipulator for torque-level control. This decomposition enables efficient real-time solution of the NMPC problem in a receding horizon fashion at 60 Hz. The optimal state and input trajectories generated by the NMPC for locomotion are tracked by a low-level nonlinear whole-body controller (WBC) running at 500 Hz, while the optimal torque commands for the manipulator are directly applied. The layered control architecture is validated through extensive numerical simulations and hardware experiments on a 15-kg Unitree Go2 quadrupedal robot augmented with a 4.4-kg 4-DoF Kinova arm. Given that the Kinova arm dynamics are non-negligible relative to the Go2 base, the proposed NMPC framework demonstrates robust stability in performing diverse loco-manipulation tasks, effectively handling external disturbances, payload variations, and uneven terrain.
>
---
#### [new 002] LITE: A Learning-Integrated Topological Explorer for Multi-Floor Indoor Environments
- **分类: cs.RO**

- **简介: 该论文属于机器人室内探索任务，旨在解决多楼层环境中的高效探索问题。作者提出LITE框架，结合学习与拓扑建模，通过楼层-楼梯拓扑结构和注意力机制提升探索效率，并在多数据集及真实机器人上验证了方法的有效性与泛化能力。**

- **链接: [http://arxiv.org/pdf/2507.21517v1](http://arxiv.org/pdf/2507.21517v1)**

> **作者:** Junhao Chen; Zhen Zhang; Chengrui Zhu; Xiaojun Hou; Tianyang Hu; Huifeng Wu; Yong Liu
>
> **备注:** IROS2025
>
> **摘要:** This work focuses on multi-floor indoor exploration, which remains an open area of research. Compared to traditional methods, recent learning-based explorers have demonstrated significant potential due to their robust environmental learning and modeling capabilities, but most are restricted to 2D environments. In this paper, we proposed a learning-integrated topological explorer, LITE, for multi-floor indoor environments. LITE decomposes the environment into a floor-stair topology, enabling seamless integration of learning or non-learning-based 2D exploration methods for 3D exploration. As we incrementally build floor-stair topology in exploration using YOLO11-based instance segmentation model, the agent can transition between floors through a finite state machine. Additionally, we implement an attention-based 2D exploration policy that utilizes an attention mechanism to capture spatial dependencies between different regions, thereby determining the next global goal for more efficient exploration. Extensive comparison and ablation studies conducted on the HM3D and MP3D datasets demonstrate that our proposed 2D exploration policy significantly outperforms all baseline explorers in terms of exploration efficiency. Furthermore, experiments in several 3D multi-floor environments indicate that our framework is compatible with various 2D exploration methods, facilitating effective multi-floor indoor exploration. Finally, we validate our method in the real world with a quadruped robot, highlighting its strong generalization capabilities.
>
---
#### [new 003] Sound Source Localization for Human-Robot Interaction in Outdoor Environments
- **分类: cs.RO; cs.HC; eess.AS**

- **简介: 该论文属于人机交互中的声音定位任务，旨在解决户外环境中操作员语音定位问题。通过麦克风阵列和异步近讲麦克风，结合信号粗对齐与回声消除算法，估计时频掩码以分离目标语音与噪声，实现选择性声源定位。实验表明该方法在1dB信噪比下具有高精度定位效果，显著优于现有方法。**

- **链接: [http://arxiv.org/pdf/2507.21431v1](http://arxiv.org/pdf/2507.21431v1)**

> **作者:** Victor Liu; Timothy Du; Jordy Sehn; Jack Collier; François Grondin
>
> **摘要:** This paper presents a sound source localization strategy that relies on a microphone array embedded in an unmanned ground vehicle and an asynchronous close-talking microphone near the operator. A signal coarse alignment strategy is combined with a time-domain acoustic echo cancellation algorithm to estimate a time-frequency ideal ratio mask to isolate the target speech from interferences and environmental noise. This allows selective sound source localization, and provides the robot with the direction of arrival of sound from the active operator, which enables rich interaction in noisy scenarios. Results demonstrate an average angle error of 4 degrees and an accuracy within 5 degrees of 95\% at a signal-to-noise ratio of 1dB, which is significantly superior to the state-of-the-art localization methods.
>
---
#### [new 004] DISCOVERSE: Efficient Robot Simulation in Complex High-Fidelity Environments
- **分类: cs.RO; 68T40; I.2.9**

- **简介: 该论文提出DISCOVERSE，一个基于3D高斯泼溅的高效机器人仿真框架，旨在解决Sim2Real迁移问题。它实现从真实到仿真的全流程，支持多传感器模态与物理仿真，提升机器人学习效果。**

- **链接: [http://arxiv.org/pdf/2507.21981v1](http://arxiv.org/pdf/2507.21981v1)**

> **作者:** Yufei Jia; Guangyu Wang; Yuhang Dong; Junzhe Wu; Yupei Zeng; Haonan Lin; Zifan Wang; Haizhou Ge; Weibin Gu; Kairui Ding; Zike Yan; Yunjie Cheng; Yue Li; Ziming Wang; Chuxuan Li; Wei Sui; Lu Shi; Guanzhong Tian; Ruqi Huang; Guyue Zhou
>
> **备注:** 8pages, IROS2025 (Camera Ready)
>
> **摘要:** We present the first unified, modular, open-source 3DGS-based simulation framework for Real2Sim2Real robot learning. It features a holistic Real2Sim pipeline that synthesizes hyper-realistic geometry and appearance of complex real-world scenarios, paving the way for analyzing and bridging the Sim2Real gap. Powered by Gaussian Splatting and MuJoCo, Discoverse enables massively parallel simulation of multiple sensor modalities and accurate physics, with inclusive supports for existing 3D assets, robot models, and ROS plugins, empowering large-scale robot learning and complex robotic benchmarks. Through extensive experiments on imitation learning, Discoverse demonstrates state-of-the-art zero-shot Sim2Real transfer performance compared to existing simulators. For code and demos: https://air-discoverse.github.io/.
>
---
#### [new 005] Research Challenges and Progress in the End-to-End V2X Cooperative Autonomous Driving Competition
- **分类: cs.RO; cs.CV; I.4.9**

- **简介: 该论文属于自动驾驶任务，旨在解决V2X协同驾驶中的多源数据融合与通信限制问题。论文组织了V2X协同自动驾驶挑战赛，设立两个赛道，基于UniV2X框架和V2X-Seq-SPD数据集，评估协同驾驶系统，分析关键技术趋势，推动可扩展、可靠V2X协同自动驾驶的发展。**

- **链接: [http://arxiv.org/pdf/2507.21610v1](http://arxiv.org/pdf/2507.21610v1)**

> **作者:** Ruiyang Hao; Haibao Yu; Jiaru Zhong; Chuanye Wang; Jiahao Wang; Yiming Kan; Wenxian Yang; Siqi Fan; Huilin Yin; Jianing Qiu; Yao Mu; Jiankai Sun; Li Chen; Walter Zimmer; Dandan Zhang; Shanghang Zhang; Mac Schwager; Wei Huang; Xiaobo Zhang; Ping Luo; Zaiqing Nie
>
> **备注:** 10 pages, 4 figures, accepted by ICCVW
>
> **摘要:** With the rapid advancement of autonomous driving technology, vehicle-to-everything (V2X) communication has emerged as a key enabler for extending perception range and enhancing driving safety by providing visibility beyond the line of sight. However, integrating multi-source sensor data from both ego-vehicles and infrastructure under real-world constraints, such as limited communication bandwidth and dynamic environments, presents significant technical challenges. To facilitate research in this area, we organized the End-to-End Autonomous Driving through V2X Cooperation Challenge, which features two tracks: cooperative temporal perception and cooperative end-to-end planning. Built on the UniV2X framework and the V2X-Seq-SPD dataset, the challenge attracted participation from over 30 teams worldwide and established a unified benchmark for evaluating cooperative driving systems. This paper describes the design and outcomes of the challenge, highlights key research problems including bandwidth-aware fusion, robust multi-agent planning, and heterogeneous sensor integration, and analyzes emerging technical trends among top-performing solutions. By addressing practical constraints in communication and data fusion, the challenge contributes to the development of scalable and reliable V2X-cooperative autonomous driving systems.
>
---
#### [new 006] Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors
- **分类: cs.RO; cs.LG; cs.SY; eess.SY**

- **简介: 该论文属于机器人触觉传感任务，旨在解决传统触觉传感器复杂、不耐用的问题。论文设计了一种基于3D打印弹性体格栅与气道的压力传感器，通过检测气压变化实现触觉感知，并结合神经网络与控制器提升感知与交互能力，实现耐用且灵活的机器人触觉系统。**

- **链接: [http://arxiv.org/pdf/2507.21225v1](http://arxiv.org/pdf/2507.21225v1)**

> **作者:** Annan Zhang; Miguel Flores-Acton; Andy Yu; Anshul Gupta; Maggie Yao; Daniela Rus
>
> **备注:** Accepted for publication in the proceedings of the 2025 International Symposium on Experimental Robotics (ISER)
>
> **摘要:** Tactile sensing plays a fundamental role in enabling robots to navigate dynamic and unstructured environments, particularly in applications such as delicate object manipulation, surface exploration, and human-robot interaction. In this paper, we introduce a passive soft robotic fingertip with integrated tactile sensing, fabricated using a 3D-printed elastomer lattice with embedded air channels. This sensorization approach, termed fluidic innervation, transforms the lattice into a tactile sensor by detecting pressure changes within sealed air channels, providing a simple yet robust solution to tactile sensing in robotics. Unlike conventional methods that rely on complex materials or designs, fluidic innervation offers a simple, scalable, single-material fabrication process. We characterize the sensors' response, develop a geometric model to estimate tip displacement, and train a neural network to accurately predict contact location and contact force. Additionally, we integrate the fingertip with an admittance controller to emulate spring-like behavior, demonstrate its capability for environment exploration through tactile feedback, and validate its durability under high impact and cyclic loading conditions. This tactile sensing technique offers advantages in terms of simplicity, adaptability, and durability and opens up new opportunities for versatile robotic manipulation.
>
---
#### [new 007] Decision Transformer-Based Drone Trajectory Planning with Dynamic Safety-Efficiency Trade-Offs
- **分类: cs.RO; cs.AI**

- **简介: 论文属于无人机路径规划任务，旨在解决动态调整安全性与效率权衡的问题。现有方法需专家调参或无法显式处理该权衡。作者提出基于决策变换器的轨迹规划方法，引入RTG参数直观控制安全与效率平衡，并通过仿真和真实实验验证其有效性与优越性。**

- **链接: [http://arxiv.org/pdf/2507.21506v1](http://arxiv.org/pdf/2507.21506v1)**

> **作者:** Chang-Hun Ji; SiWoon Song; Youn-Hee Han; SungTae Moon
>
> **备注:** Accepted to IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) 2025. \c{opyright} 2025 IEEE. Personal use of this material is permitted. \c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses
>
> **摘要:** A drone trajectory planner should be able to dynamically adjust the safety-efficiency trade-off according to varying mission requirements in unknown environments. Although traditional polynomial-based planners offer computational efficiency and smooth trajectory generation, they require expert knowledge to tune multiple parameters to adjust this trade-off. Moreover, even with careful tuning, the resulting adjustment may fail to achieve the desired trade-off. Similarly, although reinforcement learning-based planners are adaptable in unknown environments, they do not explicitly address the safety-efficiency trade-off. To overcome this limitation, we introduce a Decision Transformer-based trajectory planner that leverages a single parameter, Return-to-Go (RTG), as a \emph{temperature parameter} to dynamically adjust the safety-efficiency trade-off. In our framework, since RTG intuitively measures the safety and efficiency of a trajectory, RTG tuning does not require expert knowledge. We validate our approach using Gazebo simulations in both structured grid and unstructured random environments. The experimental results demonstrate that our planner can dynamically adjust the safety-efficiency trade-off by simply tuning the RTG parameter. Furthermore, our planner outperforms existing baseline methods across various RTG settings, generating safer trajectories when tuned for safety and more efficient trajectories when tuned for efficiency. Real-world experiments further confirm the reliability and practicality of our proposed planner.
>
---
#### [new 008] A Systematic Robot Design Optimization Methodology with Application to Redundant Dual-Arm Manipulators
- **分类: cs.RO**

- **简介: 该论文属于机器人设计优化任务，旨在解决如何在复杂农业环境中合理设计双臂机器人以提高操作性能的问题。论文提出了一种系统化设计方法，包括机器人模型、任务与环境仿真、性能指标和优化算法，并通过辣椒采摘案例验证了方法在可达性和灵活性上的显著提升。**

- **链接: [http://arxiv.org/pdf/2507.21896v1](http://arxiv.org/pdf/2507.21896v1)**

> **作者:** Dominic Guri; George Kantor
>
> **备注:** 8 pages, 6 figures, 2 tables
>
> **摘要:** One major recurring challenge in deploying manipulation robots is determining the optimal placement of manipulators to maximize performance. This challenge is exacerbated in complex, cluttered agricultural environments of high-value crops, such as flowers, fruits, and vegetables, that could greatly benefit from robotic systems tailored to their specific requirements. However, the design of such systems remains a challenging, intuition-driven process, limiting the affordability and adoption of robotics-based automation by domain experts like farmers. To address this challenge, we propose a four-part design optimization methodology for automating the development of task-specific robotic systems. This framework includes (a) a robot design model, (b) task and environment representations for simulation, (c) task-specific performance metrics, and (d) optimization algorithms for refining configurations. We demonstrate our framework by optimizing a dual-arm robotic system for pepper harvesting using two off-the-shelf redundant manipulators. To enhance performance, we introduce novel task metrics that leverage self-motion manifolds to characterize manipulator redundancy comprehensively. Our results show that our framework achieves simultaneous improvements in reachability success rates and improvements in dexterity. Specifically, our approach improves reachability success by at least 14\% over baseline methods and achieves over 30\% improvement in dexterity based on our task-specific metric.
>
---
#### [new 009] Multi-robot LiDAR SLAM: a practical case study in underground tunnel environments
- **分类: cs.RO**

- **简介: 该论文属于多机器人激光雷达SLAM任务，旨在解决地下隧道环境中定位与建图问题。论文发现当前系统存在过多误匹配问题，尤其在回环检测中表现明显。为此，作者提出一种新启发式方法以减少误匹配，提高系统鲁棒性，并指出该领域仍存在未被深入研究的方向。**

- **链接: [http://arxiv.org/pdf/2507.21553v1](http://arxiv.org/pdf/2507.21553v1)**

> **作者:** Federica Di Lauro; Domenico G. Sorrenti; Miguel Angel Sotelo
>
> **备注:** 14 pages, 14 figures
>
> **摘要:** Multi-robot SLAM aims at localizing and building a map with multiple robots, interacting with each other. In the work described in this article, we analyze the pipeline of a decentralized LiDAR SLAM system to study the current limitations of the state of the art, and we discover a significant source of failures, i.e., that the loop detection is the source of too many false positives. We therefore develop and propose a new heuristic to overcome these limitations. The environment taken as reference in this work is the highly challenging case of underground tunnels. We also highlight potential new research areas still under-explored.
>
---
#### [new 010] MoDeSuite: Robot Learning Task Suite for Benchmarking Mobile Manipulation with Deformable Objects
- **分类: cs.RO; cs.AI**

- **简介: 该论文属于机器人学习任务，旨在解决移动操作中可变形物体操控的挑战。作者提出了MoDeSuite基准套件，包含8个涉及弹性与可变形物体的任务，评估了强化学习和模仿学习算法的表现，并通过Spot机器人验证了实际应用潜力，推动移动操作与可变形物体交互的研究。**

- **链接: [http://arxiv.org/pdf/2507.21796v1](http://arxiv.org/pdf/2507.21796v1)**

> **作者:** Yuying Zhang; Kevin Sebastian Luck; Francesco Verdoja; Ville Kyrki; Joni Pajarinen
>
> **摘要:** Mobile manipulation is a critical capability for robots operating in diverse, real-world environments. However, manipulating deformable objects and materials remains a major challenge for existing robot learning algorithms. While various benchmarks have been proposed to evaluate manipulation strategies with rigid objects, there is still a notable lack of standardized benchmarks that address mobile manipulation tasks involving deformable objects. To address this gap, we introduce MoDeSuite, the first Mobile Manipulation Deformable Object task suite, designed specifically for robot learning. MoDeSuite consists of eight distinct mobile manipulation tasks covering both elastic objects and deformable objects, each presenting a unique challenge inspired by real-world robot applications. Success in these tasks requires effective collaboration between the robot's base and manipulator, as well as the ability to exploit the deformability of the objects. To evaluate and demonstrate the use of the proposed benchmark, we train two state-of-the-art reinforcement learning algorithms and two imitation learning algorithms, highlighting the difficulties encountered and showing their performance in simulation. Furthermore, we demonstrate the practical relevance of the suite by deploying the trained policies directly into the real world with the Spot robot, showcasing the potential for sim-to-real transfer. We expect that MoDeSuite will open a novel research domain in mobile manipulation involving deformable objects. Find more details, code, and videos at https://sites.google.com/view/modesuite/home.
>
---
#### [new 011] NMPCM: Nonlinear Model Predictive Control on Resource-Constrained Microcontrollers
- **分类: cs.RO**

- **简介: 该论文属于控制算法优化任务，旨在解决非线性模型预测控制（NMPC）在资源受限微控制器上计算复杂度高、难以实时运行的问题。作者提出NMPCM方法，优化计算效率并保持控制精度，通过仿真和实验证明其在四旋翼无人机上的实时有效性。**

- **链接: [http://arxiv.org/pdf/2507.21259v1](http://arxiv.org/pdf/2507.21259v1)**

> **作者:** Van Chung Nguyen; Pratik Walunj; Chuong Le; An Duy Nguyen; Hung Manh La
>
> **摘要:** Nonlinear Model Predictive Control (NMPC) is a powerful approach for controlling highly dynamic robotic systems, as it accounts for system dynamics and optimizes control inputs at each step. However, its high computational complexity makes implementation on resource-constrained microcontrollers impractical. While recent studies have demonstrated the feasibility of Model Predictive Control (MPC) with linearized dynamics on microcontrollers, applying full NMPC remains a significant challenge. This work presents an efficient solution for generating and deploying NMPC on microcontrollers (NMPCM) to control quadrotor UAVs. The proposed method optimizes computational efficiency while maintaining high control accuracy. Simulations in Gazebo/ROS and real-world experiments validate the effectiveness of the approach, demonstrating its capability to achieve high-frequency NMPC execution in real-time systems. The code is available at: https://github.com/aralab-unr/NMPCM.
>
---
#### [new 012] Adaptive Prior Scene-Object SLAM for Dynamic Environments
- **分类: cs.RO**

- **简介: 该论文属于视觉SLAM任务，旨在解决动态环境中定位与建图的漂移问题。论文提出了一种基于场景-物体的可靠性评估框架，并引入姿态优化策略，利用可靠帧信息提升定位精度，增强了系统在动态场景中的鲁棒性。**

- **链接: [http://arxiv.org/pdf/2507.21709v1](http://arxiv.org/pdf/2507.21709v1)**

> **作者:** Haolan Zhang; Thanh Nguyen Canh; Chenghao Li; Nak Young Chong
>
> **备注:** Accepted by IEEE The 2025 IEEE International Conference on Real-time Computing and Robotics
>
> **摘要:** Visual Simultaneous Localization and Mapping (SLAM) plays a vital role in real-time localization for autonomous systems. However, traditional SLAM methods, which assume a static environment, often suffer from significant localization drift in dynamic scenarios. While recent advancements have improved SLAM performance in such environments, these systems still struggle with localization drift, particularly due to abrupt viewpoint changes and poorly characterized moving objects. In this paper, we propose a novel scene-object-based reliability assessment framework that comprehensively evaluates SLAM stability through both current frame quality metrics and scene changes relative to reliable reference frames. Furthermore, to tackle the lack of error correction mechanisms in existing systems when pose estimation becomes unreliable, we employ a pose refinement strategy that leverages information from reliable frames to optimize camera pose estimation, effectively mitigating the adverse effects of dynamic interference. Extensive experiments on the TUM RGB-D datasets demonstrate that our approach achieves substantial improvements in localization accuracy and system robustness under challenging dynamic scenarios.
>
---
#### [new 013] A Deep Learning-Driven Autonomous System for Retinal Vein Cannulation: Validation Using a Chicken Embryo Model
- **分类: cs.RO**

- **简介: 该论文属于医疗机器人与深度学习结合的微手术自动化任务，旨在解决视网膜静脉穿刺手术中精度不足、操作难度大等问题。作者设计了一套基于深度学习和光学成像的自动化系统，利用鸡胚胎模型进行实验，实现了针尖定位与穿刺识别，提高了手术效率与稳定性。**

- **链接: [http://arxiv.org/pdf/2507.21965v1](http://arxiv.org/pdf/2507.21965v1)**

> **作者:** Yi Wang; Peiyao Zhang; Mojtaba Esfandiari; Peter Gehlbach; Iulian I. Iordachita
>
> **摘要:** Retinal vein cannulation (RVC) is a minimally invasive microsurgical procedure for treating retinal vein occlusion (RVO), a leading cause of vision impairment. However, the small size and fragility of retinal veins, coupled with the need for high-precision, tremor-free needle manipulation, create significant technical challenges. These limitations highlight the need for robotic assistance to improve accuracy and stability. This study presents an automated robotic system with a top-down microscope and B-scan optical coherence tomography (OCT) imaging for precise depth sensing. Deep learning-based models enable real-time needle navigation, contact detection, and vein puncture recognition, using a chicken embryo model as a surrogate for human retinal veins. The system autonomously detects needle position and puncture events with 85% accuracy. The experiments demonstrate notable reductions in navigation and puncture times compared to manual methods. Our results demonstrate the potential of integrating advanced imaging and deep learning to automate microsurgical tasks, providing a pathway for safer and more reliable RVC procedures with enhanced precision and reproducibility.
>
---
#### [new 014] Diffusion Denoiser-Aided Gyrocompassing
- **分类: cs.RO; cs.LG**

- **简介: 论文任务是提升低成本陀螺仪的航向估计精度。针对无外部导航辅助时磁干扰和噪声影响航向精度的问题，提出扩散去噪辅助的陀螺寻北方法。结合扩散模型与深度学习，处理原始惯性信号，提升航向估计性能。实验验证精度提升，适用于自动驾驶等场景。**

- **链接: [http://arxiv.org/pdf/2507.21245v1](http://arxiv.org/pdf/2507.21245v1)**

> **作者:** Gershy Ben-Arie; Daniel Engelsman; Rotem Dror; Itzik Klein
>
> **备注:** 8 pages, 8 figures
>
> **摘要:** An accurate initial heading angle is essential for efficient and safe navigation across diverse domains. Unlike magnetometers, gyroscopes can provide accurate heading reference independent of the magnetic disturbances in a process known as gyrocompassing. Yet, accurate and timely gyrocompassing, using low-cost gyroscopes, remains a significant challenge in scenarios where external navigation aids are unavailable. Such challenges are commonly addressed in real-world applications such as autonomous vehicles, where size, weight, and power limitations restrict sensor quality, and noisy measurements severely degrade gyrocompassing performance. To cope with this challenge, we propose a novel diffusion denoiser-aided gyrocompass approach. It integrates a diffusion-based denoising framework with an enhanced learning-based heading estimation model. The diffusion denoiser processes raw inertial sensor signals before input to the deep learning model, resulting in accurate gyrocompassing. Experiments using both simulated and real sensor data demonstrate that our proposed approach improves gyrocompassing accuracy by 26% compared to model-based gyrocompassing and by 15% compared to other learning-driven approaches. This advancement holds particular significance for ensuring accurate and robust navigation in autonomous platforms that incorporate low-cost gyroscopes within their navigation systems.
>
---
#### [new 015] Pretraining a Unified PDDL Domain from Real-World Demonstrations for Generalizable Robot Task Planning
- **分类: cs.RO**

- **简介: 论文提出UniDomain框架，通过预训练统一PDDL域，从真实世界机器人操作演示中提取原子域，解决机器人任务规划中的泛化问题。该工作结合语言与视觉推理，实现零样本解决复杂、未见过的任务，提升任务成功率与规划最优性。属于机器人任务规划领域。**

- **链接: [http://arxiv.org/pdf/2507.21545v1](http://arxiv.org/pdf/2507.21545v1)**

> **作者:** Haoming Ye; Yunxiao Xiao; Cewu Lu; Panpan Cai
>
> **备注:** Preprint. Under review
>
> **摘要:** Robotic task planning in real-world environments requires reasoning over implicit constraints from language and vision. While LLMs and VLMs offer strong priors, they struggle with long-horizon structure and symbolic grounding. Existing methods that combine LLMs with symbolic planning often rely on handcrafted or narrow domains, limiting generalization. We propose UniDomain, a framework that pre-trains a PDDL domain from robot manipulation demonstrations and applies it for online robotic task planning. It extracts atomic domains from 12,393 manipulation videos to form a unified domain with 3137 operators, 2875 predicates, and 16481 causal edges. Given a target class of tasks, it retrieves relevant atomics from the unified domain and systematically fuses them into high-quality meta-domains to support compositional generalization in planning. Experiments on diverse real-world tasks show that UniDomain solves complex, unseen tasks in a zero-shot manner, achieving up to 58% higher task success and 160% improvement in plan optimality over state-of-the-art LLM and LLM-PDDL baselines.
>
---
#### [new 016] Interactive Adversarial Testing of Autonomous Vehicles with Adjustable Confrontation Intensity
- **分类: cs.RO**

- **简介: 论文提出ExamPPO框架，用于自动驾驶车辆的交互式对抗测试，属于安全评估任务。旨在解决现有测试方法依赖高质量数据、交互能力弱、对抗鲁棒性差的问题。工作包括建模周围车辆为智能测试者，引入对抗因子调节测试强度，并设计评估指标，实现对AV决策鲁棒性的系统评测。**

- **链接: [http://arxiv.org/pdf/2507.21814v1](http://arxiv.org/pdf/2507.21814v1)**

> **作者:** Yicheng Guo; Chengkai Xu; Jiaqi Liu; Hao Zhang; Peng Hang; Jian Sun
>
> **摘要:** Scientific testing techniques are essential for ensuring the safe operation of autonomous vehicles (AVs), with high-risk, highly interactive scenarios being a primary focus. To address the limitations of existing testing methods, such as their heavy reliance on high-quality test data, weak interaction capabilities, and low adversarial robustness, this paper proposes ExamPPO, an interactive adversarial testing framework that enables scenario-adaptive and intensity-controllable evaluation of autonomous vehicles. The framework models the Surrounding Vehicle (SV) as an intelligent examiner, equipped with a multi-head attention-enhanced policy network, enabling context-sensitive and sustained behavioral interventions. A scalar confrontation factor is introduced to modulate the intensity of adversarial behaviors, allowing continuous, fine-grained adjustment of test difficulty. Coupled with structured evaluation metrics, ExamPPO systematically probes AV's robustness across diverse scenarios and strategies. Extensive experiments across multiple scenarios and AV strategies demonstrate that ExamPPO can effectively modulate adversarial behavior, expose decision-making weaknesses in tested AVs, and generalize across heterogeneous environments, thereby offering a unified and reproducible solution for evaluating the safety and intelligence of autonomous decision-making systems.
>
---
#### [new 017] Multi-UAV Deployment in Obstacle-Cluttered Environments with LOS Connectivity
- **分类: cs.RO**

- **简介: 该论文研究多无人机在障碍密集环境中的部署问题，旨在构建可靠通信网络。提出基于最小边RRT*的搜索方法设计多跳网络结构，并采用分布式模型预测控制策略，确保无人机间视线连通及避障。解决了网络结构设计与运动中连通性保持两大挑战。**

- **链接: [http://arxiv.org/pdf/2507.21772v1](http://arxiv.org/pdf/2507.21772v1)**

> **作者:** Yuda Chen; Shuaikang Wang; Jie Li; Meng Guo
>
> **备注:** iros2025
>
> **摘要:** A reliable communication network is essential for multiple UAVs operating within obstacle-cluttered environments, where limited communication due to obstructions often occurs. A common solution is to deploy intermediate UAVs to relay information via a multi-hop network, which introduces two challenges: (i) how to design the structure of multihop networks; and (ii) how to maintain connectivity during collaborative motion. To this end, this work first proposes an efficient constrained search method based on the minimumedge RRT? algorithm, to find a spanning-tree topology that requires a less number of UAVs for the deployment task. Then, to achieve this deployment, a distributed model predictive control strategy is proposed for the online motion coordination. It explicitly incorporates not only the inter-UAV and UAVobstacle distance constraints, but also the line-of-sight (LOS) connectivity constraint. These constraints are well-known to be nonlinear and often tackled by various approximations. In contrast, this work provides a theoretical guarantee that all agent trajectories are ensured to be collision-free with a teamwise LOS connectivity at all time. Numerous simulations are performed in 3D valley-like environments, while hardware experiments validate its dynamic adaptation when the deployment position changes online.
>
---
#### [new 018] Projecting the New Body: How Body Image Evolves During Learning to Walk with a Wearable Robot
- **分类: cs.RO; cs.SY; eess.SY**

- **简介: 该论文研究穿戴式机器人如何影响使用者行走时的身体感知与运动学习。任务是探索人机融合过程中的身体意象变化。通过测量步态与感知，发现训练使身体感知与实际动作趋近，但仍有偏差，需增强感知反馈与校准以优化训练效果。**

- **链接: [http://arxiv.org/pdf/2507.21384v1](http://arxiv.org/pdf/2507.21384v1)**

> **作者:** I-Chieh Lee; He Huang
>
> **摘要:** Advances in wearable robotics challenge the traditional definition of human motor systems, as wearable robots redefine body structure, movement capability, and perception of their own bodies. We measured gait performance and perceived body images via Selected Coefficient of Perceived Motion, SCoMo, after each training session. Based on human motor learning theory extended to wearer-robot systems, we hypothesized that learning the perceived body image when walking with a robotic leg co-evolves with the actual gait improvement and becomes more certain and more accurate to the actual motion. Our result confirmed that motor learning improved both physical and perceived gait pattern towards normal, indicating that via practice the wearers incorporated the robotic leg into their sensorimotor systems to enable wearer-robot movement coordination. However, a persistent discrepancy between perceived and actual motion remained, likely due to the absence of direct sensation and control of the prosthesis from wearers. Additionally, the perceptual overestimation at the later training sessions might limit further motor improvement. These findings suggest that enhancing the human sense of wearable robots and frequent calibrating perception of body image are essential for effective training with lower limb wearable robots and for developing more embodied assistive technologies.
>
---
#### [new 019] Autonomous Exploration with Terrestrial-Aerial Bimodal Vehicles
- **分类: cs.RO**

- **简介: 该论文属于自主探索任务，旨在解决陆空双模车辆在实际探索中的能耗与时间约束问题。作者提出了一种分层框架，结合环境感知、扩展蒙特卡洛树搜索和改进的运动规划器，优化双模态选择与路径规划，实现高效自主探索。**

- **链接: [http://arxiv.org/pdf/2507.21338v1](http://arxiv.org/pdf/2507.21338v1)**

> **作者:** Yuman Gao; Ruibin Zhang; Tiancheng Lai; Yanjun Cao; Chao Xu; Fei Gao
>
> **摘要:** Terrestrial-aerial bimodal vehicles, which integrate the high mobility of aerial robots with the long endurance of ground robots, offer significant potential for autonomous exploration. Given the inherent energy and time constraints in practical exploration tasks, we present a hierarchical framework for the bimodal vehicle to utilize its flexible locomotion modalities for exploration. Beginning with extracting environmental information to identify informative regions, we generate a set of potential bimodal viewpoints. To adaptively manage energy and time constraints, we introduce an extended Monte Carlo Tree Search approach that strategically optimizes both modality selection and viewpoint sequencing. Combined with an improved bimodal vehicle motion planner, we present a complete bimodal energy- and time-aware exploration system. Extensive simulations and deployment on a customized real-world platform demonstrate the effectiveness of our system.
>
---
#### [new 020] Model Predictive Adversarial Imitation Learning for Planning from Observation
- **分类: cs.RO; cs.AI**

- **简介: 该论文属于模仿学习与规划任务，旨在解决从观察中学习可靠规划行为的问题。现有方法依赖奖励函数学习与模型预测控制分离，导致效率低下。论文提出将对抗模仿学习与规划结合，实现端到端学习规划器，提升了样本效率、泛化能力和鲁棒性。**

- **链接: [http://arxiv.org/pdf/2507.21533v1](http://arxiv.org/pdf/2507.21533v1)**

> **作者:** Tyler Han; Yanda Bao; Bhaumik Mehta; Gabriel Guo; Anubhav Vishwakarma; Emily Kang; Sanghun Jung; Rosario Scalise; Jason Zhou; Bryan Xu; Byron Boots
>
> **备注:** Open-source code in process of being cleaned and documented for release. Please contact directly in the meantime for code. Under Review
>
> **摘要:** Human demonstration data is often ambiguous and incomplete, motivating imitation learning approaches that also exhibit reliable planning behavior. A common paradigm to perform planning-from-demonstration involves learning a reward function via Inverse Reinforcement Learning (IRL) then deploying this reward via Model Predictive Control (MPC). Towards unifying these methods, we derive a replacement of the policy in IRL with a planning-based agent. With connections to Adversarial Imitation Learning, this formulation enables end-to-end interactive learning of planners from observation-only demonstrations. In addition to benefits in interpretability, complexity, and safety, we study and observe significant improvements on sample efficiency, out-of-distribution generalization, and robustness. The study includes evaluations in both simulated control benchmarks and real-world navigation experiments using few-to-single observation-only demonstrations.
>
---
#### [new 021] Multifunctional physical reservoir computing in soft tensegrity robots
- **分类: cs.RO; cs.LG; nlin.CD**

- **简介: 该论文研究软体张力机器人中的多功能物理储层计算，旨在利用其非线性动力学实现多行为控制。通过模拟分析，探索系统在不同初始条件下的多稳态行为及未训练吸引子特性，揭示其内在结构与环境交互机制，为具身认知研究提供新视角。**

- **链接: [http://arxiv.org/pdf/2507.21496v1](http://arxiv.org/pdf/2507.21496v1)**

> **作者:** Ryo Terajima; Katsuma Inoue; Kohei Nakajima; Yasuo Kuniyoshi
>
> **备注:** 25 pages, 12 figures. The following article has been accepted by Chaos: An Interdisciplinary Journal of Nonlinear Science
>
> **摘要:** Recent studies have demonstrated that the dynamics of physical systems can be utilized for the desired information processing under the framework of physical reservoir computing (PRC). Robots with soft bodies are examples of such physical systems, and their nonlinear body-environment dynamics can be used to compute and generate the motor signals necessary for the control of their own behavior. In this simulation study, we extend this approach to control and embed not only one but also multiple behaviors into a type of soft robot called a tensegrity robot. The resulting system, consisting of the robot and the environment, is a multistable dynamical system that converges to different attractors from varying initial conditions. Furthermore, attractor analysis reveals that there exist "untrained attractors" in the state space of the system outside the training data. These untrained attractors reflect the intrinsic properties and structures of the tensegrity robot and its interactions with the environment. The impacts of these recent findings in PRC remain unexplored in embodied AI research. We here illustrate their potential to understand various features of embodied cognition that have not been fully addressed to date.
>
---
#### [new 022] ODE Methods for Computing One-Dimensional Self-Motion Manifolds
- **分类: cs.RO**

- **简介: 该论文属于机器人学任务，旨在解决冗余机械臂的全局逆运动学问题。论文提出基于常微分方程（ODE）的方法，用于计算一维自运动流形（SMM），从而获取所有可行的关节构型。研究还涵盖处理非冗余机械臂任务冗余及多段SMM搜索，并扩展至含移动关节的系统，提供精确解而无需额外优化。**

- **链接: [http://arxiv.org/pdf/2507.21957v1](http://arxiv.org/pdf/2507.21957v1)**

> **作者:** Dominic Guri; George Kantor
>
> **摘要:** Redundant manipulators are well understood to offer infinite joint configurations for achieving a desired end-effector pose. The multiplicity of inverse kinematics (IK) solutions allows for the simultaneous solving of auxiliary tasks like avoiding joint limits or obstacles. However, the most widely used IK solvers are numerical gradient-based iterative methods that inherently return a locally optimal solution. In this work, we explore the computation of self-motion manifolds (SMMs), which represent the set of all joint configurations that solve the inverse kinematics problem for redundant manipulators. Thus, SMMs are global IK solutions for redundant manipulators. We focus on task redundancies of dimensionality 1, introducing a novel ODE formulation for computing SMMs using standard explicit fixed-step ODE integrators. We also address the challenge of ``inducing'' redundancy in otherwise non-redundant manipulators assigned to tasks naturally described by one degree of freedom less than the non-redundant manipulator. Furthermore, recognizing that SMMs can consist of multiple disconnected components, we propose methods for searching for these separate SMM components. Our formulations and algorithms compute accurate SMM solutions without requiring additional IK refinement, and we extend our methods to prismatic joint systems -- an area not covered in current SMM literature. This manuscript presents the derivation of these methods and several examples that show how the methods work and their limitations.
>
---
#### [new 023] Evaluating Interactions between Automated Vehicles and Cyclists using a coupled In-the-Loop Test Environment
- **分类: cs.RO; cs.HC**

- **简介: 该论文属于智能驾驶测试任务，旨在解决自动驾驶系统与骑行者交互测试缺乏真实性的问题。通过构建一个结合虚拟环境的“人-车”闭环测试平台，实现骑行者与自动驾驶车辆的实时双向交互，验证了测试环境的可行性与有效性。**

- **链接: [http://arxiv.org/pdf/2507.21859v1](http://arxiv.org/pdf/2507.21859v1)**

> **作者:** Michael Kaiser; Clemens Groß; Lisa Marie Otto; Steffen Müller
>
> **摘要:** Testing and evaluating automated driving systems (ADS) in interactions with vulnerable road users (VRUs), such as cyclists, are essential for improving the safety of VRUs, but often lack realism. This paper presents and validates a coupled in-the-loop test environment that integrates a Cyclist-in-the Loop test bench with a Vehicle-in-the-Loop test bench via a virtual environment (VE) developed in Unreal Engine 5. The setup enables closed-loop, bidirectional interaction between a real human cyclist and a real automated vehicle under safe and controllable conditions. The automated vehicle reacts to cyclist gestures via stimulated camera input, while the cyclist, riding a stationary bicycle, perceives and reacts to the vehicle in the VE in real time. Validation experiments are conducted using a real automated shuttle bus with a track-and-follow function, performing three test maneuvers - straight-line driving with stop, circular track driving, and double lane change - on a proving ground and in the coupled in-the-loop test environment. The performance is evaluated by comparing the resulting vehicle trajectories in both environments. Additionally, the introduced latencies of individual components in the test setup are measured. The results demonstrate the feasibility of the approach and highlight its strengths and limitations for realistic ADS evaluation.
>
---
#### [new 024] Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions
- **分类: cs.CL; cs.HC; cs.LG; cs.RO; I.2.7, I.2.9, j.4,**

- **简介: 该论文属于人工智能教育交互任务，旨在解决大语言模型（LLM）在知识获取与整合上的局限性。受维果茨基社会文化理论启发，论文提出“AI Social Gym”环境，通过师生AI代理的对话式互动，探索混合主动教学策略对本体学习的效果，证明该方法优于传统单向教学和直接知识输入。**

- **链接: [http://arxiv.org/pdf/2507.21065v1](http://arxiv.org/pdf/2507.21065v1)**

> **作者:** Sabrina Patania; Luca Annese; Cansu Koyuturk; Azzurra Ruggeri; Dimitri Ognibene
>
> **备注:** submitted to ICSR2025
>
> **摘要:** Large Language Models (LLMs) have demonstrated remarkable capabilities in processing extensive offline datasets. However, they often face challenges in acquiring and integrating complex, knowledge online. Traditional AI training paradigms, predominantly based on supervised learning or reinforcement learning, mirror a 'Piagetian' model of independent exploration. These approaches typically rely on large datasets and sparse feedback signals, limiting the models' ability to learn efficiently from interactions. Drawing inspiration from Vygotsky's sociocultural theory, this study explores the potential of socially mediated learning paradigms to address these limitations. We introduce a dynamic environment, termed the 'AI Social Gym', where an AI learner agent engages in dyadic pedagogical dialogues with knowledgeable AI teacher agents. These interactions emphasize external, structured dialogue as a core mechanism for knowledge acquisition, contrasting with methods that depend solely on internal inference or pattern recognition. Our investigation focuses on how different pedagogical strategies impact the AI learning process in the context of ontology acquisition. Empirical results indicate that such dialogic approaches-particularly those involving mixed-direction interactions combining top-down explanations with learner-initiated questioning-significantly enhance the LLM's ability to acquire and apply new knowledge, outperforming both unidirectional instructional methods and direct access to structured knowledge, formats typically present in training datasets. These findings suggest that integrating pedagogical and psychological insights into AI and robot training can substantially improve post-training knowledge acquisition and response quality. This approach offers a complementary pathway to existing strategies like prompt engineering
>
---
#### [new 025] MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving
- **分类: cs.CV; cs.AI; cs.LG; cs.RO**

- **简介: 论文任务为自动驾驶中的在线矢量高精地图构建。解决传统方法无法捕捉环境不确定性与模糊性问题。工作提出MapDiffusion，采用扩散模型生成多可能地图样本，实现不确定性估计与精度提升，在nuScenes数据集上表现优越。**

- **链接: [http://arxiv.org/pdf/2507.21423v1](http://arxiv.org/pdf/2507.21423v1)**

> **作者:** Thomas Monninger; Zihan Zhang; Zhipeng Mo; Md Zafar Anwar; Steffen Staab; Sihao Ding
>
> **备注:** Accepted for 2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2025)
>
> **摘要:** Autonomous driving requires an understanding of the static environment from sensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse multiple inputs, and a vector decoder predicts a vectorized map representation from the latent BEV grid. However, traditional map construction models provide deterministic point estimates, failing to capture uncertainty and the inherent ambiguities of real-world environments, such as occlusions and missing lane markings. We propose MapDiffusion, a novel generative approach that leverages the diffusion paradigm to learn the full distribution of possible vectorized maps. Instead of predicting a single deterministic output from learned queries, MapDiffusion iteratively refines randomly initialized queries, conditioned on a BEV latent grid, to generate multiple plausible map samples. This allows aggregating samples to improve prediction accuracy and deriving uncertainty estimates that directly correlate with scene ambiguity. Extensive experiments on the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art performance in online map construction, surpassing the baseline by 5% in single-sample performance. We further show that aggregating multiple samples consistently improves performance along the ROC curve, validating the benefit of distribution modeling. Additionally, our uncertainty estimates are significantly higher in occluded areas, reinforcing their value in identifying regions with ambiguous sensor input. By modeling the full map distribution, MapDiffusion enhances the robustness and reliability of online vectorized HD map construction, enabling uncertainty-aware decision-making for autonomous vehicles in complex environments.
>
---
#### [new 026] From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning
- **分类: cs.CV; cs.RO**

- **简介: 该论文属于机器人导航任务，旨在解决导航基础模型在现实城市环境中缺乏交互性和安全行为的问题。作者提出Seeing-to-Experiencing（S2E）框架，结合视频预训练与强化学习后训练，提升模型的交互能力，同时保持其泛化能力。论文还构建了评估基准NavBench-GS，验证了S2E在提升模型性能方面的有效性。**

- **链接: [http://arxiv.org/pdf/2507.22028v1](http://arxiv.org/pdf/2507.22028v1)**

> **作者:** Honglin He; Yukai Ma; Wayne Wu; Bolei Zhou
>
> **摘要:** Navigation foundation models trained on massive webscale data enable agents to generalize across diverse environments and embodiments. However, these models trained solely on offline data, often lack the capacity to reason about the consequences of their actions or adapt through counterfactual understanding. They thus face significant limitations in the real-world urban navigation where interactive and safe behaviors, such as avoiding obstacles and moving pedestrians, are critical. To tackle these challenges, we introduce the Seeing-to-Experiencing framework to scale the capability of navigation foundation models with reinforcement learning. S2E combines the strengths of pre-training on videos and post-training through RL. It maintains the generalizability acquired from large-scale real-world videos while enhancing its interactivity through RL in simulation environments. Specifically, we introduce two innovations: an Anchor-Guided Distribution Matching strategy, which stabilizes learning and models diverse motion patterns through anchor-based supervision; and a Residual-Attention Module, which obtains reactive behaviors from simulation environments without erasing the model's pretrained knowledge. Moreover, we establish a comprehensive end-to-end evaluation benchmark, NavBench-GS, built on photorealistic 3DGS reconstructions of real-world scenes that incorporate physical interactions. It can systematically assess the generalizability and safety of navigation foundation models. Extensive experiments show that S2E mitigates the diminishing returns often seen when scaling with offline data alone. We perform a thorough analysis of the benefits of Reinforcement Learning compared to Supervised Fine-Tuning in the context of post-training for robot learning. Our findings emphasize the crucial role of integrating interactive online experiences to effectively scale foundation models in Robotics.
>
---
#### [new 027] Snap, Segment, Deploy: A Visual Data and Detection Pipeline for Wearable Industrial Assistants
- **分类: cs.HC; cs.RO**

- **简介: 该论文提出一种用于工业场景的可穿戴助手系统，属于工业智能任务。旨在解决工业装配中环境复杂、计算资源受限及隐私保护问题。工作包括构建轻量级视觉与语音交互系统，集成物体检测、语音识别与生成模型，实现本地化实时辅助操作与培训，并提出自动化数据构建与优化策略，提升跨域鲁棒性，验证了其实际可行性。**

- **链接: [http://arxiv.org/pdf/2507.21072v1](http://arxiv.org/pdf/2507.21072v1)**

> **作者:** Di Wen; Junwei Zheng; Ruiping Liu; Yi Xu; Kunyu Peng; Rainer Stiefelhagen
>
> **摘要:** Industrial assembly tasks increasingly demand rapid adaptation to complex procedures and varied components, yet are often conducted in environments with limited computing, connectivity, and strict privacy requirements. These constraints make conventional cloud-based or fully autonomous solutions impractical for factory deployment. This paper introduces a mobile-device-based assistant system for industrial training and operational support, enabling real-time, semi-hands-free interaction through on-device perception and voice interfaces. The system integrates lightweight object detection, speech recognition, and Retrieval-Augmented Generation (RAG) into a modular on-device pipeline that operates entirely on-device, enabling intuitive support for part handling and procedure understanding without relying on manual supervision or cloud services. To enable scalable training, we adopt an automated data construction pipeline and introduce a two-stage refinement strategy to improve visual robustness under domain shift. Experiments on our generated dataset, i.e., Gear8, demonstrate improved robustness to domain shift and common visual corruptions. A structured user study further confirms its practical viability, with positive user feedback on the clarity of the guidance and the quality of the interaction. These results indicate that our framework offers a deployable solution for real-time, privacy-preserving smart assistance in industrial environments. We will release the Gear8 dataset and source code upon acceptance.
>
---
#### [new 028] Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics
- **分类: cs.AI; cs.LG; cs.RO**

- **简介: 该论文提出了Assistax，一个面向辅助机器人技术的硬件加速强化学习基准测试任务。它旨在解决现有RL基准（如游戏）难以转化为实际物理应用场景的问题。论文通过基于JAX的硬件加速模拟，实现了高效的多智能体强化学习训练，并测试机器人与人类患者的交互协调能力。**

- **链接: [http://arxiv.org/pdf/2507.21638v1](http://arxiv.org/pdf/2507.21638v1)**

> **作者:** Leonard Hinckeldey; Elliot Fosong; Elle Miller; Rimvydas Rubavicius; Trevor McInroe; Patricia Wollstadt; Christiane B. Wiebel-Herboth; Subramanian Ramamoorthy; Stefano V. Albrecht
>
> **备注:** Accepted for the Coordination and Cooperation in Multi-Agent Reinforcement Learning Workshop at the Reinforcement Learning Conference 2025
>
> **摘要:** The development of reinforcement learning (RL) algorithms has been largely driven by ambitious challenge tasks and benchmarks. Games have dominated RL benchmarks because they present relevant challenges, are inexpensive to run and easy to understand. While games such as Go and Atari have led to many breakthroughs, they often do not directly translate to real-world embodied applications. In recognising the need to diversify RL benchmarks and addressing complexities that arise in embodied interaction scenarios, we introduce Assistax: an open-source benchmark designed to address challenges arising in assistive robotics tasks. Assistax uses JAX's hardware acceleration for significant speed-ups for learning in physics-based simulations. In terms of open-loop wall-clock time, Assistax runs up to $370\times$ faster when vectorising training runs compared to CPU-based alternatives. Assistax conceptualises the interaction between an assistive robot and an active human patient using multi-agent RL to train a population of diverse partner agents against which an embodied robotic agent's zero-shot coordination capabilities can be tested. Extensive evaluation and hyperparameter tuning for popular continuous control RL and MARL algorithms provide reliable baselines and establish Assistax as a practical benchmark for advancing RL research for assistive robotics. The code is available at: https://github.com/assistive-autonomy/assistax.
>
---
#### [new 029] Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation
- **分类: cs.CV; cs.RO**

- **简介: 该论文属于视觉语言导航（VLN）任务，旨在解决导航代理在理解复杂场景与语言指令时易受细节干扰、导致行为偏差的问题。作者提出递归视觉想象（RVI）和自适应语言接地（ALG）技术，通过递归总结视觉感知、增强语言对齐，提升导航决策准确性。实验表明该方法在VLN-CE和ObjectNav任务上优于现有技术。**

- **链接: [http://arxiv.org/pdf/2507.21450v1](http://arxiv.org/pdf/2507.21450v1)**

> **作者:** Bolei Chen; Jiaxu Kang; Yifei Wang; Ping Zhong; Qi Wu; Jianxin Wang
>
> **备注:** Submitted to AAAI 2026
>
> **摘要:** Vision Language Navigation (VLN) typically requires agents to navigate to specified objects or remote regions in unknown scenes by obeying linguistic commands. Such tasks require organizing historical visual observations for linguistic grounding, which is critical for long-sequence navigational decisions. However, current agents suffer from overly detailed scene representation and ambiguous vision-language alignment, which weaken their comprehension of navigation-friendly high-level scene priors and easily lead to behaviors that violate linguistic commands. To tackle these issues, we propose a navigation policy by recursively summarizing along-the-way visual perceptions, which are adaptively aligned with commands to enhance linguistic grounding. In particular, by structurally modeling historical trajectories as compact neural grids, several Recursive Visual Imagination (RVI) techniques are proposed to motivate agents to focus on the regularity of visual transitions and semantic scene layouts, instead of dealing with misleading geometric details. Then, an Adaptive Linguistic Grounding (ALG) technique is proposed to align the learned situational memories with different linguistic components purposefully. Such fine-grained semantic matching facilitates the accurate anticipation of navigation actions and progress. Our navigation policy outperforms the state-of-the-art methods on the challenging VLN-CE and ObjectNav tasks, showing the superiority of our RVI and ALG techniques for VLN.
>
---
#### [new 030] Retrieve-Augmented Generation for Speeding up Diffusion Policy without Additional Training
- **分类: cs.LG; cs.RO**

- **简介: 论文属于模仿学习任务，旨在加速扩散策略（DP）的推理过程。现有方法依赖多步去噪，生成动作慢，而知识蒸馏方法训练耗时。论文提出RAGDP，利用检索增强生成技术，通过构建专家示范的向量数据库，在推理时快速找到相似动作，减少去噪步骤，提升速度并保持精度。**

- **链接: [http://arxiv.org/pdf/2507.21452v1](http://arxiv.org/pdf/2507.21452v1)**

> **作者:** Sodtavilan Odonchimed; Tatsuya Matsushima; Simon Holk; Yusuke Iwasawa; Yutaka Matsuo
>
> **摘要:** Diffusion Policies (DPs) have attracted attention for their ability to achieve significant accuracy improvements in various imitation learning tasks. However, DPs depend on Diffusion Models, which require multiple noise removal steps to generate a single action, resulting in long generation times. To solve this problem, knowledge distillation-based methods such as Consistency Policy (CP) have been proposed. However, these methods require a significant amount of training time, especially for difficult tasks. In this study, we propose RAGDP (Retrieve-Augmented Generation for Diffusion Policies) as a novel framework that eliminates the need for additional training using a knowledge base to expedite the inference of pre-trained DPs. In concrete, RAGDP encodes observation-action pairs through the DP encoder to construct a vector database of expert demonstrations. During inference, the current observation is embedded, and the most similar expert action is extracted. This extracted action is combined with an intermediate noise removal step to reduce the number of steps required compared to the original diffusion step. We show that by using RAGDP with the base model and existing acceleration methods, we improve the accuracy and speed trade-off with no additional training. Even when accelerating the models 20 times, RAGDP maintains an advantage in accuracy, with a 7% increase over distillation models such as CP.
>
---
#### [new 031] Decentralized Modeling of Vehicular Maneuvers and Interactions at Urban Junctions
- **分类: math.OC; cs.RO; cs.SY; eess.SY**

- **简介: 该论文属于智能交通系统任务，旨在解决城市交叉口自动驾驶车辆在混行交通中的复杂交互建模问题。论文提出了一种去中心化的建模框架，结合图搜索算法与预测控制器，实现车辆轨迹规划与控制，无需中心化控制或车辆间信息共享，提升了交通效率与安全性分析能力。**

- **链接: [http://arxiv.org/pdf/2507.21547v1](http://arxiv.org/pdf/2507.21547v1)**

> **作者:** Saeed Rahmani; Simeon C. Calvert; Bart van Arem
>
> **备注:** Manuscript under review
>
> **摘要:** Modeling and evaluation of automated vehicles (AVs) in mixed-autonomy traffic is essential prior to their safe and efficient deployment. This is especially important at urban junctions where complex multi-agent interactions occur. Current approaches for modeling vehicular maneuvers and interactions at urban junctions have limitations in formulating non-cooperative interactions and vehicle dynamics within a unified mathematical framework. Previous studies either assume predefined paths or rely on cooperation and central controllability, limiting their realism and applicability in mixed-autonomy traffic. This paper addresses these limitations by proposing a modeling framework for trajectory planning and decentralized vehicular control at urban junctions. The framework employs a bi-level structure where the upper level generates kinematically feasible reference trajectories using an efficient graph search algorithm with a custom heuristic function, while the lower level employs a predictive controller for trajectory tracking and optimization. Unlike existing approaches, our framework does not require central controllability or knowledge sharing among vehicles. The vehicle kinematics are explicitly incorporated at both levels, and acceleration and steering angle are used as control variables. This intuitive formulation facilitates analysis of traffic efficiency, environmental impacts, and motion comfort. The framework's decentralized structure accommodates operational and stochastic elements, such as vehicles' detection range, perception uncertainties, and reaction delay, making the model suitable for safety analysis. Numerical and simulation experiments across diverse scenarios demonstrate the framework's capability in modeling accurate and realistic vehicular maneuvers and interactions at various urban junctions, including unsignalized intersections and roundabouts.
>
---
## 更新

#### [replaced 001] MP1: MeanFlow Tames Policy Learning in 1-step for Robotic Manipulation
- **分类: cs.RO**

- **链接: [http://arxiv.org/pdf/2507.10543v3](http://arxiv.org/pdf/2507.10543v3)**

> **作者:** Juyi Sheng; Ziyi Wang; Peiming Li; Mengyuan Liu
>
> **摘要:** In robot manipulation, robot learning has become a prevailing approach. However, generative models within this field face a fundamental trade-off between the slow, iterative sampling of diffusion models and the architectural constraints of faster Flow-based methods, which often rely on explicit consistency losses. To address these limitations, we introduce MP1, which pairs 3D point-cloud inputs with the MeanFlow paradigm to generate action trajectories in one network function evaluation (1-NFE). By directly learning the interval-averaged velocity via the "MeanFlow Identity", our policy avoids any additional consistency constraints. This formulation eliminates numerical ODE-solver errors during inference, yielding more precise trajectories. MP1 further incorporates CFG for improved trajectory controllability while retaining 1-NFE inference without reintroducing structural constraints. Because subtle scene-context variations are critical for robot learning, especially in few-shot learning, we introduce a lightweight Dispersive Loss that repels state embeddings during training, boosting generalization without slowing inference. We validate our method on the Adroit and Meta-World benchmarks, as well as in real-world scenarios. Experimental results show MP1 achieves superior average task success rates, outperforming DP3 by 10.2% and FlowPolicy by 7.3%. Its average inference time is only 6.8 ms-19x faster than DP3 and nearly 2x faster than FlowPolicy. Our code is available at https://github.com/LogSSim/MP1.git.
>
---
#### [replaced 002] Unscented Kalman Filter with a Nonlinear Propagation Model for Navigation Applications
- **分类: cs.RO; eess.SP**

- **链接: [http://arxiv.org/pdf/2507.10082v2](http://arxiv.org/pdf/2507.10082v2)**

> **作者:** Amit Levy; Itzik Klein
>
> **备注:** 6 pages, 4 figures
>
> **摘要:** The unscented Kalman filter is a nonlinear estimation algorithm commonly used in navigation applications. The prediction of the mean and covariance matrix is crucial to the stable behavior of the filter. This prediction is done by propagating the sigma points according to the dynamic model at hand. In this paper, we introduce an innovative method to propagate the sigma points according to the nonlinear dynamic model of the navigation error state vector. This improves the filter accuracy and navigation performance. We demonstrate the benefits of our proposed approach using real sensor data recorded by an autonomous underwater vehicle during several scenarios.
>
---
#### [replaced 003] A General Safety Framework for Autonomous Manipulation in Human Environments
- **分类: cs.RO; cs.SY; eess.SY**

- **链接: [http://arxiv.org/pdf/2412.10180v2](http://arxiv.org/pdf/2412.10180v2)**

> **作者:** Jakob Thumm; Julian Balletshofer; Leonardo Maglanoc; Luis Muschal; Matthias Althoff
>
> **摘要:** Autonomous robots are projected to significantly augment the manual workforce, especially in repetitive and hazardous tasks. For a successful deployment of such robots in human environments, it is crucial to guarantee human safety. State-of-the-art approaches to ensure human safety are either too conservative to permit a natural human-robot collaboration or make strong assumptions that do not hold for autonomous robots, e.g., knowledge of a pre-defined trajectory. Therefore, we propose the shield for Safe Autonomous human-robot collaboration through Reachability Analysis (SARA shield). This novel power and force limiting framework provides formal safety guarantees for manipulation in human environments while realizing fast robot speeds. As unconstrained contacts allow for significantly higher contact forces than constrained contacts (also known as clamping), we use reachability analysis to classify potential contacts by their type in a formally correct way. For each contact type, we formally verify that the kinetic energy of the robot is below pain and injury thresholds for the respective human body part in contact. Our experiments show that SARA shield satisfies the contact safety constraints while significantly improving the robot performance in comparison to state-of-the-art approaches.
>
---
#### [replaced 004] Online Concurrent Multi-Robot Coverage Path Planning
- **分类: cs.RO; cs.AI**

- **链接: [http://arxiv.org/pdf/2403.10460v2](http://arxiv.org/pdf/2403.10460v2)**

> **作者:** Ratijit Mitra; Indranil Saha
>
> **备注:** Accepted in IROS 2025
>
> **摘要:** Recently, centralized receding horizon online multi-robot coverage path planning algorithms have shown remarkable scalability in thoroughly exploring large, complex, unknown workspaces with many robots. In a horizon, the path planning and the path execution interleave, meaning when the path planning occurs for robots with no paths, the robots with outstanding paths do not execute, and subsequently, when the robots with new or outstanding paths execute to reach respective goals, path planning does not occur for those robots yet to get new paths, leading to wastage of both the robotic and the computation resources. As a remedy, we propose a centralized algorithm that is not horizon-based. It plans paths at any time for a subset of robots with no paths, i.e., who have reached their previously assigned goals, while the rest execute their outstanding paths, thereby enabling concurrent planning and execution. We formally prove that the proposed algorithm ensures complete coverage of an unknown workspace and analyze its time complexity. To demonstrate scalability, we evaluate our algorithm to cover eight large $2$D grid benchmark workspaces with up to 512 aerial and ground robots, respectively. A comparison with a state-of-the-art horizon-based algorithm shows its superiority in completing the coverage with up to 1.6x speedup. For validation, we perform ROS + Gazebo simulations in six 2D grid benchmark workspaces with 10 quadcopters and TurtleBots, respectively. We also successfully conducted one outdoor experiment with three quadcopters and one indoor with two TurtleBots.
>
---
#### [replaced 005] VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback
- **分类: cs.RO; cs.LG**

- **链接: [http://arxiv.org/pdf/2507.17294v2](http://arxiv.org/pdf/2507.17294v2)**

> **作者:** Jianxin Bi; Kevin Yuchen Ma; Ce Hao; Mike Zheng Shou; Harold Soh
>
> **备注:** 19 pages, 5 figures
>
> **摘要:** Tactile feedback is generally recognized to be crucial for effective interaction with the physical world. However, state-of-the-art Vision-Language-Action (VLA) models lack the ability to interpret and use tactile signals, limiting their effectiveness in contact-rich tasks. Incorporating tactile feedback into these systems is challenging due to the absence of large multi-modal datasets. We present VLA-Touch, an approach that enhances generalist robot policies with tactile sensing \emph{without fine-tuning} the base VLA. Our method introduces two key innovations: (1) a pipeline that leverages a pretrained tactile-language model that provides semantic tactile feedback for high-level task planning, and (2) a diffusion-based controller that refines VLA-generated actions with tactile signals for contact-rich manipulation. Through real-world experiments, we demonstrate that our dual-level integration of tactile feedback improves task planning efficiency while enhancing execution precision. Code is open-sourced at \href{https://github.com/jxbi1010/VLA-Touch}{this URL}.
>
---
#### [replaced 006] IRASim: A Fine-Grained World Model for Robot Manipulation
- **分类: cs.RO; cs.AI; cs.CV**

- **链接: [http://arxiv.org/pdf/2406.14540v2](http://arxiv.org/pdf/2406.14540v2)**

> **作者:** Fangqi Zhu; Hongtao Wu; Song Guo; Yuxiao Liu; Chilam Cheang; Tao Kong
>
> **备注:** Opensource, project website: https://gen-irasim.github.io
>
> **摘要:** World models allow autonomous agents to plan and explore by predicting the visual outcomes of different actions. However, for robot manipulation, it is challenging to accurately model the fine-grained robot-object interaction within the visual space using existing methods which overlooks precise alignment between each action and the corresponding frame. In this paper, we present IRASim, a novel world model capable of generating videos with fine-grained robot-object interaction details, conditioned on historical observations and robot action trajectories. We train a diffusion transformer and introduce a novel frame-level action-conditioning module within each transformer block to explicitly model and strengthen the action-frame alignment. Extensive experiments show that: (1) the quality of the videos generated by our method surpasses all the baseline methods and scales effectively with increased model size and computation; (2) policy evaluations using IRASim exhibit a strong correlation with those using the ground-truth simulator, highlighting its potential to accelerate real-world policy evaluation; (3) testing-time scaling through model-based planning with IRASim significantly enhances policy performance, as evidenced by an improvement in the IoU metric on the Push-T benchmark from 0.637 to 0.961; (4) IRASim provides flexible action controllability, allowing virtual robotic arms in datasets to be controlled via a keyboard or VR controller.
>
---
#### [replaced 007] RANa: Retrieval-Augmented Navigation
- **分类: cs.CV; cs.IR; cs.RO**

- **链接: [http://arxiv.org/pdf/2504.03524v2](http://arxiv.org/pdf/2504.03524v2)**

> **作者:** Gianluca Monaci; Rafael S. Rezende; Romain Deffayet; Gabriela Csurka; Guillaume Bono; Hervé Déjean; Stéphane Clinchant; Christian Wolf
>
> **摘要:** Methods for navigation based on large-scale learning typically treat each episode as a new problem, where the agent is spawned with a clean memory in an unknown environment. While these generalization capabilities to an unknown environment are extremely important, we claim that, in a realistic setting, an agent should have the capacity of exploiting information collected during earlier robot operations. We address this by introducing a new retrieval-augmented agent, trained with RL, capable of querying a database collected from previous episodes in the same environment and learning how to integrate this additional context information. We introduce a unique agent architecture for the general navigation task, evaluated on ImageNav, Instance-ImageNav and ObjectNav. Our retrieval and context encoding methods are data-driven and employ vision foundation models (FM) for both semantic and geometric understanding. We propose new benchmarks for these settings and we show that retrieval allows zero-shot transfer across tasks and environments while significantly improving performance.
>
---
#### [replaced 008] Diffusion Beats Autoregressive in Data-Constrained Settings
- **分类: cs.LG; cs.AI; cs.CV; cs.RO**

- **链接: [http://arxiv.org/pdf/2507.15857v3](http://arxiv.org/pdf/2507.15857v3)**

> **作者:** Mihir Prabhudesai; Mengning Wu; Amir Zadeh; Katerina Fragkiadaki; Deepak Pathak
>
> **备注:** Project Webpage: https://diffusion-scaling.github.io
>
> **摘要:** Autoregressive (AR) models have long dominated the landscape of large language models, driving progress across a wide range of tasks. Recently, diffusion-based language models have emerged as a promising alternative, though their advantages over AR models remain underexplored. In this paper, we systematically study masked diffusion models in data-constrained settings-where training involves repeated passes over limited data-and find that they significantly outperform AR models when compute is abundant but data is scarce. Diffusion models make better use of repeated data, achieving lower validation loss and superior downstream performance. We interpret this advantage as implicit data augmentation: masked diffusion exposes the model to a diverse distribution of token orderings and prediction tasks, unlike AR's fixed left-to-right factorization. We find new scaling laws for diffusion models and derive a closed-form expression for the critical compute threshold at which diffusion begins to outperform AR. These results suggest that when data, not compute, is the bottleneck, diffusion models offer a compelling alternative to the standard AR paradigm. Our code is available at: https://diffusion-scaling.github.io.
>
---
#### [replaced 009] Humanoid Occupancy: Enabling A Generalized Multimodal Occupancy Perception System on Humanoid Robots
- **分类: cs.RO; cs.AI; cs.CV**

- **链接: [http://arxiv.org/pdf/2507.20217v2](http://arxiv.org/pdf/2507.20217v2)**

> **作者:** Wei Cui; Haoyu Wang; Wenkang Qin; Yijie Guo; Gang Han; Wen Zhao; Jiahang Cao; Zhang Zhang; Jiaru Zhong; Jingkai Sun; Pihai Sun; Shuai Shi; Botuo Jiang; Jiahao Ma; Jiaxu Wang; Hao Cheng; Zhichao Liu; Yang Wang; Zheng Zhu; Guan Huang; Jian Tang; Qiang Zhang
>
> **备注:** Tech Report
>
> **摘要:** Humanoid robot technology is advancing rapidly, with manufacturers introducing diverse heterogeneous visual perception modules tailored to specific scenarios. Among various perception paradigms, occupancy-based representation has become widely recognized as particularly suitable for humanoid robots, as it provides both rich semantic and 3D geometric information essential for comprehensive environmental understanding. In this work, we present Humanoid Occupancy, a generalized multimodal occupancy perception system that integrates hardware and software components, data acquisition devices, and a dedicated annotation pipeline. Our framework employs advanced multi-modal fusion techniques to generate grid-based occupancy outputs encoding both occupancy status and semantic labels, thereby enabling holistic environmental understanding for downstream tasks such as task planning and navigation. To address the unique challenges of humanoid robots, we overcome issues such as kinematic interference and occlusion, and establish an effective sensor layout strategy. Furthermore, we have developed the first panoramic occupancy dataset specifically for humanoid robots, offering a valuable benchmark and resource for future research and development in this domain. The network architecture incorporates multi-modal feature fusion and temporal information integration to ensure robust perception. Overall, Humanoid Occupancy delivers effective environmental perception for humanoid robots and establishes a technical foundation for standardizing universal visual modules, paving the way for the widespread deployment of humanoid robots in complex real-world scenarios.
>
---
#### [replaced 010] Integration of Large Language Models within Cognitive Architectures for Autonomous Robots
- **分类: cs.RO**

- **链接: [http://arxiv.org/pdf/2309.14945v3](http://arxiv.org/pdf/2309.14945v3)**

> **作者:** Miguel Á. González-Santamarta; Irene González-Fernández; Francisco J. Rodríguez-Lera; Ángel Manuel Guerrero-Higueras; Vicente Matellán-Olivera
>
> **备注:** 9 pages, 6 figures, 2 tables, Submitted to ROBOT 2025 (8th Iberian Robotics Conference)
>
> **摘要:** Symbolic reasoning systems have been used in cognitive architectures to provide inference and planning capabilities. However, defining domains and problems has proven difficult and prone to errors. Moreover, Large Language Models (LLMs) have emerged as tools to process natural language for different tasks. In this paper, we propose the use of LLMs to tackle these problems. This way, this paper proposes the integration of LLMs in the ROS 2-integrated cognitive architecture MERLIN2 for autonomous robots. Specifically, we present the design, development and deployment of how to leverage the reasoning capabilities of LLMs inside the deliberative processes of MERLIN2. As a result, the deliberative system is updated from a PDDL-based planner system to a natural language planning system. This proposal is evaluated quantitatively and qualitatively, measuring the impact of incorporating the LLMs in the cognitive architecture. Results show that a classical approach achieves better performance but the proposed solution provides an enhanced interaction through natural language.
>
---
#### [replaced 011] Learning Approach to Efficient Vision-based Active Tracking of a Flying Target by an Unmanned Aerial Vehicle
- **分类: cs.RO**

- **链接: [http://arxiv.org/pdf/2506.18264v2](http://arxiv.org/pdf/2506.18264v2)**

> **作者:** Jagadeswara PKV Pothuri; Aditya Bhatt; Prajit KrisshnaKumar; Manaswin Oddiraju; Souma Chowdhury
>
> **备注:** Accepted for presentation in proceedings of AIAA Aviation 2025
>
> **摘要:** Autonomous tracking of flying aerial objects has important civilian and defense applications, ranging from search and rescue to counter-unmanned aerial systems (counter-UAS). Ground based tracking requires setting up infrastructure, could be range limited, and may not be feasible in remote areas, crowded cities or in dense vegetation areas. Vision based active tracking of aerial objects from another airborne vehicle, e.g., a chaser unmanned aerial vehicle (UAV), promises to fill this important gap, along with serving aerial coordination use cases. Vision-based active tracking by a UAV entails solving two coupled problems: 1) compute-efficient and accurate (target) object detection and target state estimation; and 2) maneuver decisions to ensure that the target remains in the field of view in the future time-steps and favorably positioned for continued detection. As a solution to the first problem, this paper presents a novel integration of standard deep learning based architectures with Kernelized Correlation Filter (KCF) to achieve compute-efficient object detection without compromising accuracy, unlike standalone learning or filtering approaches. The proposed perception framework is validated using a lab-scale setup. For the second problem, to obviate the linearity assumptions and background variations limiting effectiveness of the traditional controllers, we present the use of reinforcement learning to train a neuro-controller for fast computation of velocity maneuvers. New state space, action space and reward formulations are developed for this purpose, and training is performed in simulation using AirSim. The trained model is also tested in AirSim with respect to complex target maneuvers, and is found to outperform a baseline PID control in terms of tracking up-time and average distance maintained (from the target) during tracking.
>
---
#### [replaced 012] Automated UAV-based Wind Turbine Blade Inspection: Blade Stop Angle Estimation and Blade Detail Prioritized Exposure Adjustment
- **分类: cs.RO**

- **链接: [http://arxiv.org/pdf/2507.04922v2](http://arxiv.org/pdf/2507.04922v2)**

> **作者:** Yichuan Shi; Hao Liu; Haowen Zheng; Haowen Yu; Xianqi Liang; Jie Li; Minmin Ma; Ximin Lyu
>
> **备注:** 8 pages, 7 figures, final submission to IROS 2025
>
> **摘要:** Unmanned aerial vehicles (UAVs) are critical in the automated inspection of wind turbine blades. Nevertheless, several issues persist in this domain. Firstly, existing inspection platforms encounter challenges in meeting the demands of automated inspection tasks and scenarios. Moreover, current blade stop angle estimation methods are vulnerable to environmental factors, restricting their robustness. Additionally, there is an absence of real-time blade detail prioritized exposure adjustment during capture, where lost details cannot be restored through post-optimization. To address these challenges, we introduce a platform and two approaches. Initially, a UAV inspection platform is presented to meet the automated inspection requirements. Subsequently, a Fermat point based blade stop angle estimation approach is introduced, achieving higher precision and success rates. Finally, we propose a blade detail prioritized exposure adjustment approach to ensure appropriate brightness and preserve details during image capture. Extensive tests, comprising over 120 flights across 10 wind turbine models in 5 operational wind farms, validate the effectiveness of the proposed approaches in enhancing inspection autonomy.
>
---
#### [replaced 013] Receding Hamiltonian-Informed Optimal Neural Control and State Estimation for Closed-Loop Dynamical Systems
- **分类: eess.SY; cs.AI; cs.ET; cs.LG; cs.RO; cs.SY**

- **链接: [http://arxiv.org/pdf/2411.01297v3](http://arxiv.org/pdf/2411.01297v3)**

> **作者:** Josue N. Rivera; Dengfeng Sun
>
> **备注:** 27 pages. Source code: https://github.com/wzjoriv/Hion
>
> **摘要:** This paper formalizes Hamiltonian-Informed Optimal Neural (Hion) controllers, a novel class of neural network-based controllers for dynamical systems and explicit non-linear model-predictive control. Hion controllers estimate future states and develop an optimal control strategy using Pontryagin's Maximum Principle. The proposed framework, along with our Taylored Multi-Faceted Approach for Neural ODE and Optimal Control (T-mano) architecture, allows for custom transient behavior, predictive control, and closed-loop feedback, addressing limitations of existing methods. Comparative analyses with established model-predictive controllers revealed Hion controllers' superior optimality and tracking capabilities. Optimal control strategies are also demonstrated for both linear and non-linear dynamical systems.
>
---
#### [replaced 014] An Integrated Approach to Robotic Object Grasping and Manipulation
- **分类: cs.RO; cs.CV**

- **链接: [http://arxiv.org/pdf/2411.13205v3](http://arxiv.org/pdf/2411.13205v3)**

> **作者:** Owais Ahmed; M Huzaifa; M Areeb; Hamza Ali Khan
>
> **摘要:** In response to the growing challenges of manual labor and efficiency in warehouse operations, Amazon has embarked on a significant transformation by incorporating robotics to assist with various tasks. While a substantial number of robots have been successfully deployed for tasks such as item transportation within warehouses, the complex process of object picking from shelves remains a significant challenge. This project addresses the issue by developing an innovative robotic system capable of autonomously fulfilling a simulated order by efficiently selecting specific items from shelves. A distinguishing feature of the proposed robotic system is its capacity to navigate the challenge of uncertain object positions within each bin of the shelf. The system is engineered to autonomously adapt its approach, employing strategies that enable it to efficiently locate and retrieve the desired items, even in the absence of pre-established knowledge about their placements.
>
---
#### [replaced 015] OPAL: Encoding Causal Understanding of Physical Systems for Robot Learning
- **分类: cs.RO; cs.AI**

- **链接: [http://arxiv.org/pdf/2504.06538v2](http://arxiv.org/pdf/2504.06538v2)**

> **作者:** Daniel Tcheurekdjian; Joshua Klasmeier; Tom Cooney; Christopher McCann; Tyler Fenstermaker
>
> **备注:** We withdraw our submission following peer review feedback that identified methodological limitations: specifically, our experimental design does not adequately support the causal claims made in the submission. The work was preliminary undergraduate research that requires substantial additional experimental validation to properly establish the proposed causal relationships
>
> **摘要:** We present OPAL (Operant Physical Agent with Language), a novel vision-language-action architecture that introduces topological constraints to flow matching for robotic control. To do so, we further introduce topological attention. Our approach models action sequences as topologically-structured representations with non-trivial constraints. Experimental results across 10 complex manipulation tasks demonstrate OPAL's superior performance compared to previous approaches, including Octo, OpenVLA, and ${\pi}$0. Our architecture achieves significant improvements in zero-shot performance without requiring task-specific fine-tuning, while reducing inference computational requirements by 42%. The theoretical guarantees provided by our topological approach result in more coherent long-horizon action sequences. Our results highlight the potential of constraining the search space of learning problems in robotics by deriving from fundamental physical laws, and the possibility of using topological attention to embed causal understanding into transformer architectures.
>
---
#### [replaced 016] Scanning Bot: Efficient Scan Planning using Panoramic Cameras
- **分类: cs.RO**

- **链接: [http://arxiv.org/pdf/2507.16175v2](http://arxiv.org/pdf/2507.16175v2)**

> **作者:** Euijeong Lee; Kyung Min Han; Young J. Kim
>
> **摘要:** Panoramic RGB-D cameras are known for their ability to produce high quality 3D scene reconstructions. However, operating these cameras involves manually selecting viewpoints and physically transporting the camera, making the generation of a 3D model time consuming and tedious. Additionally, the process can be challenging for novice users due to spatial constraints, such as ensuring sufficient feature overlap between viewpoint frames. To address these challenges, we propose a fully autonomous scan planning that generates an efficient tour plan for environment scanning, ensuring collision-free navigation and adequate overlap between viewpoints within the plan. Extensive experiments conducted in both synthetic and real-world environments validate the performance of our planner against state-of-the-art view planners. In particular, our method achieved an average scan coverage of 99 percent in the real-world experiment, with our approach being up to 3 times faster than state-of-the-art planners in total scan time.
>
---
#### [replaced 017] Category-level Meta-learned NeRF Priors for Efficient Object Mapping
- **分类: cs.CV; cs.RO**

- **链接: [http://arxiv.org/pdf/2503.01582v3](http://arxiv.org/pdf/2503.01582v3)**

> **作者:** Saad Ejaz; Hriday Bavle; Laura Ribeiro; Holger Voos; Jose Luis Sanchez-Lopez
>
> **摘要:** In 3D object mapping, category-level priors enable efficient object reconstruction and canonical pose estimation, requiring only a single prior per semantic category (e.g., chair, book, laptop, etc.). DeepSDF has been used predominantly as a category-level shape prior, but it struggles to reconstruct sharp geometry and is computationally expensive. In contrast, NeRFs capture fine details but have yet to be effectively integrated with category-level priors in a real-time multi-object mapping framework. To bridge this gap, we introduce PRENOM, a Prior-based Efficient Neural Object Mapper that integrates category-level priors with object-level NeRFs to enhance reconstruction efficiency and enable canonical object pose estimation. PRENOM gets to know objects on a first-name basis by meta-learning on synthetic reconstruction tasks generated from open-source shape datasets. To account for object category variations, it employs a multi-objective genetic algorithm to optimize the NeRF architecture for each category, balancing reconstruction quality and training time. Additionally, prior-based probabilistic ray sampling directs sampling toward expected object regions, accelerating convergence and improving reconstruction quality under constrained resources. Experimental results highlight the ability of PRENOM to achieve high-quality reconstructions while maintaining computational feasibility. Specifically, comparisons with prior-free NeRF-based approaches on a synthetic dataset show a 21\% lower Chamfer distance. Furthermore, evaluations against other approaches using shape priors on a noisy real-world dataset indicate a 13\% improvement averaged across all reconstruction metrics, and comparable pose and size estimation accuracy, while being trained for 5$\times$ less time. Code available at: https://github.com/snt-arg/PRENOM
>
---
#### [replaced 018] GSON: A Group-based Social Navigation Framework with Large Multimodal Model
- **分类: cs.RO; cs.AI**

- **链接: [http://arxiv.org/pdf/2409.18084v3](http://arxiv.org/pdf/2409.18084v3)**

> **作者:** Shangyi Luo; Peng Sun; Ji Zhu; Yuhong Deng; Cunjun Yu; Anxing Xiao; Xueqian Wang
>
> **备注:** Accepted by IEEE Robotics and Automation Letters (RA-L)
>
> **摘要:** With the increasing presence of service robots and autonomous vehicles in human environments, navigation systems need to evolve beyond simple destination reach to incorporate social awareness. This paper introduces GSON, a novel group-based social navigation framework that leverages Large Multimodal Models (LMMs) to enhance robots' social perception capabilities. Our approach uses visual prompting to enable zero-shot extraction of social relationships among pedestrians and integrates these results with robust pedestrian detection and tracking pipelines to overcome the inherent inference speed limitations of LMMs. The planning system incorporates a mid-level planner that sits between global path planning and local motion planning, effectively preserving both global context and reactive responsiveness while avoiding disruption of the predicted social group. We validate GSON through extensive real-world mobile robot navigation experiments involving complex social scenarios such as queuing, conversations, and photo sessions. Comparative results show that our system significantly outperforms existing navigation approaches in minimizing social perturbations while maintaining comparable performance on traditional navigation metrics.
>
---
#### [replaced 019] ManiTaskGen: A Comprehensive Task Generator for Benchmarking and Improving Vision-Language Agents on Embodied Decision-Making
- **分类: cs.RO**

- **链接: [http://arxiv.org/pdf/2505.20726v2](http://arxiv.org/pdf/2505.20726v2)**

> **作者:** Liu Dai; Haina Wang; Weikang Wan; Hao Su
>
> **备注:** Project Website: https://manitaskgen.github.io/
>
> **摘要:** Building embodied agents capable of accomplishing arbitrary tasks is a core objective towards achieving embodied artificial general intelligence (E-AGI). While recent work has advanced such general robot policies, their training and evaluation are often limited to tasks within specific scenes, involving restricted instructions and scenarios. Existing benchmarks also typically rely on manual annotation of limited tasks in a few scenes. We argue that exploring the full spectrum of feasible tasks within any given scene is crucial, as they provide both extensive benchmarks for evaluation and valuable resources for agent improvement. Towards this end, we introduce ManiTaskGen, a novel system that automatically generates comprehensive, diverse, feasible mobile manipulation tasks for any given scene. The generated tasks encompass both process-based, specific instructions (e.g., "move object from X to Y") and outcome-based, abstract instructions (e.g., "clear the table"). We apply ManiTaskGen to both simulated and real-world scenes, demonstrating the validity and diversity of the generated tasks. We then leverage these tasks to automatically construct benchmarks, thoroughly evaluating the embodied decision-making capabilities of agents built upon existing vision-language models (VLMs). Furthermore, we propose a simple yet effective method that utilizes ManiTaskGen tasks to enhance embodied decision-making. Overall, this work presents a universal task generation framework for arbitrary scenes, facilitating both benchmarking and improvement of embodied decision-making agents.
>
---
#### [replaced 020] SurgiSR4K: A High-Resolution Endoscopic Video Dataset for Robotic-Assisted Minimally Invasive Procedures
- **分类: eess.IV; cs.AI; cs.CV; cs.RO**

- **链接: [http://arxiv.org/pdf/2507.00209v3](http://arxiv.org/pdf/2507.00209v3)**

> **作者:** Fengyi Jiang; Xiaorui Zhang; Lingbo Jin; Ruixing Liang; Yuxin Chen; Adi Chola Venkatesh; Jason Culman; Tiantian Wu; Lirong Shao; Wenqing Sun; Cong Gao; Hallie McNamara; Jingpei Lu; Omid Mohareri
>
> **摘要:** High-resolution imaging is crucial for enhancing visual clarity and enabling precise computer-assisted guidance in minimally invasive surgery (MIS). Despite the increasing adoption of 4K endoscopic systems, there remains a significant gap in publicly available native 4K datasets tailored specifically for robotic-assisted MIS. We introduce SurgiSR4K, the first publicly accessible surgical imaging and video dataset captured at a native 4K resolution, representing realistic conditions of robotic-assisted procedures. SurgiSR4K comprises diverse visual scenarios including specular reflections, tool occlusions, bleeding, and soft tissue deformations, meticulously designed to reflect common challenges faced during laparoscopic and robotic surgeries. This dataset opens up possibilities for a broad range of computer vision tasks that might benefit from high resolution data, such as super resolution (SR), smoke removal, surgical instrument detection, 3D tissue reconstruction, monocular depth estimation, instance segmentation, novel view synthesis, and vision-language model (VLM) development. SurgiSR4K provides a robust foundation for advancing research in high-resolution surgical imaging and fosters the development of intelligent imaging technologies aimed at enhancing performance, safety, and usability in image-guided robotic surgeries.
>
---
#### [replaced 021] GS-SDF: LiDAR-Augmented Gaussian Splatting and Neural SDF for Geometrically Consistent Rendering and Reconstruction
- **分类: cs.RO; cs.CV**

- **链接: [http://arxiv.org/pdf/2503.10170v2](http://arxiv.org/pdf/2503.10170v2)**

> **作者:** Jianheng Liu; Yunfei Wan; Bowen Wang; Chunran Zheng; Jiarong Lin; Fu Zhang
>
> **备注:** 8 pages, IROS 2025
>
> **摘要:** Digital twins are fundamental to the development of autonomous driving and embodied artificial intelligence. However, achieving high-granularity surface reconstruction and high-fidelity rendering remains a challenge. Gaussian splatting offers efficient photorealistic rendering but struggles with geometric inconsistencies due to fragmented primitives and sparse observational data in robotics applications. Existing regularization methods, which rely on render-derived constraints, often fail in complex environments. Moreover, effectively integrating sparse LiDAR data with Gaussian splatting remains challenging. We propose a unified LiDAR-visual system that synergizes Gaussian splatting with a neural signed distance field. The accurate LiDAR point clouds enable a trained neural signed distance field to offer a manifold geometry field. This motivates us to offer an SDF-based Gaussian initialization for physically grounded primitive placement and a comprehensive geometric regularization for geometrically consistent rendering and reconstruction. Experiments demonstrate superior reconstruction accuracy and rendering quality across diverse trajectories. To benefit the community, the codes are released at https://github.com/hku-mars/GS-SDF.
>
---
#### [replaced 022] Automated Brake Onset Detection in Naturalistic Driving Data
- **分类: cs.HC; cs.RO**

- **链接: [http://arxiv.org/pdf/2507.17943v2](http://arxiv.org/pdf/2507.17943v2)**

> **作者:** Shu-Yuan Liu; Johan Engström; Gustav Markkula
>
> **摘要:** Response timing measures play a crucial role in the assessment of automated driving systems (ADS) in collision avoidance scenarios, including but not limited to establishing human benchmarks and comparing ADS to human driver response performance. For example, measuring the response time (of a human driver or ADS) to a conflict requires the determination of a stimulus onset and a response onset. In existing studies, response onset relies on manual annotation or vehicle control signals such as accelerator and brake pedal movements. These methods are not applicable when analyzing large scale data where vehicle control signals are not available. This holds in particular for the rapidly expanding sets of ADS log data where the behavior of surrounding road users is observed via onboard sensors. To advance evaluation techniques for ADS and enable measuring response timing when vehicle control signals are not available, we developed a simple and efficient algorithm, based on a piecewise linear acceleration model, to automatically estimate brake onset that can be applied to any type of driving data that includes vehicle longitudinal time series data. We also proposed a manual annotation method to identify brake onset and used it as ground truth for validation. R^2 was used as a confidence metric to measure the accuracy of the algorithm, and its classification performance was analyzed using naturalistic collision avoidance data of both ADS and humans, where our method was validated against human manual annotation. Although our algorithm is subject to certain limitations, it is efficient, generalizable, applicable to any road user and scenario types, and is highly configurable.
>
---
